{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory with corpus, one sentence per line\n",
    "data_ac=\"indeed_jobs_extractions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src directory\n",
    "kb_base_dir=\"/mnt/efs/shared/meg_shared_scripts/meg-kb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n"
     ]
    }
   ],
   "source": [
    "%cd $kb_base_dir/src/keyword_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./corpusProcess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n",
      "\u001b[32m===Corpus Name: indeed_jobs_extractions===\u001b[m\n",
      "\u001b[32m===Current Path: /mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction===\u001b[m\n",
      "\u001b[32m===Cleaning input corpus===\u001b[m\n",
      "\u001b[32m===Running AutoPhrase===\u001b[m\n",
      "make: Nothing to be done for 'all'.\n",
      "\u001b[32m===RAW_TRAIN: ../../../data/indeed_jobs_extractions/source/corpus.clean.txt===\u001b[m\n",
      "auto_phrase.sh parameters: indeed_jobs_extractions ../../../data/indeed_jobs_extractions/source/corpus.clean.txt 10 data/EN/wiki_quality.txt 8\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m1.886s\n",
      "user\t0m12.548s\n",
      "sys\t0m0.736s\n",
      "Detected Language: EN\u001b[0K\n",
      "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
      "No provided expert labels.\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===AutoPhrasing===\u001b[m\n",
      "=== Current Settings ===\n",
      "Iterations = 2\n",
      "Minimum Support Threshold = 10\n",
      "Maximum Length Threshold = 6\n",
      "POS-Tagging Mode Disabled\n",
      "Discard Ratio = 0.050000\n",
      "Number of threads = 8\n",
      "Labeling Method = DPDN\n",
      "\tAuto labels from knowledge bases\n",
      "\tMax Positive Samples = -1\n",
      "=======\n",
      "Loading data...\n",
      "# of total tokens = 1288447\n",
      "max word token id = 21674\n",
      "# of documents = 79271\n",
      "# of distinct POS tags = 0\n",
      "Mining frequent phrases...\n",
      "selected MAGIC = 21683\n",
      "# of frequent phrases = 49580\n",
      "Extracting features...\n",
      "Constructing label pools...\n",
      "\tThe size of the positive pool = 3966\n",
      "\tThe size of the negative pool = 45252\n",
      "# truth patterns = 53171\n",
      "Estimating Phrase Quality...\n",
      "Segmenting...\n",
      "Rectifying features...\n",
      "Estimating Phrase Quality...\n",
      "Segmenting...\n",
      "Dumping results...\n",
      "Done.\n",
      "\n",
      "real\t0m6.933s\n",
      "user\t0m33.756s\n",
      "sys\t0m0.524s\n",
      "\u001b[32m===Saving Model and Results===\u001b[m\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "phrasal_segmentation.sh parameters: indeed_jobs_extractions ../../../data/indeed_jobs_extractions/source/corpus.clean.txt 0.5 0.9 8\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m1.428s\n",
      "user\t0m8.708s\n",
      "sys\t0m0.528s\n",
      "Detected Language: EN\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===Phrasal Segmentation===\u001b[m\n",
      "=== Current Settings ===\n",
      "Segmentation Model Path = models/indeed_jobs_extractions/segmentation.model\n",
      "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
      "\tQ(multi-word phrases) >= 0.500000\n",
      "\tQ(single-word phrases) >= 0.900000\n",
      "=======\n",
      "Length penalty model loaded.\n",
      "\tpenalty = 199.805\n",
      "# of loaded patterns = 10361\n",
      "# of loaded truth patterns = 57137\n",
      "Phrasal segmentation finished.\n",
      "   # of total highlighted quality phrases = 183086\n",
      "   # of total processed sentences = 177816\n",
      "   avg highlights per sentence = 1.02964\n",
      "\n",
      "real\t0m1.962s\n",
      "user\t0m1.844s\n",
      "sys\t0m0.024s\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "\u001b[32m===Generating Phrase Text===\u001b[m\n",
      "process_segmentation.py parameters: ../../../data/indeed_jobs_extractions/intermediate/ 0.5 0.9\n",
      "12.758953463435557\n",
      "\u001b[32m===Running NLP Feature Extraction===\u001b[m\n",
      "100%|███████████████████████████████████████| 9813/9813 [02:00<00:00, 81.30it/s]\n",
      " 98%|█████████████████████████████████████ | 9764/10012 [02:00<00:03, 77.64it/s]Finish NLP processing, using time 120.79859757423401 (second)\n",
      "100%|███████████████████████████████████████| 9738/9738 [02:00<00:00, 80.54it/s]\n",
      " 99%|██████████████████████████████████████▊| 9930/9992 [02:00<00:00, 91.36it/s]Finish NLP processing, using time 121.01860761642456 (second)\n",
      "100%|███████████████████████████████████████| 9992/9992 [02:01<00:00, 82.19it/s]\n",
      " 98%|█████████████████████████████████████▎| 9840/10012 [02:01<00:02, 84.43it/s]Finish NLP processing, using time 121.67983531951904 (second)\n",
      "100%|█████████████████████████████████████| 10145/10145 [02:02<00:00, 82.65it/s]\n",
      " 99%|██████████████████████████████████████▋| 9607/9677 [02:02<00:00, 89.57it/s]Finish NLP processing, using time 122.85596346855164 (second)\n",
      "100%|█████████████████████████████████████| 10012/10012 [02:03<00:00, 81.10it/s]\n",
      "100%|███████████████████████████████████████| 9677/9677 [02:03<00:00, 78.34it/s]\n",
      "Finish NLP processing, using time 123.57626819610596 (second)\n",
      "Finish NLP processing, using time 123.64467597007751 (second)\n",
      "100%|███████████████████████████████████████| 9907/9907 [02:07<00:00, 77.66it/s]\n",
      " 98%|██████████████████████████████████████▏| 9780/9987 [02:07<00:02, 87.26it/s]Finish NLP processing, using time 127.68232464790344 (second)\n",
      "100%|███████████████████████████████████████| 9987/9987 [02:09<00:00, 76.97it/s]\n",
      "Finish NLP processing, using time 129.87190532684326 (second)\n",
      "\u001b[32m===Clean unnecessary files===\u001b[m\n",
      "\u001b[32m===Key Term Extraction===\u001b[m\n",
      "Extract Key Terms from Corpus: 100%|███| 89988/89988 [00:05<00:00, 17378.89it/s]\n",
      "\u001b[32m===Sentence-wise Entity Segmentation===\u001b[m\n",
      "loading corpus for word2vec training: 100%|█| 89988/89988 [00:00<00:00, 135012.8\n",
      "100%|█████████████████████████████████| 40047/40047 [00:00<00:00, 791829.90it/s]\n",
      "100%|███████████████████████████████████| 6540/6540 [00:00<00:00, 422173.88it/s]\n",
      "100%|███████████████████████████████████| 6538/6538 [00:00<00:00, 279252.94it/s]\n"
     ]
    }
   ],
   "source": [
    "thread = 8\n",
    "!./corpusProcess.sh $data_ac $thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $kb_base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|█████████████████| 89988/89988 [00:00<00:00, 104455.54it/s]\n",
      "computing entity-wise embedding: 100%|██████| 6853/6853 [04:49<00:00, 23.69it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=3 python compute_keyphrase_embeddings.py -m bert-base-uncased -et ac -d ../../data/$data_ac/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = [\n",
    "    {\n",
    "        \"alignedCategoryName\": \"programming_language\",\n",
    "        \"unalignedCategoryName\": \"programming language\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"python\", \"sql\", \"java\", \"html\", \"perl\", \"javascript\", \"php\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"technology\",\n",
    "        \"unalignedCategoryName\": \"technology\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"distributed systems\", \"load balancing\", \"network monitoring\", \"data structures\", \"virtualization technologies\", \"search engine optimization\", \"network communications\", \"version control\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"database_type\",\n",
    "        \"unalignedCategoryName\": \"database type\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"nosql databases\", \"oracle\", \"microsoft sql server\", \"mongo db\", \"mysql databases\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"software_development_type\",\n",
    "        \"unalignedCategoryName\": \"software development type\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"fullstack\", \"server side\", \"game development\", \"enterprise architecture\", \"mobile application development\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"system_type\",\n",
    "        \"unalignedCategoryName\": \"system type\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"linux\", \"android\", \"unix\", \"windows\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"job_position\",\n",
    "        \"unalignedCategoryName\": \"job position\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"architect\", \"software engineer\", \"senior software engineer\", \"junior level\", \"entry level\"]\n",
    "    },\n",
    "        {\n",
    "        \"alignedCategoryName\": \"development_tool\",\n",
    "        \"unalignedCategoryName\": \"development tool\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"github\", \"maven\", \"eclipse\", \"jenkins\", \"cuda\", \"visual studio\", \"svn\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "seed_df = pd.DataFrame(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save taxonomy to csv\n",
    "import os\n",
    "benchmark_dir = \"../../data/indeed_jobs_extractions\"\n",
    "benchmark_filename = 'seed_aligned_concepts.csv'\n",
    "seed_df.to_csv(os.path.join(benchmark_dir, benchmark_filename), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n",
      "/home/ubuntu/anaconda3/envs/transformers_nikita/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "Seed instances: ['python', 'sql', 'java', 'html', 'perl', 'javascript', 'php', 'distributed systems', 'load balancing', 'network monitoring', 'data structures', 'virtualization technologies', 'search engine optimization', 'network communications', 'version control', 'nosql databases', 'oracle', 'microsoft sql server', 'mongo db', 'mysql databases', 'fullstack', 'server side', 'game development', 'enterprise architecture', 'mobile application development', 'linux', 'android', 'unix', 'windows', 'architect', 'software engineer', 'senior software engineer', 'junior level', 'entry level', 'github', 'maven', 'eclipse', 'jenkins', 'cuda', 'visual studio', 'svn']\n",
      "New instances: ['virtualization technologies', 'fullstack', 'jenkins', 'svn']\n",
      "loading corpus: 100%|██████████████████| 89988/89988 [00:01<00:00, 45351.56it/s]\n",
      "computing entity-wise embedding: 100%|████████████| 4/4 [00:00<00:00,  4.50it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "# add embeddings for any seed instances that have not been already computed\n",
    "%cd /mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning/\n",
    "!CUDA_VISIBLE_DEVICES=3 python add_seed_instances_embeddings.py -m bert-base-uncased -et ac -d $benchmark_dir/intermediate -b $benchmark_dir -c 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, entropy, gmean\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "import logging\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from annoy import AnnoyIndex\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "\n",
    "nlp_full = spacy.load('en_core_web_sm')\n",
    "\n",
    "from compute_concept_clusters import knn\n",
    "from compute_keyphrase_embeddings import ensure_tensor_on_device, mean_pooling\n",
    "\n",
    "from lm_probes import LMProbe, LMProbe_GPT2, LMProbe_Joint, LMProbe_PMI, LMProbe_PMI_greedy\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import load_EE_labels\n",
    "from utils import get_masked_contexts, bert_untokenize\n",
    "from utils import learn_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import load_EE_labels\n",
    "from utils import get_masked_contexts, bert_untokenize\n",
    "from utils import learn_patterns\n",
    "\n",
    "import lm_probes\n",
    "importlib.reload(lm_probes)\n",
    "from lm_probes import LMProbe, LMProbe_GPT2, LMProbe_Joint, LMProbe_PMI, LMProbe_PMI_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6857"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_emb_path = os.path.join('../../data', data_ac, 'intermediate/BERTembed+seeds.txt')\n",
    "if not os.path.exists(bert_emb_path):\n",
    "    bert_emb_path = os.path.join('../../data', data_ac, 'intermediate/BERTembed.txt')\n",
    "embeddings = load_embeddings(bert_emb_path, 768)\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Seed Entities (clustering)\n",
    "### Seed instances clustering (EE-emb)\n",
    "(using all seed instances of a concept to find neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/transformers_nikita/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "building entity index: 100%|██████████████| 6857/6857 [00:01<00:00, 6493.44it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 22.24it/s]\n"
     ]
    }
   ],
   "source": [
    "cluster_size = None\n",
    "\n",
    "!python compute_concept_seeds_knn.py \\\n",
    "-d ../../data/$data_ac/intermediate \\\n",
    "-e ../../data/$data_ac/intermediate/BERTembed+seeds.txt \\\n",
    "-b $benchmark_dir \\\n",
    "-o ../../data/$data_ac/intermediate/ee_concept_knn_k=None.csv \\\n",
    "-kdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>ruby</td>\n",
       "      <td>0.994494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>scripting</td>\n",
       "      <td>0.993874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>jquery</td>\n",
       "      <td>0.992581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>mysql</td>\n",
       "      <td>0.992376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>powershell</td>\n",
       "      <td>0.992175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>xml</td>\n",
       "      <td>0.991677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>css</td>\n",
       "      <td>0.991653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>html5</td>\n",
       "      <td>0.991362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>visual studio</td>\n",
       "      <td>0.991189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>programming_language</td>\n",
       "      <td>ajax</td>\n",
       "      <td>0.990843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                concept       neighbor       sim\n",
       "0  programming_language           ruby  0.994494\n",
       "1  programming_language      scripting  0.993874\n",
       "2  programming_language         jquery  0.992581\n",
       "3  programming_language          mysql  0.992376\n",
       "4  programming_language     powershell  0.992175\n",
       "5  programming_language            xml  0.991677\n",
       "6  programming_language            css  0.991653\n",
       "7  programming_language          html5  0.991362\n",
       "8  programming_language  visual studio  0.991189\n",
       "9  programming_language           ajax  0.990843"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_knn_path = os.path.join('../../data', data_ac, 'intermediate/ee_concept_knn_k=None.csv')\n",
    "df = pd.read_csv(concept_knn_path)\n",
    "df[df['concept'] == 'programming_language'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EE-LM-probe (prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe(model_name='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/transformers_nikita/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "lm_probe_type='bert' is deprecated, use 'mlm'\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:23<00:00,  3.37s/it]\n"
     ]
    }
   ],
   "source": [
    "!python compute_EE_LM_probe.py \\\n",
    "-d ../../data/$data_ac/intermediate \\\n",
    "-b $benchmark_dir \\\n",
    "-e ../../data/$data_ac/intermediate/BERTembed+seeds.txt \\\n",
    "-lm bert \\\n",
    "-o ../../data/$data_ac/intermediate/ee_LM_bert_k=None.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48147"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_emb_path = os.path.join('../../data', data_ac, 'intermediate/ee_concept_knn_k=None.csv')\n",
    "ee_LM_path = os.path.join('../../data', data_ac, 'intermediate/ee_LM_bert_k=None.csv')\n",
    "ee_LM_df = pd.read_csv(ee_LM_path)\n",
    "ee_emb_df = pd.read_csv(ee_emb_path)\n",
    "concept_list = ee_LM_df['concept'].drop_duplicates().tolist()\n",
    "\n",
    "## Using MRR to combine ranking \n",
    "\n",
    "ee_mrr_combine_list = []\n",
    "\n",
    "for _cc in sorted(concept_list):\n",
    "    _ce_df = ee_emb_df[ee_emb_df['concept'] == _cc].sort_values(by='sim', ascending=False)\n",
    "    _ee_emb_list = _ce_df['neighbor'].tolist()\n",
    "    _ee_LM_list = ee_LM_df[ee_LM_df['concept'] == _cc]['neighbor'].tolist()\n",
    "        \n",
    "    _all_entities_mrr = defaultdict(float)\n",
    "    for i, _e in enumerate(_ee_emb_list):\n",
    "        _all_entities_mrr[_e] += 1.0 / (i+1)\n",
    "    for i, _e in enumerate(_ee_LM_list):\n",
    "        _all_entities_mrr[_e] += 1.0 / (i+1)\n",
    "\n",
    "    _all_entities_mrr_list = sorted(list(_all_entities_mrr.items()), key=lambda p: p[-1], reverse=True)\n",
    "    \n",
    "    for _e, _mrr in _all_entities_mrr_list:\n",
    "        ee_mrr_combine_list.append((_cc, _e, _mrr))\n",
    "\n",
    "len(ee_mrr_combine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_mrr_combine_path = os.path.join('../../data', data_ac, 'intermediate/ee_mrr_combine_bert_k=None.csv')\n",
    "df = pd.DataFrame(ee_mrr_combine_list, columns=['concept', 'neighbor', 'MRR'])\n",
    "df = df.merge(ee_LM_df, how='left', on=['concept', 'neighbor'])\n",
    "df = df.merge(ee_emb_df, how='left', on=['concept', 'neighbor'])\n",
    "df.to_csv(ee_mrr_combine_path, index=None)\n",
    "df = pd.read_csv(ee_mrr_combine_path)\n",
    "mrr = df.groupby('concept').head(200)\n",
    "mrr.to_csv(os.path.join('../../data', data_ac, 'intermediate/ee_mrr_combine_bert_k=200.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database_type\n",
      "['sql', 'oracle database', 'sql server', 'microsoft sql', 'oracle databases', 'mysql', 'java', 'microsoft', 'nosql', 'oracle cloud', 'sql databases', 'postgresql', 'relational databases', 'web services', 'microsoft excel', 'microsoft azure', 'expert level', 'mongodb', 'ms sql', 'server database']\n",
      "\n",
      "\n",
      "development_tool\n",
      "['windows', 'selenium', 'java', 'sql', 'adobe flash', 'adobe', 'confluence', 'php', 'mysql', 'visual design', 'subversion', 'microsoft windows', 'bitbucket', 'oracle', 'linux', 'chrome', 'cucumber', 'scripting', 'visual programming', 'python']\n",
      "\n",
      "\n",
      "job_position\n",
      "['senior level', 'manager', 'project manager', 'advanced level', 'engineer', 'executive level', 'technical project manager', 'senior project manager', 'professional', 'software developer', 'product manager', 'senior product manager', 'technical lead', 'service level', 'technical program manager', 'program manager', 'product owner', 'phd', 'programmer', 'expert level']\n",
      "\n",
      "\n",
      "programming_language\n",
      "['ruby', 'scripting', 'visual language', 'xml', 'visual basic', 'jquery', 'mysql', 'visual programming', 'powershell', 'pdf', 'html5', 'visual studio', 'css', 'php programming', 'java ee', 'ajax', 'web framework', 'standard language', 'microsoft sql', 'programming language']\n",
      "\n",
      "\n",
      "software_development_type\n",
      "['software development', 'web development', 'web applications', 'full stack', 'application development', 'software engineering', 'web application', 'major', 'custom software', 'mobile', 'large scale', 'mobile applications', 'product development', 'software', 'senior level', 'mobile application', 'cloud', 'engineering', 'web services', 'web server']\n",
      "\n",
      "\n",
      "system_type\n",
      "['ios', 'visual studio', 'microsoft windows', 'oracle', 'java', 'sql server', 'oracle / linux', 'mac os', 'windows server', 'sql', 'github', 'os', 'aix', 'z / os', 'selenium', 'web services', 'microsoft', 'ibm aix', 'web server', 'hardware / software']\n",
      "\n",
      "\n",
      "technology\n",
      "['database', 'network management', 'databases', 'database management', 'configuration management', 'middleware', 'web applications', 'software configuration management', 'network security', 'orchestration', 'data management', 'workflow', 'cloud control', 'database systems', 'security', 'splunk', 'automation', 'management', 'oracle database', 'web content management']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for concept, grp in mrr.groupby('concept'):\n",
    "    print(concept)\n",
    "    print(grp['neighbor'].tolist()[:20])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database_type\n",
      "['oracle database', 'microsoft sql', 'oracle databases', 'sql', 'oracle cloud', 'microsoft', 'sql databases', 'microsoft excel', 'microsoft azure', 'sql server', 'server / database', 'ibm corporation', 'google', 'amazon', 'microsoft outlook', 'google cloud', 'database server', 'ibm db2', 'oracle / linux', 'ibm']\n",
      "\n",
      "\n",
      "development_tool\n",
      "['windows', 'java', 'adobe flash', 'adobe', 'php', 'visual design', 'microsoft windows', 'chrome', 'visual programming', 'flash', 'visual language', 'python', 'visual basic', 'maya', 'microsoft excel', 'microsoft project', 'microsoft', 'pdf', 'apache', 'oracle']\n",
      "\n",
      "\n",
      "job_position\n",
      "['senior level', 'advanced level', 'executive level', 'senior project manager', 'professional', 'senior product manager', 'technical project manager', 'service level', 'phd', 'technical program manager', 'expert level', 'graduate degree', 'a level', 'master', 'high level', 'technical product manager', 'associate degree', 'advanced degree', 'higher level', 'professional degree']\n",
      "\n",
      "\n",
      "programming_language\n",
      "['ruby', 'visual language', 'visual basic', 'visual programming', 'xml', 'pdf', 'php programming', 'java ee', 'web framework', 'standard language', 'microsoft sql', 'microsoft windows', 'english language', 'programming language', 'webgl', 'rtl', 'microsoft excel', 'web / design', 'web applications', 'visual studio']\n",
      "\n",
      "\n",
      "software_development_type\n",
      "['web development', 'web applications', 'application development', 'web application', 'mobile', 'mobile applications', 'software development', 'mobile application', 'web services', 'web server', 'cloud', 'desktop applications', 'application software', 'web apps', 'mobile web', 'product development', 'web design', 'application architecture', 'rapid application development', 'web hosting']\n",
      "\n",
      "\n",
      "system_type\n",
      "['ios', 'microsoft windows', 'oracle / linux', 'mac os', 'windows server', 'java', 'aix', 'z / os', 'ibm aix', 'hardware / software', 'macintosh', 'ms windows', 'ios devices', 'windows based', 'web servers', 'linux kernel', 'linux distribution', 'pc', 'apple ios', 'mobile / web']\n",
      "\n",
      "\n",
      "technology\n",
      "['network management', 'database management', 'configuration management', 'software configuration management', 'network security', 'cloud control', 'data management', 'security', 'management', 'web content management', 'configuration control', 'source control management', 'databases', 'network analysis', 'systems management', 'database', 'database management systems', 'information management', 'application security', 'content management']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm_preds = []\n",
    "for concept, grp in ee_LM_df.groupby('concept'):\n",
    "        grp = grp.reset_index()\n",
    "        grp = grp.sort_values(by='lm_score', ascending=False).head(200)\n",
    "        lm_preds.append(grp)\n",
    "lm_preds = pd.concat(lm_preds)\n",
    "lm_preds.to_csv(os.path.join('../../data', data_ac, 'intermediate/ee_lm_bert_k=200.csv'), index=None)\n",
    "lm_preds\n",
    "\n",
    "for concept, grp in lm_preds.groupby('concept'):\n",
    "    print(concept)\n",
    "    print(grp['neighbor'].tolist()[:20])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database_type\n",
      "['sql', 'sql server', 'mysql', 'java', 'nosql', 'postgresql', 'relational databases', 'web services', 'expert level', 'mongodb', 'visual studio', 'power bi', 'db2', 'ms sql', 'api', 'microsoft', 'rest api', 'linux', 'selenium', 'pl / sql']\n",
      "\n",
      "\n",
      "development_tool\n",
      "['selenium', 'java', 'sql', 'confluence', 'mysql', 'subversion', 'bitbucket', 'cucumber', 'scripting', 'rest api', 'linux', 'oracle', 'sql server', 'web services', 'mvc', 'terraform', 'puppet', 'db2', 'spring boot', 'ide']\n",
      "\n",
      "\n",
      "job_position\n",
      "['manager', 'project manager', 'engineer', 'senior level', 'software developer', 'product manager', 'technical lead', 'technical project manager', 'product owner', 'program manager', 'programmer', 'automation engineer', 'member', 'database engineer', 'lead', 'major', 'product development', 'ecommerce', 'product management', 'area']\n",
      "\n",
      "\n",
      "programming_language\n",
      "['ruby', 'scripting', 'jquery', 'mysql', 'powershell', 'xml', 'css', 'html5', 'visual studio', 'ajax', 'mvc', 'groovy', 'eclipse', 'c++', 'angularjs', 'json', 'matlab', 'selenium', 'linux', 'pl / sql']\n",
      "\n",
      "\n",
      "software_development_type\n",
      "['software development', 'full stack', 'software engineering', 'major', 'custom software', 'large scale', 'software', 'senior level', 'engineering', 'product development', 'manager', 'application development', 'design', 'dashboard', 'saas', 'development methodologies', 'open source software', 'product owner', 'information security', 'technology']\n",
      "\n",
      "\n",
      "system_type\n",
      "['visual studio', 'oracle', 'sql server', 'java', 'sql', 'github', 'os', 'selenium', 'web services', 'scripting', 'microsoft', 'rest api', 'db2', 'mysql', 'api', 'web server', 'cli', 'operating systems', 'drupal', 'mainframe']\n",
      "\n",
      "\n",
      "technology\n",
      "['database', 'databases', 'middleware', 'web applications', 'orchestration', 'workflow', 'splunk', 'automation', 'database systems', 'oracle database', 'user interface', 'api', 'web based', 'relational database', 'back end', 'programming', 'messaging', 'data', 'cloud based', 'data analysis']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emb_preds = []\n",
    "for concept, grp in ee_emb_df.groupby('concept'):\n",
    "        grp = grp.reset_index()\n",
    "        grp = grp.sort_values(by='sim', ascending=False).head(200)\n",
    "        emb_preds.append(grp)\n",
    "emb_preds = pd.concat(emb_preds)\n",
    "emb_preds.to_csv(os.path.join('../../data', data_ac, 'intermediate/ee_emb_bert_k=200.csv'), index=None)\n",
    "emb_preds\n",
    "\n",
    "for concept, grp in emb_preds.groupby('concept'):\n",
    "    print(concept)\n",
    "    print(grp['neighbor'].tolist()[:20])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_transformers_nikita)",
   "language": "python",
   "name": "conda_transformers_nikita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
