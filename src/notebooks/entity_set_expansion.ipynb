{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/transformers_nikita/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory with corpus, one sentence per line\n",
    "data_ac=\"data/jobs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src directory\n",
    "kb_base_dir=\"/mnt/efs/shared/meg-kb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/mnt/efs/shared/meg-kb/src/keyword_extraction/'\n",
      "/mnt/efs/shared/meg_shared_scripts/knowledge-hub\n"
     ]
    }
   ],
   "source": [
    "%cd $kb_base_dir/src/keyword_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./corpusProcess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = 8\n",
    "!./corpusProcess.sh $data_ac $thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $kb_base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=3 python compute_keyphrase_embeddings.py -m bert-base-uncased -et ac -d $data_ac/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = [\n",
    "    {\n",
    "        \"alignedCategoryName\": \"programming_language\",\n",
    "        \"unalignedCategoryName\": \"programming language\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"python\", \"sql\", \"java\", \"html\", \"perl\", \"javascript\", \"php\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"technology\",\n",
    "        \"unalignedCategoryName\": \"technology\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"distributed systems\", \"load balancing\", \"network monitoring\", \"data structures\", \"virtualization technologies\", \"search engine optimization\", \"network communications\", \"version control\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"database_type\",\n",
    "        \"unalignedCategoryName\": \"database type\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"nosql databases\", \"oracle\", \"microsoft sql server\", \"mongo db\", \"mysql databases\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"software_development_type\",\n",
    "        \"unalignedCategoryName\": \"software development type\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"fullstack\", \"server side\", \"game development\", \"enterprise architecture\", \"mobile application development\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"system_type\",\n",
    "        \"unalignedCategoryName\": \"system type\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"linux\", \"android\", \"unix\", \"windows\"]\n",
    "    },\n",
    "    {\n",
    "        \"alignedCategoryName\": \"job_position\",\n",
    "        \"unalignedCategoryName\": \"job position\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"architect\", \"software engineer\", \"senior software engineer\", \"junior level\", \"entry level\"]\n",
    "    },\n",
    "        {\n",
    "        \"alignedCategoryName\": \"development_tool\",\n",
    "        \"unalignedCategoryName\": \"development tool\",\n",
    "        \"generalizations\": None,\n",
    "        \"seedInstances\": [\"github\", \"maven\", \"eclipse\", \"jenkins\", \"cuda\", \"visual studio\", \"svn\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "seed_df = pd.DataFrame(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save taxonomy to csv\n",
    "import os\n",
    "benchmark_dir = \"data/jobs\"\n",
    "benchmark_filename = 'seed_aligned_concepts.csv'\n",
    "seed_df.to_csv(os.path.join(benchmark_dir, benchmark_filename), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add embeddings for any seed instances that have not been already computed\n",
    "%cd /mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning/\n",
    "!CUDA_VISIBLE_DEVICES=3 python add_seed_instances_embeddings.py -m bert-base-uncased -et ac -d $data_ac/intermediate -b $benchmark_dir -c 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, entropy, gmean\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "import logging\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from annoy import AnnoyIndex\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "\n",
    "nlp_full = spacy.load('en_core_web_sm')\n",
    "\n",
    "from compute_concept_clusters import knn\n",
    "from compute_keyphrase_embeddings import ensure_tensor_on_device, mean_pooling\n",
    "\n",
    "from lm_probes import LMProbe, LMProbe_GPT2, LMProbe_Joint, LMProbe_PMI, LMProbe_PMI_greedy\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import load_EE_labels\n",
    "from utils import get_masked_contexts, bert_untokenize\n",
    "from utils import learn_patterns\n",
    "\n",
    "from roberta_ses.interface import Roberta_SES_Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import load_EE_labels\n",
    "from utils import get_masked_contexts, bert_untokenize\n",
    "from utils import learn_patterns\n",
    "\n",
    "import lm_probes\n",
    "importlib.reload(lm_probes)\n",
    "from lm_probes import LMProbe, LMProbe_GPT2, LMProbe_Joint, LMProbe_PMI, LMProbe_PMI_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_emb_path = os.path.join(data_ac, 'intermediate/BERTembed+seeds.txt')\n",
    "if not os.path.exists(bert_emb_path):\n",
    "    bert_emb_path = os.path.join(data_ac, 'intermediate/BERTembed.txt')\n",
    "embeddings = load_embeddings(bert_emb_path, 768)\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Seed Entities (clustering)\n",
    "### Seed instances clustering (EE-emb)\n",
    "(using all seed instances of a concept to find neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_size = None\n",
    "\n",
    "!python compute_concept_seeds_knn.py \\\n",
    "-d $data_ac/intermediate \\\n",
    "-e $data_ac/intermediate/BERTembed+seeds.txt \\\n",
    "-b $benchmark_dir \\\n",
    "-o $data_ac/intermediate/ee_concept_knn_k=None.csv \\\n",
    "-kdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_knn_path = os.path.join(data_ac, 'intermediate/ee_concept_knn_k=None.csv')\n",
    "df = pd.read_csv(concept_knn_path)\n",
    "df[df['concept'] == 'programming_language'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EE-LM-probe (prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probe = LMProbe(model_name='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python compute_EE_LM_probe.py \\\n",
    "-d $data_ac/intermediate \\\n",
    "-b $benchmark_dir \\\n",
    "-e $data_ac/intermediate/BERTembed+seeds.txt \\\n",
    "-lm bert \\\n",
    "-o $data_ac/intermediate/ee_LM_bert_k=None.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_emb_path = os.path.join(data_ac, 'intermediate/ee_concept_knn_k=None.csv')\n",
    "ee_LM_path = os.path.join(data_ac, 'intermediate/ee_LM_bert_k=None.csv')\n",
    "ee_LM_df = pd.read_csv(ee_LM_path)\n",
    "ee_emb_df = pd.read_csv(ee_emb_path)\n",
    "concept_list = ee_LM_df['concept'].drop_duplicates().tolist()\n",
    "\n",
    "## Using MRR to combine ranking \n",
    "\n",
    "ee_mrr_combine_list = []\n",
    "\n",
    "for _cc in sorted(concept_list):\n",
    "    _ce_df = ee_emb_df[ee_emb_df['concept'] == _cc].sort_values(by='sim', ascending=False)\n",
    "    _ee_emb_list = _ce_df['neighbor'].tolist()\n",
    "    _ee_LM_list = ee_LM_df[ee_LM_df['concept'] == _cc]['neighbor'].tolist()\n",
    "        \n",
    "    _all_entities_mrr = defaultdict(float)\n",
    "    for i, _e in enumerate(_ee_emb_list):\n",
    "        _all_entities_mrr[_e] += 1.0 / (i+1)\n",
    "    for i, _e in enumerate(_ee_LM_list):\n",
    "        _all_entities_mrr[_e] += 1.0 / (i+1)\n",
    "\n",
    "    _all_entities_mrr_list = sorted(list(_all_entities_mrr.items()), key=lambda p: p[-1], reverse=True)\n",
    "    \n",
    "    for _e, _mrr in _all_entities_mrr_list:\n",
    "        ee_mrr_combine_list.append((_cc, _e, _mrr))\n",
    "\n",
    "len(ee_mrr_combine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_mrr_combine_path = os.path.join(data_ac, 'intermediate/ee_mrr_combine_bert_k=None.csv')\n",
    "df = pd.DataFrame(ee_mrr_combine_list, columns=['concept', 'neighbor', 'MRR'])\n",
    "df = df.merge(ee_LM_df, how='left', on=['concept', 'neighbor'])\n",
    "df = df.merge(ee_emb_df, how='left', on=['concept', 'neighbor'])\n",
    "df.to_csv(ee_mrr_combine_path, index=None)\n",
    "df = pd.read_csv(ee_mrr_combine_path)\n",
    "mrr = df.groupby('concept').head(200)\n",
    "mrr.to_csv(os.path.join(data_ac, 'intermediate/ee_mrr_combine_bert_k=200.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept, grp in mrr.groupby('concept'):\n",
    "    print(concept)\n",
    "    print(grp['neighbor'].tolist()[:20])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_preds = []\n",
    "for concept, grp in ee_LM_df.groupby('concept'):\n",
    "        grp = grp.reset_index()\n",
    "        grp = grp.sort_values(by='lm_score', ascending=False).head(200)\n",
    "        lm_preds.append(grp)\n",
    "lm_preds = pd.concat(lm_preds)\n",
    "lm_preds.to_csv(os.path.join(data_ac, 'intermediate/ee_lm_bert_k=200.csv'), index=None)\n",
    "lm_preds\n",
    "\n",
    "for concept, grp in lm_preds.groupby('concept'):\n",
    "    print(concept)\n",
    "    print(grp['neighbor'].tolist()[:20])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_preds = []\n",
    "for concept, grp in ee_emb_df.groupby('concept'):\n",
    "        grp = grp.reset_index()\n",
    "        grp = grp.sort_values(by='sim', ascending=False).head(200)\n",
    "        emb_preds.append(grp)\n",
    "emb_preds = pd.concat(emb_preds)\n",
    "emb_preds.to_csv(os.path.join(data_ac, 'intermediate/ee_emb_bert_k=200.csv'), index=None)\n",
    "emb_preds\n",
    "\n",
    "for concept, grp in emb_preds.groupby('concept'):\n",
    "    print(concept)\n",
    "    print(grp['neighbor'].tolist()[:20])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_transformers_nikita)",
   "language": "python",
   "name": "conda_transformers_nikita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
