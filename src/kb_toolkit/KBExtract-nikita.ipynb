{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"/mnt/efs/shared/meg_shared_scripts/meg-kb\"\n",
    "data_ac=\"indeeda-meg-ac\"\n",
    "data_pt=\"indeeda-meg-pt\"\n",
    "yutong_base_dir=\"/home/ubuntu/users/yutong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, entropy, gmean\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "import logging\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from annoy import AnnoyIndex\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "\n",
    "\n",
    "from compute_concept_clusters import knn\n",
    "from compute_keyphrase_embeddings import ensure_tensor_on_device, mean_pooling\n",
    "\n",
    "from lm_probes import LMProbe, LMProbe_GPT2, LMProbe_Joint, LMProbe_PMI, LMProbe_PMI_greedy\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import get_masked_contexts, bert_untokenize\n",
    "from utils import learn_patterns\n",
    "\n",
    "from roberta_ses.interface import Roberta_SES_Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import get_masked_contexts, bert_untokenize\n",
    "from utils import learn_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# EE-LM-probe (prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@Nikita: Here are the code blocks for exploring LM prompts for EE.\n",
    "\n",
    "Some core code:\n",
    "lm_probe = LMProbe()        // LMProbe: BERT; LMProbe_GPT2: GPT2; etc.\n",
    "all_entitites = ...         // all the entities\n",
    "_template = \"Dress code like jeans, [MASK] and tattoos.\" // A string with [MASK] (LMProbe automatically takes care of all entity token lengths, so don't need to duplicate mask tokens)\n",
    "_res = lm_probe.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))  // Show results (rank, cand, score)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lm_probe = LMProbe('/home/ubuntu/users/nikita/models/bert_finetuned_lm/indeed_reviews_ques_ans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  alignedCategoryName unalignedCategoryName generalizations  \\\n",
      "0             company               company             NaN   \n",
      "1          dress_code            dress code             NaN   \n",
      "2        job_position          job position             NaN   \n",
      "3        pay_schedule            pay period             NaN   \n",
      "4            benefits              benefits    compensation   \n",
      "\n",
      "                                       seedInstances  \n",
      "0       [walmart, amazon, subway, microsoft, target]  \n",
      "1  [business casual, uniform, hair color, tattoos...  \n",
      "2  [delivery driver, store manager, cashier, pack...  \n",
      "3               [weekly, biweekly, friday, saturday]  \n",
      "4  [health insurance, flexible schedule, 401k, pa...  \n",
      "['multiple times', 'upper', 'management', 'wal mart', 'company', 'overnight stocker', 'walmart', 'prejudice', 'tuition assistance', 'mgr', 'department', 'manager', 'knowledge', 'leadership', 'job security', 'current position', 'positive attitude', 'business', '* *', 'talk']\n",
      "['walmart', 'amazon', 'subway', 'microsoft', 'target', 'business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings', 'delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher', 'weekly', 'biweekly', 'friday', 'saturday', 'health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'base pay', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'direct deposit', 'prepaid card', 'drug test', 'criminal background check', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors', 'hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting', 'night shift', 'dinner shift', 'early morning shift', '8 hour shift', 'christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'workstation', 'training', 'team lunch']\n"
     ]
    }
   ],
   "source": [
    "seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "print(seed_concepts_df.head())\n",
    "emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "with open(emb_num_path, 'r') as f:\n",
    "    all_entities = [l.rsplit(' ', 1)[0] for l in f]\n",
    "print(all_entities[:20])\n",
    "all_entities = list(set(all_entities))\n",
    "\n",
    "seed_instances_dict = dict(zip(\n",
    "        seed_concepts_df['alignedCategoryName'].tolist(),\n",
    "        seed_concepts_df['seedInstances'].tolist()\n",
    "    ))\n",
    "    \n",
    "seed_entities_lst = seed_concepts_df['seedInstances'].tolist()\n",
    "seed_entities = [item for sublist in seed_entities_lst for item in sublist]\n",
    "print(seed_entities)\n",
    "concepts = seed_concepts_df['alignedCategoryName'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_ee = pd.read_csv('../../../tmp/gold_ee.csv')\n",
    "gold_ee = gold_ee[~gold_ee['neighbor'].isin(seed_entities)]\n",
    "gold_ee = gold_ee.drop_duplicates(subset=['concept', 'neighbor'])\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "def pratk(df, score='lm_score'):\n",
    "    df = pd.merge(df, gold_ee, on=['concept', 'neighbor'])\n",
    "    df = df.fillna(1)\n",
    "    grped = df.groupby('concept')\n",
    "    scores = {}\n",
    "    for name, grp in grped:\n",
    "        grp = grp.reset_index()\n",
    "        grp = grp.sort_values(by=score, ascending=False)\n",
    "        ks = [1,2,5,10,25,50,75,100,200]\n",
    "        ks = [k for k in ks if k < len(grp)]\n",
    "        all_correct = len(grp[grp['Majority'] > 0])\n",
    "        patk = {}\n",
    "        ratk = {}\n",
    "        mink = {}\n",
    "        for k in ks:\n",
    "            sub = grp.head(k)\n",
    "            correct = sub[sub['Majority'] > 0]\n",
    "            precision = sub['Majority'].sum() / k\n",
    "            recall = sub['Majority'].sum() / all_correct\n",
    "            patk[k] = precision\n",
    "            ratk[k] = recall\n",
    "            mink[k] = correct.iloc[-1][score] if len(correct) > 0 else -1\n",
    "        scores[name] = {\"precision\": patk, \"recall\": ratk, \"min_score\": mink}\n",
    "    for cc, c_scores in scores.items():\n",
    "        print(cc)\n",
    "        print(pd.DataFrame(c_scores).to_string())\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg. Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_and_eval(lm_probe, concept, probe_prompts, concept_phrase=None, evaluate=True):\n",
    "    seeds = seed_instances_dict[concept]\n",
    "    if concept_phrase is None:\n",
    "        cc_phrase = ' '.join(concept.split('_'))\n",
    "    else:\n",
    "        cc_phrase = concept_phrase\n",
    "    cand_scores_per_template = []\n",
    "    cand_scores = []\n",
    "    for template in probe_prompts:\n",
    "        _input_txt = template.format(cc_phrase, ', '.join(seeds[:-1]), '[MASK]', seeds[-1])\n",
    "        _cand_scores = lm_probe.score_candidates(_input_txt, all_entities)\n",
    "        _cand_scores.sort(key=lambda d : d[\"cand\"])\n",
    "        cand_scores_per_template.append(_cand_scores)\n",
    "\n",
    "    for _cand_score_lst in zip(*cand_scores_per_template):\n",
    "                    # _cand_score_lst: List[Dict[\"cand\", \"score\"]], for the same \"cand\" and different template \n",
    "            _cand = _cand_score_lst[0][\"cand\"]\n",
    "            _score = sum([d[\"score\"] for d in _cand_score_lst]) / len(_cand_score_lst)\n",
    "                    # _score = np.log(_score)\n",
    "            cand_scores.append({\"cand\": _cand, \"score\": _score})\n",
    "\n",
    "    extraction_results = []\n",
    "    for d in cand_scores:\n",
    "        e = d[\"cand\"]\n",
    "        if e in seeds:\n",
    "            continue\n",
    "        lm_score = d[\"score\"]\n",
    "        extraction_results.append({'concept': concept,\n",
    "                                           'neighbor': e,\n",
    "                                           'lm_score': lm_score\n",
    "                                          })\n",
    "\n",
    "        extraction_results.sort(key=lambda d : d['lm_score'], reverse=True)\n",
    "        results_df = pd.DataFrame(extraction_results)\n",
    "    if evaluate:\n",
    "        pratk(results_df)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.008772   0.068087\n",
      "2     1.000000  0.017544   0.046398\n",
      "5     1.000000  0.043860   0.020752\n",
      "10    1.000000  0.087719   0.010284\n",
      "25    1.000000  0.219298   0.002511\n",
      "50    0.840000  0.368421   0.000986\n",
      "75    0.706667  0.464912   0.000690\n",
      "100   0.600000  0.526316   0.000380\n",
      "with relation prompts\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.008772   0.034074\n",
      "2     1.000000  0.017544   0.023606\n",
      "5     1.000000  0.043860   0.012628\n",
      "10    1.000000  0.087719   0.005199\n",
      "25    0.960000  0.210526   0.001541\n",
      "50    0.780000  0.342105   0.000706\n",
      "75    0.706667  0.464912   0.000488\n",
      "100   0.600000  0.526316   0.000320\n",
      "\n",
      "Domain-adapted BERT\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.008772   0.063044\n",
      "2         1.00  0.017544   0.034719\n",
      "5         1.00  0.043860   0.014492\n",
      "10        1.00  0.087719   0.009953\n",
      "25        1.00  0.219298   0.005252\n",
      "50        0.88  0.385965   0.001830\n",
      "75        0.76  0.500000   0.000813\n",
      "100       0.72  0.631579   0.000405\n",
      "with relation prompts\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.008772   0.034768\n",
      "2     1.000000  0.017544   0.019843\n",
      "5     1.000000  0.043860   0.010139\n",
      "10    0.900000  0.078947   0.007869\n",
      "25    0.920000  0.201754   0.003654\n",
      "50    0.860000  0.377193   0.001630\n",
      "75    0.773333  0.508772   0.000783\n",
      "100   0.720000  0.631579   0.000364\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>lm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>3.476803e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>1.984275e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>nike</td>\n",
       "      <td>1.751212e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>company</td>\n",
       "      <td>amazons</td>\n",
       "      <td>1.739639e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "      <td>mcdonald ' s</td>\n",
       "      <td>1.101652e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>company</td>\n",
       "      <td>gdansk</td>\n",
       "      <td>3.600702e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>company</td>\n",
       "      <td>screenplay</td>\n",
       "      <td>3.215033e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>company</td>\n",
       "      <td>mascara</td>\n",
       "      <td>2.928107e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>company</td>\n",
       "      <td>flute</td>\n",
       "      <td>2.463806e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>company</td>\n",
       "      <td>dhaka</td>\n",
       "      <td>2.281147e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8037 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      concept      neighbor      lm_score\n",
       "0     company     starbucks  3.476803e-02\n",
       "1     company     mcdonalds  1.984275e-02\n",
       "2     company          nike  1.751212e-02\n",
       "3     company       amazons  1.739639e-02\n",
       "4     company  mcdonald ' s  1.101652e-02\n",
       "...       ...           ...           ...\n",
       "8032  company        gdansk  3.600702e-08\n",
       "8033  company    screenplay  3.215033e-08\n",
       "8034  company       mascara  2.928107e-08\n",
       "8035  company         flute  2.463806e-08\n",
       "8036  company         dhaka  2.281147e-08\n",
       "\n",
       "[8037 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"{2} has many employees.\",\n",
    "        \"I worked at {2}\",\n",
    "        \"hired at {2}.\"\n",
    "    ]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval(lm_probe, 'company', probe_prompts)\n",
    "print('with relation prompts')\n",
    "probe_and_eval(lm_probe,'company', probe_prompts2)\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval(d_lm_probe,'company', probe_prompts)\n",
    "print('with relation prompts')\n",
    "probe_and_eval(d_lm_probe,'company', probe_prompts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.008772   0.063044\n",
      "2         1.00  0.017544   0.034719\n",
      "5         1.00  0.043860   0.014492\n",
      "10        1.00  0.087719   0.009953\n",
      "25        1.00  0.219298   0.005252\n",
      "50        0.88  0.385965   0.001830\n",
      "75        0.76  0.500000   0.000813\n",
      "100       0.72  0.631579   0.000405\n"
     ]
    }
   ],
   "source": [
    "_results_df = probe_and_eval(d_lm_probe, 'company', probe_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>lm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>0.063044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company</td>\n",
       "      <td>nike</td>\n",
       "      <td>0.034719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>amazons</td>\n",
       "      <td>0.025174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>company</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.018960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "      <td>etcs</td>\n",
       "      <td>0.018090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>company</td>\n",
       "      <td>macs</td>\n",
       "      <td>0.017288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>company</td>\n",
       "      <td>fasts</td>\n",
       "      <td>0.014690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>company</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>0.014492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>company</td>\n",
       "      <td>wal mart</td>\n",
       "      <td>0.012479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>company</td>\n",
       "      <td>wal mart</td>\n",
       "      <td>0.012479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   concept   neighbor  lm_score\n",
       "0  company  starbucks  0.063044\n",
       "1  company       nike  0.034719\n",
       "2  company    amazons  0.025174\n",
       "3  company      apple  0.018960\n",
       "4  company       etcs  0.018090\n",
       "5  company       macs  0.017288\n",
       "6  company      fasts  0.014690\n",
       "7  company  mcdonalds  0.014492\n",
       "8  company   wal mart  0.012479\n",
       "9  company   wal mart  0.012479"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' YS: \"fasts\" and \"etcs\" are not company, why P@10 = 1.00 ?? '''\n",
    "\n",
    "_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.012346   0.068725\n",
      "2     1.000000  0.024691   0.061470\n",
      "5     0.800000  0.049383   0.027790\n",
      "10    0.800000  0.098765   0.010895\n",
      "25    0.720000  0.222222   0.006133\n",
      "50    0.680000  0.419753   0.004163\n",
      "75    0.546667  0.506173   0.002976\n",
      "100   0.580000  0.716049   0.002050\n",
      "with relation prompts\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.012346   0.034897\n",
      "2         1.00  0.024691   0.030772\n",
      "5         0.80  0.049383   0.013992\n",
      "10        0.90  0.111111   0.006143\n",
      "25        0.76  0.234568   0.003983\n",
      "50        0.68  0.419753   0.002365\n",
      "75        0.60  0.555556   0.001736\n",
      "100       0.58  0.716049   0.001147\n",
      "\n",
      "Domain-adapted BERT\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     0.000000  0.000000  -1.000000\n",
      "2     0.000000  0.000000  -1.000000\n",
      "5     0.600000  0.037037   0.085545\n",
      "10    0.700000  0.086420   0.024580\n",
      "25    0.720000  0.222222   0.009247\n",
      "50    0.600000  0.370370   0.003561\n",
      "75    0.586667  0.543210   0.001411\n",
      "100   0.570000  0.703704   0.000601\n",
      "with relation prompts\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     0.000000  0.000000  -1.000000\n",
      "2     0.000000  0.000000  -1.000000\n",
      "5     0.600000  0.037037   0.045309\n",
      "10    0.800000  0.098765   0.013504\n",
      "25    0.720000  0.222222   0.004822\n",
      "50    0.620000  0.382716   0.001851\n",
      "75    0.586667  0.543210   0.001135\n",
      "100   0.560000  0.691358   0.000419\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"The company did not do {2}.\",\n",
    "        \"They check your {2}.\",\n",
    "        \"{2} is not a card.\"\n",
    "    ]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval(lm_probe, 'background_screening', probe_prompts)\n",
    "print('with relation prompts')\n",
    "probe_and_eval(lm_probe, 'background_screening', probe_prompts2)\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval(d_lm_probe,'background_screening', probe_prompts)\n",
    "print('with relation prompts')\n",
    "probe_and_eval(d_lm_probe,'background_screening', probe_prompts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "hire_prerequisite\n",
      "     precision  recall  min_score\n",
      "1     1.000000    0.01   0.052757\n",
      "2     1.000000    0.02   0.013271\n",
      "5     0.400000    0.02   0.013271\n",
      "10    0.500000    0.05   0.005917\n",
      "25    0.560000    0.14   0.004174\n",
      "50    0.660000    0.33   0.002382\n",
      "75    0.626667    0.47   0.001623\n",
      "100   0.610000    0.61   0.001089\n",
      "200   0.495000    0.99   0.000005\n",
      "with relation prompts\n",
      "hire_prerequisite\n",
      "     precision  recall  min_score\n",
      "1     1.000000    0.01   0.031668\n",
      "2     0.500000    0.01   0.031668\n",
      "5     0.600000    0.03   0.008726\n",
      "10    0.500000    0.05   0.004849\n",
      "25    0.600000    0.15   0.003153\n",
      "50    0.640000    0.32   0.001702\n",
      "75    0.653333    0.49   0.001265\n",
      "100   0.620000    0.62   0.000885\n",
      "200   0.495000    0.99   0.000004\n",
      "\n",
      "Domain-adapted BERT\n",
      "hire_prerequisite\n",
      "     precision  recall  min_score\n",
      "1     1.000000    0.01   0.019661\n",
      "2     1.000000    0.02   0.016057\n",
      "5     0.800000    0.04   0.005686\n",
      "10    0.800000    0.08   0.003724\n",
      "25    0.880000    0.22   0.002821\n",
      "50    0.780000    0.39   0.001621\n",
      "75    0.706667    0.53   0.001014\n",
      "100   0.670000    0.67   0.000550\n",
      "200   0.495000    0.99   0.000009\n",
      "with relation prompts\n",
      "hire_prerequisite\n",
      "     precision  recall  min_score\n",
      "1     0.000000    0.00  -1.000000\n",
      "2     0.500000    0.01   0.015059\n",
      "5     0.800000    0.04   0.005860\n",
      "10    0.800000    0.08   0.004059\n",
      "25    0.880000    0.22   0.002365\n",
      "50    0.820000    0.41   0.001300\n",
      "75    0.733333    0.55   0.000896\n",
      "100   0.660000    0.66   0.000523\n",
      "200   0.495000    0.99   0.000008\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"The job requires {2}.\",\n",
    "        \"You need to have {2} to apply.\",\n",
    "    ]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval(lm_probe, 'hire_prerequisite', probe_prompts, 'requirements')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(lm_probe, 'hire_prerequisite', probe_prompts2, 'requirements')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval(d_lm_probe,'hire_prerequisite', probe_prompts, 'requirements')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(d_lm_probe,'hire_prerequisite', probe_prompts2, 'requirements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.029412   0.027419\n",
      "2     1.000000  0.058824   0.015791\n",
      "5     0.800000  0.117647   0.005052\n",
      "10    0.900000  0.264706   0.002278\n",
      "25    0.640000  0.470588   0.001025\n",
      "50    0.440000  0.647059   0.000608\n",
      "75    0.346667  0.764706   0.000365\n",
      "100   0.280000  0.823529   0.000266\n",
      "with relation prompts\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.029412   0.020585\n",
      "2     1.000000  0.058824   0.011879\n",
      "5     0.800000  0.117647   0.003799\n",
      "10    0.900000  0.264706   0.001718\n",
      "25    0.680000  0.500000   0.000803\n",
      "50    0.460000  0.676471   0.000445\n",
      "75    0.346667  0.764706   0.000278\n",
      "100   0.280000  0.823529   0.000204\n",
      "\n",
      "Domain-adapted BERT\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.029412   0.036885\n",
      "2         1.00  0.058824   0.019011\n",
      "5         1.00  0.147059   0.012808\n",
      "10        0.60  0.176471   0.011755\n",
      "25        0.68  0.500000   0.002846\n",
      "50        0.48  0.705882   0.001528\n",
      "75        0.36  0.794118   0.000558\n",
      "100       0.31  0.911765   0.000310\n",
      "with relation prompts\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.029412   0.027669\n",
      "2     1.000000  0.058824   0.014267\n",
      "5     1.000000  0.147059   0.009669\n",
      "10    0.600000  0.176471   0.008825\n",
      "25    0.680000  0.500000   0.002311\n",
      "50    0.480000  0.705882   0.001150\n",
      "75    0.346667  0.764706   0.000473\n",
      "100   0.310000  0.911765   0.000242\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"they will hire people {2}.\",\n",
    "    ]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval(lm_probe, 'person', probe_prompts, 'person')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(lm_probe, 'person', probe_prompts2, 'person')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval(d_lm_probe,'person', probe_prompts, 'person')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(d_lm_probe,'person', probe_prompts2, 'person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "dress_code\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.003922   0.044785\n",
      "2         1.00  0.007843   0.030868\n",
      "5         1.00  0.019608   0.017537\n",
      "10        1.00  0.039216   0.008212\n",
      "25        0.96  0.094118   0.002613\n",
      "50        0.92  0.180392   0.001255\n",
      "75        0.84  0.247059   0.000754\n",
      "100       0.86  0.337255   0.000488\n",
      "200       0.89  0.698039   0.000045\n",
      "with relation prompts\n",
      "dress_code\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.003922   0.026927\n",
      "2     1.000000  0.007843   0.018830\n",
      "5     1.000000  0.019608   0.010764\n",
      "10    1.000000  0.039216   0.006065\n",
      "25    0.960000  0.094118   0.002116\n",
      "50    0.980000  0.192157   0.001280\n",
      "75    0.933333  0.274510   0.000853\n",
      "100   0.880000  0.345098   0.000605\n",
      "200   0.885000  0.694118   0.000108\n",
      "\n",
      "Domain-adapted BERT\n",
      "dress_code\n",
      "     precision    recall  min_score\n",
      "1         0.00  0.000000  -1.000000\n",
      "2         0.50  0.003922   0.056419\n",
      "5         0.80  0.015686   0.033686\n",
      "10        0.90  0.035294   0.015546\n",
      "25        0.88  0.086275   0.004478\n",
      "50        0.90  0.176471   0.002061\n",
      "75        0.88  0.258824   0.001101\n",
      "100       0.89  0.349020   0.000692\n",
      "200       0.92  0.721569   0.000089\n",
      "with relation prompts\n",
      "dress_code\n",
      "     precision    recall  min_score\n",
      "1         0.00  0.000000  -1.000000\n",
      "2         0.50  0.003922   0.035079\n",
      "5         0.80  0.015686   0.030221\n",
      "10        0.90  0.035294   0.012049\n",
      "25        0.96  0.094118   0.005414\n",
      "50        0.94  0.184314   0.002650\n",
      "75        0.92  0.270588   0.001732\n",
      "100       0.91  0.356863   0.001192\n",
      "200       0.91  0.713725   0.000161\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"they allow you to wear {2}.\",\n",
    "        \"{2} are allowed.\"\n",
    "    ]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval(lm_probe, 'dress_code', probe_prompts, 'dress_code')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(lm_probe, 'dress_code', probe_prompts2, 'dress_code')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval(d_lm_probe,'dress_code', probe_prompts, 'dress_code')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(d_lm_probe,'dress_code', probe_prompts2, 'dress_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hard , unless you 're favorited .\",\n",
       " 'I asked <phrase>multiple times</phrase> to be trained on other things through out the store and refused .',\n",
       " 'nearly impossible , unless you have an in with <phrase>upper</phrase> level <phrase>management</phrase> your better off finding a better job anywhere else',\n",
       " 'Very easy to get promoted as long as you work hard show your motivated and are reliable .',\n",
       " 'It can be really easy to get promoted !',\n",
       " 'The <phrase>management</phrase> team , promotes associates to <phrase>management</phrase> and above within the store , before they look for someone outside <phrase>wal mart</phrase>',\n",
       " 'It is difficult to be promoted .',\n",
       " 'A lot of factors go into a store employee promotion .',\n",
       " \"It 's pretty easy to get the job done as long as you are on time , respectful , kind , trustworthy and get the job done when it 's suppose to .\",\n",
       " \"you 'll be promoted .\",\n",
       " 'Easy if you are willing to work around more hours and little pay raise .',\n",
       " 'not hard at all',\n",
       " 'Very hard .',\n",
       " 'My friend has been working for this <phrase>company</phrase> for 16years as an <phrase>overnight stocker</phrase> and keep asking about promotion but <phrase>walmart</phrase> has its favorites',\n",
       " 'and I think is a very <phrase>prejudice</phrase> <phrase>company</phrase> <phrase>company</phrase> when it comes to promotion .',\n",
       " 'Its somewhat difficult which is the down side of working at <phrase>walmart</phrase> .',\n",
       " 'Need the right connections to get promoted at <phrase>walmart</phrase> or not at all .',\n",
       " 'There is also , <phrase>tuition assistance</phrase> program for promotion within the <phrase>company</phrase> .',\n",
       " 'Very hard i ve tried for 6 yrs to move up to asst <phrase>mgr</phrase> and gotten 1 interview to the point i give up',\n",
       " 'i ve been told they do nt want to lose me in the store i m to valuable in what i know or do']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sent_segmentation.txt')\n",
    "with open(corpus_path, 'r') as f:\n",
    "    corpus = f.readlines()\n",
    "    corpus = [l.strip() for l in corpus]\n",
    "print(len(corpus))\n",
    "corpus[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to work at <tgt> .', 63), ('<tgt> does not drug', 56), ('to work at <tgt>', 50), ('to work for <tgt>', 22), ('No <tgt> does not drug', 19), ('while working at <tgt> .', 17), ('<tgt> is a good', 15), ('<tgt> is a great', 15), ('No , <tgt> does not drug', 15), ('<tgt> does not hire', 14), ('to work for <tgt> .', 13), ('<tgt> is a <phrase>great', 13), ('<tgt> does not do', 12), ('No <tgt> does not hire', 11), ('<tgt> will work with', 10), ('<tgt> is always hiring', 10), ('The <tgt> I worked at', 10), ('<tgt> pays bi weekly', 10), ('from home for <tgt>', 10), ('<tgt> is a <phrase>drug', 10)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "def get_context(entities, corpus):\n",
    "    \n",
    "    matched_context = []\n",
    "    contexts = []\n",
    "    for entity in entities: \n",
    "        token = '<phrase>{}</phrase>'.format(entity)\n",
    "        for sent in corpus:\n",
    "            if token in sent:\n",
    "                matched_context.append(sent)\n",
    "        for sent in matched_context:\n",
    "            splits = sent.split(token)\n",
    "            if len(splits) < 2:\n",
    "                continue\n",
    "            left_context_words = splits[0].split(' ')\n",
    "            left_context_words = left_context_words[-min(len(left_context_words), 4):]\n",
    "\n",
    "            right_context_words = splits[1].split(' ')\n",
    "            right_context_words = right_context_words[:min(len(right_context_words), 4)]\n",
    "            context = ' '.join(left_context_words) + '<tgt>' + ' '.join(right_context_words)\n",
    "            context_words = context.split(' ')\n",
    "            if len(context_words) < 4:\n",
    "                continue\n",
    "            contexts.append(context)\n",
    "    print(collections.Counter(contexts).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to work at <tgt> .', 63), ('<tgt> does not drug', 56), ('to work at <tgt>', 50), ('to work for <tgt>', 22), ('No <tgt> does not drug', 19), ('while working at <tgt> .', 17), ('<tgt> is a good', 15), ('<tgt> is a great', 15), ('No , <tgt> does not drug', 15), ('<tgt> does not hire', 14), ('to work for <tgt> .', 13), ('<tgt> is a <phrase>great', 13), ('<tgt> does not do', 12), ('No <tgt> does not hire', 11), ('<tgt> will work with', 10), ('<tgt> is always hiring', 10), ('The <tgt> I worked at', 10), ('<tgt> pays bi weekly', 10), ('from home for <tgt>', 10), ('<tgt> is a <phrase>drug', 10)]\n"
     ]
    }
   ],
   "source": [
    "get_context(['walmart', 'amazon', 'subway', 'microsoft', 'target'], corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.008772   0.068087\n",
      "2     1.000000  0.017544   0.046398\n",
      "5     1.000000  0.043860   0.020752\n",
      "10    1.000000  0.087719   0.010284\n",
      "25    1.000000  0.219298   0.002511\n",
      "50    0.840000  0.368421   0.000986\n",
      "75    0.706667  0.464912   0.000690\n",
      "100   0.600000  0.526316   0.000380\n",
      "with relation prompts\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.008772   0.034133\n",
      "2     1.000000  0.017544   0.023354\n",
      "5     1.000000  0.043860   0.012258\n",
      "10    1.000000  0.087719   0.005157\n",
      "25    0.960000  0.210526   0.001551\n",
      "50    0.780000  0.342105   0.000703\n",
      "75    0.666667  0.438596   0.000495\n",
      "100   0.590000  0.517544   0.000362\n",
      "\n",
      "Domain-adapted BERT\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.008772   0.063044\n",
      "2         1.00  0.017544   0.034719\n",
      "5         1.00  0.043860   0.014492\n",
      "10        1.00  0.087719   0.009953\n",
      "25        1.00  0.219298   0.005252\n",
      "50        0.88  0.385965   0.001830\n",
      "75        0.76  0.500000   0.000813\n",
      "100       0.72  0.631579   0.000405\n",
      "with relation prompts\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.008772   0.036026\n",
      "2     0.500000  0.008772   0.036026\n",
      "5     0.800000  0.035088   0.018296\n",
      "10    0.900000  0.078947   0.009216\n",
      "25    0.960000  0.210526   0.004289\n",
      "50    0.840000  0.368421   0.002149\n",
      "75    0.773333  0.508772   0.001052\n",
      "100   0.740000  0.649123   0.000560\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"to work at {2}.\",\n",
    "        \"{2} does not drug.\",\n",
    "        \"while working at {2}.\"\n",
    "    ]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval(lm_probe, 'company', probe_prompts, 'company')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(lm_probe, 'company', probe_prompts2, 'company')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval(d_lm_probe,'company', probe_prompts, 'company')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(d_lm_probe,'company', probe_prompts2, 'company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to take a <tgt> .', 167), ('to take a <tgt>', 114), ('Yes they do <tgt>', 85), ('Yes they do <tgt> .', 44), ('to do a <tgt> .', 40), ('Yes they <tgt> .', 38), ('<phrase>background check</phrase> and <tgt> .', 34), ('There was no <tgt>', 32), ('they do nt <tgt>', 31), ('<phrase>background check</phrase> and <tgt>', 27), ('to do a <tgt>', 22), ('There is no <tgt>', 22), ('They do nt <tgt>', 22), ('to pass a <tgt> .', 21), ('They do <tgt> .', 20), ('never failed a <tgt> .', 20), ('There was no <tgt> .', 19), ('not have a <tgt> .', 19), (\"do n't do <tgt>\", 19), ('What kind of <tgt> do they do', 16)]\n"
     ]
    }
   ],
   "source": [
    "get_context(['drug test', 'criminal background check', 'employment verification', 'driving record', 'credit report', 'criminal record'], corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.012346   0.092631\n",
      "2     1.000000  0.024691   0.046511\n",
      "5     1.000000  0.061728   0.025006\n",
      "10    0.800000  0.098765   0.016128\n",
      "25    0.640000  0.197531   0.007512\n",
      "50    0.640000  0.395062   0.004474\n",
      "75    0.586667  0.543210   0.003032\n",
      "100   0.570000  0.703704   0.002000\n",
      "with relation prompts\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.012346   0.039700\n",
      "2     1.000000  0.024691   0.019934\n",
      "5     1.000000  0.061728   0.012520\n",
      "10    0.800000  0.098765   0.008386\n",
      "25    0.680000  0.209877   0.003598\n",
      "50    0.640000  0.395062   0.002311\n",
      "75    0.586667  0.543210   0.001503\n",
      "100   0.580000  0.716049   0.000915\n",
      "\n",
      "Domain-adapted BERT\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     0.000000  0.000000  -1.000000\n",
      "2     0.000000  0.000000  -1.000000\n",
      "5     0.600000  0.037037   0.081086\n",
      "10    0.700000  0.086420   0.021252\n",
      "25    0.760000  0.234568   0.008927\n",
      "50    0.620000  0.382716   0.002983\n",
      "75    0.573333  0.530864   0.001287\n",
      "100   0.570000  0.703704   0.000560\n",
      "with relation prompts\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     0.000000  0.000000  -1.000000\n",
      "2     0.000000  0.000000  -1.000000\n",
      "5     0.600000  0.037037   0.040997\n",
      "10    0.700000  0.086420   0.016545\n",
      "25    0.640000  0.197531   0.006770\n",
      "50    0.600000  0.370370   0.002153\n",
      "75    0.573333  0.530864   0.000804\n",
      "100   0.550000  0.679012   0.000349\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"to take a {2}.\",\n",
    "        \"Yes they do {2}.\",\n",
    "        \"to pass a {2}.\", \n",
    "        \"they run a {2} before hiring.\"\n",
    "    ]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval(lm_probe, 'background_screening', probe_prompts, 'background_screening')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(lm_probe, 'background_screening', probe_prompts2, 'background_screening')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval(d_lm_probe,'background_screening', probe_prompts, 'background_screening')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(d_lm_probe,'background_screening', probe_prompts2, 'background_screening')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('you have a <tgt> .', 8), ('I had a <tgt> ', 8), ('you have a <tgt>', 8), ('depends on the <tgt>', 8), ('not have a <tgt>', 6), ('I had a <tgt>', 6), ('on what the <tgt> was for .', 6), ('depends on the <tgt> .', 4), ('I have a <tgt> on my background', 4), ('people with a <tgt> on their record', 4), ('anyone with a <tgt> .', 4), ('someone with a <tgt> .', 4), ('you with a <tgt> ', 4), ('you have a <tgt> of <phrase>theft</phrase> but', 4), ('I have a <tgt> .', 4), ('you with a <tgt>', 4), ('person with a <tgt> ', 4), ('depending on the <tgt>', 4), ('I have a <tgt> for <phrase>assault</phrase> and', 4), ('hired with a <tgt> .', 4)]\n"
     ]
    }
   ],
   "source": [
    "get_context([\"felons\", \"criminals\", \"disabled\", \"drug addicts\", \"high schoolers\", \"misdemeanor\", \"students\", \"seniors\"], corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.029412   0.027419\n",
      "2     1.000000  0.058824   0.015791\n",
      "5     0.800000  0.117647   0.005052\n",
      "10    0.900000  0.264706   0.002278\n",
      "25    0.640000  0.470588   0.001025\n",
      "50    0.440000  0.647059   0.000608\n",
      "75    0.346667  0.764706   0.000365\n",
      "100   0.280000  0.823529   0.000266\n",
      "with relation prompts\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.029412   0.018603\n",
      "2     1.000000  0.058824   0.011497\n",
      "5     0.800000  0.117647   0.003313\n",
      "10    0.800000  0.235294   0.001663\n",
      "25    0.600000  0.441176   0.000873\n",
      "50    0.420000  0.617647   0.000513\n",
      "75    0.333333  0.735294   0.000266\n",
      "100   0.270000  0.794118   0.000237\n",
      "\n",
      "Domain-adapted BERT\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.029412   0.036885\n",
      "2         1.00  0.058824   0.019011\n",
      "5         1.00  0.147059   0.012808\n",
      "10        0.60  0.176471   0.011755\n",
      "25        0.68  0.500000   0.002846\n",
      "50        0.48  0.705882   0.001528\n",
      "75        0.36  0.794118   0.000558\n",
      "100       0.31  0.911765   0.000310\n",
      "with relation prompts\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.029412   0.026860\n",
      "2     1.000000  0.058824   0.014795\n",
      "5     0.800000  0.117647   0.009803\n",
      "10    0.700000  0.205882   0.006244\n",
      "25    0.640000  0.470588   0.002806\n",
      "50    0.480000  0.705882   0.001184\n",
      "75    0.346667  0.764706   0.000756\n",
      "100   0.310000  0.911765   0.000359\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"hire {0}, such as {1}, {2} and {3}.\",\n",
    "    \"people with a {2} on their record.\"\n",
    "    ]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval(lm_probe, 'person', probe_prompts, 'person')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(lm_probe, 'person', probe_prompts2, 'person')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval(d_lm_probe,'person', probe_prompts, 'person')\n",
    "print('with relation prompts')\n",
    "probe_and_eval(d_lm_probe,'person', probe_prompts2, 'person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different scoring schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_and_eval_grps(lm_probe, concept, probe_prompts, prompt_groups, concept_phrase=None):\n",
    "    seeds = seed_instances_dict[concept]\n",
    "    if concept_phrase is None:\n",
    "        cc_phrase = ' '.join(concept.split('_'))\n",
    "    else:\n",
    "        cc_phrase = concept_phrase\n",
    "    cand_scores_per_template = []\n",
    "    cand_scores = []\n",
    "    \n",
    "    for template in probe_prompts:\n",
    "        _input_txt = template.format(cc_phrase, ', '.join(seeds[:-1]), '[MASK]', seeds[-1])\n",
    "        _cand_scores = lm_probe.score_candidates(_input_txt, all_entities)\n",
    "        _cand_scores.sort(key=lambda d : d[\"cand\"])\n",
    "        cand_scores_per_template.append(_cand_scores)\n",
    "\n",
    "    for _cand_score_lst in zip(*cand_scores_per_template):\n",
    "                    # _cand_score_lst: List[Dict[\"cand\", \"score\"]], for the same \"cand\" and different template \n",
    "            _cand = _cand_score_lst[0][\"cand\"]\n",
    "            grp_scores = {}\n",
    "            for i, g in enumerate(prompt_groups):\n",
    "                _score_i = _cand_score_lst[i]['score']\n",
    "                grp_score_lst = grp_scores.get(g, [])\n",
    "                grp_score_lst.append(_score_i)\n",
    "                grp_scores[g] = grp_score_lst\n",
    "            _score = 1.0\n",
    "            for val in grp_scores.values():\n",
    "                _score = _score * (sum(val) / len(val))\n",
    "            cand_scores.append({\"cand\": _cand, \"score\": _score})\n",
    "\n",
    "    extraction_results = []\n",
    "    for d in cand_scores:\n",
    "        e = d[\"cand\"]\n",
    "        if e in seeds:\n",
    "            continue\n",
    "        lm_score = d[\"score\"]\n",
    "        extraction_results.append({'concept': concept,\n",
    "                                           'neighbor': e,\n",
    "                                           'lm_score': lm_score\n",
    "                                          })\n",
    "\n",
    "        extraction_results.sort(key=lambda d : d['lm_score'], reverse=True)\n",
    "    pratk(pd.DataFrame(extraction_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.008772   0.068087\n",
      "2     1.000000  0.017544   0.046398\n",
      "5     1.000000  0.043860   0.020752\n",
      "10    1.000000  0.087719   0.010284\n",
      "25    1.000000  0.219298   0.002511\n",
      "50    0.840000  0.368421   0.000986\n",
      "75    0.706667  0.464912   0.000690\n",
      "100   0.600000  0.526316   0.000380\n",
      "with relation prompts\n",
      "company\n",
      "     precision    recall     min_score\n",
      "1         1.00  0.008772  6.400130e-09\n",
      "2         1.00  0.017544  9.283904e-10\n",
      "5         0.80  0.035088  7.966789e-10\n",
      "10        0.60  0.052632  4.044021e-10\n",
      "25        0.56  0.122807  8.737789e-11\n",
      "50        0.58  0.254386  1.661150e-11\n",
      "75        0.60  0.394737  4.061542e-12\n",
      "100       0.63  0.552632  1.156959e-12\n",
      "\n",
      "Domain-adapted BERT\n",
      "company\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.008772   0.063044\n",
      "2         1.00  0.017544   0.034719\n",
      "5         1.00  0.043860   0.014492\n",
      "10        1.00  0.087719   0.009953\n",
      "25        1.00  0.219298   0.005252\n",
      "50        0.88  0.385965   0.001830\n",
      "75        0.76  0.500000   0.000813\n",
      "100       0.72  0.631579   0.000405\n",
      "with relation prompts\n",
      "company\n",
      "     precision    recall     min_score\n",
      "1     1.000000  0.008772  1.471092e-06\n",
      "2     1.000000  0.017544  1.294321e-06\n",
      "5     1.000000  0.043860  5.960820e-07\n",
      "10    0.900000  0.078947  1.307210e-07\n",
      "25    0.880000  0.192982  1.379870e-08\n",
      "50    0.780000  0.342105  2.448148e-09\n",
      "75    0.746667  0.491228  2.268859e-10\n",
      "100   0.740000  0.649123  2.776589e-11\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "prompt_grps = [1,1,1]\n",
    "\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"to work at {2}.\",\n",
    "        \"{2} does not drug.\",\n",
    "        \"while working at {2}.\"\n",
    "    ]\n",
    "prompt_grps2 = [1,1,1,2,3,2]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval_grps(lm_probe, 'company', probe_prompts, prompt_grps, 'company')\n",
    "print('with relation prompts')\n",
    "probe_and_eval_grps(lm_probe, 'company', probe_prompts2, prompt_grps2, 'company')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval_grps(d_lm_probe,'company', probe_prompts, prompt_grps, 'company')\n",
    "print('with relation prompts')\n",
    "probe_and_eval_grps(d_lm_probe,'company', probe_prompts2, prompt_grps2,'company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.012346   0.092631\n",
      "2     1.000000  0.024691   0.046511\n",
      "5     1.000000  0.061728   0.025006\n",
      "10    0.800000  0.098765   0.016128\n",
      "25    0.640000  0.197531   0.007512\n",
      "50    0.640000  0.395062   0.004474\n",
      "75    0.586667  0.543210   0.003032\n",
      "100   0.570000  0.703704   0.002000\n",
      "with relation prompts\n",
      "background_screening\n",
      "     precision    recall     min_score\n",
      "1     1.000000  0.012346  7.751327e-07\n",
      "2     1.000000  0.024691  3.283780e-08\n",
      "5     0.800000  0.049383  1.165075e-08\n",
      "10    0.600000  0.074074  3.171605e-09\n",
      "25    0.640000  0.197531  5.394475e-10\n",
      "50    0.580000  0.358025  6.611104e-11\n",
      "75    0.586667  0.543210  8.228445e-12\n",
      "100   0.520000  0.641975  1.107889e-12\n",
      "\n",
      "Domain-adapted BERT\n",
      "background_screening\n",
      "     precision    recall  min_score\n",
      "1     0.000000  0.000000  -1.000000\n",
      "2     0.000000  0.000000  -1.000000\n",
      "5     0.600000  0.037037   0.081086\n",
      "10    0.700000  0.086420   0.021252\n",
      "25    0.760000  0.234568   0.008927\n",
      "50    0.620000  0.382716   0.002983\n",
      "75    0.573333  0.530864   0.001287\n",
      "100   0.570000  0.703704   0.000560\n",
      "with relation prompts\n",
      "background_screening\n",
      "     precision    recall     min_score\n",
      "1     0.000000  0.000000 -1.000000e+00\n",
      "2     0.500000  0.012346  1.032208e-04\n",
      "5     0.600000  0.037037  1.016645e-05\n",
      "10    0.700000  0.086420  7.449310e-07\n",
      "25    0.680000  0.209877  3.539964e-08\n",
      "50    0.580000  0.358025  6.813685e-10\n",
      "75    0.493333  0.456790  2.233701e-11\n",
      "100   0.510000  0.629630  2.007632e-12\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "prompt_grps = [1,1,1]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"to take a {2}.\",\n",
    "        \"Yes they do {2}.\",\n",
    "        \"to pass a {2}.\", \n",
    "        \"they run a {2} before hiring.\"\n",
    "    ]\n",
    "prompt_grps2 = [1,1,1,2,3,2,3]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval_grps(lm_probe, 'background_screening', probe_prompts, prompt_grps, 'background_screening')\n",
    "print('with relation prompts')\n",
    "probe_and_eval_grps(lm_probe, 'background_screening', probe_prompts2, prompt_grps2, 'background_screening')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval_grps(d_lm_probe,'background_screening', probe_prompts, prompt_grps, 'background_screening')\n",
    "print('with relation prompts')\n",
    "probe_and_eval_grps(d_lm_probe,'background_screening', probe_prompts2, prompt_grps2, 'background_screening')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-base\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1     1.000000  0.029412   0.027419\n",
      "2     1.000000  0.058824   0.015791\n",
      "5     0.800000  0.117647   0.005052\n",
      "10    0.900000  0.264706   0.002278\n",
      "25    0.640000  0.470588   0.001025\n",
      "50    0.440000  0.647059   0.000608\n",
      "75    0.346667  0.764706   0.000365\n",
      "100   0.280000  0.823529   0.000266\n",
      "with relation prompts\n",
      "person\n",
      "     precision    recall     min_score\n",
      "1         1.00  0.029412  1.474955e-04\n",
      "2         1.00  0.058824  7.982930e-05\n",
      "5         0.80  0.117647  4.348215e-06\n",
      "10        0.70  0.205882  2.206297e-06\n",
      "25        0.56  0.411765  4.635252e-07\n",
      "50        0.38  0.558824  1.242914e-07\n",
      "75        0.32  0.705882  4.555480e-08\n",
      "100       0.28  0.823529  1.098820e-08\n",
      "\n",
      "Domain-adapted BERT\n",
      "person\n",
      "     precision    recall  min_score\n",
      "1         1.00  0.029412   0.036885\n",
      "2         1.00  0.058824   0.019011\n",
      "5         1.00  0.147059   0.012808\n",
      "10        0.60  0.176471   0.011755\n",
      "25        0.68  0.500000   0.002846\n",
      "50        0.48  0.705882   0.001528\n",
      "75        0.36  0.794118   0.000558\n",
      "100       0.31  0.911765   0.000310\n",
      "with relation prompts\n",
      "person\n",
      "     precision    recall     min_score\n",
      "1     1.000000  0.029412  4.360911e-04\n",
      "2     1.000000  0.058824  1.610482e-04\n",
      "5     0.600000  0.088235  1.055282e-04\n",
      "10    0.800000  0.235294  1.651966e-05\n",
      "25    0.680000  0.500000  6.214738e-06\n",
      "50    0.480000  0.705882  1.021262e-06\n",
      "75    0.333333  0.735294  2.432641e-07\n",
      "100   0.310000  0.911765  8.993521e-08\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "prompt_grps = [1,1,1]\n",
    "probe_prompts2 = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "        \"hire {0}, such as {1}, {2} and {3}.\",\n",
    "    \"people with a {2} on their record.\"\n",
    "    ]\n",
    "prompt_grps2 = [1,1,1,2,2]\n",
    "\n",
    "print('BERT-base')\n",
    "probe_and_eval_grps(lm_probe, 'person', probe_prompts, prompt_grps, 'person')\n",
    "print('with relation prompts')\n",
    "probe_and_eval_grps(lm_probe, 'person', probe_prompts2, prompt_grps2, 'person')\n",
    "\n",
    "print()\n",
    "print('Domain-adapted BERT')\n",
    "probe_and_eval_grps(d_lm_probe,'person', probe_prompts, prompt_grps, 'person')\n",
    "print('with relation prompts')\n",
    "probe_and_eval_grps(d_lm_probe,'person', probe_prompts2, prompt_grps2, 'person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roberta_ses.interface import Roberta_SES_Entailment\n",
    "yutong_base_dir=\"/home/ubuntu/users/yutong\"\n",
    "roberta_ses_dir = os.path.join(yutong_base_dir, \"repos\", \"Roberta_SES\")\n",
    "# 0 = contra, 1 = neutral, 2 = entail\n",
    "entailment_model = Roberta_SES_Entailment(roberta_path='/home/ubuntu/users/yutong/models/roberta-large',\n",
    "        ckpt_path=os.path.join(roberta_ses_dir, 'checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt'),\n",
    "        max_length=512,\n",
    "        device_name='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "d_entailment_model = SentenceTransformer('/home/ubuntu/users/nikita/models/bert_finetuned_lm_sts/indeed_all/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rel(sent, rel):\n",
    "    return entailment_model.predict(sent, rel)[1].tolist()\n",
    "\n",
    "def d_predict_rel(sent, rel):\n",
    "    embedding1 = d_entailment_model.encode(sent, convert_to_tensor=True)\n",
    "    embedding2 = d_entailment_model.encode(rel, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    return cosine_scores.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0018634856678545475, 0.008392865769565105, 0.9897436499595642]\n",
      "0.9119620323181152\n"
     ]
    }
   ],
   "source": [
    "s1 = 'walmart : we have to wear uniform'\n",
    "s2 = 'walmart requires uniform'\n",
    "print(predict_rel(s1,s2))\n",
    "print(d_predict_rel(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003196667181327939, 0.039147090166807175, 0.9576562643051147]\n",
      "0.4612185060977936\n"
     ]
    }
   ],
   "source": [
    "s1 = \"kroger stores : our kroger did n't have a pharmacy when i was there , but they paid for the permit test to sell alcohol .\"\n",
    "s2 = \"permit is needed for pharmacy .\"\n",
    "print(predict_rel(s1,s2))\n",
    "print(d_predict_rel(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002546712290495634, 0.016983652487397194, 0.9804696440696716]\n",
      "0.6139006614685059\n"
     ]
    }
   ],
   "source": [
    "s1 = \"cvs health : general orientation is usually about six hours ; after , pharmacy techs will be brought to the pharmacy for a separate orientation .\"\n",
    "s2 = \"There is orientation for pharmacy .\"\n",
    "print(predict_rel(s1,s2))\n",
    "print(d_predict_rel(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0007973050232976675, 0.001054643071256578, 0.9981480836868286]\n",
      "0.5119340419769287\n"
     ]
    }
   ],
   "source": [
    "s1 = \"walmart : 401k , health insurance , full time status as soon as there was a space open in your area .\"\n",
    "s2 = \"walmart offers health insurance.\"\n",
    "print(predict_rel(s1,s2))\n",
    "print(d_predict_rel(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0008081113919615746, 0.009821068495512009, 0.9893708229064941]\n",
      "0.5245642066001892\n"
     ]
    }
   ],
   "source": [
    "s1 = \"walmart : 30 - 40hrs weekly , flexible schedule .\"\n",
    "s2 = \"walmart provides flexible schedule.\"\n",
    "print(predict_rel(s1,s2))\n",
    "print(d_predict_rel(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0009289175504818559, 0.023315617814660072, 0.975755512714386]\n",
      "0.6597525477409363\n"
     ]
    }
   ],
   "source": [
    "s1 = \"subway : it was a flexible schedule to go to school either morning or evenings .\"\n",
    "s2 = \"subway provides flexible schedule.\"\n",
    "print(predict_rel(s1,s2))\n",
    "print(d_predict_rel(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005240839906036854, 0.06974846869707108, 0.9250107407569885]\n",
      "0.733309805393219\n"
     ]
    }
   ],
   "source": [
    "s1 = \"cvs health : after completing their training you get a raise switching you from pharmacy associate to pharmacy tech .\"\n",
    "s2 = \"You can work training as pharmacy .\"\n",
    "print(predict_rel(s1,s2))\n",
    "print(d_predict_rel(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company\n",
      "dress_code\n",
      "job_position\n",
      "pay_schedule\n",
      "benefits\n",
      "compensation\n",
      "payment_option\n",
      "background_screening\n",
      "person\n",
      "hire_prerequisite\n",
      "shifts\n",
      "schedule\n",
      "employee_type\n",
      "onboarding_steps\n"
     ]
    }
   ],
   "source": [
    "probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "concepts_to_expand = concepts\n",
    "expanded_instances = {}\n",
    "for c in concepts_to_expand:\n",
    "    print(c)\n",
    "    results = probe_and_eval(d_lm_probe,c, probe_prompts, c, evaluate=False)\n",
    "    expanded_instances[c] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>lm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>6.304385e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company</td>\n",
       "      <td>nike</td>\n",
       "      <td>3.471876e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>amazons</td>\n",
       "      <td>2.517403e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>company</td>\n",
       "      <td>apple</td>\n",
       "      <td>1.895988e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "      <td>etcs</td>\n",
       "      <td>1.808982e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>company</td>\n",
       "      <td>romans</td>\n",
       "      <td>7.788047e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>company</td>\n",
       "      <td>divorce</td>\n",
       "      <td>7.192135e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>company</td>\n",
       "      <td>jurisdiction</td>\n",
       "      <td>6.065130e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>company</td>\n",
       "      <td>gdansk</td>\n",
       "      <td>3.015721e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>company</td>\n",
       "      <td>loch</td>\n",
       "      <td>2.247079e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8037 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      concept      neighbor      lm_score\n",
       "0     company     starbucks  6.304385e-02\n",
       "1     company          nike  3.471876e-02\n",
       "2     company       amazons  2.517403e-02\n",
       "3     company         apple  1.895988e-02\n",
       "4     company          etcs  1.808982e-02\n",
       "...       ...           ...           ...\n",
       "8032  company        romans  7.788047e-09\n",
       "8033  company       divorce  7.192135e-09\n",
       "8034  company  jurisdiction  6.065130e-09\n",
       "8035  company        gdansk  3.015721e-09\n",
       "8036  company          loch  2.247079e-09\n",
       "\n",
       "[8037 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_instances['company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nearly impossible', 'upper'), ('nearly impossible', 'management'), ('upper', 'management')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = \"<phrase>nearly impossible</phrase> , unless you have an in with <phrase>upper</phrase> level <phrase>management</phrase> your better off finding a better job anywhere else\"\n",
    "phrases = re.findall(r'<phrase>(.*?)</phrase>', s)\n",
    "pairs = []\n",
    "if len(phrases) > 1:\n",
    "    for i in range(0, len(phrases)):\n",
    "        for j in range(i, len(phrases)):\n",
    "            if i != j:\n",
    "                pairs.append((phrases[i], phrases[j]))\n",
    "                \n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_mentions(corpus):\n",
    "    mapping = {}\n",
    "    for sent in corpus:\n",
    "        phrases = re.findall(r'<phrase>(.*?)</phrase>', sent)\n",
    "        pairs = []\n",
    "        if len(phrases) > 1:\n",
    "            for i in range(0, len(phrases)):\n",
    "                for j in range(i, len(phrases)):\n",
    "                    if i != j:\n",
    "                        w1 = phrases[i]\n",
    "                        w2 = phrases[j]\n",
    "                        if w1 == w2:\n",
    "                            continue\n",
    "                        pair_key = str(set([w1, w2]))\n",
    "                        sents = mapping.get(pair_key, [])\n",
    "                        sents.append(sent)\n",
    "                        mapping[pair_key] = sents\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def find_context(concept1, concept2, mapping, instances):\n",
    "    concept1_instances = instances[concept1]\n",
    "    concept2_instances = instances[concept2]\n",
    "    patterns = {}\n",
    "    for c1 in concept1_instances:\n",
    "        for c2 in concept2_instances:\n",
    "            pair_key = str(set([c1,c2]))\n",
    "#             print(pair_key)\n",
    "            sents = mapping.get(pair_key, [])\n",
    "            for sent in sents:\n",
    "                sent = sent.replace(\"<phrase>\", \"\")\n",
    "                sent = sent.replace(\"</phrase>\", \"\")\n",
    "                i1 = sent.index(c1)\n",
    "                i2 = sent.index(c2)\n",
    "                if i1 == -1 or i2 == -1: \n",
    "                    continue\n",
    "                start = min(i1, i2)\n",
    "                end = max(i1, i2)\n",
    "                offset = len(c2) if end == i2 else len(c1)\n",
    "                pat = sent[start: end+offset]\n",
    "#                 print(sent)\n",
    "#                 print(pair_key)\n",
    "#                 print(pat)\n",
    "                pat = pat.replace(c1, '<src>')\n",
    "                pat = pat.replace(c2, '<tgt>')\n",
    "                \n",
    "                left_context_words = sent[:start].split(' ')\n",
    "                left_context_words = left_context_words[-min(len(left_context_words), 2):]\n",
    "\n",
    "                right_context_words = sent[end+offset:].split(' ')\n",
    "                right_context_words = right_context_words[:min(len(right_context_words), 2)]\n",
    "            \n",
    "                context_pat = ' '.join(left_context_words) + pat + ' '.join(right_context_words)\n",
    "#                 print(context_pat)\n",
    "                pat_ct = patterns.get(context_pat, 0)\n",
    "                pat_ct += 1\n",
    "                patterns[context_pat] = pat_ct\n",
    "    return sorted(patterns.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': ['starbucks', 'nike', 'amazons', 'apple', 'etcs', 'macs', 'fasts', 'mcdonalds', 'wal mart', 'wal mart', 'google', 'facebook', 'qs', 'wal marts', \"mcdonald ' s\", 'css', 'apple store', 'kroger', \"macy ' s\", 'sos', 'walmart', 'amazon', 'subway', 'microsoft', 'target'], 'dress_code': ['etcs', 'facial piercings', 'nose piercings', 'hair', 'ear piercings', 'visible piercings', 'face piercings', 'body piercings', 'facial jewelry', 'colored hair', 'facial piercing', 'nose piercing', 'color hair', 'scrubs', 'leggings', 'blue scrubs', 'fragrances', 'nose rings', 'gis', 'dyes', 'business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings'], 'job_position': ['prep cook', 'line cook', 'customer service', 'dish washer', 'bartender', 'assistant manager', 'team member', 'night stocker', 'customer host', 'chef', 'floor associate', 'morning stocker', 'stock', 'shift leader', 'cash handling', 'manager', 'phone operator', 'food handlers', 'general manager', 'assistant manger', 'delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher'], 'pay_schedule': ['sunday', 'saturday sunday', 'saturday and sunday', 'sunday saturday', 'monday friday', 'friday saturday', 'friday saturday', 'saturday / sunday', 'sunday thursday', 'monday saturday', 'monday saturday', 'monday thursday', 'monday thursday', 'friday / saturday', 'monday sunday', 'saturday morning', 'saturday night', 'thursday morning', 'friday morning', 'thursday night', 'weekly', 'biweekly', 'friday', 'saturday'], 'benefits': ['dental insurance', 'health dental', 'medical dental', 'life insurance', 'dental vision', 'medical / dental', 'medical insurance', '401k plan', 'dental and vision', 'dental / vision', 'dental benefits', 'health care', 'health care insurance', 'paid vacations', 'car insurance', 'disability insurance', 'kpk', 'life', 'health', 'vacation days', 'health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance'], 'compensation': ['holiday pay', 'annual raises', 'annual salary', 'insurance', 'annual raise', 'yearly raises', '401k', 'yearly raise', 'hourly pay', 'vacation days', '401k plan', 'annual performance', 'paid vacations', 'sick days', 'health benefits', 'retirement plan', 'annual review', 'pension', 'monthly bonus', 'competitive pay', 'base pay', 'stock options', 'benefits', 'overtime pay', 'bonus'], 'payment_option': ['debit card', 'credit card', 'cash money', 'bank card', 'debit cards', 'debit', 'atm card', 'credit check', 'gift card', 'card', 'payment card', 'charge card', 'discount card', 'credit cards', 'paper check', 'postcard', 'cash register', 'cashier', 'cd', 'ss card', 'checks', 'direct deposit', 'prepaid card'], 'background_screening': ['background check', 'background screening', 'drug screening', 'drug testing', 'background checks', 'employment', 'credit check', 'drug', 'orientation', 'unemployment', 'credit checks', 'background report', 'pre screening', 'random drug test', 'citizenship', 'random drug testing', 'federal background check', 'urine drug test', 'drug tests', 'job interview', 'drug test', 'criminal background check', 'employment verification'], 'person': ['homeless', 'older workers', 'high school student', 'young adults', 'young kids', 'etcs', 'college student', 'family', 'co workers', 'co workers', 'hispanics', 'alcoholics', 'high school', 'css', 'meds', 'senior citizens', 'younger people', 'gays', 'ys', 'cps', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors'], 'hire_prerequisite': ['safety', 'permit', 'personal experience', 'etcs', 'driving record', 'disability', 'training', 'certifications', 'orientation', 'physical disability', 'physical assessment', 'labor', 'construction', 'social skills', 'physical fitness', 'driving test', 'driver license', 'security', 'fork lift', 'felons', 'hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting'], 'shifts': ['evening shift', 'afternoon shift', 'mid shift', 'overnight shift', 'closing shift', 'morning shift', 'graveyard shift', '12 hour shifts', '3rd shift', '2nd shift', 'weekend shift', '8 hour shifts', 'evening shifts', 'afternoon shifts', 'third shift', 'double shift', 'night shifts', 'mid shifts', 'swing shift', 'rotating shift', 'night shift', 'dinner shift', 'early morning shift', '8 hour shift'], 'schedule': ['friday', 'thursday night', 'friday / saturday', 'monday night', 'monday friday', 'saturday night', 'saturday and sunday', 'saturday / sunday', 'friday saturday', 'friday saturday', 'monday thursday', 'monday thursday', 'monday saturday', 'monday saturday', 'thursday morning', 'sunday thursday', 'friday morning', 'monday sunday', 'saturday sunday', 'late night', 'christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend'], 'employee_type': ['full timer', 'full timers', 'part timer', 'part timers', 'contract', 'reduced time', 'christmas', 'seasonal employee', 'weekend', 'tempe', 'holiday season', 'seasonal associate', 'asi', 'season', 'temporary job', 'seasonal employees', 'temporary employee', 'temp service', 'temp agency', 'christmas season', 'full time', 'part time', 'seasonal'], 'onboarding_steps': ['team building', 'classroom training', 'training sessions', 'team lead', 'training classes', 'email', 'class room', 'lunch break', 'cafeteria', 'lunch breaks', 'management', 'training class', 'onboarding', 'group interview', 'break room', 'etcs', 'orientation class', 'lunch / break', 'team leads', 'lunch and dinner', 'orientation', 'introduction', 'workstation', 'training', 'team lunch']}\n"
     ]
    }
   ],
   "source": [
    "sent_mapping = get_all_mentions(corpus)\n",
    "\n",
    "reliable_expanded_instances = {}\n",
    "for key, val in expanded_instances.items():\n",
    "    sub_df = val.iloc[:min(20, len(val))]\n",
    "    reliable_expanded_instances[key] = sub_df['neighbor'].tolist() + seed_instances_dict.get(key, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"candidates <tgt> ca n't be trusted to make that decision ) but the panels have completely devolved into a murder trial that are the most painful and bureaucratic thing done at <src> amazon\",\n",
       "  14),\n",
       " ('a <tgt> or leader of the warehouse i am sure Fulltime employement at <src> amazon',\n",
       "  8),\n",
       " ('A <tgt> at <src> amazon', 8),\n",
       " ('successful <tgt> at <src> amazon', 8),\n",
       " ('a <tgt> at <src> amazon', 8),\n",
       " ('the <tgt> who hired me started <src> as', 6),\n",
       " ('at <src> I was interviewed by both a <tgt> and', 6),\n",
       " ('<src> has many job openings and options from door greeter , to a cart pusher , receiving associate to a supervisor , a department <tgt> to',\n",
       "  6),\n",
       " ('The <src> <src> warehouse does offer flexible hours but <src> flex is <tgt> position',\n",
       "  6),\n",
       " (', <src> offers a great program to relocate to another <src> , so long as they are hiring , transfers are put above standard applications to ensure that a <tgt> gets',\n",
       "  5),\n",
       " ('<src> <tgt>', 4),\n",
       " ('all <src> <src> <tgt> employees', 4),\n",
       " ('or <src> , since you will be on blending and working in the <tgt> stock',\n",
       "  4),\n",
       " ('on <src> <src> <tgt> approach', 4),\n",
       " ('opening <tgt> said You should look for another job I ve never been so humiliated by a <tgt> , and that s when I knew that I would not be returning to <src> and',\n",
       "  4),\n",
       " ('a <tgt> with anxiety and depression sucks at <src> mcdonalds', 4),\n",
       " ('a <tgt> , you might keep team members on target to meet goals , plan for peak hours during shifts , and check in with customers to make sure everyone at your <src> is',\n",
       "  4),\n",
       " ('crush <src> to be honest as a Support <tgt> at', 4),\n",
       " ('at <src> 4303 , started went the building was empty and build it up , work in hard line and overall the place , unfairly treated and disrespect by assist management and <tgt> ,',\n",
       "  4),\n",
       " ('the <tgt> and a few people in the corporate office are arrogant , rude , hateful , pompous azz humans and the <src> corporation',\n",
       "  4),\n",
       " (\"department <tgt> is concerned about their numbers , they 'd stop hiding in the <tgt> 's office talking trash about partners , texting , and playing on <src> ,\",\n",
       "  4),\n",
       " ('hired <src> bounced me over department <tgt> ,', 4),\n",
       " ('hire <tgt> with bachelor or some undergraduate or graduate university , most of the <tgt> who are working over there they got that position for years working in <src> and',\n",
       "  4),\n",
       " ('you <src> for not taking care of ur bad pharmacy pharmacy <tgt> manager',\n",
       "  4),\n",
       " ('Facilities <tgt> in April of 2017 on the <src> amazon', 4),\n",
       " (\"at <src> because of the too much pressure about rate , and I 'm not good under pressure the second things some of the <tgt> manager\",\n",
       "  4),\n",
       " ('with <src> by a <tgt> manager', 4),\n",
       " ('a <tgt> , you might keep team members on <src> to', 4),\n",
       " ('<src> puts their employee through many classes to help certify the <tgt> for',\n",
       "  3),\n",
       " ('on <tgt> which at <src> is', 2),\n",
       " ('called <src> <tgt> I', 2),\n",
       " ('a <tgt> working in cafe or <src> within', 2),\n",
       " ('target <tgt> you can use your employee discount at the <src> in', 2),\n",
       " (', <src> is a fortune 500 company with huge <tgt> options', 2),\n",
       " ('<src> , Inc . , offers , health , Vision , Dental , 401 K and offers a <tgt> sharing',\n",
       "  2),\n",
       " ('all <src> partners averaging 20 hours or more per work week are eligible for medical benefits , 401k , and <tgt> options',\n",
       "  2),\n",
       " ('<src> <tgt> options', 2),\n",
       " ('my <tgt> did not offer the full time hours , that led me to work at <src> .',\n",
       "  2),\n",
       " ('a <src> <tgt> would', 2),\n",
       " ('Will <src> <tgt> let', 2),\n",
       " ('the <src> and ask to speak to the <tgt> and', 2),\n",
       " ('a <tgt> at <src> is', 2),\n",
       " ('what <src> calls a PDP ( personal development Plan ) , where you sit down with your <tgt> to',\n",
       "  2),\n",
       " ('calling <src> and speaking with the <tgt> where', 2),\n",
       " ('the <src> corporation put you on a list of people that each <tgt> ,', 2),\n",
       " ('have <src> called the number and ask for information you may ask to contact the shift supervisor or a <tgt> for',\n",
       "  2),\n",
       " ('for <src> for almost a year and a half now , starting as a <tgt> ,', 2),\n",
       " ('at <src> is a <tgt> .', 2),\n",
       " ('a <src> <tgt> is', 2),\n",
       " ('designated <tgt> shifts at <src>', 2),\n",
       " ('with <src> vcs Virtual <tgt> team', 2),\n",
       " (', <src> does offer work from home <tgt> and', 2),\n",
       " ('for <src> <tgt> and', 2),\n",
       " (\"anything <src> , I 've since drunk the cool aid and have my fair share , but you definitely do n't need to own anything other than a good attitude and a propensity for <tgt> .\",\n",
       "  2),\n",
       " ('a <tgt> at this <src> bees', 2),\n",
       " ('certain <tgt> prefer no pockets because <src> bees', 2),\n",
       " (\"<src> bee 's did n't have a <tgt> everyone\", 2),\n",
       " ('<tgt> and Cashier is a position a 12 year old can make while working at <src> .',\n",
       "  2),\n",
       " ('<src> is an equal opportunity employer ready to get you to the next level if you work hard enough <tgt> positions',\n",
       "  2),\n",
       " ('for <src> in bradenton and sarasota so therefor i do not know anything about the salary or hourly pay for <tgt> position',\n",
       "  2),\n",
       " ('to <src> and ask a <tgt> that', 2),\n",
       " (', <src> shirt authorized or given by the <tgt> ,', 2),\n",
       " ('a <src> and ask to speak to a <tgt> .', 2),\n",
       " ('a <tgt> in a franchise <src> at', 2),\n",
       " ('our <src> , but at others you can just simply ask a <tgt> .', 2),\n",
       " ('at <src> for 6 months and become a <tgt>', 2),\n",
       " ('at <src> , talk to the <tgt> about', 2),\n",
       " ('the <tgt> at the <src> you', 2),\n",
       " ('a <tgt> of <src>', 2),\n",
       " ('in <src> wearing black dress is a crew member and/or <tgt>', 2),\n",
       " ('at <src> as a Shift <tgt> ,', 2),\n",
       " ('your <tgt> , some allow you to some do nt unless its a <src> sweater', 2),\n",
       " (\"a <tgt> I did n't always require applicant to have experience , however there were times when I was specifically looking for people with <src> experience\",\n",
       "  2),\n",
       " ('for <src> <tgt> at', 2),\n",
       " ('<src> is not a <tgt>', 2),\n",
       " ('a <tgt> position at our <src> ,', 2),\n",
       " ('at <src> those are some happy people and their <tgt> is', 2),\n",
       " ('on <src> or call <tgt>', 2),\n",
       " ('become <tgt> or <src> .', 2),\n",
       " ('actual <tgt> a <src> does', 2),\n",
       " ('at <src> their whole life and have no idea how to handle anything as a <tgt> should',\n",
       "  2),\n",
       " ('the <src> system as a <tgt> yet', 2),\n",
       " ('No <src> stores really did nt offer much full time unless you was a <tgt> or',\n",
       "  2),\n",
       " ('a <tgt> , <src> will', 2),\n",
       " ('keep <src> down and <tgt> in', 2),\n",
       " ('at <src> with the exception that I am not allowed to work in <tgt> or', 2),\n",
       " ('your <tgt> experience and what you would bring to <src> as', 2),\n",
       " (', <src> has upgrade their <tgt> ,', 2),\n",
       " (', <src> Cashier , petsmart and office depot <tgt>', 2),\n",
       " ('an <tgt> worked to <src> for', 2),\n",
       " ('an <tgt> at <src>', 2),\n",
       " ('<src> goes back 20 years and this came out the <tgt> mouth', 2),\n",
       " ('Call <src> and ask to speak to the <tgt> and', 2),\n",
       " ('a <tgt> , but <src> did', 2),\n",
       " ('offer <tgt> purchase plan to buy <src> stocks', 2),\n",
       " ('night <tgt> at most <src> stores', 2),\n",
       " ('the <src> app allows us to review items in <tgt> at', 2),\n",
       " ('a <src> <tgt> .', 2),\n",
       " ('other <tgt>s by using their headsets and codes to perform a \" No escape plan \" meaning a <tgt> or <src> employee',\n",
       "  2),\n",
       " ('with <src> again but due to what the old <tgt> put', 2),\n",
       " ('NOT <src> POLICY since I immediately informed the pharmacy pharmacy pharmacy <tgt> with',\n",
       "  2),\n",
       " ('with <src> as a support and supervisor <tgt> for', 2),\n",
       " ('normal <src> shift , but if you get the right <tgt> they', 2),\n",
       " ('Call <src> and ask to the <tgt> what', 2),\n",
       " ('<src> no longer has Zone <tgt> positions', 2),\n",
       " ('the <tgt> had told me and other new employees how he transferred to a different <src> when',\n",
       "  2),\n",
       " ('any <tgt> that s employed at <src>', 2),\n",
       " ('at <src> unless you become a <tgt> .', 2),\n",
       " ('new <tgt> and the hired extra people lus they cut everyones hours at <src> due',\n",
       "  2),\n",
       " ('<src> does nt allow for 12 hour shifts and are moving to a more standard hours shifts like 4 am    1 pm , 1 pm 11 pm , as a department <tgt> you',\n",
       "  2),\n",
       " ('the <tgt> likes you and how well you can conform to the <src> way', 2),\n",
       " ('at <src> currently and besides the daily disgusted looks I get by my supervisor , the <tgt> (',\n",
       "  2),\n",
       " ('left <src> after the <tgt> grabbed', 2),\n",
       " ('at <src> for 6 months to transfer and to transfer you have to get with you <tgt>',\n",
       "  2),\n",
       " ('for <src> jobs in lebanon or palmyra solar <tgt> position', 2),\n",
       " ('a <tgt> job with <src> from', 2),\n",
       " ('for <src> to promote good <tgt> and', 2),\n",
       " ('if <src> is here to stay , let mail carriers focus on mail delivery , processing plant and delivery/ <tgt> need',\n",
       "  2),\n",
       " ('to <src> to work from home as a <tgt> Rep', 2),\n",
       " ('of <src> <src> <tgt> .', 2),\n",
       " ('own <src> <tgt> and', 2),\n",
       " ('mighty <src> how can someone that s been told by my <tgt> manager', 2),\n",
       " ('my <tgt> approved and signed off on the time I requested even at Mighty <src> amazon',\n",
       "  2),\n",
       " (\"time <src> fulfills their FT and PT company needs and the individual still has n't been contacted by HR or a <tgt> ,\",\n",
       "  2),\n",
       " ('a <tgt> too many bad changes trying to keep up with <src> not', 2),\n",
       " ('if <src> is here to stay , let mail carriers focus on mail delivery , processing plant and delivery/ customer service need to work together always , hire more employees , have a <tgt> and',\n",
       "  2),\n",
       " ('for <src> server operation <tgt> .', 2),\n",
       " ('for <src> flex <tgt> for', 2),\n",
       " ('<src> is an easy job , must be proficient in <tgt> and', 2),\n",
       " (\"at <src> because it 's a fun place to work and meet people and to make sure that the <tgt> is\",\n",
       "  2),\n",
       " ('a <tgt> , I supervised and trained employees , engaged in conversations with customers and made sure we were in compliance with <src> standards',\n",
       "  2),\n",
       " ('any <src> and ask the <tgt> for', 2),\n",
       " ('are <src> and my <tgt>', 2),\n",
       " ('the <src> shops and pick up a paper application and ask for the <tgt> in',\n",
       "  2),\n",
       " ('at <src> is on going until the new employee is trained to become a <tgt> and',\n",
       "  2),\n",
       " ('a <tgt> on duty at <src>', 2),\n",
       " ('with <src> has helped me with <tgt> skill', 2),\n",
       " ('a <src> <tgt> ?', 2),\n",
       " ('<src> logistic and back room <tgt> are', 2),\n",
       " (\"in <src> and the company provides all training , your degree wo n't make you stand out against a team lead or <tgt> who\",\n",
       "  2),\n",
       " ('a <tgt> at <src> and', 2),\n",
       " ('global <tgt> at <src> ,', 2),\n",
       " ('beauty <tgt> at <src> .', 2),\n",
       " ('a <tgt> at <src>', 2),\n",
       " (\"<src> did n't have a Beauty <tgt> .\", 2),\n",
       " ('a <src> <tgt> you', 2),\n",
       " ('supervisor <tgt> for 4 years but was let go due to corruption in management putting new Associates on an island and not helping them and the worst part was they made new Associates look bad in front of clients which is a huge issue since I was a trainer in <src> for',\n",
       "  2),\n",
       " ('a <tgt> from <src> .', 2),\n",
       " ('<tgt> position <src> will', 2),\n",
       " ('HR <tgt> said it was to expensive for <src> .', 2),\n",
       " ('a <tgt> for starbucks inside <src> .', 2),\n",
       " ('<src> requires at least one shift supervisor to be on staff at all times for the store to be open , so my <tgt> has',\n",
       "  1),\n",
       " (\"good <tgt> because i was moving i could n't go back to <src> .\", 1),\n",
       " ('At <src> its all about how you are with a <tgt> on', 1),\n",
       " ('area <tgt> posted about needing sandwich makers in a local Job seeking group on <src> .',\n",
       "  1),\n",
       " ('An <tgt> comes to a new <src> after', 1),\n",
       " (', <tgt> purchases are discounted , cell phone bill is discounted , disney tickets are discounted , and so many more deals but just being employed with <src> .',\n",
       "  1),\n",
       " ('buy <src> <tgt> .', 1),\n",
       " ('resources <tgt> at the rantoul , IL <src> Facility', 1),\n",
       " ('about <src> as a competitor because we do what we are supposed to do and provide excellent <tgt> .',\n",
       "  1),\n",
       " ('<src> will fire some before they can get <tgt> in', 1),\n",
       " ('for <src> in 2008 they were very selective and a position as a <tgt> was',\n",
       "  1),\n",
       " ('<src> needs to crush wal mart to be honest as a Support <tgt> at', 1),\n",
       " ('Facilities <tgt> with JLL on the <src> Account', 1),\n",
       " ('company <src> hires specifically to work against you in the appeal , so even if you win the appeal directly against your <tgt> ,',\n",
       "  1),\n",
       " ('with <src> for <tgt> for', 1),\n",
       " ('<src> talks a lot about giving good sandwiches and good <tgt> but', 1),\n",
       " ('<tgt> , grace under pressure , stocking , prep work , cash register knowledge and depending on the <src> ,',\n",
       "  1),\n",
       " ('at <src> that gave the <tgt> a', 1),\n",
       " ('a <src> <tgt> ,', 1)]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_context('company', 'job_position', sent_mapping, reliable_expanded_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hire <tgt> tested , but on a monthly basis , Corporate would randomly choose anywhere from five to twenty associate names that a <src> in',\n",
       "  6),\n",
       " ('Usually <tgt> testing is random ; However , if a <src> suspects', 6),\n",
       " (', <tgt> tests are always possible , and a <src> can', 6),\n",
       " (', <tgt> are always possible , and a <src> can', 6),\n",
       " (\"hire <tgt> tested , but on a monthly basis , Corporate would randomly choose anywhere from five to twenty associate names that a manager in charge had to immediately call into the <src> 's\",\n",
       "  6),\n",
       " ('in <src> call center we are not involve with the human resources group , which is a totally different department , and to my knowledge they do a complete <tgt> for',\n",
       "  4),\n",
       " ('a <src> position they did not <tgt> test', 4),\n",
       " ('to <src> , and never once seen anyone get <tgt> drug', 4),\n",
       " ('a <src> and I can tell you that <tgt> drug', 4),\n",
       " ('ex <src> and asked to come in and complete a physical and <tgt> .', 3),\n",
       " ('the <tgt> ( they have a toll free number for questions and <src> )', 2),\n",
       " ('for <src> representative <tgt> is', 2),\n",
       " ('call <tgt> <src> and', 2),\n",
       " ('just <tgt> , but they rely heavily on the <src> aspect', 2),\n",
       " ('the <src> number to check the <tgt> or', 2),\n",
       " ('have <src> and quality assurance <tgt> from', 2),\n",
       " ('a <src> <tgt> .', 2),\n",
       " ('or <src> background you have a good chance of getting <tgt> with', 2),\n",
       " ('Training <tgt> screening <src> testing', 2),\n",
       " ('a <tgt> screening and a <src> quiz', 2),\n",
       " ('a <tgt> screen when I went to ap ( asset protection , the people at the door ) , pharmacy , TLE ( automotive ) , ap , <src> ,',\n",
       "  2),\n",
       " ('<src> department did <tgt> testing', 2),\n",
       " ('for <tgt>s but as a <src> agent', 2),\n",
       " ('performs <tgt> for <src> representative', 2),\n",
       " ('home <src> position , there was no <tgt> .', 2),\n",
       " ('for <tgt> for the <src> or', 2),\n",
       " ('The <src> <tgt> age', 2),\n",
       " ('a <src> I had to go through a <tgt> ,', 2),\n",
       " ('an <src> the <tgt> goes', 2),\n",
       " ('the <src> , got drug tested , <tgt> and', 2),\n",
       " ('to <src> or store manager they will definitely do a <tgt> and', 2),\n",
       " (\"an <src> and I do n't know much about there <tgt>\", 2),\n",
       " ('to <src> Trainee however once boots took over they redid the <tgt> structure',\n",
       "  2),\n",
       " ('or <src> upon <tgt> /interview', 2),\n",
       " ('and <src> during the time of <tgt>', 2),\n",
       " ('they <tgt> tested me for a <src> position', 2),\n",
       " ('was <tgt> tested once I passed my math test for <src>', 2),\n",
       " ('only <tgt> testing done is for applicants applying for lead sales associate , <src> ,',\n",
       "  2),\n",
       " ('and <src> are <tgt> tested', 2),\n",
       " ('a <tgt> when you get promoted to <src> .', 2),\n",
       " ('a <src> or every time you get promoted to another level they have you complete a <tgt> .',\n",
       "  2),\n",
       " ('the <tgt> on Friday , became <src> within', 2),\n",
       " ('does <tgt> for the position of Managers and <src>', 2),\n",
       " ('No <tgt> , until you reach the level of <src>', 2),\n",
       " ('a <tgt> when switching roles from <src> to', 2),\n",
       " ('new <src> need to pass the <tgt> .', 2),\n",
       " ('global <src> at target , I was not <tgt> tested', 2),\n",
       " ('seasonal <src> , then my old position became available and I did not have to submit any <tgt> .',\n",
       "  2),\n",
       " ('a <src> , took my drug test and submitted my <tgt> today', 2),\n",
       " ('a <src> , took my <tgt> and', 2),\n",
       " ('procure <tgt> with security , respect among upper and lower management , and growth opportunities as well as compensation in monetary or <src> form',\n",
       "  2),\n",
       " (', <src> , and discount card after 3 months of <tgt>', 2),\n",
       " ('the <src> area to the floor required strength and will , as well as , wanting to perform at your best to maintain <tgt> .',\n",
       "  2),\n",
       " ('They <tgt> everyone to <src> juice', 2),\n",
       " ('do <tgt> <src> room', 2),\n",
       " ('Full <tgt> are necessary as one is dealing with <src> ,', 2),\n",
       " ('full <tgt> are necessary as one is dealing with <src> ,', 2),\n",
       " ('the <src> had said it was because of the <tgt> they', 2),\n",
       " ('a <tgt> for <src> .', 2),\n",
       " ('an <tgt> will the <src> call', 2),\n",
       " ('and <tgt> before hired as <src>', 2),\n",
       " ('the <src> of the store and if it come up on a <tgt>', 2),\n",
       " ('by <src> stating my <tgt> had', 2),\n",
       " ('store <src> ( and already have gotten a <tgt> before', 2),\n",
       " ('pass <tgt> and eligible to work has <src> .', 2),\n",
       " ('the <src> who gave the <tgt> saying', 2),\n",
       " ('the <src> and tell them that you received the <tgt> and', 2),\n",
       " ('the <src> and I started talking , and he hired me the next few days after <tgt> .',\n",
       "  2),\n",
       " ('their <tgt> , however you would need to contact the Personnel <src> for',\n",
       "  2),\n",
       " ('Our <src> does a <tgt> thru', 2),\n",
       " ('The <src> gave me a <tgt>', 2),\n",
       " ('a <tgt> is not required for a position at this company unless it is for a <src> position',\n",
       "  2),\n",
       " ('a <src> requires a <tgt> .', 2),\n",
       " ('Operation <src> [ BOM ] workload and whether or not your <tgt> has', 2),\n",
       " ('a <tgt> and may hire , check with a <src> .', 2),\n",
       " (\"The <src> is probably off for the week , they 'll call when they are back , or your <tgt> has\",\n",
       "  2),\n",
       " ('a <tgt> when switching roles from team member to shift <src> ,', 2),\n",
       " ('the <src> and see if my <tgt> is', 2),\n",
       " ('the <src> wants to hire you then you go for your drug test and wait for your <tgt> to',\n",
       "  2),\n",
       " ('and <tgt> , but at the end if whatever the <src> decides', 2),\n",
       " ('The <src> called the day after my interview and done a <tgt> ,', 2),\n",
       " (\"a <tgt> unless you 're being a <src>\", 2),\n",
       " ('or <src> is to have a clean <tgt> ,', 2),\n",
       " ('a <src> <tgt>', 2),\n",
       " ('My <src> would do a <tgt> of', 2),\n",
       " ('a <src> they do a full <tgt> .', 2),\n",
       " ('do <tgt> on any type of <src> but', 2),\n",
       " ('do <tgt> and drug tests to make sure your the right loyal employee/ <src> for',\n",
       "  2),\n",
       " ('those <tgt> are done by the area <src> and', 2),\n",
       " ('All <tgt> are taken care of after a <src> reviews', 2),\n",
       " ('do <tgt> , the <src> just', 2),\n",
       " ('do <tgt> all depending on which <src>', 2),\n",
       " ('do <tgt> for all <src> positions', 2),\n",
       " ('the <src> and their schedule and the list of <tgt> opportunities', 2),\n",
       " ('a <src> , may not have been selected to continue <tgt> and', 2),\n",
       " ('the <src> where they describe expectations and have the drivers complete standard <tgt> documents',\n",
       "  2),\n",
       " ('a <src> constantly hovering over them , threatening to write them up , suspend them , or terminate their <tgt> for',\n",
       "  2),\n",
       " ('both <src> , and assistant <src> during the time of <tgt>', 2),\n",
       " (\"district <src> , if you get a reply of I 'll see what a I can , or a response of be patient , Contact you regional <src> , Be sure to stress to them all details you have mentions to store <src> and district <src> , with 48 hours they 'll assign a Job/ <tgt> coach\",\n",
       "  2),\n",
       " ('your <src> /supervisor and closely look at your attendance and time arrivals during your <tgt> there',\n",
       "  2),\n",
       " ('a <tgt> for Co <src> application', 2),\n",
       " ('the <src> wants to hire you and after that is completed you need <tgt> screen',\n",
       "  2),\n",
       " ('Market <src> was battling with a <tgt> addiction', 2),\n",
       " ('previous <src> did nt require any <tgt> screening', 2),\n",
       " ('only <tgt> testing done is for applicants applying for lead sales associate , assistant <src> ,',\n",
       "  2),\n",
       " ('a <src> , then you can get <tgt> tested', 2),\n",
       " ('do <tgt> testing only if you become a <src>', 2),\n",
       " ('to <src> , but I have never once been <tgt> tested', 2),\n",
       " ('only <tgt> testing i knew about was if the <src> suspected', 2),\n",
       " ('get <tgt> tested until you are a <src>', 2),\n",
       " ('get <tgt> tested if you become a <src> and', 2),\n",
       " ('general <src>s discretion   when a concern about an employee coming to work high was brought up , the <src> mentioned possibly performing a surprise <tgt> screen',\n",
       "  2),\n",
       " ('and <src> gets scared when you have to report an injury and tells us not to , so no one gets <tgt> tested',\n",
       "  2),\n",
       " ('the <src> and assistant <src> are <tgt> tested', 2),\n",
       " ('a <src> suspects the can also do a <tgt> during', 2),\n",
       " ('the <src> asked if it would be a problem if they took a <tgt> ,', 2),\n",
       " ('and <tgt> to make sure your the right loyal employee/ <src> for', 2),\n",
       " ('or <tgt> until you move to a <src> position', 2),\n",
       " ('failed <tgt> means you are fired on the spot by the <src> .', 2),\n",
       " ('if <src> chooses to go a head with a person to getva <tgt> .', 2),\n",
       " ('of <src> but absolutely no <tgt> .', 2),\n",
       " ('Cosmetic <src> require a <tgt> ?', 2),\n",
       " ('My <src> by passed the <tgt> some', 2),\n",
       " ('The <tgt> was easy , the <src> got', 2),\n",
       " ('what <tgt> a <src> is', 2),\n",
       " ('the <src> will hire anyone if they can pass <tgt>', 2),\n",
       " ('a <tgt> if a <src> asks', 2),\n",
       " ('chain <src> who she interviewed for when they asked her if she can oass a <tgt> that',\n",
       "  2),\n",
       " ('to <tgt> the <src> ,', 2),\n",
       " ('no <tgt> unless there s a negative background or if <src> has', 2),\n",
       " ('No <tgt> for package handlers only when u become <src>', 2),\n",
       " ('fuction <src> <tgt>', 2),\n",
       " ('a <tgt> would have to be preformed before becoming the pharmacy department <src> .',\n",
       "  2),\n",
       " ('one <tgt> when I became a <src> .', 2),\n",
       " ('the <src> wants to hire you then you go for your <tgt> and', 2),\n",
       " ('for <src> but no <tgt> for', 2),\n",
       " ('do <tgt> and background check , but at the end if whatever the <src> decides',\n",
       "  2),\n",
       " ('a <src> they did nt require me to do a <tgt>', 2),\n",
       " ('a <tgt> for a <src> position', 2),\n",
       " ('the <tgt> test worked , I would receive an email from my head <src> giving',\n",
       "  2),\n",
       " ('do <tgt> because <src> was', 2),\n",
       " ('managers/ <src> to find out the status of <tgt>', 2),\n",
       " ('the <src> gets <tgt> tested', 2),\n",
       " ('No <tgt> administered at time of hire , only when getting to promoted to <src> .',\n",
       "  2),\n",
       " ('<src> <tgt> would', 2),\n",
       " ('of <tgt> does amazon uses for a <src> ?', 2),\n",
       " ('a <src> and will now lose that offer due to this false positive , with no option for a retake <tgt> test',\n",
       "  2),\n",
       " ('No <tgt> and no <src> positions', 2),\n",
       " ('the <src> they did a criminal and standard <tgt>', 2),\n",
       " ('or <src> they will definitely do a <tgt> and', 2),\n",
       " ('the <tgt> to come back to the <src> .', 2),\n",
       " ('the <src> ( and already have gotten a <tgt> before', 2),\n",
       " ('the <src> once my <tgt> came', 2),\n",
       " ('current <src> usually <tgt> can', 2),\n",
       " ('the <src> gets the result of your <tgt> from', 2),\n",
       " ('negative <tgt> , the <src> can', 2),\n",
       " ('a <src> can over ride a negative <tgt> .', 2),\n",
       " ('The <src> should have informed you that they would be submitting the <tgt> and',\n",
       "  2),\n",
       " ('my <tgt> for a <src> position', 2),\n",
       " ('<src> , several times throughout my <tgt> at', 2),\n",
       " ('a <src> and was thinking to myself , was this a good <tgt> decision', 2),\n",
       " ('city <tgt> making $ 18hr attempted to obtain another job at family dollar for security as I have experience the <src> desparately',\n",
       "  2),\n",
       " ('the <src> request for new hire <tgt> .', 2),\n",
       " ('to <tgt> or interview once they complete whatever the award term is ask your area supervisor or <src> typically',\n",
       "  2),\n",
       " ('INTERVIEW <src> AND district manager USE TO BE <tgt> TESTED', 2),\n",
       " ('several <src>s had never even worked in <tgt> g', 2),\n",
       " ('The <src> must print out the dollar general <tgt> testing', 2),\n",
       " ('a <tgt> test at the store while assistant managers and <src> go', 2),\n",
       " ('a <tgt> with the <src> .', 2),\n",
       " ('a <tgt> to be a <src> or', 2),\n",
       " ('a <tgt> at the store while assistant managers and <src> go', 2),\n",
       " ('the <src> for an interview and then immediately took a <tgt> so', 2),\n",
       " ('all <tgt> for lower level potions , but its required for anything from a <src> up',\n",
       "  2),\n",
       " ('for <src> , after the interview they told me it takes a week or 2 for a <tgt> .',\n",
       "  2),\n",
       " ('<tgt> as a <src> requires', 2),\n",
       " ('driver <tgt> would first require certifications such as CDLs and would likely be difficult to advance to from a <src> position',\n",
       "  2),\n",
       " ('get <tgt> tested , if you are a <src> then', 2),\n",
       " ('an <tgt> tesat for the <src> position', 2),\n",
       " ('A <src> For UPS And <src>s Did Not Have To Take An <tgt>', 2),\n",
       " ('<src> , New Haven , Indiana , No <tgt>', 2),\n",
       " ('Tx <tgt> for <src>', 2),\n",
       " ('fedex <tgt> for <src> in', 2),\n",
       " ('ups <tgt> for <src> in', 2),\n",
       " ('a <tgt> to be a <src>', 2),\n",
       " ('a <src> has a failed <tgt>', 2),\n",
       " ('No <tgt> for the <src>', 2),\n",
       " ('No <tgt> for <src> .', 2),\n",
       " ('regular <src> is not <tgt> tested', 2),\n",
       " ('employment <tgt> screen for part time <src> .', 2),\n",
       " ('get <tgt> tested for the Cashier/ <src> position', 2),\n",
       " ('time <src> and I have to do a <tgt> .', 2),\n",
       " ('as <src> and no <tgt> was', 1),\n",
       " ('with <src> / store manager or both , interview with district manager , <tgt> .',\n",
       "  1),\n",
       " ('the <src> in question present and they are very good at using lawyers to block <tgt> .',\n",
       "  1),\n",
       " ('the <src> as well as any other position foreseeing a <tgt> .', 1),\n",
       " ('<tgt> , education checks , credit checks , 3 interviews , Phone , in person audition , and <src> interview',\n",
       "  1),\n",
       " ('site <src> the next day and she did a <tgt> on', 1),\n",
       " ('site <src> who ran both a drivers license check and <tgt> .', 1),\n",
       " ('a <tgt> to become a <src> .', 1),\n",
       " ('a <tgt> , but you can be a <src> with', 1),\n",
       " ('the <tgt> the site <src> told', 1),\n",
       " ('do <tgt> unless you are applying for <src>', 1),\n",
       " ('the <src> that the following convictions do bar you from <tgt> however', 1),\n",
       " ('the <src> of the store since they got back to me about my application in a timely manner and allowed me to get the most out of my <tgt> .',\n",
       "  1),\n",
       " ('a <src> and have never had any kind of background or <tgt> check', 1),\n",
       " ('the <src> on the phone 2 months later for my first and second interview which were both on the same day , also that day I was handed a <tgt> screen',\n",
       "  1),\n",
       " ('for <tgt> testing and had another interview with the <src> of', 1),\n",
       " (', <tgt> , 3 interviews , Phone , in person audition , and <src> interview',\n",
       "  1),\n",
       " ('my <src> the first day I started that they do nt do <tgt> anymore', 1),\n",
       " ('longer <tgt> for any positions except <src> !', 1),\n",
       " ('But <src> positions are required to take <tgt> .', 1),\n",
       " ('the <src> running the shrewsbury location beat the <tgt> buy', 1),\n",
       " ('pharmacy <src> , then the store <src> , took a <tgt> and', 1),\n",
       " ('the <src> on the phone 2 months later for my first and second interview which were both on the same day , also that day I was handed a drug screen paper to go take my <tgt>',\n",
       "  1),\n",
       " (\"My <src> hired me on the spot yesterday , I 'm gon na fill out paperwork tomorrow and they are making me take a <tgt>\",\n",
       "  1),\n",
       " ('to <src> and this is my 1st time taking a <tgt> .', 1),\n",
       " ('a <tgt> and a mental health evaluation on my former <src> ,', 1),\n",
       " ('<tgt> , phone interview and <src> interview', 1),\n",
       " ('/ <src> or both , interview with district manager , <tgt> .', 1),\n",
       " ('the <src> , took a <tgt> and', 1),\n",
       " ('recently <tgt> only if your coming in as a <src> .', 1),\n",
       " ('No <tgt> required for <src> in', 1),\n",
       " ('as <src> tomorrow , will I have to do a <tgt> at', 1),\n",
       " ('for <src> , but during / after training to become a key holder they ll do a <tgt> as',\n",
       "  1)]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_context('job_position', 'background_screening', sent_mapping, reliable_expanded_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good <src> and seeing how the store is free from <tgt> safety', 4),\n",
       " ('great <src> but often has to use her vacation hours to hit <tgt> labor', 4),\n",
       " ('shift <src> , they start as a shift <src> with no <tgt> to', 4),\n",
       " ('your <tgt> to your <src> and', 4),\n",
       " ('on <src> , <tgt> ,', 2),\n",
       " ('on <src> and food handling and <tgt> tips', 2),\n",
       " (', <src> and <tgt> for', 2),\n",
       " ('of <src> especially in food preparation or sales , I completed an ekg tech program , I had <tgt> in',\n",
       "  2),\n",
       " ('More <tgt> intense then <src>', 2),\n",
       " ('<src> skills , computer skills , <tgt> ,', 2),\n",
       " (\"'s <src> , and they will help you reset your passwords and <tgt> answers\",\n",
       "  2),\n",
       " ('off <tgt> , have 4 year <src> experience', 2),\n",
       " ('a <tgt> to become an <src>', 2),\n",
       " ('an <src> application was as little as half a year to a year of <tgt> ,', 2),\n",
       " ('<tgt> <src> .', 2),\n",
       " ('a <tgt> vest while spotting another associate that would be on a <src> picker',\n",
       "  2),\n",
       " (\"did <tgt> , q'ing ovens , grill , fryers , <src> ,\", 2),\n",
       " ('of <src> are organized with a <tgt> First', 2),\n",
       " ('term <tgt> , vision insurance 401k and <src> .', 2),\n",
       " ('with <tgt> , respect among upper and lower management , and growth opportunities as well as compensation in monetary or <src> form',\n",
       "  2),\n",
       " ('personal <src> in you , supportive of union <tgt> and', 2),\n",
       " ('in <src> which is bringing the new stuff into the sales floor , you can cashier , you can be sales floor and make sure everything is picked up off the floor and assist cashier , you can be an area supervisor or even the <tgt>',\n",
       "  2),\n",
       " (\"Most <src> do n't care about <tgt> .\", 2),\n",
       " ('or <tgt> <src>', 2),\n",
       " ('A <src> had a <tgt> violation', 2),\n",
       " ('and <tgt> <src> total', 2),\n",
       " ('one <tgt> <src> for', 2),\n",
       " ('a <src> who does nt respect <tgt> policy', 2),\n",
       " (\"My <src> did n't like me and forced me to work nights knowing I lived in a bad neighborhood and was risking my <tgt> .\",\n",
       "  2),\n",
       " (\"the <src> gave me a dirty look and told me I 'd have to stand there while they finished cleaning because she could n't unlock the doors for <tgt> reasons\",\n",
       "  2),\n",
       " ('A <src> made fun of my <tgt>', 2),\n",
       " (\"the <src> that was at this taco bell probably would n't have hired anybody with any kind of <tgt> .\",\n",
       "  2),\n",
       " ('If <src> , regional & district persons are knowledgeable , know <tgt> laws',\n",
       "  2),\n",
       " ('shift <src> watches over the whole store but tries to focus more on money and <tgt> when',\n",
       "  2),\n",
       " ('area <src> is in charge of operations as well as fluidity of <tgt> cost',\n",
       "  2),\n",
       " ('hourly <tgt> to supervisor to salaried <src> .', 2),\n",
       " ('one <src> made everyone not happy , even the customers were not happy with him around , due to his \" <tgt> with',\n",
       "  2),\n",
       " ('valid <tgt> for a <src> position', 2),\n",
       " ('The <src> I spoke was interested in my <tgt> experience', 2),\n",
       " (', <tgt> was a big joke when i was threated to be killed by a fellow employee and <src>',\n",
       "  2),\n",
       " ('a <tgt> company that had no communication between the three <src>s and', 2),\n",
       " ('Employee/ <tgt> Relations , eeoc /AAP , Executive and management Compensation Administration , and Benefits Enrollment including 401k ; manage $ 500K+ budget reporting to hotel 5 <src> .',\n",
       "  2),\n",
       " ('clear <tgt> to be a <src>', 2),\n",
       " ('a <src> they will do a <tgt> check', 2),\n",
       " ('your <tgt> matter for the non cdl <src> position', 2),\n",
       " ('a <src> with a good <tgt> .', 2),\n",
       " ('<src> employment would first require <tgt> such', 2),\n",
       " ('the <tgt> of the employees , the owner hired a racist black <src> ,', 2),\n",
       " ('a <src> on salary any meeting or training you attend is usually your day off because there is no <tgt> hours',\n",
       "  2),\n",
       " ('The <tgt> budget is so slim that if one person on the freight throwing team fails meet the expectations of the standards , the <src> has',\n",
       "  2),\n",
       " ('INTERVIEW <src> AND district manager USE TO BE drug TESTED RAN BY BACKGROUND AND BY HOMELAND <tgt>',\n",
       "  2),\n",
       " ('for <tgt> as I have experience the <src> desparately', 2),\n",
       " ('require <tgt> such as CDLs and would likely be difficult to advance to from a <src> position',\n",
       "  2),\n",
       " ('a <src> requires minimal to no <tgt> ,', 2),\n",
       " ('closing <src> position and it was given to someone from the outside who had no <tgt> or',\n",
       "  2),\n",
       " ('The <tgt> for a starbucks <src> is', 2),\n",
       " ('a <tgt> hazard , i only learned how to wash dishes and run the <src> because',\n",
       "  2),\n",
       " ('giving <src> to our customers enjoyed the managers who showed me how to make sandwiches fries and <tgt> of',\n",
       "  1),\n",
       " (', <tgt> ( long and short ) , <src> options', 1),\n",
       " ('your <src> , if the issue is not resolved you can call the ethics hotline ; However , these steps have not proven to be helpful in my <tgt> .',\n",
       "  1)]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_context('job_position', 'hire_prerequisite', sent_mapping, reliable_expanded_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_transformers_nikita)",
   "language": "python",
   "name": "conda_transformers_nikita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
