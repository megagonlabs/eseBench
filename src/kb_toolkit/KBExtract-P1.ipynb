{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"/mnt/efs/shared/meg_shared_scripts/meg-kb\"\n",
    "# data_ac=\"indeeda-meg-ac\"\n",
    "# data_pt=\"indeeda-meg-pt\"\n",
    "yutong_base_dir=\"/home/ubuntu/users/yutong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, entropy, gmean\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import logging\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "\n",
    "from compute_concept_clusters import knn\n",
    "from compute_keyphrase_embeddings import ensure_tensor_on_device, mean_pooling\n",
    "\n",
    "from utils import LMProbe, LMProbe_GPT2\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import get_masked_contexts\n",
    "\n",
    "from roberta_ses.interface import Roberta_SES_Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: text corpus\n",
    "# step 1: extract key phrases (autophrase)\n",
    "# step 2: generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Key Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/keyword_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n"
     ]
    }
   ],
   "source": [
    "#change to keyword extractor directory\n",
    "%cd $base_dir/src/keyword_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./corpusProcess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dataset and thread no\n",
    "data_ac = 'indeeda-meg-ac'\n",
    "data_pt = 'indeeda-meg-pt'\n",
    "thread = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n",
      "\u001b[32m===Corpus Name: indeeda-meg-ac===\u001b[m\n",
      "\u001b[32m===Current Path: /mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction===\u001b[m\n",
      "\u001b[32m===Cleaning input corpus===\u001b[m\n",
      "\u001b[32m===Running AutoPhrase===\u001b[m\n",
      "make: Nothing to be done for 'all'.\n",
      "\u001b[32m===RAW_TRAIN: ../../../data/indeeda-meg-ac/source/corpus.clean.txt===\u001b[m\n",
      "auto_phrase.sh parameters: indeeda-meg-ac ../../../data/indeeda-meg-ac/source/corpus.clean.txt 10 data/EN/wiki_quality.txt 1\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m12.787s\n",
      "user\t0m19.848s\n",
      "sys\t0m2.588s\n",
      "Detected Language: EN\u001b[0K\n",
      "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
      "No provided expert labels.\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===AutoPhrasing===\u001b[m\n",
      "=== Current Settings ===\n",
      "Iterations = 2\n",
      "Minimum Support Threshold = 10\n",
      "Maximum Length Threshold = 6\n",
      "POS-Tagging Mode Disabled\n",
      "Discard Ratio = 0.050000\n",
      "Number of threads = 1\n",
      "Labeling Method = DPDN\n",
      "\tAuto labels from knowledge bases\n",
      "\tMax Positive Samples = -1\n",
      "=======\n",
      "Loading data...\n",
      "# of total tokens = 4450746\n",
      "max word token id = 45746\n",
      "# of documents = 318786\n",
      "# of distinct POS tags = 0\n",
      "Mining frequent phrases...\n",
      "selected MAGIC = 45751\n",
      "# of frequent phrases = 130500\n",
      "Extracting features...\n",
      "Constructing label pools...\n",
      "\tThe size of the positive pool = 5026\n",
      "\tThe size of the negative pool = 124960\n",
      "# truth patterns = 78931\n",
      "Estimating Phrase Quality...\n",
      "Segmenting...\n",
      "Rectifying features...\n",
      "Estimating Phrase Quality...\n",
      "Segmenting...\n",
      "Dumping results...\n",
      "Done.\n",
      "\n",
      "real\t1m12.981s\n",
      "user\t1m12.520s\n",
      "sys\t0m0.224s\n",
      "\u001b[32m===Saving Model and Results===\u001b[m\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "phrasal_segmentation.sh parameters: indeeda-meg-ac ../../../data/indeeda-meg-ac/source/corpus.clean.txt 0.5 0.9 1\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m4.855s\n",
      "user\t0m8.700s\n",
      "sys\t0m1.444s\n",
      "Detected Language: EN\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===Phrasal Segmentation===\u001b[m\n",
      "=== Current Settings ===\n",
      "Segmentation Model Path = models/indeeda-meg-ac/segmentation.model\n",
      "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
      "\tQ(multi-word phrases) >= 0.500000\n",
      "\tQ(single-word phrases) >= 0.900000\n",
      "=======\n",
      "Length penalty model loaded.\n",
      "\tpenalty = 199.805\n",
      "# of loaded patterns = 15029\n",
      "# of loaded truth patterns = 83957\n",
      "Phrasal segmentation finished.\n",
      "   # of total highlighted quality phrases = 322757\n",
      "   # of total processed sentences = 562341\n",
      "   avg highlights per sentence = 0.573952\n",
      "\n",
      "real\t0m6.539s\n",
      "user\t0m6.292s\n",
      "sys\t0m0.020s\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "\u001b[32m===Generating Phrase Text===\u001b[m\n",
      "process_segmentation.py parameters: ../../../data/indeeda-meg-ac/intermediate/ 0.5 0.9\n",
      "12.064924432064144\n",
      "\u001b[32m===Running NLP Feature Extraction===\u001b[m\n",
      "100%|████████████████████████████████████| 41529/41529 [06:51<00:00, 101.01it/s]\n",
      "Finish NLP processing, using time 411.26008439064026 (second)\n",
      "100%|████████████████████████████████████| 50080/50080 [07:26<00:00, 112.13it/s]\n",
      "Finish NLP processing, using time 446.79743480682373 (second)\n",
      "100%|████████████████████████████████████| 45250/45250 [07:07<00:00, 105.94it/s]\n",
      "Finish NLP processing, using time 427.29006242752075 (second)\n",
      "100%|█████████████████████████████████████| 36409/36409 [06:07<00:00, 99.11it/s]\n",
      "Finish NLP processing, using time 367.5125126838684 (second)\n",
      "100%|████████████████████████████████████| 45334/45334 [07:10<00:00, 105.32it/s]\n",
      "Finish NLP processing, using time 430.6026060581207 (second)\n",
      "100%|██████████████████████████████████| 318786/318786 [47:33<00:00, 111.70it/s]\n",
      "Finish NLP processing, using time 2854.495377779007 (second)\n",
      "100%|████████████████████████████████████| 48210/48210 [07:12<00:00, 111.56it/s]\n",
      "Finish NLP processing, using time 432.35684394836426 (second)\n",
      "100%|█████████████████████████████████████| 21213/21213 [04:07<00:00, 85.70it/s]\n",
      "Finish NLP processing, using time 247.74400305747986 (second)\n",
      "\u001b[32m===Clean unnecessary files===\u001b[m\n",
      "\u001b[32m===Key Term Extraction===\u001b[m\n",
      "Extract Key Terms from Corpus: 100%|█| 901796/901796 [00:33<00:00, 27081.92it/s]\n",
      "\u001b[32m===Sentence-wise Entity Segmentation===\u001b[m\n",
      "loading corpus for word2vec training: 100%|█| 901796/901796 [00:01<00:00, 512350\n",
      "100%|█████████████████████████████████| 99711/99711 [00:00<00:00, 831877.80it/s]\n",
      "100%|███████████████████████████████████| 6617/6617 [00:00<00:00, 297371.79it/s]\n",
      "100%|███████████████████████████████████| 6594/6594 [00:00<00:00, 324607.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# process corpus and generate key prhases (long time! ~90min)\n",
    "!./corpusProcess.sh $data_ac $thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy these results to sample-meg-pt\n",
    "# !cp -r ../../data/$data_ac ../../data/$data_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus with company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/question_answers.csv'\n",
    "# company_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/fccid-companyName.csv'\n",
    "# entity_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "# out_corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lines: 100%|████████████████| 307122/307122 [11:54<00:00, 430.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "!python build_corpus_with_companies.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-rd /home/ubuntu/users/nikita/data/indeed/indeedQA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "#change to concept learning directory\n",
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|███████████████| 901796/901796 [00:03<00:00, 267569.33it/s]\n",
      "computing entity-wise embedding: 100%|██████| 8028/8028 [07:01<00:00, 19.03it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!python compute_keyphrase_embeddings.py -m bert-base-uncased -et ac -d ../../data/$data_ac/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenated Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|███████████████| 465226/465226 [00:01<00:00, 257167.06it/s]\n",
      "computing entity-wise embedding:   4%|▏    | 311/7973 [01:59<1:01:48,  2.07it/s]####NOT FOUND#####\n",
      "computing entity-wise embedding:   4%|▎      | 316/7973 [02:01<56:16,  2.27it/s]####NOT FOUND#####\n",
      "computing entity-wise embedding:  14%|▊     | 1136/7973 [04:04<07:51, 14.51it/s]####NOT FOUND#####\n",
      "computing entity-wise embedding:  26%|█▌    | 2103/7973 [04:58<08:12, 11.93it/s]####NOT FOUND#####\n",
      "computing entity-wise embedding:  29%|█▊    | 2340/7973 [05:10<02:54, 32.25it/s]####NOT FOUND#####\n",
      "computing entity-wise embedding:  68%|████  | 5457/7973 [06:27<00:49, 50.69it/s]####NOT FOUND#####\n",
      "computing entity-wise embedding: 100%|██████| 7973/7973 [07:15<00:00, 18.32it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!python compute_keyphrase_embeddings.py -m bert-base-uncased -et pt -d ../../data/$data_pt/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/tools/AutoPhrase\n"
     ]
    }
   ],
   "source": [
    "# change directory to autophrase\n",
    "%cd $base_dir/src/tools/AutoPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corel = 'sample-indeeda-corel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2021-07-07 00:47:48,693 : INFO : loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2021-07-07 00:47:49,035 : INFO : loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ubuntu/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2021-07-07 00:47:49,036 : INFO : Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2021-07-07 00:47:49,353 : INFO : loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/ubuntu/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "Traceback (most recent call last):\n",
      "  File \"extractBertEmbedding.py\", line 86, in <module>\n",
      "    with open(inputFilePath, \"r\") as fin:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../../../data/sample-indeeda-corel/intermediate//sent_segmentation.txt'\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python extractBertEmbedding.py ../../../data/$data_corel/intermediate/ $thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add embeddings for seed instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences.json')\n",
    "# seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "\n",
    "# orig_bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed.txt')\n",
    "# orig_bert_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum.txt')\n",
    "\n",
    "# new_bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "# new_bert_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed instances: ['walmart', 'amazon', 'subway', 'microsoft', 'target', 'business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings', 'delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher', 'weekly', 'biweekly', 'friday', 'saturday', 'health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'base pay', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'direct deposit', 'prepaid card', 'drug test', 'criminal background check', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors', 'hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting', 'night shift', 'dinner shift', 'early morning shift', '8 hour shift', 'christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "New instances: ['uniform', 'hair color', 'tattoos', 'shoes', 'cashier', 'weekly', 'biweekly', 'friday', 'saturday', '401k', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'pregnant', 'students', 'seniors', '8 hour shift', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'training', 'team lunch']\n",
      "loading corpus: 100%|████████████████| 901796/901796 [00:18<00:00, 48709.84it/s]\n",
      "computing entity-wise embedding: 100%|██████████| 36/36 [00:18<00:00,  1.90it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "# Using script\n",
    "\n",
    "!python add_seed_instances_embeddings.py -m bert-base-uncased -et ac -d $base_dir/data/$data_ac/intermediate -b $base_dir/data/indeed-benchmark -c 750\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Seed Entities (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "#change to concept learning directory\n",
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn sentence-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 100\n",
    "output = '../../data/'+data_ac+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|██████████████| 8028/8028 [00:01<00:00, 6489.66it/s]\n",
      "finding nearest neighbors by entity: 100%|█| 8028/8028 [00:17<00:00, 449.07it/s]\n"
     ]
    }
   ],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_ac/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit here: /meg_shared_scripts/meg-kb/src/analysis/concept_learning-test.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed instances clustering\n",
    "(using all seed instances of a concept to find neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "# seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "# seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "# concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_{cluster_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|██████████████| 8064/8064 [00:01<00:00, 6412.04it/s]\n",
      "finding nearest neighbors by concept: 14it [00:00, 334.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "# cluster_size = 100\n",
    "!python compute_concept_seeds_knn.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-s 100 \\\n",
    "--kdt \\\n",
    "-o $base_dir/data/$data_ac/intermediate/concept_knn_100.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity expansion evaluation\n",
    "Now using benchmark entities, mean reciprocal rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "# seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "# benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "# concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: company / company\n",
      "seeds: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "{\n",
      "    \"united states postal service\": NaN,\n",
      "    \"wendys\": NaN,\n",
      "    \"whataburger\": NaN,\n",
      "    \"marriott international, inc.\": NaN,\n",
      "    \"geico\": 30,\n",
      "    \"foot locker\": NaN,\n",
      "    \"the wendy's company\": NaN,\n",
      "    \"mcdonald\": NaN,\n",
      "    \"home depot\": 5,\n",
      "    \"allied universal security services, systems and solutions\": NaN,\n",
      "    \"goodwill industries\": NaN,\n",
      "    \"american eagle outfitters\": NaN,\n",
      "    \"chipotle mexican grill\": NaN,\n",
      "    \"chick-fil-a\": NaN,\n",
      "    \"heb\": NaN,\n",
      "    \"sonic drive-in\": NaN,\n",
      "    \"frito\": NaN,\n",
      "    \"jcpenney\": 21,\n",
      "    \"aldi\": NaN,\n",
      "    \"electric\": NaN,\n",
      "    \"pepsi\": 39,\n",
      "    \"sitel\": 42,\n",
      "    \"cvs health\": NaN,\n",
      "    \"dick's sporting goods\": NaN,\n",
      "    \"costco wholesale\": NaN,\n",
      "    \"burlington stores\": NaN,\n",
      "    \"dd\": 84,\n",
      "    \"olive garden\": 12,\n",
      "    \"fedex\": 36,\n",
      "    \"dunkin donuts\": 43,\n",
      "    \"primark\": NaN,\n",
      "    \"best buy\": 13,\n",
      "    \"frito lay\": 33,\n",
      "    \"marshalls\": 35,\n",
      "    \"domino's\": NaN,\n",
      "    \"tim hortons\": NaN,\n",
      "    \"mcdonald's\": NaN,\n",
      "    \"subways\": NaN,\n",
      "    \"chipotle\": 34,\n",
      "    \"t.j. maxx\": NaN,\n",
      "    \"walmart\": -1,\n",
      "    \"hobby lobby\": 73,\n",
      "    \"panera bread\": 11,\n",
      "    \"amazon.com\": NaN,\n",
      "    \"petsmart\": 40,\n",
      "    \"concentrix\": NaN,\n",
      "    \"applebee's\": NaN,\n",
      "    \"target\": -1,\n",
      "    \"the home depot\": NaN,\n",
      "    \"sam's club\": NaN,\n",
      "    \"tj maxx\": 49,\n",
      "    \"verizon\": 38,\n",
      "    \"little caesars\": 74,\n",
      "    \"family dollar\": 15,\n",
      "    \"amazon\": -1,\n",
      "    \"pizza hut\": 9,\n",
      "    \"menards\": 24,\n",
      "    \"ulta\": NaN,\n",
      "    \"quiktrip\": NaN,\n",
      "    \"kfc\": 19,\n",
      "    \"t-mobile\": NaN,\n",
      "    \"fedex ground\": NaN,\n",
      "    \"cracker barrel\": 20,\n",
      "    \"panera\": NaN,\n",
      "    \"at&t\": 41,\n",
      "    \"planet fitness\": 65,\n",
      "    \"kroger stores\": NaN,\n",
      "    \"dollar tree\": 17,\n",
      "    \"chili's\": NaN,\n",
      "    \"chilis\": NaN,\n",
      "    \"wells fargo\": 50,\n",
      "    \"costco\": 2,\n",
      "    \"doordash\": NaN,\n",
      "    \"taco bell\": 37,\n",
      "    \"enterprise holdings\": NaN,\n",
      "    \"ups\": NaN,\n",
      "    \"teleperformance\": NaN,\n",
      "    \"frito-lay\": NaN,\n",
      "    \"safeway\": 22,\n",
      "    \"pepsico\": 53,\n",
      "    \"spectrum\": 18,\n",
      "    \"publix\": 8,\n",
      "    \"lowe's\": NaN,\n",
      "    \"subway\": -1,\n",
      "    \"alorica\": NaN,\n",
      "    \"kohl's\": NaN,\n",
      "    \"barnes & noble\": NaN,\n",
      "    \"walgreens\": 6,\n",
      "    \"instacart\": NaN,\n",
      "    \"old navy\": 16,\n",
      "    \"ross dress for less\": NaN,\n",
      "    \"lowes\": NaN,\n",
      "    \"mcdonalds\": 14,\n",
      "    \"whole foods market\": NaN,\n",
      "    \"victoria's secret\": NaN,\n",
      "    \"kroger\": 7,\n",
      "    \"macy's\": NaN,\n",
      "    \"training\": 92,\n",
      "    \"dollar general\": 3,\n",
      "    \"dunkin' donuts\": NaN,\n",
      "    \"burger king\": 32,\n",
      "    \"g4s\": 44,\n",
      "    \"ihop\": 26,\n",
      "    \"starbucks\": 10,\n",
      "    \"cvs\": 25\n",
      "}\n",
      "MRR: 0.03034062040121059\n",
      "\n",
      "Concept: dress_code / dress code\n",
      "seeds: ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\n",
      "{\n",
      "    \"natural colors\": 78,\n",
      "    \"strict dress code\": 48,\n",
      "    \"color hair\": 35,\n",
      "    \"resistant shoes\": NaN,\n",
      "    \"black jeans\": NaN,\n",
      "    \"attire\": NaN,\n",
      "    \"professional\": 21,\n",
      "    \"dress shirts\": NaN,\n",
      "    \"uniforms\": NaN,\n",
      "    \"casual\": NaN,\n",
      "    \"wear shorts\": NaN,\n",
      "    \"facial hair\": -1,\n",
      "    \"natural colored hair\": NaN,\n",
      "    \"shirt\": NaN,\n",
      "    \"non slip shoes\": NaN,\n",
      "    \"dress pants\": NaN,\n",
      "    \"colorful hair\": 62,\n",
      "    \"shirts\": NaN,\n",
      "    \"brown pants\": NaN,\n",
      "    \"uniform\": -1,\n",
      "    \"skirts\": NaN,\n",
      "    \"hats\": NaN,\n",
      "    \"hair color\": -1,\n",
      "    \"scrubs\": 58,\n",
      "    \"wear fake nails\": NaN,\n",
      "    \"business casual\": -1,\n",
      "    \"hair colors\": NaN,\n",
      "    \"uniform shirts\": NaN,\n",
      "    \"casual dress code\": NaN,\n",
      "    \"lab coats\": NaN,\n",
      "    \"unnatural colored hair\": NaN,\n",
      "    \"hat\": NaN,\n",
      "    \"facial piercings\": 3,\n",
      "    \"nose rings\": 9,\n",
      "    \"red shirts\": NaN,\n",
      "    \"unnatural hair colors\": NaN,\n",
      "    \"jewelry\": NaN,\n",
      "    \"hair net\": NaN,\n",
      "    \"black slacks\": NaN,\n",
      "    \"wear jeans\": NaN,\n",
      "    \"shoes\": -1,\n",
      "    \"black pants\": NaN,\n",
      "    \"pants\": NaN,\n",
      "    \"polo shirts\": NaN,\n",
      "    \"blue collar\": NaN,\n",
      "    \"ponytail\": NaN,\n",
      "    \"face tattoos\": NaN,\n",
      "    \"fake nails\": 8,\n",
      "    \"jeans\": NaN,\n",
      "    \"mustaches\": NaN,\n",
      "    \"piercings\": -1,\n",
      "    \"uniform policy\": 23,\n",
      "    \"shorts\": NaN,\n",
      "    \"unnatural hair color\": NaN,\n",
      "    \"hairnets\": NaN\n",
      "}\n",
      "MRR: 0.015431376310749824\n",
      "\n",
      "Concept: job_position / job position\n",
      "seeds: ['delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher']\n",
      "{\n",
      "    \"cashier\": -1,\n",
      "    \"servers\": NaN,\n",
      "    \"truck drivers\": NaN,\n",
      "    \"server\": NaN,\n",
      "    \"shift leader\": 10\n",
      "}\n",
      "MRR: 0.025\n",
      "\n",
      "Concept: pay_schedule / pay period\n",
      "seeds: ['weekly', 'biweekly', 'friday', 'saturday']\n",
      "{\n",
      "    \"friday\": -1,\n",
      "    \"paid weekly\": NaN,\n",
      "    \"tuesday\": NaN,\n",
      "    \"weeks\": NaN,\n",
      "    \"paid biweekly\": NaN,\n",
      "    \"bi weekly\": 3,\n",
      "    \"fridays\": NaN,\n",
      "    \"paid bi weekly\": NaN,\n",
      "    \"week\": NaN,\n",
      "    \"tuesdays\": NaN,\n",
      "    \"biweekly\": -1,\n",
      "    \"weekly\": -1\n",
      "}\n",
      "MRR: 0.037037037037037035\n",
      "\n",
      "Concept: benefits / benefits\n",
      "seeds: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "{\n",
      "    \"health plans\": NaN,\n",
      "    \"401 k\": NaN,\n",
      "    \"breakfast\": NaN,\n",
      "    \"health care\": 2,\n",
      "    \"relocation\": NaN,\n",
      "    \"relocate\": NaN,\n",
      "    \"vacation\": NaN,\n",
      "    \"healthcare\": 1,\n",
      "    \"retirement plan\": 74,\n",
      "    \"sick leave\": -1,\n",
      "    \"paid vacations\": 65,\n",
      "    \"health benefits\": NaN,\n",
      "    \"health insurance\": -1,\n",
      "    \"pto\": NaN,\n",
      "    \"free lunch\": NaN,\n",
      "    \"prescription drugs\": NaN,\n",
      "    \"discounts\": NaN,\n",
      "    \"life insurance\": 8,\n",
      "    \"monthly bonus\": NaN,\n",
      "    \"health\": 7,\n",
      "    \"401k\": -1,\n",
      "    \"tuition assistance\": NaN,\n",
      "    \"discount\": NaN,\n",
      "    \"health coverage\": NaN,\n",
      "    \"retirement\": NaN,\n",
      "    \"pension\": 63,\n",
      "    \"401k plan\": NaN,\n",
      "    \"schooling\": NaN,\n",
      "    \"vacations\": NaN,\n",
      "    \"sick days\": 10\n",
      "}\n",
      "MRR: 0.07083808472697362\n",
      "\n",
      "Concept: compensation / compensation\n",
      "seeds: ['base pay', 'stock options', 'benefits', 'overtime pay', 'bonus']\n",
      "{\n",
      "    \"benfits\": NaN,\n",
      "    \"compensation\": NaN,\n",
      "    \"benefits\": -1\n",
      "}\n",
      "MRR: 0.0\n",
      "\n",
      "Concept: payment_option / nan\n",
      "seeds: ['checks', 'direct deposit', 'prepaid card']\n",
      "{\n",
      "    \"direct deposit\": -1,\n",
      "    \"prepaid card\": -1,\n",
      "    \"paper checks\": NaN,\n",
      "    \"checks\": -1,\n",
      "    \"direct deposits\": 13,\n",
      "    \"paycheck\": 14\n",
      "}\n",
      "MRR: 0.04945054945054945\n",
      "\n",
      "Concept: background_screening / background screening\n",
      "seeds: ['drug test', 'criminal background check', 'employment verification']\n",
      "{\n",
      "    \"previous employment\": 34,\n",
      "    \"follicle test\": NaN,\n",
      "    \"backround\": NaN,\n",
      "    \"criminal background check\": -1,\n",
      "    \"drug screens\": NaN,\n",
      "    \"drug text\": NaN,\n",
      "    \"saliva test\": NaN,\n",
      "    \"screen\": NaN,\n",
      "    \"backgrounds\": NaN,\n",
      "    \"mouth swab\": NaN,\n",
      "    \"pre employment drug screening\": NaN,\n",
      "    \"saliva drug test\": NaN,\n",
      "    \"random drug test\": 80,\n",
      "    \"mouth\": NaN,\n",
      "    \"drug\": 77,\n",
      "    \"hair sample\": NaN,\n",
      "    \"hair follicle test\": NaN,\n",
      "    \"background check\": 14,\n",
      "    \"dui\": 29,\n",
      "    \"driving record\": 6,\n",
      "    \"random tests\": NaN,\n",
      "    \"credit score\": NaN,\n",
      "    \"screening\": NaN,\n",
      "    \"social media\": 54,\n",
      "    \"criminal backgrounds\": NaN,\n",
      "    \"social security\": NaN,\n",
      "    \"swab test\": NaN,\n",
      "    \"urine sample\": NaN,\n",
      "    \"backround checks\": NaN,\n",
      "    \"credit checks\": NaN,\n",
      "    \"drug test\": -1,\n",
      "    \"urine drug screen\": NaN,\n",
      "    \"background report\": NaN,\n",
      "    \"urine testing\": NaN,\n",
      "    \"screening process\": NaN,\n",
      "    \"social security number\": 50,\n",
      "    \"previously worked\": NaN,\n",
      "    \"saliva\": NaN,\n",
      "    \"backround check\": NaN,\n",
      "    \"background checks\": NaN,\n",
      "    \"cheek swab\": NaN,\n",
      "    \"drug screened\": NaN,\n",
      "    \"criminal records\": NaN,\n",
      "    \"random drug tests\": 75,\n",
      "    \"criminal record\": 10,\n",
      "    \"previous jobs\": NaN,\n",
      "    \"urine\": NaN,\n",
      "    \"mouth swabs\": NaN,\n",
      "    \"urine tests\": NaN,\n",
      "    \"credit history\": 89,\n",
      "    \"test\": 11,\n",
      "    \"drug screen\": NaN,\n",
      "    \"testing\": NaN,\n",
      "    \"blood test\": NaN,\n",
      "    \"credit check\": 18,\n",
      "    \"criminal history\": 1,\n",
      "    \"previous employer\": NaN,\n",
      "    \"criminal background\": 8,\n",
      "    \"drug testing\": NaN,\n",
      "    \"previous employers\": NaN,\n",
      "    \"urine test\": NaN,\n",
      "    \"alcohol\": NaN,\n",
      "    \"drug tests\": 82,\n",
      "    \"cannabis\": NaN,\n",
      "    \"drugged tested\": NaN,\n",
      "    \"random drug testing\": NaN,\n",
      "    \"drug tested\": NaN,\n",
      "    \"urine drug test\": NaN,\n",
      "    \"drugs\": 40,\n",
      "    \"mouth swap\": NaN,\n",
      "    \"drug screening\": NaN,\n",
      "    \"credit report\": 63,\n",
      "    \"criminal background checks\": NaN\n",
      "}\n",
      "MRR: 0.025564751628249806\n",
      "\n",
      "Concept: person / nan\n",
      "seeds: ['felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors']\n",
      "{\n",
      "    \"ex felons\": 50,\n",
      "    \"pregnant\": -1,\n",
      "    \"school students\": NaN,\n",
      "    \"senior citizens\": 57,\n",
      "    \"high school\": 55,\n",
      "    \"disabilities\": NaN,\n",
      "    \"felonies\": 44,\n",
      "    \"disabled\": -1,\n",
      "    \"high school graduate\": NaN,\n",
      "    \"felonys\": NaN,\n",
      "    \"misdemeanor\": -1,\n",
      "    \"felony\": NaN,\n",
      "    \"misdemeanor charges\": NaN,\n",
      "    \"schoolers\": NaN,\n",
      "    \"felons\": -1,\n",
      "    \"criminals\": -1,\n",
      "    \"pregnant women\": 25,\n",
      "    \"seniors\": -1,\n",
      "    \"convicted felons\": NaN,\n",
      "    \"sex offenders\": NaN,\n",
      "    \"misdemeanor theft\": NaN,\n",
      "    \"felony record\": NaN,\n",
      "    \"seniority\": NaN,\n",
      "    \"high schoolers\": -1,\n",
      "    \"high school students\": NaN\n",
      "}\n",
      "MRR: 0.006580719475456318\n",
      "\n",
      "Concept: hire_prerequisite / qualification\n",
      "seeds: ['hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting']\n",
      "{\n",
      "    \"diploma\": 76,\n",
      "    \"degrees\": NaN,\n",
      "    \"high school diploma\": NaN,\n",
      "    \"high school education\": NaN,\n",
      "    \"gpa\": NaN,\n",
      "    \"hs diploma\": NaN,\n",
      "    \"workers permit\": NaN,\n",
      "    \"birth certificate\": NaN,\n",
      "    \"college degree\": 97,\n",
      "    \"working permit\": -1,\n",
      "    \"ged\": NaN,\n",
      "    \"bachelor degree\": NaN\n",
      "}\n",
      "MRR: 0.0021333793715779606\n",
      "\n",
      "Concept: shifts / work shift\n",
      "seeds: ['night shift', 'dinner shift', 'early morning shift', '8 hour shift']\n",
      "{\n",
      "    \"night shifts\": 10,\n",
      "    \"3rd shift\": 37,\n",
      "    \"12 hour shifts\": 17,\n",
      "    \"open 24 hours\": NaN,\n",
      "    \"weekend shift\": 12\n",
      "}\n",
      "MRR: 0.05383677795442501\n",
      "\n",
      "Concept: schedule / nan\n",
      "seeds: ['christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend']\n",
      "{\n",
      "    \"early morning\": -1,\n",
      "    \"weekends\": NaN,\n",
      "    \"open 7 days\": NaN,\n",
      "    \"federal holidays\": NaN,\n",
      "    \"christmas eve\": -1,\n",
      "    \"sunday\": -1,\n",
      "    \"saturday\": -1,\n",
      "    \"saturdays\": NaN,\n",
      "    \"hoildays\": NaN,\n",
      "    \"weekend\": -1\n",
      "}\n",
      "MRR: 0.0\n",
      "\n",
      "Concept: employee_type / nan\n",
      "seeds: ['full time', 'part time', 'seasonal']\n",
      "{\n",
      "    \"seasonal positions\": NaN,\n",
      "    \"seasonals\": NaN,\n",
      "    \"ft\": NaN,\n",
      "    \"fulltime\": NaN,\n",
      "    \"seasonal\": -1,\n",
      "    \"season\": NaN,\n",
      "    \"seasons\": NaN,\n",
      "    \"seasonal workers\": 64,\n",
      "    \"seasonal employees\": 10\n",
      "}\n",
      "MRR: 0.014453125\n",
      "\n",
      "Concept: onboarding_steps / onboarding process steps\n",
      "seeds: ['orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "{\n",
      "    \"training program\": NaN,\n",
      "    \"training classes\": 38,\n",
      "    \"orientation\": -1,\n",
      "    \"training\": -1\n",
      "}\n",
      "MRR: 0.013157894736842105\n",
      "\n",
      "--- Summary ---\n",
      "{\n",
      "  \"company\": 0.03034062040121059,\n",
      "  \"dress_code\": 0.015431376310749824,\n",
      "  \"job_position\": 0.025,\n",
      "  \"pay_schedule\": 0.037037037037037035,\n",
      "  \"benefits\": 0.07083808472697362,\n",
      "  \"compensation\": 0.0,\n",
      "  \"payment_option\": 0.04945054945054945,\n",
      "  \"background_screening\": 0.025564751628249806,\n",
      "  \"person\": 0.006580719475456318,\n",
      "  \"hire_prerequisite\": 0.0021333793715779606,\n",
      "  \"shifts\": 0.05383677795442501,\n",
      "  \"schedule\": 0.0,\n",
      "  \"employee_type\": 0.014453125,\n",
      "  \"onboarding_steps\": 0.013157894736842105\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "!python eval_entities.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/concept_knn_100.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Extraction Baselines\n",
    "Currently only for single relation. TODO: include all relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null baseline - Cartesian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "# seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "# seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "# seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "# # knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/knn_{cluster_size}.csv')\n",
    "# concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "\n",
    "# relation = 'has_benefits'\n",
    "# cartesian_re_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_cartesian-{relation}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company \t pay_schedule\r\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\r\n",
      "seed_tails: ['weekly', 'biweekly', 'friday', 'saturday']\r\n",
      "cand_heads: ('walmart', 'amazon', 'subway', 'microsoft', 'target', 'wal mart', 'costco', 'dollar general', 'apple', 'home depot', 'walgreens', 'kroger', 'publix', 'pizza hut', 'starbucks', 'panera bread', 'olive garden', 'best buy', 'mcdonalds', 'family dollar', 'old navy', 'dollar tree', 'spectrum', 'kfc', 'cracker barrel', 'jcpenney', 'safeway', 'whole foods', 'menards', 'cvs', 'ihop', 'center', 'burlington', \"sam 's club\", 'geico', 'usps', 'burger king', 'frito lay', 'chipotle', 'marshalls', 'fedex', 'taco bell', 'verizon', 'pepsi', 'petsmart', 'at&t', 'sitel', 'dunkin donuts', 'g4s', 'company', 'warehouse', 'jcp', 'retail', 'tj maxx', 'wells fargo', 'pharmacy', 'post office', 'pepsico', 'management', \"macy 's\", 't mobile', 'chick fil a', 'call center', 'union', 'cashier', 'department', 'home office', 'asset protection', 'corporate office', 'planet fitness', 'area', 'door dash', 'hotel', 'manager', 'restaurant', 'business', 'america', 'hobby lobby', 'little caesars', \"mcdonald 's\", 'general manager', 'house', 'postal service', 'military', 'ad', 'fed ex', 'seasonal', 'insurance', 'dd', 'fulfillment center', 'school', 'gm', 'previous experience', 'ap', 'city', 'security', 'training', 'family', 'loss prevention', 'delivery driver', 'private', 'dc')\r\n",
      "cand_tails: ('weekly', 'biweekly', 'friday', 'saturday', 'sunday', 'weekend', 'bi weekly', 'night shift', '3rd shift', 'pay period', 'paycheck', 'direct deposit', 'payday', 'holiday pay', 'lunch break', 'burger king', 'night shifts', 'part time', '30 mins', 'minimum wage', 'morning shift', '7 days', '8 hour shifts', 'sun', '40 hrs', '30 minutes', 'peak season', 'sick days', '12 hour shifts', 'burlington', '8 hour shift', 'night maintenance', 'full time', 'overnight shift', 'bonus', 'pay periods', 'every other friday', 'mandatory', 'christmas', 'morning shifts', 'six months', 'taco bell', 'evening shift', 'season', 'witch', 'early morning', 'graveyard shift', 'third shift', 'seasonal', 'dollar tree', 'kfc', '6 months', 'hourly rate', '90 days', 'free food', 'open interviews', '2nd shift', 'health insurance', 'm f', \"mcdonald 's\", 'closing shift', 'freight team', 'dunkin donuts', 'monday morning', 'pay rate', 'base pay', 'pay cycle', 'peak', 'training', 'sat', 'orientation', '30 min', 'split', 'paid vacation', 'cracker barrel', 'min wage', 'hourly wage', 'hourly pay', 'burger kings', 'late night', 'mid shift', 'free', 'sales associates', 'family dollar', 'tim hortons', 'overnight stockers', 'benefits', 'probation', 'seasonal employees', 'insurance', 'holiday season', 'seasonal workers', 'ihop', 'warehouse', 'maternity leave', 'olive garden', 'lunch breaks', 'road', 'hourly associates', 'flexible schedule', 'card')\r\n"
     ]
    }
   ],
   "source": [
    "!python relation_extraction_cartesian.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_pay_schedule-RE=Ct.csv \\\n",
    "-r has_pay_schedule \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_100.csv\n",
    "# -topk 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company \t background_screening\r\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\r\n",
      "seed_tails: ['drug test', 'criminal background check', 'employment verification']\r\n",
      "cand_heads: ('walmart', 'amazon', 'subway', 'microsoft', 'target', 'wal mart', 'costco', 'dollar general', 'apple', 'home depot', 'walgreens', 'kroger', 'publix', 'pizza hut', 'starbucks', 'panera bread', 'olive garden', 'best buy', 'mcdonalds', 'family dollar', 'old navy', 'dollar tree', 'spectrum', 'kfc', 'cracker barrel', 'jcpenney', 'safeway', 'whole foods', 'menards', 'cvs', 'ihop', 'center', 'burlington', \"sam 's club\", 'geico', 'usps', 'burger king', 'frito lay', 'chipotle', 'marshalls', 'fedex', 'taco bell', 'verizon', 'pepsi', 'petsmart', 'at&t', 'sitel', 'dunkin donuts', 'g4s', 'company', 'warehouse', 'jcp', 'retail', 'tj maxx', 'wells fargo', 'pharmacy', 'post office', 'pepsico', 'management', \"macy 's\", 't mobile', 'chick fil a', 'call center', 'union', 'cashier', 'department', 'home office', 'asset protection', 'corporate office', 'planet fitness', 'area', 'door dash', 'hotel', 'manager', 'restaurant', 'business', 'america', 'hobby lobby', 'little caesars', \"mcdonald 's\", 'general manager', 'house', 'postal service', 'military', 'ad', 'fed ex', 'seasonal', 'insurance', 'dd', 'fulfillment center', 'school', 'gm', 'previous experience', 'ap', 'city', 'security', 'training', 'family', 'loss prevention', 'delivery driver', 'private', 'dc')\r\n",
      "cand_tails: ('drug test', 'criminal background check', 'employment verification', 'criminal history', 'fingerprints', 'employment', 'ap', 'background screening', 'driving record', 'police', 'criminal background', 'back ground check', 'criminal record', 'test', 'back round check', 'felony', 'background check', 'ua', 'government', 'application process', 'credit check', 'back ground', 'property', 'past employment', 'state', 'job offer', 'home depot', \"macy 's\", 'ad', 'assessment test', 'dmv', 'dui', 'g4s', 'wal mart', 'private', '3rd party', 'previous employment', 'military', 'potential employees', 'extensive background check', 'history', 'bankruptcy', 'drugs', 'criminal back ground', 'law', 'prescription drugs', 'checks', 'jcp', 'report', 'tj maxx', 'driving records', 'center', 'social security number', 'fed ex', 'manager', 'felonies', 'social media', 'cash office', 'usps', 'company', 'information', 'theft', 'little caesars', 'previous experience', 'verizon', 'credit report', 'motor vehicle', 'home office', 'planet fitness', 'misdemeanor', 'red flag', 'tests', 'pizza hut', 'old navy', 'walmart', 'urinalysis', 'results', 'random drug tests', 'mail', 'drug', 'spectrum', 'dollar general', 'random drug test', 'job description', 'drug tests', 'pass', 'carrier', 'drivers license', 'general manager', 'dollar generals', 'initial interview', 'credit history', 'contract', 'frito lay', 'paper', 'medical marijuana', 'security', 'pepsi', 'finger printing', 'county', 'fir')\r\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_cartesian.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_background_screening-RE=Ct.csv \\\n",
    "-r has_background_screening \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_100.csv\n",
    "# -topk 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction - scores weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "# seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "# # knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/knn_{cluster_size}.csv')\n",
    "# concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_100.csv')\n",
    "# bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "\n",
    "# templates_path = 'templates_manual.json'\n",
    "\n",
    "# extraction_save_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "company \t benefits\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "100%|█████████████████████████████████████████| 102/102 [00:37<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_avg_scores.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=avg.csv \\\n",
    "-r has_benefits \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_100.csv \\\n",
    "-dim 768\n",
    "# -topk 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "company \t dress_code\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\n",
      "100%|█████████████████████████████████████████| 102/102 [00:30<00:00,  3.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_avg_scores.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=avg.csv \\\n",
    "-r has_dress_code \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_100.csv \\\n",
    "-dim 768\n",
    "# -topk 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Verification baseline\n",
    "(finding co-occurrences of head / tail from corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Finding evidence for rels: 100%|████████| 10302/10302 [1:11:38<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-in $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=Ct.csv \\\n",
    "-o_kv $base_dir/data/$data_ac/intermediate/kv_evidences-has_dress_code-RE=Ct.json \\\n",
    "-o_re $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=Ct+KV=0.9.csv \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p_kv 0.7 \\\n",
    "-p_re 0.9 \\\n",
    "--fast_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Finding evidence for rels: 100%|██████████████| 300/300 [01:58<00:00,  2.52it/s]\n"
     ]
    }
   ],
   "source": [
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-in $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=avg.csv \\\n",
    "-o_kv $base_dir/data/$data_ac/intermediate/kv_evidences-has_dress_code-RE=avg.json \\\n",
    "-o_re $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=avg+KV=0.9.csv \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p_kv 0.7 \\\n",
    "-p_re 0.9 \\\n",
    "--fast_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Finding evidence for rels: 100%|████████| 10404/10404 [2:20:15<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-in $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=Ct.csv \\\n",
    "-o_kv $base_dir/data/$data_ac/intermediate/kv_evidences-has_benefits-RE=Ct.json \\\n",
    "-o_re $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=Ct+KV=0.9.csv \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p_kv 0.7 \\\n",
    "-p_re 0.9 \\\n",
    "--fast_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Finding evidence for rels: 100%|██████████████| 300/300 [02:53<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-in $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=avg.csv \\\n",
    "-o_kv $base_dir/data/$data_ac/intermediate/kv_evidences-has_benefits-RE=avg.json \\\n",
    "-o_re $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=avg+KV=0.9.csv \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p_kv 0.7 \\\n",
    "-p_re 0.9 \\\n",
    "--fast_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## has_pay_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Finding evidence for rels: 100%|████████| 10302/10302 [1:33:26<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-in $base_dir/data/$data_ac/intermediate/rel_extraction-has_pay_schedule-RE=Ct.csv \\\n",
    "-o_kv $base_dir/data/$data_ac/intermediate/kv_evidences-has_pay_schedule-RE=Ct.json \\\n",
    "-o_re $base_dir/data/$data_ac/intermediate/rel_extraction-has_pay_schedule-RE=Ct+KV=0.9.csv \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p_kv 0.7 \\\n",
    "-p_re 0.9 \\\n",
    "--fast_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## has_background_screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Finding evidence for rels: 100%|████████| 10302/10302 [7:21:16<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-in $base_dir/data/$data_ac/intermediate/rel_extraction-has_background_screening-RE=Ct.csv \\\n",
    "-o_kv $base_dir/data/$data_ac/intermediate/kv_evidences-has_background_screening-RE=Ct.json \\\n",
    "-o_re $base_dir/data/$data_ac/intermediate/rel_extraction-has_background_screening-RE=Ct+KV=0.9.csv \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p_kv 0.7 \\\n",
    "-p_re 0.9 \\\n",
    "--fast_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline Evaluation (on relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 107\r\n",
      "Predicted relations: 10302\r\n",
      "Intersection: 15\r\n",
      "P = 0.0015, R = 0.1402, F1 = 0.0029\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('at&t', 'has_dress_code', 'uniform')\r\n",
      "('best buy', 'has_dress_code', 'uniform')\r\n",
      "('costco', 'has_dress_code', 'hair color')\r\n",
      "('dd', 'has_dress_code', 'facial hair')\r\n",
      "('dollar general', 'has_dress_code', 'strict dress code')\r\n",
      "('dollar tree', 'has_dress_code', 'professional')\r\n",
      "('dollar tree', 'has_dress_code', 'uniform')\r\n",
      "('family dollar', 'has_dress_code', 'facial hair')\r\n",
      "('jcpenney', 'has_dress_code', 'uniform policy')\r\n",
      "('marshalls', 'has_dress_code', 'color hair')\r\n",
      "('olive garden', 'has_dress_code', 'facial hair')\r\n",
      "('subway', 'has_dress_code', 'piercings')\r\n",
      "('taco bell', 'has_dress_code', 'nose rings')\r\n",
      "('walgreens', 'has_dress_code', 'hair color')\r\n",
      "('walmart', 'has_dress_code', 'uniform')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=Ct.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 107\r\n",
      "Predicted relations: 2052\r\n",
      "Intersection: 14\r\n",
      "P = 0.0068, R = 0.1308, F1 = 0.0130\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('at&t', 'has_dress_code', 'uniform')\r\n",
      "('best buy', 'has_dress_code', 'uniform')\r\n",
      "('costco', 'has_dress_code', 'hair color')\r\n",
      "('dd', 'has_dress_code', 'facial hair')\r\n",
      "('dollar tree', 'has_dress_code', 'professional')\r\n",
      "('dollar tree', 'has_dress_code', 'uniform')\r\n",
      "('family dollar', 'has_dress_code', 'facial hair')\r\n",
      "('jcpenney', 'has_dress_code', 'uniform policy')\r\n",
      "('marshalls', 'has_dress_code', 'color hair')\r\n",
      "('olive garden', 'has_dress_code', 'facial hair')\r\n",
      "('subway', 'has_dress_code', 'piercings')\r\n",
      "('taco bell', 'has_dress_code', 'nose rings')\r\n",
      "('walgreens', 'has_dress_code', 'hair color')\r\n",
      "('walmart', 'has_dress_code', 'uniform')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=Ct+KV=0.9.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 107\r\n",
      "Predicted relations: 300\r\n",
      "Intersection: 0\r\n",
      "P = 0.0000, R = 0.0000, F1 = 0.0000\r\n",
      "\r\n",
      "Intersection:\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=avg.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 10404\r\n",
      "Intersection: 9\r\n",
      "P = 0.0009, R = 0.1607, F1 = 0.0017\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('burger king', 'has_benefits', 'health')\r\n",
      "('burger king', 'has_benefits', 'sick leave')\r\n",
      "('dollar general', 'has_benefits', 'health insurance')\r\n",
      "('g4s', 'has_benefits', 'sick leave')\r\n",
      "('starbucks', 'has_benefits', 'health')\r\n",
      "('target', 'has_benefits', 'health insurance')\r\n",
      "('walmart', 'has_benefits', '401k')\r\n",
      "('walmart', 'has_benefits', 'life insurance')\r\n",
      "('walmart', 'has_benefits', 'paid vacations')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=Ct.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 3384\r\n",
      "Intersection: 9\r\n",
      "P = 0.0027, R = 0.1607, F1 = 0.0052\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('burger king', 'has_benefits', 'health')\r\n",
      "('burger king', 'has_benefits', 'sick leave')\r\n",
      "('dollar general', 'has_benefits', 'health insurance')\r\n",
      "('g4s', 'has_benefits', 'sick leave')\r\n",
      "('starbucks', 'has_benefits', 'health')\r\n",
      "('target', 'has_benefits', 'health insurance')\r\n",
      "('walmart', 'has_benefits', '401k')\r\n",
      "('walmart', 'has_benefits', 'life insurance')\r\n",
      "('walmart', 'has_benefits', 'paid vacations')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=Ct+KV=0.9.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 300\r\n",
      "Intersection: 0\r\n",
      "P = 0.0000, R = 0.0000, F1 = 0.0000\r\n",
      "\r\n",
      "Intersection:\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=avg.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussions:\n",
    "# coherence clustering / ensemble models?\n",
    "# trying for other relations or entities\n",
    "# using entities in sub-categories\n",
    "# fine-tuning\n",
    "# ambiguous samples (high for pos and neg)\n",
    "# quantitative-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore various techniques\n",
    "# Get prompts \"between\" entities\n",
    "# Get prompts by syntactic parsing\n",
    "# Get prompts by paraphrasing\n",
    "# Get prompts uisng AutoPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit here: /meg-kb/src/analysis/pattern_mining.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Prompt Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit here: /meg-kb/src/analysis/lm_probing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggest Quality Prompts"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_transformers_nikita)",
   "language": "python",
   "name": "conda_transformers_nikita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
