{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"/mnt/efs/shared/meg_shared_scripts/meg-kb\"\n",
    "data_ac=\"indeeda-meg-ac\"\n",
    "data_pt=\"indeeda-meg-pt\"\n",
    "yutong_base_dir=\"/home/ubuntu/users/yutong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, entropy, gmean\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "import logging\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from annoy import AnnoyIndex\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "\n",
    "\n",
    "from compute_concept_clusters import knn\n",
    "from compute_keyphrase_embeddings import ensure_tensor_on_device, mean_pooling\n",
    "\n",
    "from lm_probes import LMProbe, LMProbe_GPT2, LMProbe_Joint, LMProbe_PMI, LMProbe_PMI_greedy\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import get_masked_contexts, bert_untokenize\n",
    "from utils import learn_patterns\n",
    "\n",
    "from roberta_ses.interface import Roberta_SES_Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import get_masked_contexts, bert_untokenize\n",
    "from utils import learn_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: text corpus\n",
    "# step 1: extract key phrases (autophrase)\n",
    "# step 2: generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Key Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/keyword_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n"
     ]
    }
   ],
   "source": [
    "#change to keyword extractor directory\n",
    "%cd $base_dir/src/keyword_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./corpusProcess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dataset and thread no\n",
    "data_ac = 'indeeda-meg-ac'\n",
    "data_pt = 'indeeda-meg-pt'\n",
    "thread = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n",
      "\u001b[32m===Corpus Name: sample-indeeda-meg-ac===\u001b[m\n",
      "\u001b[32m===Current Path: /mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction===\u001b[m\n",
      "\u001b[32m===Cleaning input corpus===\u001b[m\n",
      "\u001b[32m===Running AutoPhrase===\u001b[m\n",
      "make: Nothing to be done for 'all'.\n",
      "\u001b[32m===RAW_TRAIN: ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt===\u001b[m\n",
      "auto_phrase.sh parameters: sample-indeeda-meg-ac ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt 10 data/EN/wiki_quality.txt 8\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m0.702s\n",
      "user\t0m1.668s\n",
      "sys\t0m0.100s\n",
      "Detected Language: EN\u001b[0K\n",
      "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
      "No provided expert labels.\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===AutoPhrasing===\u001b[m\n",
      "=== Current Settings ===\n",
      "Iterations = 2\n",
      "Minimum Support Threshold = 10\n",
      "Maximum Length Threshold = 6\n",
      "POS-Tagging Mode Disabled\n",
      "Discard Ratio = 0.050000\n",
      "Number of threads = 8\n",
      "Labeling Method = DPDN\n",
      "\tAuto labels from knowledge bases\n",
      "\tMax Positive Samples = -1\n",
      "=======\n",
      "Loading data...\n",
      "# of total tokens = 6553\n",
      "max word token id = 1450\n",
      "# of documents = 500\n",
      "# of distinct POS tags = 0\n",
      "Mining frequent phrases...\n",
      "selected MAGIC = 1451\n",
      "# of frequent phrases = 1483\n",
      "Extracting features...\n",
      "Constructing label pools...\n",
      "\tThe size of the positive pool = 192\n",
      "\tThe size of the negative pool = 1282\n",
      "# truth patterns = 1202\n",
      "Estimating Phrase Quality...\n",
      "0 32\n",
      "[ERROR] not enough training data found!\n",
      "Segmenting...\n",
      "Rectifying features...\n",
      "Estimating Phrase Quality...\n",
      "0 32\n",
      "[ERROR] not enough training data found!\n",
      "Segmenting...\n",
      "Dumping results...\n",
      "Done.\n",
      "\n",
      "real\t0m1.922s\n",
      "user\t0m2.496s\n",
      "sys\t0m0.016s\n",
      "\u001b[32m===Saving Model and Results===\u001b[m\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "phrasal_segmentation.sh parameters: sample-indeeda-meg-ac ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt 0.5 0.9 8\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m0.568s\n",
      "user\t0m1.396s\n",
      "sys\t0m0.108s\n",
      "Detected Language: EN\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===Phrasal Segmentation===\u001b[m\n",
      "=== Current Settings ===\n",
      "Segmentation Model Path = models/sample-indeeda-meg-ac/segmentation.model\n",
      "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
      "\tQ(multi-word phrases) >= 0.500000\n",
      "\tQ(single-word phrases) >= 0.900000\n",
      "=======\n",
      "Length penalty model loaded.\n",
      "\tpenalty = 199.805\n",
      "# of loaded patterns = 136\n",
      "# of loaded truth patterns = 1394\n",
      "Phrasal segmentation finished.\n",
      "   # of total highlighted quality phrases = 715\n",
      "   # of total processed sentences = 828\n",
      "   avg highlights per sentence = 0.863527\n",
      "\n",
      "real\t0m0.050s\n",
      "user\t0m0.016s\n",
      "sys\t0m0.000s\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "\u001b[32m===Generating Phrase Text===\u001b[m\n",
      "process_segmentation.py parameters: ../../../data/sample-indeeda-meg-ac/intermediate/ 0.5 0.9\n",
      "11.152\n",
      "\u001b[32m===Running NLP Feature Extraction===\u001b[m\n",
      "100%|███████████████████████████████████████████| 51/51 [00:00<00:00, 66.53it/s]\n",
      " 71%|██████████████████████████████▌            | 47/66 [00:00<00:00, 58.53it/s]Finish NLP processing, using time 0.8209497928619385 (second)\n",
      "100%|███████████████████████████████████████████| 57/57 [00:00<00:00, 65.72it/s]\n",
      " 80%|██████████████████████████████████▌        | 53/66 [00:00<00:00, 57.33it/s]Finish NLP processing, using time 0.9230477809906006 (second)\n",
      "100%|███████████████████████████████████████████| 62/62 [00:00<00:00, 70.06it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:00<00:00, 57.63it/s]\n",
      "Finish NLP processing, using time 0.9408359527587891 (second)\n",
      " 95%|████████████████████████████████████████▉  | 60/63 [00:00<00:00, 74.56it/s]Finish NLP processing, using time 0.8718316555023193 (second)\n",
      "100%|███████████████████████████████████████████| 66/66 [00:01<00:00, 62.34it/s]\n",
      "100%|███████████████████████████████████████████| 63/63 [00:00<00:00, 68.87it/s]\n",
      "Finish NLP processing, using time 1.1157433986663818 (second)\n",
      "100%|███████████████████████████████████████████| 76/76 [00:00<00:00, 80.52it/s]\n",
      "Finish NLP processing, using time 0.9821081161499023 (second)\n",
      "Finish NLP processing, using time 1.003368854522705 (second)\n",
      "100%|███████████████████████████████████████████| 79/79 [00:01<00:00, 76.95it/s]\n",
      "Finish NLP processing, using time 1.0861637592315674 (second)\n",
      "\u001b[32m===Clean unnecessary files===\u001b[m\n",
      "\u001b[32m===Key Term Extraction===\u001b[m\n",
      "Extract Key Terms from Corpus: 100%|███████| 694/694 [00:00<00:00, 24407.16it/s]\n",
      "\u001b[32m===Sentence-wise Entity Segmentation===\u001b[m\n",
      "loading corpus for word2vec training: 100%|█| 694/694 [00:00<00:00, 288117.09it/\n",
      "100%|███████████████████████████████████████| 94/94 [00:00<00:00, 431834.15it/s]\n",
      "100%|█████████████████████████████████████| 122/122 [00:00<00:00, 423947.88it/s]\n",
      "100%|█████████████████████████████████████| 118/118 [00:00<00:00, 377519.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# process corpus and generate key prhases\n",
    "!./corpusProcess.sh $data_ac $thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy these results to sample-meg-pt\n",
    "!cp -r ../../data/$data_ac ../../data/$data_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus with company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/question_answers.csv'\n",
    "company_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/fccid-companyName.csv'\n",
    "entity_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "out_corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8053"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(entity_emb_num_path, 'r') as f:\n",
    "    entities = [l.strip().rsplit(' ', 1)[0] for l in f.readlines()]\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv(dataset_path) \n",
    "df_dataset = df_dataset[df_dataset['answerContent'].notna()]\n",
    "df_company = pd.read_csv(company_path)\n",
    "\n",
    "df_merged_dataset = df_dataset.merge(df_company, how='inner', on='fccompanyId')\n",
    "df_merged_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307122, 11)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I, applied, online, and, submitted, all, attachments, that, I, could, .]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df_merged_dataset.iloc[1]\n",
    "_d = nlp(row[\"answerContent\"])\n",
    "list(_d.sents)\n",
    "list(list(_d.sents)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_corpus = []\n",
    "\n",
    "for i, row in df_merged_dataset.iterrows():\n",
    "    if i > 0 and i % 5000 == 0:\n",
    "        print(f'Progress: {i} / {df_merged_dataset.shape[0]}')\n",
    "    \n",
    "    company = row[\"companyName\"]\n",
    "    ans = row[\"answerContent\"]\n",
    "    ans_nlp = nlp(ans)\n",
    "    for sent in ans_nlp.sents:\n",
    "        sent_tok_list = [str(t) for t in sent]\n",
    "        _s = f' {company} : {\" \".join(sent_tok_list)} '.lower()\n",
    "        _ents = []\n",
    "        for _e in entities:\n",
    "            if f' {_e} ' in _s:\n",
    "                _ents.append(_e)\n",
    "        out_corpus.append({\n",
    "            \"tokens\": sent_tok_list,\n",
    "            \"company\": company,\n",
    "            \"entities\": _ents,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out_corpus), out_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_corpus_path, 'w') as f:\n",
    "    for d in out_corpus:\n",
    "        f.write(json.dumps(d) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lines: 100%|████████████████| 307122/307122 [11:51<00:00, 431.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "!python build_corpus_with_companies.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-rd /home/ubuntu/users/nikita/data/indeed/indeedQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "#change to concept learning directory\n",
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|█████████████████████| 694/694 [00:00<00:00, 194471.34it/s]\n",
      "computing entity-wise embedding: 100%|████████| 177/177 [00:03<00:00, 50.59it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!python compute_keyphrase_embeddings.py -m bert-base-uncased -et ac -d ../../data/$data_ac/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenated Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|█████████████████████| 694/694 [00:00<00:00, 191566.11it/s]\n",
      "computing entity-wise embedding: 100%|████████| 177/177 [00:03<00:00, 53.88it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!python compute_keyphrase_embeddings.py -m bert-base-uncased -et pt -d ../../data/$data_pt/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/tools/AutoPhrase\n"
     ]
    }
   ],
   "source": [
    "# change directory to autophrase\n",
    "%cd $base_dir/src/tools/AutoPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corel = 'sample-indeeda-corel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2021-06-18 00:36:18,384 : INFO : loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2021-06-18 00:36:18,776 : INFO : loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ubuntu/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2021-06-18 00:36:18,777 : INFO : Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2021-06-18 00:36:19,108 : INFO : loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/ubuntu/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "Traceback (most recent call last):\n",
      "  File \"extractBertEmbedding.py\", line 86, in <module>\n",
      "    with open(inputFilePath, \"r\") as fin:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../../../data/sample-indeeda-corel/intermediate//sent_segmentation.txt'\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python extractBertEmbedding.py ../../../data/$data_corel/intermediate/ $thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add embeddings for seed instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_masked_contexts_for_entities(entities, input_file):\n",
    "    \"\"\"Return a (list of) sentence(s) with entity replaced with MASK.\"\"\"\n",
    "    \"\"\"YS: input should be sentences.json\"\"\"\n",
    "    \n",
    "    ent_freq = {ent : 0 for ent in entities}\n",
    "    ent_context = {ent : [] for ent in entities}\n",
    "    \n",
    "    with open(input_file, \"r\") as fin:\n",
    "        lines = fin.readlines()\n",
    "        for line in tqdm(lines, total=len(lines), desc=\"loading corpus\"):\n",
    "            json_dict = json.loads(line)\n",
    "            sent = ' ' + ' '.join(json_dict['tokens']).lower() + ' '\n",
    "            #entities = [match.group(1) for match in re.finditer(pat, line)]\n",
    "            \n",
    "            for entity in entities:\n",
    "                pat = f' {entity} '\n",
    "                if pat not in sent:\n",
    "                    continue\n",
    "\n",
    "                context = sent.replace(pat, ' [MASK] ').strip()\n",
    "                c = context.split('[MASK]')\n",
    "                if len(c) != 2:  # sanity to not have too many repeating phrases in the context\n",
    "                    continue\n",
    "\n",
    "                # ignore too short contexts\n",
    "                if len(context) < 15:\n",
    "                    continue\n",
    "\n",
    "                # print(entity)\n",
    "                # print(context)\n",
    "                \n",
    "                _freq = ent_freq.get(entity, 0)\n",
    "                ent_freq[entity] = _freq + 1\n",
    "\n",
    "                context_lst = ent_context.get(entity, [])\n",
    "                context_lst.append(context)\n",
    "                ent_context[entity] = context_lst\n",
    "\n",
    "    dedup_context = {}\n",
    "    for e, v in ent_context.items():\n",
    "        dedup_context[e] = list(set(v))\n",
    "    return ent_freq, dedup_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_avg_context_embedding_for_entities(entities, model_path, input_file, max_context_ct):\n",
    "    '''\n",
    "    mean pooling from sentence-transformers\n",
    "    :param entity: List[str], the entities to compute embeddings for\n",
    "    :param model_path:\n",
    "    :param input_file:\n",
    "    :return:\n",
    "    '''\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "    ent_freq, ent_context = get_masked_contexts_for_entities(entities, input_file)\n",
    "    \n",
    "    entity_embeddings = {}\n",
    "    for entity, en_context_lst in tqdm(ent_context.items(), total=len(ent_context), desc=\"computing entity-wise embedding\"):\n",
    "#     for entity, en_context_lst in ent_context.items():\n",
    "        print(entity)\n",
    "        en_context_lst = random.sample(en_context_lst, min(len(en_context_lst), max_context_ct))\n",
    "        chunks = [en_context_lst[i:i + 100] for i in range(0, len(en_context_lst), 100)]\n",
    "        # print(entity)\n",
    "        # print(len(en_context_lst))\n",
    "        all_context_embeddings = []\n",
    "        for chunk in chunks:\n",
    "            encoded_input = tokenizer.batch_encode_plus(chunk, return_token_type_ids=True, add_special_tokens=True, max_length=128, return_tensors='pt', padding=True, pad_to_max_length=True, truncation=True)\n",
    "            mask = encoded_input['input_ids'] != mask_token_id\n",
    "            with torch.no_grad():\n",
    "                encoded_input = ensure_tensor_on_device(device, **encoded_input)\n",
    "                model_output = model(**encoded_input)  # Compute token embeddings\n",
    "            context_embeddings = mean_pooling(model_output, mask)  # mean pooling\n",
    "            all_context_embeddings.append(context_embeddings)\n",
    "            \n",
    "        assert len(all_context_embeddings) > 0\n",
    "            \n",
    "        entity_embedding = torch.mean(torch.cat(all_context_embeddings, dim=0), dim=0).cpu().detach().numpy().tolist()\n",
    "        entity_embeddings[entity] = entity_embedding\n",
    "    \n",
    "    return entity_embeddings, ent_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences.json')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "\n",
    "orig_bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed.txt')\n",
    "orig_bert_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum.txt')\n",
    "\n",
    "new_bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "new_bert_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "\n",
    "orig_emb_df = load_embeddings(bert_emb_path, 768)\n",
    "emb_dict = dict(zip(orig_emb_df['entity'].to_list(), orig_emb_df['embedding'].to_list()))\n",
    "\n",
    "with open(orig_bert_emb_num_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    emb_freq_dict = dict([l.strip().rsplit(' ', 1) for l in lines])\n",
    "\n",
    "concepts_df = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "seed_instances_list = [inst for _, (_a_con, _u_con, _gnrl, _seed_instances) in concepts_df.iterrows()\n",
    "                           for inst in _seed_instances]\n",
    "\n",
    "## debug\n",
    "seed_instances_list = seed_instances_list[::10]\n",
    "\n",
    "print(seed_instances_list)\n",
    "\n",
    "entity_embeddings, ent_freq = \\\n",
    "    get_avg_context_embedding_for_entities(entities=seed_instances_list, \n",
    "                                           model_path='bert-base-uncased',\n",
    "                                           input_file=corpus_path,\n",
    "                                           max_context_ct=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "for inst in seed_instances_list:\n",
    "    emb = entity_embeddings[inst]\n",
    "    freq = ent_freq[inst]\n",
    "    if inst in emb_dict:\n",
    "        print(f'Already exists: {inst}')\n",
    "#         assert np.allclose(emb_dict[inst], emb)\n",
    "#         assert emb_freq_dict[inst] == freq, f'{inst}: orig {emb_freq_dict[inst]} != new {freq}'\n",
    "#         print(f'Check passed: {inst}')\n",
    "    else:\n",
    "        emb_dict[inst] = emb\n",
    "        emb_freq_dict[inst] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "entity_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "with open(new_bert_emb_path, 'w') as f, open(new_bert_emb_num_path, 'w') as f2:\n",
    "    for inst in seed_instances_list:\n",
    "        emb = emb_dict[inst]\n",
    "        freq = ent_freq[inst]\n",
    "        f.write(\"{} {}\\n\".format(inst, ' '.join([str(x) for x in emb])))\n",
    "        f2.write(\"{} {}\\n\".format(inst, freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed instances: ['walmart', 'amazon', 'subway', 'microsoft', 'target', 'business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings', 'delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher', 'weekly', 'biweekly', 'friday', 'saturday', 'health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'base pay', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'direct deposit', 'prepaid card', 'drug test', 'criminal background check', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors', 'hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting', 'night shift', 'dinner shift', 'early morning shift', '8 hour shift', 'christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "New instances: ['uniform', 'hair color', 'tattoos', 'shoes', 'cashier', 'weekly', 'biweekly', 'friday', 'saturday', '401k', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'pregnant', 'students', 'seniors', '8 hour shift', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'training', 'team lunch']\n",
      "loading corpus: 100%|████████████████| 465226/465226 [00:09<00:00, 47556.15it/s]\n",
      "computing entity-wise embedding: 100%|██████████| 36/36 [00:41<00:00,  1.14s/it]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "# Using script\n",
    "\n",
    "!python add_seed_instances_embeddings.py -m bert-base-uncased -et ac -d $base_dir/data/$data_ac/intermediate -b $base_dir/data/indeed-benchmark -c 750\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub_dir = data_ac\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/BERTembed+seeds.txt')\n",
    "\n",
    "embeddings = load_embeddings(bert_emb_path, 768)\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>biweekly</td>\n",
       "      <td>[0.06975648552179337, -0.06970633566379547, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity                                          embedding\n",
       "8023  biweekly  [0.06975648552179337, -0.06970633566379547, 0...."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[embeddings['entity'] == 'biweekly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (X) Other ways of embeddings / clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|██████████| 458/458 [00:00<00:00, 73813.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(175, 175)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/sent_segmentation.txt')\n",
    "ent_freq, dedup_context = get_masked_contexts(input_file_path)\n",
    "len(ent_freq), len(dedup_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [\"we dropped by in hopes of finding atkinson 's peanut_butter bars ( we first tried them from honey salt 's [MASK] bowl ) and after searching a few minutes , we found it .\",\n",
       "  \"if you 're searching for a [MASK] or soda_pop you grew up with and can no longer find , there 's a good chance you 'll find it here .\"])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_freq['candy'], dedup_context['candy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_all_context_embeddings(model_path, input_file, max_context_ct):\n",
    "    '''\n",
    "    Adapted from get_avg_context_embeddings()\n",
    "    keep all context embeddings, using max similarity for knn\n",
    "    :param model_path:\n",
    "    :param input_file:\n",
    "    :return:\n",
    "    '''\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "    ent_freq, ent_context = get_masked_contexts(input_file)\n",
    "    entity_embeddings = {}\n",
    "    for entity, en_context_lst in tqdm(ent_context.items(), total=len(ent_context), desc=\"computing entity-wise embedding\"):\n",
    "        en_context_lst = random.sample(en_context_lst, min(len(en_context_lst), max_context_ct))\n",
    "        chunks = [en_context_lst[i:i + 100] for i in range(0, len(en_context_lst), 100)]\n",
    "        # print(entity)\n",
    "        # print(len(en_context_lst))\n",
    "        all_context_embeddings = []\n",
    "        for chunk in chunks:\n",
    "            encoded_input = tokenizer.batch_encode_plus(chunk, return_token_type_ids=True, add_special_tokens=True, max_length=128, return_tensors='pt', padding=True, pad_to_max_length=True, truncation=True)\n",
    "            mask = encoded_input['input_ids'] != mask_token_id\n",
    "            with torch.no_grad():\n",
    "                encoded_input = ensure_tensor_on_device(device, **encoded_input)\n",
    "                model_output = model(**encoded_input)  # Compute token embeddings\n",
    "            context_embeddings = mean_pooling(model_output, mask)  # mean pooling\n",
    "            # print(context_embeddings.size())\n",
    "            all_context_embeddings.append(context_embeddings)\n",
    "            \n",
    "        # entity_embedding = torch.mean(torch.cat(all_context_embeddings, dim=0), dim=0).cpu().detach().numpy().tolist()\n",
    "        # entity_embeddings[entity] = entity_embedding\n",
    "        entity_embeddings[entity] = torch.cat(all_context_embeddings, dim=0).cpu().detach().numpy().tolist()\n",
    "        \n",
    "    return entity_embeddings, ent_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|██████████| 458/458 [00:00<00:00, 150194.78it/s]\n",
      "computing entity-wise embedding: 100%|██████████| 175/175 [00:04<00:00, 41.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(175, 175)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'bert-base-uncased'\n",
    "input_file_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/sent_segmentation.txt')\n",
    "max_context_ct = 10\n",
    "\n",
    "entity_embeddings, ent_freq = get_all_context_embeddings(model_path, input_file_path, max_context_ct)\n",
    "len(entity_embeddings), len(ent_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_embeddings['candy'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _knn(entity_embeddings, embedding_dim, cluster_size, thread_ct=None, cluster_dest=None, **kwargs):\n",
    "    # entity_embeddings = load_embeddings(embed_src, embedding_dim)\n",
    "    \n",
    "    t = AnnoyIndex(embedding_dim, 'angular')\n",
    "    # entities = entity_embeddings['entity'].tolist()\n",
    "    entities = [f'{entity}-{_i}' for entity, embs in entity_embeddings.items() for _i in range(len(embs))]\n",
    "    # print(entities)\n",
    "    # for i, row in tqdm(entity_embeddings.iterrows(), total=entity_embeddings.shape[0], desc=\"building entity index\"):\n",
    "    #     t.add_item(i, row['embedding'])\n",
    "    i = 0\n",
    "    for entity, embs in tqdm(entity_embeddings.items(), total=len(entity_embeddings)):\n",
    "        for emb in embs:\n",
    "            t.add_item(i, emb)\n",
    "            i += 1\n",
    "    assert i == len(entities)\n",
    "    \n",
    "    t.build(100)\n",
    "    \n",
    "    neighbors = []\n",
    "    for i, entity in enumerate(tqdm(entities, desc=\"finding nearest neighbors by entity\")):\n",
    "        # print(i, entity)\n",
    "        nns, dists = t.get_nns_by_item(i, cluster_size + 1, include_distances=True)\n",
    "        cos_sim_scores = [(2 - d ** 2) / 2 for d in dists]  # convert angular distance to cosine similarity\n",
    "        zipped = list(zip(nns, cos_sim_scores))\n",
    "        sorted_nns = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "        if len(sorted_nns) > 0:\n",
    "            for nn_idx, d in sorted_nns:\n",
    "                neighbor_entity = entities[nn_idx]\n",
    "                if neighbor_entity == entity:\n",
    "                    continue\n",
    "                neighbors.append({\"entity\": entity, \"neighbor\": neighbor_entity, \"sim\": d})\n",
    "    c_df = pd.DataFrame(neighbors)\n",
    "    return c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 24854.50it/s]\n",
      "finding nearest neighbors by entity: 100%|██████████| 269/269 [00:00<00:00, 6006.44it/s]\n"
     ]
    }
   ],
   "source": [
    "knn_results = _knn(entity_embeddings, 768, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = 'meat'\n",
    "\n",
    "df = knn_results\n",
    "\n",
    "n_embs = len(entity_embeddings[query])\n",
    "sub_frames = []\n",
    "for _i in range(n_embs):\n",
    "    ent_name = f'{query}-{_i}'\n",
    "    sub_frames.append(df[df['entity'] == ent_name])\n",
    "\n",
    "pd.concat(sub_frames).sort_values('sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original avg context knn \n",
    "knn_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/knn_100.csv')\n",
    "\n",
    "knn_results = pd.read_csv(knn_path)\n",
    "df = knn_results\n",
    "\n",
    "query = 'walmart'\n",
    "sub_frame = df[df['entity'] == query]\n",
    "sub_frame.sort_values('sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Seed Entities (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "#change to concept learning directory\n",
    "%cd ../../concept_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn sentence-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 100\n",
    "output = '../../data/'+data_ac+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|████████████████| 177/177 [00:00<00:00, 5435.26it/s]\n",
      "finding nearest neighbors by entity: 100%|██| 177/177 [00:00<00:00, 2001.57it/s]\n"
     ]
    }
   ],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_ac/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn token concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 20\n",
    "output = '../../data/'+data_pt+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|████████████████| 177/177 [00:00<00:00, 3661.18it/s]\n",
      "finding nearest neighbors by entity: 100%|██| 177/177 [00:00<00:00, 4052.00it/s]\n"
     ]
    }
   ],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_pt/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 20\n",
    "output = '../../data/'+data_pt+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_corel/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed instances clustering (EE-emb)\n",
    "(using all seed instances of a concept to find neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "# seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# def get_concept_knn(embed_src, embedding_dim, seed_aligned_concept_src, cluster_size, thread_ct, cluster_dest, kdt, **kwargs):\n",
    "#     seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concept_src)\n",
    "    \n",
    "#     entity_embeddings = load_embeddings(embed_src, embedding_dim)\n",
    "#     entities = entity_embeddings['entity'].tolist()\n",
    "#     embeddings = entity_embeddings['embedding'].tolist()\n",
    "#     entity_emb_dict = dict(zip(entities, embeddings))\n",
    "\n",
    "#     neighbors = []\n",
    "    \n",
    "#     if kdt:\n",
    "#         t = AnnoyIndex(embedding_dim, 'angular')\n",
    "#         for i, row in tqdm(entity_embeddings.iterrows(), total=entity_embeddings.shape[0], desc=\"building entity index\"):\n",
    "#             t.add_item(i, row['embedding'])\n",
    "#         t.build(100)\n",
    "#     else:\n",
    "#         t = None\n",
    "        \n",
    "#     for i, (a_concept, u_concept, gnrl, seed_instances) in tqdm(seed_concepts_df.iterrows(), desc=\"finding nearest neighbors by concept\"):\n",
    "#         embs = []\n",
    "#         for inst in seed_instances:\n",
    "#             try:\n",
    "#                 embs.append(entity_emb_dict[inst])\n",
    "#             except KeyError:\n",
    "#                 print(f\"{inst} not found in entity_emb_dict??\")\n",
    "#                 continue\n",
    "#         if len(embs) == 0:\n",
    "#             continue\n",
    "#         concept_emb = np.mean(embs, axis=0)\n",
    "\n",
    "#         if kdt:\n",
    "#             nns, dists = t.get_nns_by_vector(concept_emb, cluster_size + 1, include_distances=True)\n",
    "#             cos_sim_scores = [(2 - d ** 2) / 2 for d in dists]  # convert angular distance to cosine similarity\n",
    "#         else:\n",
    "#             all_cos_sim_scores = cosine_similarity([concept_emb.tolist()], embeddings)[0]\n",
    "#             _partition = np.argpartition(-all_cos_sim_scores, kth=cluster_size)\n",
    "#             nns = _partition[:cluster_size]\n",
    "#             cos_sim_scores = [all_cos_sim_scores[i] for i in nns]\n",
    "            \n",
    "#         zipped = list(zip(nns, cos_sim_scores))\n",
    "#         sorted_nns = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "#         if len(sorted_nns) > 0:\n",
    "#             for nn_idx, d in sorted_nns:\n",
    "#                 neighbor_entity = entities[nn_idx]\n",
    "#                 if neighbor_entity in seed_instances:\n",
    "#                     continue\n",
    "#                 neighbors.append({\"concept\": a_concept, \"neighbor\": neighbor_entity, \"sim\": d})\n",
    "   \n",
    "#     c_df = pd.DataFrame(neighbors)\n",
    "#     c_df.to_csv(cluster_dest, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a2b2dab0ad402b89a830a0639a90b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='finding nearest neighbors by concept', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_size = 100\n",
    "\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "# seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "# seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_{cluster_size}_TEST.csv')\n",
    "\n",
    "get_concept_knn(embed_src=bert_emb_path,\n",
    "                embedding_dim=768,\n",
    "                seed_aligned_concept_src=seed_aligned_concepts_path,\n",
    "                cluster_size=cluster_size,\n",
    "                thread_ct=1,\n",
    "                kdt=True,\n",
    "                cluster_dest=concept_knn_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8064"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_entity_embeddings = load_embeddings(bert_emb_path, 768)\n",
    "_entities = _entity_embeddings['entity'].tolist()\n",
    "_embeddings = _entity_embeddings['embedding'].tolist()\n",
    "_entity_emb_dict = dict(zip(_entities, _embeddings))\n",
    "len(_entity_emb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040605662115216434"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(_entity_emb_dict['401k plan'], _entity_emb_dict['401k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding nearest neighbors by concept: 14it [00:05,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "cluster_size = None\n",
    "\n",
    "!python compute_concept_seeds_knn.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/ee_concept_knn_k=None.csv \\\n",
    "-kdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check results \n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_{cluster_size}.csv')\n",
    "\n",
    "df = pd.read_csv(concept_knn_path)\n",
    "df[df['concept'] == 'company'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(concept_knn_path)\n",
    "df[df['concept'] == 'pay_schedule'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive EE-emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_concept_contrastive_knn(embed_src, embedding_dim, seed_aligned_concept_src, cluster_size, cluster_dest, **kwargs):\n",
    "    \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concept_src)\n",
    "    \n",
    "    entity_embeddings = load_embeddings(embed_src, embedding_dim)\n",
    "    entities = entity_embeddings['entity'].tolist()\n",
    "    embeddings = entity_embeddings['embedding'].tolist()\n",
    "    entity_emb_dict = dict(zip(entities, embeddings))\n",
    "\n",
    "    neighbors = []\n",
    "    \n",
    "    concept_emb_dict = dict()\n",
    "    for i, (a_concept, u_concept, gnrl, seed_instances) in tqdm(seed_concepts_df.iterrows(), desc=\"finding nearest neighbors by concept\"):\n",
    "        embs = []\n",
    "        for inst in seed_instances:\n",
    "            try:\n",
    "                embs.append(entity_emb_dict[inst])\n",
    "            except KeyError:\n",
    "                print(f\"{inst} not found in entity_emb_dict??\")\n",
    "                continue\n",
    "        if len(embs) == 0:\n",
    "            continue\n",
    "        concept_emb = np.mean(embs, axis=0)\n",
    "        concept_emb_dict[a_concept] = concept_emb\n",
    "    \n",
    "    concepts = list(concept_emb_dict.keys())\n",
    "    concept_embs = list(concept_emb_dict.values())\n",
    "\n",
    "    # (n_concepts, n_entities)\n",
    "    cos_matrix = cosine_similarity(concept_embs, embeddings)\n",
    "    \n",
    "    cands_for_concepts = [[] for _ in range(len(concepts))]\n",
    "    for e_id, e in enumerate(entities):\n",
    "        _scores = cos_matrix[:, e_id]\n",
    "        _cc_ranking = np.argsort(-_scores)\n",
    "        _max_cc_id = _cc_ranking[0]\n",
    "        _second_cc_id = _cc_ranking[1]\n",
    "        _score = _scores[_max_cc_id]\n",
    "        _2nd_score = _scores[_second_cc_id]\n",
    "        _margin = _score - _2nd_score\n",
    "        cands_for_concepts[_max_cc_id].append({\n",
    "            'concept': concepts[_max_cc_id],\n",
    "            '2nd_concept': concepts[_second_cc_id],\n",
    "            'neighbor': e,\n",
    "            'sim': _score,\n",
    "            '2nd_sim': _2nd_score,\n",
    "            'margin': _margin,\n",
    "            'sim+margin': _score + _margin\n",
    "        })\n",
    "    \n",
    "#         _partition = np.argpartition(-all_cos_sim_scores, kth=cluster_size)\n",
    "#         nns = _partition[:cluster_size]\n",
    "#         cos_sim_scores = [all_cos_sim_scores[i] for i in nns]\n",
    "            \n",
    "#         zipped = list(zip(nns, cos_sim_scores))\n",
    "#         sorted_nns = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "#         if len(sorted_nns) > 0:\n",
    "#             for nn_idx, d in sorted_nns:\n",
    "#                 neighbor_entity = entities[nn_idx]\n",
    "#                 if neighbor_entity in seed_instances:\n",
    "#                     continue\n",
    "#                 neighbors.append({\"concept\": a_concept, \"neighbor\": neighbor_entity, \"sim\": d})\n",
    "   \n",
    "    for cc_id, cands in enumerate(cands_for_concepts):\n",
    "        cands_sorted = sorted(cands, key=lambda d: d['sim'], reverse=True)\n",
    "        neighbors.extend(cands_sorted[:cluster_size])\n",
    "    \n",
    "    c_df = pd.DataFrame(neighbors)\n",
    "    c_df.to_csv(cluster_dest, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9814662813fb491b858d21fbbafc95df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='finding nearest neighbors by concept', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_size = None\n",
    "\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "# seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "# seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "concept_contr_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/ee_concept_contr_knn_k={cluster_size}.csv')\n",
    "\n",
    "get_concept_contrastive_knn(embed_src=bert_emb_path,\n",
    "                            embedding_dim=768,\n",
    "                            seed_aligned_concept_src=seed_aligned_concepts_path,\n",
    "                            cluster_size=cluster_size,\n",
    "                            cluster_dest=concept_contr_knn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "finding nearest neighbors by concept: 0it [00:00, ?it/s]\r",
      "finding nearest neighbors by concept: 14it [00:00, 2789.16it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "cluster_size = 100\n",
    "\n",
    "!python compute_concept_contrastive_knn.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-s 100 \\\n",
    "-o $base_dir/data/$data_ac/intermediate/ee_concept_contr_knn_k=100.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EE-LM-probe (prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probe_gpt2 = LMProbe_GPT2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_100.csv')\n",
    "ee_df = pd.read_csv(ee_path)\n",
    "ee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company dress_code\n",
      "['walmart', 'amazon', 'subway', 'microsoft', 'target'] ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\n",
      "97 94\n"
     ]
    }
   ],
   "source": [
    "_r = 'has_dress_code'\n",
    "\n",
    "_r_row = seed_relations_df[seed_relations_df['alignedRelationName'] == _r].iloc[0]\n",
    "_h_type = _r_row['domain']\n",
    "_t_type = _r_row['range']\n",
    "print(_h_type, _t_type)\n",
    "\n",
    "_seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _h_type]['seedInstances'].item()\n",
    "_seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _t_type]['seedInstances'].item()\n",
    "print(_seed_heads, _seed_tails)\n",
    "\n",
    "_cand_heads = ee_df[ee_df['concept'] == _h_type]['neighbor'].tolist()\n",
    "_cand_tails = ee_df[ee_df['concept'] == _t_type]['neighbor'].tolist()\n",
    "print(len(_cand_heads), len(_cand_tails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8064, ['multiple times', 'upper', 'management'])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "with open(emb_num_path, 'r') as f:\n",
    "    all_entities = [l.rsplit(' ', 1)[0] for l in f]\n",
    "len(all_entities), all_entities[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'moccasins', 'score': 0.012966644052698999}),\n",
       " (1, {'cand': 'plantar fasciitis', 'score': 0.011055307323823867}),\n",
       " (2, {'cand': 'body piercings', 'score': 0.010491419243759924}),\n",
       " (3, {'cand': 'facial piercings', 'score': 0.010034629877810949}),\n",
       " (4, {'cand': 'face piercings', 'score': 0.009526236054152915}),\n",
       " (5, {'cand': 'rheumatoid arthritis', 'score': 0.00951552640771071}),\n",
       " (6, {'cand': 'pajamas', 'score': 0.009477122792155289}),\n",
       " (7, {'cand': 'leggings', 'score': 0.009350592230433023}),\n",
       " (8, {'cand': 'piercings', 'score': 0.009299829888659331}),\n",
       " (9, {'cand': 'flip flops', 'score': 0.008907867295359917}),\n",
       " (10, {'cand': 'mannequins', 'score': 0.00890319615818204}),\n",
       " (11, {'cand': 'black leggings', 'score': 0.008793791346326064}),\n",
       " (12, {'cand': 'spandex', 'score': 0.00877137791733358}),\n",
       " (13, {'cand': 'hysterectomy', 'score': 0.008692049287385687}),\n",
       " (14, {'cand': 'drug paraphernalia', 'score': 0.008071037304557648}),\n",
       " (15, {'cand': 'brazilian jiu jitsu', 'score': 0.00786899605349841}),\n",
       " (16, {'cand': 'cataract surgery', 'score': 0.007839012969890117}),\n",
       " (17, {'cand': 'collared shirts', 'score': 0.007770054178984074}),\n",
       " (18, {'cand': 'ear piercings', 'score': 0.007641697655793423}),\n",
       " (19, {'cand': 'nose piercings', 'score': 0.007541139127262901}),\n",
       " (20, {'cand': 'mezzanine', 'score': 0.007377462016867646}),\n",
       " (21, {'cand': 'fragrances', 'score': 0.007216821240476278}),\n",
       " (22, {'cand': 'liposuction', 'score': 0.007027157430347241}),\n",
       " (23, {'cand': 'quadriplegic', 'score': 0.006840080436745622}),\n",
       " (24, {'cand': 'nacogdoches', 'score': 0.006703224963139107}),\n",
       " (25, {'cand': 'methamphetamines', 'score': 0.0066745099338262875}),\n",
       " (26, {'cand': 'scoliosis', 'score': 0.006559223018746865}),\n",
       " (27, {'cand': 'cockroaches', 'score': 0.006238188346540641}),\n",
       " (28, {'cand': 'visible piercings', 'score': 0.006157974902103395}),\n",
       " (29, {'cand': 'corduroy', 'score': 0.006141632340661572}),\n",
       " (30, {'cand': 'porcelain', 'score': 0.006106208550787994}),\n",
       " (31, {'cand': 'sexual innuendo', 'score': 0.006033322527820061}),\n",
       " (32, {'cand': 'walkie talkie', 'score': 0.006023606395908631}),\n",
       " (33, {'cand': 'guacamole', 'score': 0.006008640337455053}),\n",
       " (34, {'cand': 'orthopedic surgery', 'score': 0.005904305771822065}),\n",
       " (35, {'cand': 'wristwatches', 'score': 0.005880914089553312}),\n",
       " (36, {'cand': 'alexandria', 'score': 0.005850223543620291}),\n",
       " (37, {'cand': 'barbiturates', 'score': 0.005828404994760877}),\n",
       " (38, {'cand': 'ibuprofen', 'score': 0.005794713236684606}),\n",
       " (39, {'cand': 'cosmetology', 'score': 0.005766669185974254}),\n",
       " (40, {'cand': 'styrofoam', 'score': 0.0056247128315210435}),\n",
       " (41, {'cand': 'jean pants', 'score': 0.00561873766882279}),\n",
       " (42, {'cand': 'hosiery', 'score': 0.005576785722194955}),\n",
       " (43, {'cand': 'deodorant', 'score': 0.005559530211071104}),\n",
       " (44, {'cand': 'vinaigrette', 'score': 0.00554906865355329}),\n",
       " (45, {'cand': 'gluteus maximus', 'score': 0.00548722946311113}),\n",
       " (46, {'cand': 'goatee', 'score': 0.005448181517572082}),\n",
       " (47, {'cand': 'ypsilanti', 'score': 0.0054092592600998675}),\n",
       " (48, {'cand': 'sideburns', 'score': 0.005389624965504524}),\n",
       " (49, {'cand': 'loitering', 'score': 0.005384995862431087})]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'We allow jeans, [MASK] and tattoos.'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant', '##ar', 'fa', '##sc', '##ii', '##tis']: too many wordpieces\n",
      "['work', '##man', \"'\", 's', 'com', '##p']: too many wordpieces\n",
      "['met', '##ham', '##ph', '##eta', '##mine', '##s']: too many wordpieces\n",
      "['pt', 'ang', '##kas', '##a', 'pu', '##ra', 'ii']: too many wordpieces\n",
      "['d', '##3', 'dan', 's', '##1', 'se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['pen', '##di', '##di', '##kan', 'sm', '##a']: too many wordpieces\n",
      "['sl', '##ta', '/', 'sm', '##k', 'minimal', '7', 'dan', 'ip', '##k']: too many wordpieces\n",
      "['rude', 'and', 'di', '##sr', '##es', '##pe', '##ct', '##ful']: too many wordpieces\n",
      "['ada', '##pu', '##n', 'po', '##sis', '##i', 'low', '##onga', '##n', 'ke', '##r', '##ja', 'pt', 'ang', '##kas', '##a']: too many wordpieces\n",
      "['low', '##onga', '##n', 'ke', '##r', '##ja']: too many wordpieces\n",
      "['se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['patient', 'protection', 'and', 'affordable', 'care', 'act']: too many wordpieces\n",
      "['ta', '##hl', '##e', '##qua', '##h', 'oklahoma']: too many wordpieces\n",
      "['north', 'ton', '##awan', '##da', 'new', 'york']: too many wordpieces\n",
      "['mo', '##zi', '##lla', 'fire', '##fo', '##x']: too many wordpieces\n",
      "['benz', '##od', '##ia', '##ze', '##pine', '##s']: too many wordpieces\n",
      "['r', '##he', '##uma', '##to', '##id', 'arthritis']: too many wordpieces\n",
      "['las', 'cr', '##uce', '##s', 'new', 'mexico']: too many wordpieces\n",
      "['tri', '##io', '##dot', '##hy', '##ron', '##ine']: too many wordpieces\n",
      "['i', 'd', 'and', 'social', 'security', 'card']: too many wordpieces\n",
      "['ze', '##phy', '##rh', '##ill', '##s', 'florida']: too many wordpieces\n",
      "['ve', '##riz', '##on', '/', 'fi', '##os']: too many wordpieces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'shoes', 'score': 0.04184859618544578}),\n",
       " (1, {'cand': 'panties', 'score': 0.02703012898564339}),\n",
       " (2, {'cand': 'hair', 'score': 0.021639285609126088}),\n",
       " (3, {'cand': 'tattoos', 'score': 0.019144266843795776}),\n",
       " (4, {'cand': 'jeans', 'score': 0.013062405399978163}),\n",
       " (5, {'cand': 'sunglasses', 'score': 0.006786400452256205}),\n",
       " (6, {'cand': 'bra', 'score': 0.0038306557107716816}),\n",
       " (7, {'cand': 'caps', 'score': 0.0034439887385815395}),\n",
       " (8, {'cand': 'lipstick', 'score': 0.0030804190319031486}),\n",
       " (9, {'cand': 'skin', 'score': 0.0020948206074535842}),\n",
       " (10, {'cand': 'leather', 'score': 0.00207862164825201}),\n",
       " (11, {'cand': 'pajamas', 'score': 0.0015055921394377947}),\n",
       " (12, {'cand': 'cologne', 'score': 0.001362455193884671}),\n",
       " (13, {'cand': 'cigarettes', 'score': 0.0013264154549688096}),\n",
       " (14, {'cand': 'blouse', 'score': 0.0012996237492188807}),\n",
       " (15, {'cand': 'jewellery', 'score': 0.0012973581906408072}),\n",
       " (16, {'cand': 'arms', 'score': 0.0011891197646036742}),\n",
       " (17, {'cand': 'clothing', 'score': 0.0009357598610222335}),\n",
       " (18, {'cand': 'phones', 'score': 0.0009310193709097803}),\n",
       " (19, {'cand': 'logos', 'score': 0.000879008031915873}),\n",
       " (20, {'cand': 'yoga', 'score': 0.0005969737539999185}),\n",
       " (21, {'cand': 'handcuffs', 'score': 0.00043309078318998234}),\n",
       " (22, {'cand': 'labels', 'score': 0.00043170482967980217}),\n",
       " (23, {'cand': 'money', 'score': 0.0004262141010258347}),\n",
       " (24, {'cand': 'denim', 'score': 0.00042296829633414756}),\n",
       " (25, {'cand': 'hearts', 'score': 0.0004199247632641344}),\n",
       " (26, {'cand': 'flyers', 'score': 0.00040431399247609073}),\n",
       " (27, {'cand': 'polo', 'score': 0.000396855699364096}),\n",
       " (28, {'cand': 'black', 'score': 0.0003950561804231257}),\n",
       " (29, {'cand': 'tanks', 'score': 0.0003905096673406661}),\n",
       " (30, {'cand': 'red', 'score': 0.00033472536597400877}),\n",
       " (31, {'cand': 'pink', 'score': 0.00032434295280836533}),\n",
       " (32, {'cand': 'bikes', 'score': 0.0003065669152420013}),\n",
       " (33, {'cand': 'buses', 'score': 0.00029738229932263477}),\n",
       " (34, {'cand': 'flowers', 'score': 0.0002679389144759625}),\n",
       " (35, {'cand': 'ponytail', 'score': 0.0002656400320120156}),\n",
       " (36, {'cand': 'nipples', 'score': 0.00025229301536455767}),\n",
       " (37, {'cand': 'cosmetics', 'score': 0.00024696392938494666}),\n",
       " (38, {'cand': 'ink', 'score': 0.00021521911548916234}),\n",
       " (39, {'cand': 'jersey', 'score': 0.0002045845176326112}),\n",
       " (40, {'cand': 'tubes', 'score': 0.0002000119711738079}),\n",
       " (41, {'cand': 'magazines', 'score': 0.00019962903752457334}),\n",
       " (42, {'cand': 'soap', 'score': 0.0001973012113012373}),\n",
       " (43, {'cand': 'girlfriends', 'score': 0.00019616985809989284}),\n",
       " (44, {'cand': 'strips', 'score': 0.00019590037118177853}),\n",
       " (45, {'cand': 'tank', 'score': 0.00018544388876762247}),\n",
       " (46, {'cand': 'braid', 'score': 0.0001849491818575189}),\n",
       " (47, {'cand': 'bicycles', 'score': 0.00018095054838340746}),\n",
       " (48, {'cand': 'windows', 'score': 0.00017861963715404267}),\n",
       " (49, {'cand': 'films', 'score': 0.00017376522009726627})]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'We allow jeans, [MASK] and tattoos.'\n",
    "_res = lm_probe.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant', '##ar', 'fa', '##sc', '##ii', '##tis']: too many wordpieces\n",
      "['work', '##man', \"'\", 's', 'com', '##p']: too many wordpieces\n",
      "['met', '##ham', '##ph', '##eta', '##mine', '##s']: too many wordpieces\n",
      "['pt', 'ang', '##kas', '##a', 'pu', '##ra', 'ii']: too many wordpieces\n",
      "['d', '##3', 'dan', 's', '##1', 'se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['pen', '##di', '##di', '##kan', 'sm', '##a']: too many wordpieces\n",
      "['sl', '##ta', '/', 'sm', '##k', 'minimal', '7', 'dan', 'ip', '##k']: too many wordpieces\n",
      "['rude', 'and', 'di', '##sr', '##es', '##pe', '##ct', '##ful']: too many wordpieces\n",
      "['ada', '##pu', '##n', 'po', '##sis', '##i', 'low', '##onga', '##n', 'ke', '##r', '##ja', 'pt', 'ang', '##kas', '##a']: too many wordpieces\n",
      "['low', '##onga', '##n', 'ke', '##r', '##ja']: too many wordpieces\n",
      "['se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['patient', 'protection', 'and', 'affordable', 'care', 'act']: too many wordpieces\n",
      "['ta', '##hl', '##e', '##qua', '##h', 'oklahoma']: too many wordpieces\n",
      "['north', 'ton', '##awan', '##da', 'new', 'york']: too many wordpieces\n",
      "['mo', '##zi', '##lla', 'fire', '##fo', '##x']: too many wordpieces\n",
      "['benz', '##od', '##ia', '##ze', '##pine', '##s']: too many wordpieces\n",
      "['r', '##he', '##uma', '##to', '##id', 'arthritis']: too many wordpieces\n",
      "['las', 'cr', '##uce', '##s', 'new', 'mexico']: too many wordpieces\n",
      "['tri', '##io', '##dot', '##hy', '##ron', '##ine']: too many wordpieces\n",
      "['i', 'd', 'and', 'social', 'security', 'card']: too many wordpieces\n",
      "['ze', '##phy', '##rh', '##ill', '##s', 'florida']: too many wordpieces\n",
      "['ve', '##riz', '##on', '/', 'fi', '##os']: too many wordpieces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'jeans', 'score': 0.1053730323910713}),\n",
       " (1, {'cand': 'shoes', 'score': 0.08028024435043335}),\n",
       " (2, {'cand': 'sunglasses', 'score': 0.0030999192968010902}),\n",
       " (3, {'cand': 'caps', 'score': 0.0027481289580464367}),\n",
       " (4, {'cand': 'panties', 'score': 0.0017155319219455125}),\n",
       " (5, {'cand': 'denim', 'score': 0.001618258655071259}),\n",
       " (6, {'cand': 'buses', 'score': 0.0009692866588011381}),\n",
       " (7, {'cand': 'pajamas', 'score': 0.0007222475833259522}),\n",
       " (8, {'cand': 'leather', 'score': 0.0005088149337098004}),\n",
       " (9, {'cand': 'polo', 'score': 0.0004302898305468261}),\n",
       " (10, {'cand': 'tanks', 'score': 0.0003051776147913187}),\n",
       " (11, {'cand': 'cigarettes', 'score': 0.00027609075186774124}),\n",
       " (12, {'cand': 'hair', 'score': 0.00020207812485750748}),\n",
       " (13, {'cand': 'blouse', 'score': 0.0001957619679160417}),\n",
       " (14, {'cand': 'jewellery', 'score': 0.00018753786571323882}),\n",
       " (15, {'cand': 'flyers', 'score': 0.0001843944774009287}),\n",
       " (16, {'cand': 'yoga', 'score': 0.00017563693108968426}),\n",
       " (17, {'cand': 'bra', 'score': 0.00014828082930762326}),\n",
       " (18, {'cand': 'reds', 'score': 0.00014152497169561695}),\n",
       " (19, {'cand': 'spurs', 'score': 0.00012843501463066797}),\n",
       " (20, {'cand': 'logos', 'score': 0.00011283694038866089}),\n",
       " (21, {'cand': 'bikes', 'score': 7.963976531755178e-05}),\n",
       " (22, {'cand': 'black', 'score': 7.465406088158486e-05}),\n",
       " (23, {'cand': 'walks', 'score': 7.0709727879148e-05}),\n",
       " (24, {'cand': 'checks', 'score': 7.07000581314787e-05}),\n",
       " (25, {'cand': 'marines', 'score': 6.775063229724761e-05}),\n",
       " (26, {'cand': 'tattoos', 'score': 6.739616219419986e-05}),\n",
       " (27, {'cand': 'films', 'score': 6.336520891636606e-05}),\n",
       " (28, {'cand': 'phones', 'score': 6.133972055977209e-05}),\n",
       " (29, {'cand': 'bicycles', 'score': 5.7541183196008165e-05}),\n",
       " (30, {'cand': 'lipstick', 'score': 5.088500984129501e-05}),\n",
       " (31, {'cand': 'camouflage', 'score': 4.744959005620329e-05}),\n",
       " (32, {'cand': 'jogging', 'score': 4.373767296783624e-05}),\n",
       " (33, {'cand': 'mascara', 'score': 3.965624273405412e-05}),\n",
       " (34, {'cand': 'tractors', 'score': 3.828980698017404e-05}),\n",
       " (35, {'cand': 'strips', 'score': 3.717934305313972e-05}),\n",
       " (36, {'cand': 'tank', 'score': 3.68319379049353e-05}),\n",
       " (37, {'cand': 'cards', 'score': 3.6767469282494885e-05}),\n",
       " (38, {'cand': 'cologne', 'score': 3.51516828231979e-05}),\n",
       " (39, {'cand': 'clothing', 'score': 3.505222412059081e-05}),\n",
       " (40, {'cand': 'hotels', 'score': 3.200554419890976e-05}),\n",
       " (41, {'cand': 'poles', 'score': 3.0091237931628725e-05}),\n",
       " (42, {'cand': 'browns', 'score': 2.944164589280264e-05}),\n",
       " (43, {'cand': 'products', 'score': 2.777141344267877e-05}),\n",
       " (44, {'cand': 'nike', 'score': 2.7590871468419226e-05}),\n",
       " (45, {'cand': 'handcuffs', 'score': 2.7296253392705718e-05}),\n",
       " (46, {'cand': 'arms', 'score': 2.6867017368203937e-05}),\n",
       " (47, {'cand': 'magazines', 'score': 2.6186417017015615e-05}),\n",
       " (48, {'cand': 'nylon', 'score': 2.5457589799771085e-05}),\n",
       " (49, {'cand': 'ponytail', 'score': 2.5017581720021557e-05})]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'The company allows employees to wear jeans, [MASK] and shirts.'\n",
    "_res = lm_probe.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant', '##ar', 'fa', '##sc', '##ii', '##tis']: too many wordpieces\n",
      "['work', '##man', \"'\", 's', 'com', '##p']: too many wordpieces\n",
      "['met', '##ham', '##ph', '##eta', '##mine', '##s']: too many wordpieces\n",
      "['pt', 'ang', '##kas', '##a', 'pu', '##ra', 'ii']: too many wordpieces\n",
      "['d', '##3', 'dan', 's', '##1', 'se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['pen', '##di', '##di', '##kan', 'sm', '##a']: too many wordpieces\n",
      "['sl', '##ta', '/', 'sm', '##k', 'minimal', '7', 'dan', 'ip', '##k']: too many wordpieces\n",
      "['rude', 'and', 'di', '##sr', '##es', '##pe', '##ct', '##ful']: too many wordpieces\n",
      "['ada', '##pu', '##n', 'po', '##sis', '##i', 'low', '##onga', '##n', 'ke', '##r', '##ja', 'pt', 'ang', '##kas', '##a']: too many wordpieces\n",
      "['low', '##onga', '##n', 'ke', '##r', '##ja']: too many wordpieces\n",
      "['se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['patient', 'protection', 'and', 'affordable', 'care', 'act']: too many wordpieces\n",
      "['ta', '##hl', '##e', '##qua', '##h', 'oklahoma']: too many wordpieces\n",
      "['north', 'ton', '##awan', '##da', 'new', 'york']: too many wordpieces\n",
      "['mo', '##zi', '##lla', 'fire', '##fo', '##x']: too many wordpieces\n",
      "['benz', '##od', '##ia', '##ze', '##pine', '##s']: too many wordpieces\n",
      "['r', '##he', '##uma', '##to', '##id', 'arthritis']: too many wordpieces\n",
      "['las', 'cr', '##uce', '##s', 'new', 'mexico']: too many wordpieces\n",
      "['tri', '##io', '##dot', '##hy', '##ron', '##ine']: too many wordpieces\n",
      "['i', 'd', 'and', 'social', 'security', 'card']: too many wordpieces\n",
      "['ze', '##phy', '##rh', '##ill', '##s', 'florida']: too many wordpieces\n",
      "['ve', '##riz', '##on', '/', 'fi', '##os']: too many wordpieces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'tattoos', 'score': 0.6991829872131348}),\n",
       " (1, {'cand': 'hair', 'score': 0.0065090949647128565}),\n",
       " (2, {'cand': 'lipstick', 'score': 0.00543932057917118}),\n",
       " (3, {'cand': 'logos', 'score': 0.0022039660252630715}),\n",
       " (4, {'cand': 'nipples', 'score': 0.0019367007771506906}),\n",
       " (5, {'cand': 'tattoo', 'score': 0.00139555218629539}),\n",
       " (6, {'cand': 'cosmetics', 'score': 0.0007131393649615346}),\n",
       " (7, {'cand': 'surgery', 'score': 0.000528711767401546}),\n",
       " (8, {'cand': 'clothing', 'score': 0.00046022533206269134}),\n",
       " (9, {'cand': 'drugs', 'score': 0.00041217444231733664}),\n",
       " (10, {'cand': 'skin', 'score': 0.0004079583450220527}),\n",
       " (11, {'cand': 'sunglasses', 'score': 0.00033981521846726526}),\n",
       " (12, {'cand': 'jewellery', 'score': 0.0003285531711298971}),\n",
       " (13, {'cand': 'labels', 'score': 0.00029281346360221516}),\n",
       " (14, {'cand': 'ink', 'score': 0.0002547384647186845}),\n",
       " (15, {'cand': 'handcuffs', 'score': 0.0002248705568490548}),\n",
       " (16, {'cand': 'transgender', 'score': 0.00022246957814786564}),\n",
       " (17, {'cand': 'tubes', 'score': 0.00019809472723864005}),\n",
       " (18, {'cand': 'spurs', 'score': 0.0001902326184790582}),\n",
       " (19, {'cand': 'aids', 'score': 0.00016230402979999775}),\n",
       " (20, {'cand': 'jeans', 'score': 0.00014474135241471242}),\n",
       " (21, {'cand': 'diamonds', 'score': 0.00013829108502250157}),\n",
       " (22, {'cand': 'hearts', 'score': 0.0001297777344007046}),\n",
       " (23, {'cand': 'bones', 'score': 0.00012701733794528986}),\n",
       " (24, {'cand': 'damages', 'score': 0.00012488245556596675}),\n",
       " (25, {'cand': 'mascara', 'score': 0.00010682170250220231}),\n",
       " (26, {'cand': 'panties', 'score': 0.00010431643022457131}),\n",
       " (27, {'cand': 'blood', 'score': 9.972015686798838e-05}),\n",
       " (28, {'cand': 'cancer', 'score': 9.185012459056456e-05}),\n",
       " (29, {'cand': 'alcohol', 'score': 8.813543536234647e-05}),\n",
       " (30, {'cand': 'shoes', 'score': 8.573890954721724e-05}),\n",
       " (31, {'cand': 'walks', 'score': 8.421057282248506e-05}),\n",
       " (32, {'cand': 'twitter', 'score': 8.114732918329541e-05}),\n",
       " (33, {'cand': 'bra', 'score': 8.064832218224176e-05}),\n",
       " (34, {'cand': 'backs', 'score': 7.708576595177869e-05}),\n",
       " (35, {'cand': 'phones', 'score': 7.17695147613995e-05}),\n",
       " (36, {'cand': 'tests', 'score': 7.004549115663389e-05}),\n",
       " (37, {'cand': 'benefits', 'score': 6.988149107201025e-05}),\n",
       " (38, {'cand': 'runs', 'score': 6.80203593219631e-05}),\n",
       " (39, {'cand': 'mri', 'score': 6.615590973524373e-05}),\n",
       " (40, {'cand': 'caps', 'score': 6.36914483038708e-05}),\n",
       " (41, {'cand': 'parties', 'score': 5.972961662337182e-05}),\n",
       " (42, {'cand': 'sarcasm', 'score': 5.743965812143866e-05}),\n",
       " (43, {'cand': 'gender', 'score': 5.6954675528686467e-05}),\n",
       " (44, {'cand': 'pain', 'score': 5.3300915169529576e-05}),\n",
       " (45, {'cand': 'sexuality', 'score': 5.178478022571651e-05}),\n",
       " (46, {'cand': 'stones', 'score': 5.091201455797999e-05}),\n",
       " (47, {'cand': 'icons', 'score': 4.902010186924602e-05}),\n",
       " (48, {'cand': 'products', 'score': 4.820740286959332e-05}),\n",
       " (49, {'cand': 'diabetes', 'score': 4.7217308747349293e-05})]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'The company allows employees to have piercings, [MASK] and tattoos.'\n",
    "_res = lm_probe.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant', '##ar', 'fa', '##sc', '##ii', '##tis']: too many wordpieces\n",
      "['work', '##man', \"'\", 's', 'com', '##p']: too many wordpieces\n",
      "['met', '##ham', '##ph', '##eta', '##mine', '##s']: too many wordpieces\n",
      "['pt', 'ang', '##kas', '##a', 'pu', '##ra', 'ii']: too many wordpieces\n",
      "['d', '##3', 'dan', 's', '##1', 'se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['pen', '##di', '##di', '##kan', 'sm', '##a']: too many wordpieces\n",
      "['sl', '##ta', '/', 'sm', '##k', 'minimal', '7', 'dan', 'ip', '##k']: too many wordpieces\n",
      "['rude', 'and', 'di', '##sr', '##es', '##pe', '##ct', '##ful']: too many wordpieces\n",
      "['ada', '##pu', '##n', 'po', '##sis', '##i', 'low', '##onga', '##n', 'ke', '##r', '##ja', 'pt', 'ang', '##kas', '##a']: too many wordpieces\n",
      "['low', '##onga', '##n', 'ke', '##r', '##ja']: too many wordpieces\n",
      "['se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['patient', 'protection', 'and', 'affordable', 'care', 'act']: too many wordpieces\n",
      "['ta', '##hl', '##e', '##qua', '##h', 'oklahoma']: too many wordpieces\n",
      "['north', 'ton', '##awan', '##da', 'new', 'york']: too many wordpieces\n",
      "['mo', '##zi', '##lla', 'fire', '##fo', '##x']: too many wordpieces\n",
      "['benz', '##od', '##ia', '##ze', '##pine', '##s']: too many wordpieces\n",
      "['r', '##he', '##uma', '##to', '##id', 'arthritis']: too many wordpieces\n",
      "['las', 'cr', '##uce', '##s', 'new', 'mexico']: too many wordpieces\n",
      "['tri', '##io', '##dot', '##hy', '##ron', '##ine']: too many wordpieces\n",
      "['i', 'd', 'and', 'social', 'security', 'card']: too many wordpieces\n",
      "['ze', '##phy', '##rh', '##ill', '##s', 'florida']: too many wordpieces\n",
      "['ve', '##riz', '##on', '/', 'fi', '##os']: too many wordpieces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'shoes', 'score': 0.12526971101760861}),\n",
       " (1, {'cand': 'clothing', 'score': 0.06428885459899901}),\n",
       " (2, {'cand': 'uniform', 'score': 0.04750930517911912}),\n",
       " (3, {'cand': 'cap', 'score': 0.016608720645308498}),\n",
       " (4, {'cand': 'caps', 'score': 0.006373641081154344}),\n",
       " (5, {'cand': 'blouse', 'score': 0.005406954325735569}),\n",
       " (6, {'cand': 'jeans', 'score': 0.004977909382432701}),\n",
       " (7, {'cand': 'jewellery', 'score': 0.004148608073592186}),\n",
       " (8, {'cand': 'logo', 'score': 0.002692297799512743}),\n",
       " (9, {'cand': 'sunglasses', 'score': 0.002085869200527669}),\n",
       " (10, {'cand': 'fashion', 'score': 0.001943003735505044}),\n",
       " (11, {'cand': 'hair', 'score': 0.0015218171756714582}),\n",
       " (12, {'cand': 'cologne', 'score': 0.0011592373484745617}),\n",
       " (13, {'cand': 'food', 'score': 0.001128159230574966}),\n",
       " (14, {'cand': 'panties', 'score': 0.0011100757401436563}),\n",
       " (15, {'cand': 'perfume', 'score': 0.0010554154869168992}),\n",
       " (16, {'cand': 'helmet', 'score': 0.0010541978990659118}),\n",
       " (17, {'cand': 'cigarettes', 'score': 0.0009916352573782206}),\n",
       " (18, {'cand': 'music', 'score': 0.0008911946206353607}),\n",
       " (19, {'cand': 'cosmetics', 'score': 0.0008404902182519433}),\n",
       " (20, {'cand': 'cards', 'score': 0.000755676534026861}),\n",
       " (21, {'cand': 'lipstick', 'score': 0.0006851590587757529}),\n",
       " (22, {'cand': 'polo', 'score': 0.0006783886929042636}),\n",
       " (23, {'cand': 'sash', 'score': 0.0005966385942883792}),\n",
       " (24, {'cand': 'harness', 'score': 0.000572110526263714}),\n",
       " (25, {'cand': 'pajamas', 'score': 0.0005327916005626319}),\n",
       " (26, {'cand': 'spurs', 'score': 0.0005282152560539545}),\n",
       " (27, {'cand': 'tunic', 'score': 0.0005043302080594003}),\n",
       " (28, {'cand': 'card', 'score': 0.00048778770724311487}),\n",
       " (29, {'cand': 'textile', 'score': 0.0004615451907739045}),\n",
       " (30, {'cand': 'tattoos', 'score': 0.0004260381974745543}),\n",
       " (31, {'cand': 'tobacco', 'score': 0.00042370797018520545}),\n",
       " (32, {'cand': 'parade', 'score': 0.00041266466723754986}),\n",
       " (33, {'cand': 'weapon', 'score': 0.000365512096323073}),\n",
       " (34, {'cand': 'training', 'score': 0.00033949289354495715}),\n",
       " (35, {'cand': 'bicycles', 'score': 0.0003356962697580458}),\n",
       " (36, {'cand': 'mail', 'score': 0.0003220062062609941}),\n",
       " (37, {'cand': 'games', 'score': 0.00029857558547519126}),\n",
       " (38, {'cand': 'money', 'score': 0.00028129841666668675}),\n",
       " (39, {'cand': 'camouflage', 'score': 0.0002769655256997796}),\n",
       " (40, {'cand': 'logos', 'score': 0.0002693864516913892}),\n",
       " (41, {'cand': 'leather', 'score': 0.0002617668360471727}),\n",
       " (42, {'cand': 'jersey', 'score': 0.00025667541194707155}),\n",
       " (43, {'cand': 'drugs', 'score': 0.0002526318130549043}),\n",
       " (44, {'cand': 'dance', 'score': 0.00021990633103996515}),\n",
       " (45, {'cand': 'furniture', 'score': 0.00021379644749686108}),\n",
       " (46, {'cand': 'arms', 'score': 0.00020720223255921155}),\n",
       " (47, {'cand': 'labels', 'score': 0.0002045862202066929}),\n",
       " (48, {'cand': 'language', 'score': 0.00020225226762704557}),\n",
       " (49, {'cand': 'passport', 'score': 0.0001870016858447343})]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'The company requires a dress code including uniform, [MASK] and shoes.'\n",
    "_res = lm_probe.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant', '##ar', 'fa', '##sc', '##ii', '##tis']: too many wordpieces\n",
      "['work', '##man', \"'\", 's', 'com', '##p']: too many wordpieces\n",
      "['met', '##ham', '##ph', '##eta', '##mine', '##s']: too many wordpieces\n",
      "['pt', 'ang', '##kas', '##a', 'pu', '##ra', 'ii']: too many wordpieces\n",
      "['d', '##3', 'dan', 's', '##1', 'se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['pen', '##di', '##di', '##kan', 'sm', '##a']: too many wordpieces\n",
      "['sl', '##ta', '/', 'sm', '##k', 'minimal', '7', 'dan', 'ip', '##k']: too many wordpieces\n",
      "['rude', 'and', 'di', '##sr', '##es', '##pe', '##ct', '##ful']: too many wordpieces\n",
      "['ada', '##pu', '##n', 'po', '##sis', '##i', 'low', '##onga', '##n', 'ke', '##r', '##ja', 'pt', 'ang', '##kas', '##a']: too many wordpieces\n",
      "['low', '##onga', '##n', 'ke', '##r', '##ja']: too many wordpieces\n",
      "['se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['patient', 'protection', 'and', 'affordable', 'care', 'act']: too many wordpieces\n",
      "['ta', '##hl', '##e', '##qua', '##h', 'oklahoma']: too many wordpieces\n",
      "['north', 'ton', '##awan', '##da', 'new', 'york']: too many wordpieces\n",
      "['mo', '##zi', '##lla', 'fire', '##fo', '##x']: too many wordpieces\n",
      "['benz', '##od', '##ia', '##ze', '##pine', '##s']: too many wordpieces\n",
      "['r', '##he', '##uma', '##to', '##id', 'arthritis']: too many wordpieces\n",
      "['las', 'cr', '##uce', '##s', 'new', 'mexico']: too many wordpieces\n",
      "['tri', '##io', '##dot', '##hy', '##ron', '##ine']: too many wordpieces\n",
      "['i', 'd', 'and', 'social', 'security', 'card']: too many wordpieces\n",
      "['ze', '##phy', '##rh', '##ill', '##s', 'florida']: too many wordpieces\n",
      "['ve', '##riz', '##on', '/', 'fi', '##os']: too many wordpieces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'jeans', 'score': 0.18732795119285583}),\n",
       " (1, {'cand': 'shoes', 'score': 0.04137388244271279}),\n",
       " (2, {'cand': 'denim', 'score': 0.00565440859645605}),\n",
       " (3, {'cand': 'sunglasses', 'score': 0.003932376392185689}),\n",
       " (4, {'cand': 'panties', 'score': 0.0020852549932897095}),\n",
       " (5, {'cand': 'buses', 'score': 0.0016753433737903833}),\n",
       " (6, {'cand': 'caps', 'score': 0.0011914296774193645}),\n",
       " (7, {'cand': 'leather', 'score': 0.0010424052597954867}),\n",
       " (8, {'cand': 'yoga', 'score': 0.0008445206331089139}),\n",
       " (9, {'cand': 'pajamas', 'score': 0.0006508376100100576}),\n",
       " (10, {'cand': 'tanks', 'score': 0.0004852299753110855}),\n",
       " (11, {'cand': 'polo', 'score': 0.0004803886695299296}),\n",
       " (12, {'cand': 'blouse', 'score': 0.0003862084413412959}),\n",
       " (13, {'cand': 'jewellery', 'score': 0.00033101392909884437}),\n",
       " (14, {'cand': 'hair', 'score': 0.0002776607871055606}),\n",
       " (15, {'cand': 'cigarettes', 'score': 0.00027209889958612637}),\n",
       " (16, {'cand': 'flyers', 'score': 0.00024334085173904904}),\n",
       " (17, {'cand': 'black', 'score': 0.00022067257668823}),\n",
       " (18, {'cand': 'reds', 'score': 0.00019653876370284698}),\n",
       " (19, {'cand': 'bra', 'score': 0.00019139975483994945}),\n",
       " (20, {'cand': 'tattoos', 'score': 0.00017308056703768681}),\n",
       " (21, {'cand': 'lipstick', 'score': 0.0001430923439329489}),\n",
       " (22, {'cand': 'films', 'score': 0.00012854138913098717}),\n",
       " (23, {'cand': 'magazines', 'score': 0.00011817886843346065}),\n",
       " (24, {'cand': 'jogging', 'score': 0.00011120203998871142}),\n",
       " (25, {'cand': 'walks', 'score': 0.00011015928612323482}),\n",
       " (26, {'cand': 'bikes', 'score': 9.965975914383315e-05}),\n",
       " (27, {'cand': 'mascara', 'score': 9.464729373576113e-05}),\n",
       " (28, {'cand': 'marines', 'score': 9.1066256572958e-05}),\n",
       " (29, {'cand': 'logos', 'score': 8.952320786193008e-05}),\n",
       " (30, {'cand': 'phones', 'score': 8.759213960729534e-05}),\n",
       " (31, {'cand': 'sports', 'score': 8.732327842153603e-05}),\n",
       " (32, {'cand': 'cologne', 'score': 8.518995309714222e-05}),\n",
       " (33, {'cand': 'bears', 'score': 8.463230187771843e-05}),\n",
       " (34, {'cand': 'tank', 'score': 7.804403867339717e-05}),\n",
       " (35, {'cand': 'clothing', 'score': 7.290078065125273e-05}),\n",
       " (36, {'cand': 'cosmetics', 'score': 7.09334635757841e-05}),\n",
       " (37, {'cand': 'bicycles', 'score': 6.72304740874097e-05}),\n",
       " (38, {'cand': 'perfume', 'score': 6.336013757390901e-05}),\n",
       " (39, {'cand': 'labels', 'score': 6.260285590542483e-05}),\n",
       " (40, {'cand': 'games', 'score': 6.122478953329842e-05}),\n",
       " (41, {'cand': 'products', 'score': 6.108318484621124e-05}),\n",
       " (42, {'cand': 'hotels', 'score': 6.0453814512584325e-05}),\n",
       " (43, {'cand': 'nylon', 'score': 5.7879904488800094e-05}),\n",
       " (44, {'cand': 'spurs', 'score': 5.5119420721894144e-05}),\n",
       " (45, {'cand': 'checks', 'score': 5.5028714996296885e-05}),\n",
       " (46, {'cand': 'lace', 'score': 5.1380426157265915e-05}),\n",
       " (47, {'cand': 'red', 'score': 5.110636993777006e-05}),\n",
       " (48, {'cand': 'camouflage', 'score': 5.0682112487265806e-05}),\n",
       " (49, {'cand': 'cards', 'score': 4.918470949633048e-05})]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'The company has a dress code including jeans, [MASK], and shirts.'\n",
    "_res = lm_probe.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant', '##ar', 'fa', '##sc', '##ii', '##tis']: too many wordpieces\n",
      "['work', '##man', \"'\", 's', 'com', '##p']: too many wordpieces\n",
      "['met', '##ham', '##ph', '##eta', '##mine', '##s']: too many wordpieces\n",
      "['pt', 'ang', '##kas', '##a', 'pu', '##ra', 'ii']: too many wordpieces\n",
      "['d', '##3', 'dan', 's', '##1', 'se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['pen', '##di', '##di', '##kan', 'sm', '##a']: too many wordpieces\n",
      "['sl', '##ta', '/', 'sm', '##k', 'minimal', '7', 'dan', 'ip', '##k']: too many wordpieces\n",
      "['rude', 'and', 'di', '##sr', '##es', '##pe', '##ct', '##ful']: too many wordpieces\n",
      "['ada', '##pu', '##n', 'po', '##sis', '##i', 'low', '##onga', '##n', 'ke', '##r', '##ja', 'pt', 'ang', '##kas', '##a']: too many wordpieces\n",
      "['low', '##onga', '##n', 'ke', '##r', '##ja']: too many wordpieces\n",
      "['se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['patient', 'protection', 'and', 'affordable', 'care', 'act']: too many wordpieces\n",
      "['ta', '##hl', '##e', '##qua', '##h', 'oklahoma']: too many wordpieces\n",
      "['north', 'ton', '##awan', '##da', 'new', 'york']: too many wordpieces\n",
      "['mo', '##zi', '##lla', 'fire', '##fo', '##x']: too many wordpieces\n",
      "['benz', '##od', '##ia', '##ze', '##pine', '##s']: too many wordpieces\n",
      "['r', '##he', '##uma', '##to', '##id', 'arthritis']: too many wordpieces\n",
      "['las', 'cr', '##uce', '##s', 'new', 'mexico']: too many wordpieces\n",
      "['tri', '##io', '##dot', '##hy', '##ron', '##ine']: too many wordpieces\n",
      "['i', 'd', 'and', 'social', 'security', 'card']: too many wordpieces\n",
      "['ze', '##phy', '##rh', '##ill', '##s', 'florida']: too many wordpieces\n",
      "['ve', '##riz', '##on', '/', 'fi', '##os']: too many wordpieces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'uniform', 'score': 0.04455406591296197}),\n",
       " (1, {'cand': 'polo', 'score': 0.02965527400374413}),\n",
       " (2, {'cand': 'black', 'score': 0.017656834796071056}),\n",
       " (3, {'cand': 'fashion', 'score': 0.007025882601737979}),\n",
       " (4, {'cand': 'white', 'score': 0.0069195297546684725}),\n",
       " (5, {'cand': 'business', 'score': 0.006704169325530528}),\n",
       " (6, {'cand': 'sport', 'score': 0.006549005396664144}),\n",
       " (7, {'cand': 'sports', 'score': 0.006161295343190433}),\n",
       " (8, {'cand': 'blouse', 'score': 0.0048272940330207365}),\n",
       " (9, {'cand': 'professional', 'score': 0.004728434607386588}),\n",
       " (10, {'cand': 'military', 'score': 0.004313169047236442}),\n",
       " (11, {'cand': 'academic', 'score': 0.0034318733960390087}),\n",
       " (12, {'cand': 'leather', 'score': 0.003102471120655537}),\n",
       " (13, {'cand': 'conservative', 'score': 0.0030637043528258814}),\n",
       " (14, {'cand': 'jeans', 'score': 0.002665560925379397}),\n",
       " (15, {'cand': 'navy', 'score': 0.002620982471853495}),\n",
       " (16, {'cand': 'blue', 'score': 0.00248737121000886}),\n",
       " (17, {'cand': 'dance', 'score': 0.002241447567939758}),\n",
       " (18, {'cand': 'gym', 'score': 0.002041458850726485}),\n",
       " (19, {'cand': 'red', 'score': 0.0016900965711101894}),\n",
       " (20, {'cand': 'short', 'score': 0.0016679898835718632}),\n",
       " (21, {'cand': 'ballet', 'score': 0.001553352572955191}),\n",
       " (22, {'cand': 'cocktail', 'score': 0.0013658510288223624}),\n",
       " (23, {'cand': 'shoes', 'score': 0.0013606954598799352}),\n",
       " (24, {'cand': 'school', 'score': 0.0013034377479925754}),\n",
       " (25, {'cand': 'parade', 'score': 0.0011954922229051586}),\n",
       " (26, {'cand': 'cologne', 'score': 0.0011775169987231497}),\n",
       " (27, {'cand': 'camouflage', 'score': 0.001124104717746377}),\n",
       " (28, {'cand': 'clothing', 'score': 0.0011121432762593027}),\n",
       " (29, {'cand': 'western', 'score': 0.0010557781206443904}),\n",
       " (30, {'cand': 'hiking', 'score': 0.0010368055664002893}),\n",
       " (31, {'cand': 'cap', 'score': 0.0010314350947737694}),\n",
       " (32, {'cand': 'games', 'score': 0.000994460890069604}),\n",
       " (33, {'cand': 'private', 'score': 0.0008647564100101592}),\n",
       " (34, {'cand': 'green', 'score': 0.0007808788213878868}),\n",
       " (35, {'cand': 'fencing', 'score': 0.0007750410004518925}),\n",
       " (36, {'cand': 'yoga', 'score': 0.000770907441619784}),\n",
       " (37, {'cand': 'race', 'score': 0.0007613834459334611}),\n",
       " (38, {'cand': 'mandatory', 'score': 0.0007547856657765805}),\n",
       " (39, {'cand': 'police', 'score': 0.000732660235371441}),\n",
       " (40, {'cand': 'logo', 'score': 0.0007080797804519533}),\n",
       " (41, {'cand': 'golf', 'score': 0.0006943650660105047}),\n",
       " (42, {'cand': 'textile', 'score': 0.0006380623672157527}),\n",
       " (43, {'cand': 'oxford', 'score': 0.0006100764148868621}),\n",
       " (44, {'cand': 'alternative', 'score': 0.0006094449199736118}),\n",
       " (45, {'cand': 'general', 'score': 0.0006087826914153993}),\n",
       " (46, {'cand': 'house', 'score': 0.0005967789329588415}),\n",
       " (47, {'cand': 'music', 'score': 0.0005966964527033267}),\n",
       " (48, {'cand': 'jewellery', 'score': 0.0005728304968215525}),\n",
       " (49, {'cand': 'french', 'score': 0.0005440290551632642})]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'dress code including business casual, [MASK] and uniform.'\n",
    "_res = lm_probe.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant', '##ar', 'fa', '##sc', '##ii', '##tis']: too many wordpieces\n",
      "['work', '##man', \"'\", 's', 'com', '##p']: too many wordpieces\n",
      "['met', '##ham', '##ph', '##eta', '##mine', '##s']: too many wordpieces\n",
      "['pt', 'ang', '##kas', '##a', 'pu', '##ra', 'ii']: too many wordpieces\n",
      "['d', '##3', 'dan', 's', '##1', 'se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['pen', '##di', '##di', '##kan', 'sm', '##a']: too many wordpieces\n",
      "['sl', '##ta', '/', 'sm', '##k', 'minimal', '7', 'dan', 'ip', '##k']: too many wordpieces\n",
      "['rude', 'and', 'di', '##sr', '##es', '##pe', '##ct', '##ful']: too many wordpieces\n",
      "['ada', '##pu', '##n', 'po', '##sis', '##i', 'low', '##onga', '##n', 'ke', '##r', '##ja', 'pt', 'ang', '##kas', '##a']: too many wordpieces\n",
      "['low', '##onga', '##n', 'ke', '##r', '##ja']: too many wordpieces\n",
      "['se', '##mu', '##a', 'ju', '##rus', '##an']: too many wordpieces\n",
      "['patient', 'protection', 'and', 'affordable', 'care', 'act']: too many wordpieces\n",
      "['ta', '##hl', '##e', '##qua', '##h', 'oklahoma']: too many wordpieces\n",
      "['north', 'ton', '##awan', '##da', 'new', 'york']: too many wordpieces\n",
      "['mo', '##zi', '##lla', 'fire', '##fo', '##x']: too many wordpieces\n",
      "['benz', '##od', '##ia', '##ze', '##pine', '##s']: too many wordpieces\n",
      "['r', '##he', '##uma', '##to', '##id', 'arthritis']: too many wordpieces\n",
      "['las', 'cr', '##uce', '##s', 'new', 'mexico']: too many wordpieces\n",
      "['tri', '##io', '##dot', '##hy', '##ron', '##ine']: too many wordpieces\n",
      "['i', 'd', 'and', 'social', 'security', 'card']: too many wordpieces\n",
      "['ze', '##phy', '##rh', '##ill', '##s', 'florida']: too many wordpieces\n",
      "['ve', '##riz', '##on', '/', 'fi', '##os']: too many wordpieces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'tattoos', 'score': 0.4160754084587097}),\n",
       " (1, {'cand': 'hair', 'score': 0.039885014295577996}),\n",
       " (2, {'cand': 'lipstick', 'score': 0.02614353969693184}),\n",
       " (3, {'cand': 'sunglasses', 'score': 0.012342552654445166}),\n",
       " (4, {'cand': 'clothing', 'score': 0.006540362257510425}),\n",
       " (5, {'cand': 'jewellery', 'score': 0.006417935248464348}),\n",
       " (6, {'cand': 'cosmetics', 'score': 0.00435011088848114}),\n",
       " (7, {'cand': 'tattoo', 'score': 0.0035406514070928105}),\n",
       " (8, {'cand': 'shoes', 'score': 0.002573060104623437}),\n",
       " (9, {'cand': 'jeans', 'score': 0.0015570956747978924}),\n",
       " (10, {'cand': 'mascara', 'score': 0.0012895131949335337}),\n",
       " (11, {'cand': 'nipples', 'score': 0.001285086153075099}),\n",
       " (12, {'cand': 'skin', 'score': 0.0012442303122952583}),\n",
       " (13, {'cand': 'logos', 'score': 0.0007056326139718295}),\n",
       " (14, {'cand': 'ponytail', 'score': 0.0006706683780066669}),\n",
       " (15, {'cand': 'cologne', 'score': 0.0005899472744204106}),\n",
       " (16, {'cand': 'handcuffs', 'score': 0.0004861631023231892}),\n",
       " (17, {'cand': 'fashion', 'score': 0.00040361110586673027}),\n",
       " (18, {'cand': 'ink', 'score': 0.0003704534901771694}),\n",
       " (19, {'cand': 'leather', 'score': 0.00036086651380173857}),\n",
       " (20, {'cand': 'bra', 'score': 0.0003455223341006785}),\n",
       " (21, {'cand': 'panties', 'score': 0.00032147014280781123}),\n",
       " (22, {'cand': 'diamonds', 'score': 0.00022189784795045853}),\n",
       " (23, {'cand': 'perfume', 'score': 0.0002087581233354285}),\n",
       " (24, {'cand': 'blouse', 'score': 0.00020739002502523352}),\n",
       " (25, {'cand': 'caps', 'score': 0.00019489179248921576}),\n",
       " (26, {'cand': 'massage', 'score': 0.00018562667537480606}),\n",
       " (27, {'cand': 'strings', 'score': 0.0001827444357331843}),\n",
       " (28, {'cand': 'spurs', 'score': 0.00017977858078666042}),\n",
       " (29, {'cand': 'drugs', 'score': 0.00017894087068270884}),\n",
       " (30, {'cand': 'braid', 'score': 0.00014467231812886896}),\n",
       " (31, {'cand': 'salsa', 'score': 0.00014367171388585112}),\n",
       " (32, {'cand': 'ipod', 'score': 0.00013278145343065256}),\n",
       " (33, {'cand': 'helmet', 'score': 0.00013081241922918702}),\n",
       " (34, {'cand': 'walks', 'score': 0.0001287970080738888}),\n",
       " (35, {'cand': 'arms', 'score': 0.00012560494360513993}),\n",
       " (36, {'cand': 'magazines', 'score': 0.00012389807670842845}),\n",
       " (37, {'cand': 'electronics', 'score': 0.0001164442001027056}),\n",
       " (38, {'cand': 'mouth', 'score': 0.00011105674639111385}),\n",
       " (39, {'cand': 'black', 'score': 0.00010903218208113692}),\n",
       " (40, {'cand': 'bald', 'score': 0.00010864356590900566}),\n",
       " (41, {'cand': 'pink', 'score': 0.00010707452747737987}),\n",
       " (42, {'cand': 'surgery', 'score': 0.00010323254537070171}),\n",
       " (43, {'cand': 'soap', 'score': 0.00010150847083423295}),\n",
       " (44, {'cand': 'uniform', 'score': 9.195468010148038e-05}),\n",
       " (45, {'cand': 'phones', 'score': 9.121437324211007e-05}),\n",
       " (46, {'cand': 'aids', 'score': 8.46141119836829e-05}),\n",
       " (47, {'cand': 'transgender', 'score': 8.40947468532249e-05}),\n",
       " (48, {'cand': 'microphone', 'score': 7.96550011727959e-05}),\n",
       " (49, {'cand': 'tongue', 'score': 7.839599129511046e-05})]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'dress code including business casual, uniform, hair color, tattoos, facial hair, shoes, [MASK] and piercings.'\n",
    "_res = lm_probe.score_candidates(input_txt=_template, cands=all_entities)\n",
    "list(enumerate(_res[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EE_LMProbe(seed_concepts_path,\n",
    "               emb_path,\n",
    "               lm_probe_type,\n",
    "               concepts=None,\n",
    "               embedding_dim=768,\n",
    "               tmpl_agg_func=None,\n",
    "               max_n_grams=5,\n",
    "               topk=None,\n",
    "               dest=None,\n",
    "               **kwargs):\n",
    "    '''\n",
    "    EE using LM probing with Hearst prompts like:\n",
    "    \"dress code, such as jeans, [MASK] and shirts.\" or \n",
    "    \"dress code, including jeans, [MASK] and shirts.\" or\n",
    "    \"jeans, [MASK], shirts and other dress code\" or \n",
    "    '''\n",
    "    \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    entity_embeddings = load_embeddings(emb_path, embedding_dim)\n",
    "    all_entities = entity_embeddings['entity'].tolist()\n",
    "    all_embeddings = entity_embeddings['embedding'].tolist()\n",
    "    entity_emb_dict = dict(zip(all_entities, all_embeddings))\n",
    "    \n",
    "#     with open(templates_path, 'r') as f:\n",
    "#         all_templates = json.load(f)\n",
    "#     templates = all_templates[relation]\n",
    "#     templates = templates['positive'] + templates['negative']\n",
    "    \n",
    "    probe_prompts = [\n",
    "        \"{0}, such as {1}, {2} and {3}.\",\n",
    "        \"{0}, including {1}, {2} and {3}.\",\n",
    "        \"{1}, {2}, {3} and other {0}.\",\n",
    "    ]\n",
    "\n",
    "    if lm_probe_type == 'bert':\n",
    "        lm_probe = LMProbe(max_n_grams=max_n_grams)\n",
    "    elif lm_probe_type == 'gpt2':\n",
    "        lm_probe = LMProbe_GPT2()\n",
    "    elif lm_probe_type == 'joint':\n",
    "        lm_probe = LMProbe_Joint(max_n_grams=max_n_grams)\n",
    "#     elif lm_probe_type == 'pmi':\n",
    "#         lm_probe = LMProbe_PMI()\n",
    "#     elif lm_probe_type == 'pmi_greedy':\n",
    "#         lm_probe = LMProbe_PMI_greedy()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"lm_probe_type = {lm_probe_type}\")\n",
    "    \n",
    "    if lm_probe_type in ['bert', 'joint']:\n",
    "        all_cand_entities = [e for e in all_entities if len(lm_probe.tokenizer.tokenize(e)) <= max_n_grams]\n",
    "    else:\n",
    "        all_cand_entities = all_entities\n",
    "    all_cand_entities = list(set(all_cand_entities))\n",
    "    \n",
    "    if tmpl_agg_func is None:\n",
    "        tmpl_agg_func = max\n",
    "    \n",
    "    seed_instances_dict = dict(zip(\n",
    "        seed_concepts_df['alignedCategoryName'].tolist(),\n",
    "        seed_concepts_df['seedInstances'].tolist()\n",
    "    ))\n",
    "    \n",
    "    if concepts is None:\n",
    "        concepts = seed_concepts_df['alignedCategoryName'].tolist()\n",
    "    \n",
    "    all_extraction_results = []\n",
    "    for cc in tqdm(concepts):\n",
    "        # c_head_tokenized = lm_probe.tokenizer.tokenize(c_head)\n",
    "        seeds = seed_instances_dict[cc]\n",
    "        cc_phrase = ' '.join(cc.split('_'))\n",
    "\n",
    "        extraction_results = []\n",
    "        cand_scores = []  # List[Dict[\"cand\", \"score\"]], for each \"cand\" the average score \n",
    "        \n",
    "        if lm_probe_type in ['bert', 'gpt2', 'joint']:\n",
    "            # Score: prob\n",
    "            cand_scores_per_template = []\n",
    "            for template in probe_prompts:\n",
    "                # template: {0} = concept, {1-3} = instances\n",
    "                _input_txt = template.format(cc_phrase, ', '.join(seeds[:-1]), '[MASK]', seeds[-1])\n",
    "                # print(_input_txt)\n",
    "                _cand_scores = lm_probe.score_candidates(_input_txt, all_cand_entities)\n",
    "                _cand_scores.sort(key=lambda d : d[\"cand\"])\n",
    "                # List[Dict[\"cand\", \"score\"]]\n",
    "                cand_scores_per_template.append(_cand_scores)\n",
    "\n",
    "            for _cand_score_lst in zip(*cand_scores_per_template):\n",
    "                # _cand_score_lst: List[Dict[\"cand\", \"score\"]], for the same \"cand\" and different template \n",
    "                _cand = _cand_score_lst[0][\"cand\"]\n",
    "                assert all(d[\"cand\"] == _cand for d in _cand_score_lst), _cand_score_lst\n",
    "                _score = tmpl_agg_func([d[\"score\"] for d in _cand_score_lst])\n",
    "                # _score = np.log(_score)\n",
    "                cand_scores.append({\"cand\": _cand, \"score\": _score})\n",
    "        elif lm_probe_type in ['pmi', 'pmi_greedy']:\n",
    "            # Score: PMI \n",
    "            raise NotImplementedError\n",
    "            \n",
    "\n",
    "        for d in cand_scores:\n",
    "            e = d[\"cand\"]\n",
    "            if e in seeds:\n",
    "                continue\n",
    "\n",
    "            lm_score = d[\"score\"]\n",
    "            extraction_results.append({'concept': cc,\n",
    "                                       'neighbor': e,\n",
    "                                       'lm_score': lm_score\n",
    "                                      })\n",
    "        \n",
    "        extraction_results.sort(key=lambda d : d['lm_score'], reverse=True)\n",
    "        all_extraction_results.extend(extraction_results[:topk])\n",
    "\n",
    "#     all_extraction_results.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "#     all_extraction_results = all_extraction_results[:topk]\n",
    "\n",
    "    results_df = pd.DataFrame(all_extraction_results)\n",
    "    if dest is not None:\n",
    "        results_df.to_csv(dest, index=None)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56aaa3daf4224f679f5100a196d1982e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>lm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company</td>\n",
       "      <td>nike</td>\n",
       "      <td>0.073686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.053486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>ibm</td>\n",
       "      <td>0.047059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>company</td>\n",
       "      <td>sears</td>\n",
       "      <td>0.043689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>0.026793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>onboarding_steps</td>\n",
       "      <td>job performance</td>\n",
       "      <td>0.001784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>onboarding_steps</td>\n",
       "      <td>school</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>onboarding_steps</td>\n",
       "      <td>staff members</td>\n",
       "      <td>0.001776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>onboarding_steps</td>\n",
       "      <td>gym</td>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>onboarding_steps</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0.001742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               concept         neighbor  lm_score\n",
       "0              company             nike  0.073686\n",
       "1              company            apple  0.053486\n",
       "2              company              ibm  0.047059\n",
       "3              company            sears  0.043689\n",
       "4              company        starbucks  0.026793\n",
       "...                ...              ...       ...\n",
       "1395  onboarding_steps  job performance  0.001784\n",
       "1396  onboarding_steps           school  0.001783\n",
       "1397  onboarding_steps    staff members  0.001776\n",
       "1398  onboarding_steps              gym  0.001750\n",
       "1399  onboarding_steps        nutrition  0.001742\n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "\n",
    "topk = 100\n",
    "ee_output_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/ee_LM_bert_k={topk}.csv')\n",
    "\n",
    "EE_LMProbe(seed_concepts_path=seed_aligned_concepts_path,\n",
    "           emb_path=emb_path,\n",
    "           lm_probe_type='bert',\n",
    "           concepts=None,\n",
    "           embedding_dim=768,\n",
    "           tmpl_agg_func=None,\n",
    "           max_n_grams=5,\n",
    "           topk=topk,\n",
    "           dest=ee_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████| 14/14 [00:52<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use scripts \n",
    "!python compute_EE_LM_probe.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-lm bert \\\n",
    "-topk 200 \\\n",
    "-o $base_dir/data/$data_ac/intermediate/ee_LM_bert_k=200.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit here: /meg_shared_scripts/meg-kb/src/analysis/concept_learning-test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')\n",
    "\n",
    "concept_knn_path = concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_embeddings = load_embeddings(bert_emb_path, 768)\n",
    "entity_emb_dict = dict(zip(entity_embeddings['entity'].tolist(), entity_embeddings['embedding'].tolist()))\n",
    "\n",
    "seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "\n",
    "concepts_knn_df = pd.read_csv(concept_knn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_records = []\n",
    "# record item: List[\n",
    "#     (con_name, con_emb),\n",
    "#     List[(seed_name, seed_emb)],\n",
    "#     List[(inst_name, inst_emb)],\n",
    "# ]\n",
    "\n",
    "for i, (a_concept, u_concept, gnrl, _seed_instances) in seed_concepts_df.iterrows():\n",
    "    _seed_embs = []\n",
    "    for inst in _seed_instances:\n",
    "        try:\n",
    "            _emb = entity_emb_dict[inst]\n",
    "            _seed_embs.append(_emb)\n",
    "        except KeyError:\n",
    "            print(f\"{inst} not found in entity_emb_dict??\")\n",
    "            continue\n",
    "    if len(_seed_embs) == 0:\n",
    "        continue\n",
    "    _concept_emb = np.mean(_seed_embs, axis=0)\n",
    "    \n",
    "    _concept_knns = concepts_knn_df[concepts_knn_df['concept'] == a_concept]['neighbor'].tolist()\n",
    "    _concept_knn_embs = [entity_emb_dict[inst] for inst in _concept_knns]\n",
    "    \n",
    "    _record = [(a_concept, _concept_emb),\n",
    "       list(zip(seed_instances, _seed_embs)),\n",
    "       list(zip(_concept_knns, _concept_knn_embs))\n",
    "    ]\n",
    "    \n",
    "    vis_records.append(_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "_label_list = []\n",
    "_raw_emb_list = []\n",
    "_size_list = []   # knn = 1, seed = 2, concept = 3 \n",
    "_color_id_list = []\n",
    "\n",
    "_CONCEPT_SIZE = 100\n",
    "_SEED_SIZE = 30\n",
    "_CAND_SIZE = 1\n",
    "\n",
    "for c_id, ((_con, _con_emb), _seeds, _knns) in enumerate(vis_records):\n",
    "    _label_list.append(_con)\n",
    "    _raw_emb_list.append(_con_emb)\n",
    "    _size_list.append(_CONCEPT_SIZE)\n",
    "    _color_id_list.append(c_id)\n",
    "    for _seed, _seed_emb in _seeds:\n",
    "        _label_list.append(_seed)\n",
    "        _raw_emb_list.append(_seed_emb)\n",
    "        _size_list.append(_SEED_SIZE)\n",
    "        _color_id_list.append(c_id)\n",
    "    for _inst, _inst_emb in _knns:\n",
    "        _label_list.append(_inst)\n",
    "        _raw_emb_list.append(_inst_emb)\n",
    "        _size_list.append(_CAND_SIZE)\n",
    "        _color_id_list.append(c_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_raw_emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "_tsne_emb_list = tsne.fit_transform(_raw_emb_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_tsne_x, _tsne_y = list(zip(*_tsne_emb_list))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.gca()\n",
    "\n",
    "# _scatter = ax.scatter(_tsne_x, _tsne_y, s=_size_list, c=_color_id_list)\n",
    "\n",
    "cmap = plt.get_cmap(name='viridis')\n",
    "\n",
    "for c_id, _record in enumerate(vis_records[:10]):\n",
    "    _data_ids = [i for i, c in enumerate(_color_id_list) if c == c_id]\n",
    "    _x = [_tsne_x[i] for i in _data_ids]\n",
    "    _y = [_tsne_y[i] for i in _data_ids]\n",
    "    _s = [_size_list[i] for i in _data_ids]\n",
    "#     _c = [c_id for i in _data_ids]\n",
    "#     _c = matplotlib.colors.rgb2hex(cmap(1.0 * c_id / len(vis_records)))\n",
    "    ax.scatter(_x, _y, s=_s, label=_record[0][0])\n",
    "\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend1 = ax.legend(*_scatter.legend_elements(), title=\"Classes\")\n",
    "# # ax.add_artist(legend1)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.colors.rgb2hex(cmap(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112515, 3)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/ee_LM_bert_k=None.csv')\n",
    "ee_df = pd.read_csv(ee_path)\n",
    "ee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8036"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cc = 'benefits'\n",
    "_cc_df = ee_df[ee_df['concept'] == _cc]\n",
    "_cc_cands = _cc_df['neighbor'].tolist()\n",
    "len(_cc_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corporate offices',\n",
       " 'limited availability',\n",
       " 'intelligence',\n",
       " 'history',\n",
       " 'pay increase',\n",
       " '24 hrs',\n",
       " 'drivers license',\n",
       " 'higher pay',\n",
       " 'costumer service',\n",
       " 'television',\n",
       " 'contact number',\n",
       " 'online courses',\n",
       " 'pay grade',\n",
       " 'email address',\n",
       " 'criminal back ground',\n",
       " 'lease',\n",
       " 'rest breaks',\n",
       " '48 hrs',\n",
       " 'pre hire',\n",
       " 'pre hire',\n",
       " 'previous jobs',\n",
       " 'airline',\n",
       " 'record report',\n",
       " 'incident management',\n",
       " 'low pay',\n",
       " 'sexual orientation',\n",
       " 'electric chair',\n",
       " 'guard card',\n",
       " 'career path',\n",
       " 'final interview',\n",
       " 'legal issues',\n",
       " 'climate',\n",
       " 'set schedule',\n",
       " 'phone interviews',\n",
       " 'pre screening',\n",
       " '$ 1 . 50',\n",
       " 'air conditioner',\n",
       " 'new jersey',\n",
       " 'prepaid card',\n",
       " 'lifeguard',\n",
       " 'sleep deprivation',\n",
       " 'brown or black',\n",
       " 'aids',\n",
       " 'fourty hours',\n",
       " 'retail sales',\n",
       " 'debit card',\n",
       " 'pharmacy department',\n",
       " 'basic english',\n",
       " 'seasonal workers',\n",
       " 'grade point average',\n",
       " 'contract',\n",
       " 'prep food',\n",
       " 'company policies',\n",
       " 'wind',\n",
       " 'customer engagement',\n",
       " 'online application',\n",
       " 'general warehouse',\n",
       " 'fertility',\n",
       " 'charge card',\n",
       " 'purchase order',\n",
       " 'federal prison',\n",
       " 'salon manager',\n",
       " 'shipping and receiving',\n",
       " 'college station',\n",
       " 'meal periods',\n",
       " 'discount rate',\n",
       " 'hire date',\n",
       " 'assisted living',\n",
       " 'trainee program',\n",
       " 'plus tips',\n",
       " 'civil rights',\n",
       " 'guardian',\n",
       " 'hunger games',\n",
       " 'career goals',\n",
       " 'inventory control',\n",
       " 'small raise',\n",
       " 'pay attention',\n",
       " 'tan or black pants',\n",
       " 'firearm',\n",
       " 'pay structure',\n",
       " 'checking account',\n",
       " 'sales consultant',\n",
       " 'overnight stockers',\n",
       " 'certifications',\n",
       " 'air conditioning',\n",
       " 'mental disorders',\n",
       " 'chief executive officer',\n",
       " 'kidney failure',\n",
       " 'social networks',\n",
       " 'shopping experience',\n",
       " 'criminal background',\n",
       " 'population growth',\n",
       " '45 mins',\n",
       " 'poverty',\n",
       " 'federal government',\n",
       " 'production company',\n",
       " 'beauty advisor',\n",
       " 'industrial',\n",
       " 'multi tasking',\n",
       " 'multi tasking']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some correct: higher pay, pay increase, aids, small raise, etc,\n",
    "\n",
    "_cc_cands[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toleration',\n",
       " 'jury duty',\n",
       " 'vultures',\n",
       " 'central california',\n",
       " 'es muy',\n",
       " 'assistant manger',\n",
       " 'lemont illinois',\n",
       " 'guam',\n",
       " 'pre screen',\n",
       " 'crew members',\n",
       " 'store brand',\n",
       " 'independent contractor',\n",
       " 'park city',\n",
       " 'wide variety',\n",
       " 'union',\n",
       " 'olympia',\n",
       " 'door greeters',\n",
       " 'safeway',\n",
       " 'class b',\n",
       " 'west palm beach florida',\n",
       " 'hardware store',\n",
       " 'assembly line',\n",
       " 'diamond',\n",
       " 'tipped out',\n",
       " 'web browser',\n",
       " 'green polo',\n",
       " 'seatbelt',\n",
       " 'police officer',\n",
       " 'stipend',\n",
       " 'assist customers',\n",
       " 'nonprofit',\n",
       " 'pepsi center',\n",
       " 'best bet',\n",
       " 'felony friendly',\n",
       " 'ralphs',\n",
       " 'team lead',\n",
       " 'halter',\n",
       " 'store owner',\n",
       " 'coney island',\n",
       " 'longmont colorado',\n",
       " 'unions',\n",
       " 'juice',\n",
       " 'perris california',\n",
       " 'manoa',\n",
       " '6 months',\n",
       " 'cultural',\n",
       " 'american airlines',\n",
       " 'saturday sunday',\n",
       " 'monday sunday',\n",
       " 'camera',\n",
       " 'rivets',\n",
       " 'hybrid',\n",
       " 'sunday saturday',\n",
       " 'restoration',\n",
       " 'grand island nebraska',\n",
       " 'lead',\n",
       " 'dialysis',\n",
       " 'team effort',\n",
       " 'washington state',\n",
       " 'billerica',\n",
       " 'phoenix arizona',\n",
       " 'tj maxx',\n",
       " 'neckline',\n",
       " 'florida',\n",
       " 'bad timing',\n",
       " 'little ceasers',\n",
       " 'southern company',\n",
       " 'store volume',\n",
       " 'whole foods',\n",
       " 'strict policy',\n",
       " 'afterlife',\n",
       " 'tractor trailer',\n",
       " 'a 4',\n",
       " 'federal',\n",
       " 'asst managers',\n",
       " 'fl',\n",
       " 'garlic',\n",
       " 'attic',\n",
       " 'routing number',\n",
       " 'webinar',\n",
       " 'last minute',\n",
       " 'couple weeks',\n",
       " 'american eagle outfitters',\n",
       " 'inhaler',\n",
       " 'collective bargaining',\n",
       " 'wear gloves',\n",
       " 'rhetorical question',\n",
       " 'temp service',\n",
       " 'ranch',\n",
       " 'barbiturate',\n",
       " 'half price',\n",
       " 'fast pace',\n",
       " 'psy',\n",
       " 'hip hop music',\n",
       " 'violence',\n",
       " 'individualism',\n",
       " 'colored shirt',\n",
       " 'dinning room',\n",
       " 'busiest days',\n",
       " 'photographer']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some correct: stipend\n",
    "\n",
    "_cc_cands[3000:3100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8037"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cc = 'company'\n",
    "_cc_df = ee_df[ee_df['concept'] == _cc]\n",
    "_cc_cands = _cc_df['neighbor'].tolist()\n",
    "len(_cc_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meeting new people',\n",
       " 'panda express',\n",
       " 'corporate offices',\n",
       " 'wv',\n",
       " 'casual clothing',\n",
       " 'seat belt',\n",
       " 'burlington',\n",
       " 'pc',\n",
       " 'tort',\n",
       " 'rogers arkansas',\n",
       " 'east point georgia',\n",
       " 'marketing',\n",
       " 'miller county',\n",
       " 'montebello',\n",
       " 'store mgr',\n",
       " 'tampa international airport',\n",
       " 'chick fil',\n",
       " 'home shopping',\n",
       " 'quest diagnostics',\n",
       " 'orange shirt',\n",
       " 'cram school',\n",
       " 'overnight stockers',\n",
       " 'carriage house',\n",
       " 'new hire packet',\n",
       " 'attorney general',\n",
       " 'sapphire',\n",
       " 'track records',\n",
       " 'field tech',\n",
       " 'panama city beach',\n",
       " 'friendswood texas',\n",
       " 'skylight',\n",
       " 'memphis tn',\n",
       " 'battery',\n",
       " 'medical history',\n",
       " 'tobacco smoking',\n",
       " 'great deal',\n",
       " 'black khaki',\n",
       " 'sams',\n",
       " 'deep learning',\n",
       " 'ocean city',\n",
       " 'red polo shirt',\n",
       " 'cps',\n",
       " 'dna',\n",
       " 'finance',\n",
       " 'push ups',\n",
       " 'personal development',\n",
       " 'plum',\n",
       " 'mobile device',\n",
       " 'email',\n",
       " 'a 10',\n",
       " 'american eagle outfitters',\n",
       " 'ram',\n",
       " \"doctor ' s note\",\n",
       " 'biggie',\n",
       " 'npc',\n",
       " 'innovation',\n",
       " 'sweet tea',\n",
       " 'cpi',\n",
       " 'owl',\n",
       " 'cambridge ohio',\n",
       " 'thomas circle',\n",
       " 'jsa',\n",
       " 'capital',\n",
       " 'second chance',\n",
       " 'second chance',\n",
       " 'little rock',\n",
       " 'car',\n",
       " 'webinar',\n",
       " 'blizzards',\n",
       " 'cet',\n",
       " 'nac',\n",
       " 'nuclear science',\n",
       " 'home care',\n",
       " 'longwood',\n",
       " 'a 20',\n",
       " 'fedex express',\n",
       " 'root',\n",
       " 'alaska',\n",
       " 'food court',\n",
       " 'polo ralph lauren',\n",
       " 'public school',\n",
       " 'permanent position',\n",
       " \"macy ' s\",\n",
       " 'snakebite',\n",
       " 'cpr',\n",
       " 'school bus',\n",
       " 'safari',\n",
       " 'hudson',\n",
       " 'sideburns',\n",
       " 'gsm',\n",
       " 'rsc',\n",
       " 'central islip',\n",
       " 'hit / miss',\n",
       " 'west haven',\n",
       " 'oakland california',\n",
       " 'us citizen',\n",
       " 'blizzard',\n",
       " 'russia',\n",
       " 'magazine',\n",
       " 'tifton georgia']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some correct: panda express, little rock?, fedex express, blizzard?, macy's, etc.\n",
    "\n",
    "_cc_cands[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pepperoni',\n",
       " 'ma',\n",
       " 'osmosis',\n",
       " 'winston salem',\n",
       " 'prestige',\n",
       " 'christian values',\n",
       " 'citrus heights',\n",
       " 'hourly guarantee',\n",
       " 'calendar year',\n",
       " 'food allergy',\n",
       " 'west mifflin',\n",
       " 'disneyland',\n",
       " 'topeka',\n",
       " 'inventory control',\n",
       " 'angry customer',\n",
       " 'torrance',\n",
       " 'heraclitus',\n",
       " 'electricity',\n",
       " 'americus',\n",
       " 'huntingdon',\n",
       " 'bubble gum',\n",
       " 'bartlesville',\n",
       " 'pays bi weekly',\n",
       " 'shotguns',\n",
       " 'clovis',\n",
       " 'suicide note',\n",
       " 'santa monica california',\n",
       " 'cronyism',\n",
       " 'ted nugent',\n",
       " 'patent',\n",
       " 'holiday inn express',\n",
       " 'lead',\n",
       " 'magnet',\n",
       " 'downers grove',\n",
       " 'barbiturate',\n",
       " 'el paso tx',\n",
       " 'phone numbers',\n",
       " 'los angeles ca',\n",
       " 'newspaper',\n",
       " 'holiday clerk',\n",
       " 'jasmine',\n",
       " 'blue jacket',\n",
       " 'mass number',\n",
       " 'high school',\n",
       " 'cafeteria',\n",
       " 'toxic work environment',\n",
       " 'lol',\n",
       " 'leaf',\n",
       " 'capri',\n",
       " 'heart failure',\n",
       " 'missoula county',\n",
       " 'pedi',\n",
       " 'marsh',\n",
       " 'tivo',\n",
       " 'burrow',\n",
       " 'cohasset',\n",
       " 'funland',\n",
       " 'sauna',\n",
       " 'ship',\n",
       " 'athens ga',\n",
       " 'enforcement agency',\n",
       " 'tangerang',\n",
       " 'seafood',\n",
       " 'mesa',\n",
       " 'drug related crime',\n",
       " 'abilene kansas',\n",
       " 'laptops',\n",
       " 'lafayette indiana',\n",
       " 'aeg',\n",
       " 'grace period',\n",
       " 'corinth',\n",
       " 'warranty',\n",
       " 'high blood pressure',\n",
       " 'dv',\n",
       " 'live oak',\n",
       " '50 lbs',\n",
       " 'college station',\n",
       " 'steel',\n",
       " 'dubai',\n",
       " 'plus tips',\n",
       " 'dress business casual',\n",
       " 'mile run',\n",
       " 'scapegoat',\n",
       " 'greenville texas',\n",
       " 'saint paul',\n",
       " 'dayton',\n",
       " 'met team',\n",
       " 'low paying',\n",
       " 'acrylic nails',\n",
       " 'advance notice',\n",
       " 'polo shirt',\n",
       " 'philadelphia',\n",
       " 'la mesa',\n",
       " 'secaucus',\n",
       " 'vine',\n",
       " 'learning experience',\n",
       " 'dispatcher',\n",
       " 'isu',\n",
       " 'telegraph',\n",
       " 'gis']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some correct: disneyland? (many unsure...)\n",
    "\n",
    "_cc_cands[3000:3100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111941, 3)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/ee_concept_knn_k=None.csv')\n",
    "ee_df = pd.read_csv(ee_path)\n",
    "ee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7995"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cc = 'benefits'\n",
    "_cc_df = ee_df[ee_df['concept'] == _cc]\n",
    "_cc_cands = _cc_df['neighbor'].tolist()\n",
    "len(_cc_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['senior citizens',\n",
       " 'chick fil',\n",
       " 'operating hours',\n",
       " 'florida',\n",
       " 'fbi',\n",
       " 'pending charges',\n",
       " 'store mgr',\n",
       " 'job fairs',\n",
       " 'taco',\n",
       " 'rotating schedule',\n",
       " 'orientation date',\n",
       " 'night stocker',\n",
       " 'friendly',\n",
       " 'starting wage',\n",
       " 'lod',\n",
       " 'hard worker',\n",
       " 'drama',\n",
       " 'pop',\n",
       " 'sms',\n",
       " 'reliable transportation',\n",
       " 'christmas',\n",
       " 'hiring list',\n",
       " '15 minute break',\n",
       " 'equal opportunity',\n",
       " 'next step',\n",
       " 'fl',\n",
       " 'dental and vision',\n",
       " 'career opportunities',\n",
       " 'washington dc',\n",
       " 'personal information',\n",
       " 'hostile work environment',\n",
       " 'chicken',\n",
       " 'scheduling system',\n",
       " 'customer base',\n",
       " 'seafood',\n",
       " 'md',\n",
       " 'salaried managers',\n",
       " 'alaska',\n",
       " 'coffee',\n",
       " 'hostile environment',\n",
       " 'performance review',\n",
       " 'basic knowledge',\n",
       " 'dish washer',\n",
       " 'legal age',\n",
       " 'oregon',\n",
       " 'cultural',\n",
       " 'scrubs',\n",
       " 'gps',\n",
       " 'ss card',\n",
       " 'personal issues',\n",
       " 'drugs tests',\n",
       " 'big deal',\n",
       " 'louisiana',\n",
       " 'selection list',\n",
       " 'bakery department',\n",
       " 'hygiene',\n",
       " 'philadelphia',\n",
       " 'different kinds',\n",
       " 'cobra',\n",
       " 'smoke breaks',\n",
       " 'alabama',\n",
       " 'low paying',\n",
       " 'taste',\n",
       " 'nature',\n",
       " 'phone interview',\n",
       " 'racist',\n",
       " 'backround check',\n",
       " 'seasonal worker',\n",
       " 'dairy',\n",
       " 'high schoolers',\n",
       " 'assistant manger',\n",
       " 'az',\n",
       " 'substance abuse',\n",
       " 'close attention',\n",
       " 'training class',\n",
       " 'front counter',\n",
       " 'pennsylvania',\n",
       " 'advance notice',\n",
       " 'benefits package',\n",
       " 'local stores',\n",
       " 'water',\n",
       " 'halloween',\n",
       " 'finger prints',\n",
       " 'heat',\n",
       " 'checking account',\n",
       " 'apartments',\n",
       " 'operations manager',\n",
       " 'laptop',\n",
       " 'age group',\n",
       " 'friday',\n",
       " 'tattoos',\n",
       " 'temperature',\n",
       " 'insulated bags',\n",
       " 'wv',\n",
       " 'floor associate',\n",
       " 'cca position',\n",
       " 'buffet',\n",
       " 'break room',\n",
       " 'illegal drugs',\n",
       " '30 min']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some correct: not found \n",
    "\n",
    "_cc_cands[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my worst enemy',\n",
       " 'saint',\n",
       " 'bentonville',\n",
       " 'sit down',\n",
       " 'radar',\n",
       " 'tennis',\n",
       " 'food quality',\n",
       " 'tsa',\n",
       " 'civilian',\n",
       " 'toed shoes',\n",
       " 'leather',\n",
       " 'two face',\n",
       " 'ro',\n",
       " 'pmr',\n",
       " 'minute breaks',\n",
       " 'financial services',\n",
       " 'dv',\n",
       " 'closed toe',\n",
       " 'decatur',\n",
       " 'refrigeration',\n",
       " '10 pm 7 am',\n",
       " 'kool aid',\n",
       " 'charleston',\n",
       " 'liberal',\n",
       " 'macon ga',\n",
       " 'assembler',\n",
       " 'velcro',\n",
       " 'bean',\n",
       " 'maintenance workers',\n",
       " 'goat',\n",
       " 'non compete clause',\n",
       " 'southern illinois',\n",
       " 'sponge',\n",
       " 'black',\n",
       " 'hard copy',\n",
       " 'mountains',\n",
       " 'stimulant',\n",
       " 'rock',\n",
       " 'car wash',\n",
       " 'open toe',\n",
       " 'atlantic',\n",
       " 'ugg boots',\n",
       " 'non slip',\n",
       " 'probability',\n",
       " 'poster',\n",
       " 'magazine',\n",
       " 'voice mail',\n",
       " 'logic',\n",
       " 'vista',\n",
       " 'independently owned',\n",
       " 'ocala',\n",
       " 'butter',\n",
       " 'windsor',\n",
       " 'edwardsville',\n",
       " 'reconstruction',\n",
       " 'farce',\n",
       " 'painting',\n",
       " 'absolute garbage',\n",
       " 'negligence',\n",
       " 'rat',\n",
       " 'festival',\n",
       " 'bpo',\n",
       " 'wallingford',\n",
       " 'sexuality',\n",
       " 'mobile phones',\n",
       " 'solid color',\n",
       " 'black t shirt',\n",
       " 'resistance shoes',\n",
       " 'detective',\n",
       " 'class action lawsuit',\n",
       " 'pharmacy school',\n",
       " 'embezzlement',\n",
       " 'flannel',\n",
       " 'savannah ga',\n",
       " 'personal development',\n",
       " 'speedway',\n",
       " 'birth control',\n",
       " 'lab coats',\n",
       " 'wells fargo bank',\n",
       " 'urban',\n",
       " 'nation wide',\n",
       " 'comfortable clothes',\n",
       " 'tulsa oklahoma',\n",
       " 'salt',\n",
       " 'close toe',\n",
       " 'hiv',\n",
       " 'recording',\n",
       " 'business card',\n",
       " 'extremely flexible',\n",
       " 'rainbow',\n",
       " 'multiple choice',\n",
       " 'picnic',\n",
       " 'fcc',\n",
       " 'omaha nebraska',\n",
       " 'petersburg',\n",
       " 'well groomed',\n",
       " 'change management',\n",
       " 'plain black',\n",
       " 'infrastructure',\n",
       " 'salary based']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some correct: not found \n",
    "\n",
    "_cc_cands[3000:3100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7996"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cc = 'company'\n",
    "_cc_df = ee_df[ee_df['concept'] == _cc]\n",
    "_cc_cands = _cc_df['neighbor'].tolist()\n",
    "len(_cc_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['owner operator',\n",
       " 'grocery stores',\n",
       " 'lafayette',\n",
       " 'sam walton',\n",
       " 'peers',\n",
       " 'met team',\n",
       " 'indianapolis',\n",
       " 'extensive background checks',\n",
       " 'higher level',\n",
       " 'lawyer',\n",
       " 'couple months',\n",
       " 'sms',\n",
       " 'cleveland',\n",
       " 'primark',\n",
       " 'solution',\n",
       " 'togo',\n",
       " 'tv',\n",
       " 'common practice',\n",
       " 'fork lift',\n",
       " 'door greeter',\n",
       " 'taste',\n",
       " 'hard worker',\n",
       " 'motivation',\n",
       " 'appeal',\n",
       " 'min wage',\n",
       " 'forest',\n",
       " 'strict policy',\n",
       " 'test results',\n",
       " 'medical marijuana card',\n",
       " 'lower management',\n",
       " 'nashville',\n",
       " 'professional',\n",
       " 'starting point',\n",
       " 'bonus structure',\n",
       " 'facial hair',\n",
       " 'purple hair',\n",
       " '1st interview',\n",
       " 'shift leads',\n",
       " 'colored hair',\n",
       " 'hire date',\n",
       " 'direct deposits',\n",
       " 'social security',\n",
       " 'starter job',\n",
       " 'light',\n",
       " 'guide lines',\n",
       " 'toy',\n",
       " 'turnover rate',\n",
       " 'hr dept',\n",
       " 'mc',\n",
       " 'annual review',\n",
       " 'oklahoma city',\n",
       " 'payment card',\n",
       " 'home jobs',\n",
       " '3rd shift',\n",
       " 'bare minimum',\n",
       " 'own vehicle',\n",
       " 'career employee',\n",
       " 'pet care',\n",
       " 'maine',\n",
       " 'cart pusher',\n",
       " 'clean driving record',\n",
       " 'team effort',\n",
       " 'hair color',\n",
       " 'universal',\n",
       " 'energy',\n",
       " 'car insurance',\n",
       " 'hourly associates',\n",
       " 'life insurance',\n",
       " 'payroll card',\n",
       " 'cake',\n",
       " 'garage',\n",
       " 'cart pushers',\n",
       " 'idaho',\n",
       " 'robbery',\n",
       " 'sacramento',\n",
       " 'cotton',\n",
       " 'spartanburg',\n",
       " 'application entry',\n",
       " 'reno',\n",
       " 'rehire policy',\n",
       " 'click list',\n",
       " 'online assessment',\n",
       " 'seasonal jobs',\n",
       " 'cash tips',\n",
       " 'candy',\n",
       " 'severance pay',\n",
       " 'a 4',\n",
       " 'employee discounts',\n",
       " 'an independent contractor',\n",
       " 'nature',\n",
       " 'area coach',\n",
       " 'sun',\n",
       " 'uniform policy',\n",
       " 'fbi',\n",
       " 'united healthcare',\n",
       " 'third party company',\n",
       " 'heat',\n",
       " 'movie',\n",
       " '7 days',\n",
       " 'circle']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some correct: not found \n",
    "\n",
    "_cc_cands[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business card',\n",
       " 'bar code',\n",
       " 'pedophiles',\n",
       " 'fried chicken',\n",
       " 'protected',\n",
       " 'parents permission',\n",
       " 'steel toed',\n",
       " 'directed',\n",
       " 'atlanta ga',\n",
       " 'hot mess',\n",
       " 'tina',\n",
       " 'designated hitter',\n",
       " 'invoice',\n",
       " 'dv',\n",
       " 'vista',\n",
       " 'ugg boots',\n",
       " 'cuba',\n",
       " 'pump',\n",
       " 'buckeye warehouse',\n",
       " 'lab coat',\n",
       " 'salt',\n",
       " 'denton',\n",
       " 'collard shirts',\n",
       " 'magazine',\n",
       " 'indians',\n",
       " 'larceny',\n",
       " 'job titles',\n",
       " 'petersburg',\n",
       " 'job satisfaction',\n",
       " 'case basis',\n",
       " 'hillsboro',\n",
       " 'tractors',\n",
       " 'rat',\n",
       " 'management trainee',\n",
       " 'shorter than',\n",
       " 'west mifflin',\n",
       " 'wells fargo bank',\n",
       " 'russia',\n",
       " 'merrillville',\n",
       " 'judge',\n",
       " 'palm',\n",
       " 'tulsa oklahoma',\n",
       " 'proper steps',\n",
       " 'clarksville',\n",
       " 'velcro',\n",
       " 'kuwait city',\n",
       " 'automation',\n",
       " 'dearborn',\n",
       " 'guru',\n",
       " 'plymouth',\n",
       " 'team leads',\n",
       " 'red',\n",
       " 'marine',\n",
       " 'rays',\n",
       " 'pajamas',\n",
       " 'portage',\n",
       " 'noc',\n",
       " 'austin tx',\n",
       " 'congress',\n",
       " 'jeans',\n",
       " 'ato',\n",
       " 'salary based',\n",
       " 'chattanooga',\n",
       " 'shark',\n",
       " 'switcher',\n",
       " 'multiple choice',\n",
       " 'ares',\n",
       " 'pretty fast',\n",
       " 'bird',\n",
       " 'high schools',\n",
       " 'ocala',\n",
       " 't shirt',\n",
       " 'atlantic',\n",
       " 'tourist',\n",
       " 'festival',\n",
       " 'clinique',\n",
       " 'casual attire',\n",
       " 'weekly paychecks',\n",
       " 'vending machines',\n",
       " 'resistant shoes',\n",
       " 'medical emergency',\n",
       " 'clover',\n",
       " 'ten dollars',\n",
       " 'millennials',\n",
       " 'pharmacy school',\n",
       " 'browser',\n",
       " 'european',\n",
       " 'savannah ga',\n",
       " 'extremely low',\n",
       " 'mars',\n",
       " 'watching videos',\n",
       " 'summer hours',\n",
       " 'wy',\n",
       " 'public library',\n",
       " 'denim jeans',\n",
       " 'toaster',\n",
       " 'red polo',\n",
       " 'algorithm',\n",
       " 'tacoma washington',\n",
       " 'financial services']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some correct: not found \n",
    "\n",
    "_cc_cands[3000:3100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8064, 7)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/ee_concept_contr_knn_k=None.csv')\n",
    "ee_df = pd.read_csv(ee_path)\n",
    "ee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7580"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cc = 'dress_code'\n",
    "_cc_df = ee_df[(ee_df['concept'] != _cc) & (ee_df['2nd_concept'] != _cc)]\n",
    "_cc_cands = _cc_df['neighbor'].tolist()\n",
    "len(_cc_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coppell',\n",
       " 'healthcare',\n",
       " 'attendance policy',\n",
       " 'full service shoppers',\n",
       " 'etl',\n",
       " 'reverse discrimination',\n",
       " 'medical marijuana card',\n",
       " 'death star',\n",
       " 'southern california',\n",
       " 'etcs',\n",
       " 'dinner rush',\n",
       " 'recidivism',\n",
       " 'chelmsford',\n",
       " 'lgbt',\n",
       " 'hard workers',\n",
       " 'fannie mae',\n",
       " 'paid 15 minute breaks',\n",
       " 'northern virginia',\n",
       " 'extremely low',\n",
       " 'mass hysteria',\n",
       " 'my worst enemy',\n",
       " 'public relations',\n",
       " 'biddeford maine',\n",
       " 'kitchener',\n",
       " 'bucks',\n",
       " 'easter seals',\n",
       " 'sponge',\n",
       " 'national guard',\n",
       " 'vcs',\n",
       " 'tms',\n",
       " 'potatoes',\n",
       " 'salary cap',\n",
       " 'jackson michigan',\n",
       " 'kidney disease',\n",
       " 'chauffeur',\n",
       " 'stimulant',\n",
       " 'big smile',\n",
       " 'japan',\n",
       " 'ghost',\n",
       " 'laboratory school',\n",
       " 'first advantage',\n",
       " 'legal age',\n",
       " 'moral turpitude',\n",
       " 'school district',\n",
       " 'teaching experience',\n",
       " 'charleston west virginia',\n",
       " 'darden restaurants',\n",
       " 'pension',\n",
       " 'urine',\n",
       " 'fresno ca',\n",
       " 'super bowl',\n",
       " 'fraud',\n",
       " 'whitewater',\n",
       " 'torrance',\n",
       " \"hawai'i\",\n",
       " 'ua',\n",
       " 'telegraph',\n",
       " 'akron',\n",
       " 'age limit',\n",
       " 'mc',\n",
       " 'dobbs ferry',\n",
       " 'application entry',\n",
       " 'augusta ga',\n",
       " 'higher position',\n",
       " 'panama city',\n",
       " 'salem',\n",
       " 'offer letter',\n",
       " 'pennsylvania',\n",
       " 'tanning',\n",
       " 'insurance',\n",
       " 'shift bids',\n",
       " 'constantly changing',\n",
       " 'el monte',\n",
       " 'ten dollars',\n",
       " 'pregnancy',\n",
       " 'buffalo ny',\n",
       " 'swab test',\n",
       " 'jp morgan chase',\n",
       " 'fast fashion',\n",
       " 'bathroom breaks',\n",
       " 'derecho',\n",
       " 'meal break',\n",
       " 'los angeles ca',\n",
       " 'clavicle',\n",
       " 'writer',\n",
       " '4 am    12 pm',\n",
       " 'sociology',\n",
       " 'men and women',\n",
       " 'chick fil a',\n",
       " 'gmail',\n",
       " 'mass',\n",
       " 'hampstead',\n",
       " 'hockey',\n",
       " 'marshal',\n",
       " 'springfield mo',\n",
       " 'advancement opportunities',\n",
       " 'huntsville alabama',\n",
       " 'immigrant',\n",
       " 'almost impossible',\n",
       " 'unions']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct: not found \n",
    "random.sample(_cc_cands, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity expansion evaluation\n",
    "Now using benchmark entities, mean reciprocal rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['company', 'dress_code', 'job_position', 'pay_schedule', 'benefits', 'compensation', 'payment_option', 'background_screening', 'person', 'hire_prerequisite', 'shifts', 'schedule', 'employee_type', 'onboarding_steps']\n",
      "['has_pay_schedule', 'has_pay_schedule', 'has_dress_code', 'has_dress_code', 'has_background_screening', 'has_benefits', 'has_benefits', 'hires_person', 'has_compensation', 'has_compensation', 'has_hire_prerequisite', 'operates_on', 'hires_employee_type', 'has_onboarding_steps', 'has_shifts', 'has_shifts', 'has_job_position', 'has_hiring_policy', 'has_payment_option']\n",
      "{'onboarding_steps', 'pay_schedule', 'shifts', 'schedule', 'company', 'job_position', 'hire_prerequisite', 'payment_option', 'benefits', 'background_screening', 'person', 'employee_type', 'dress_code', 'compensation'}\n",
      "(706, 17)\n"
     ]
    }
   ],
   "source": [
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')\n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "\n",
    "seed_aligned_concepts = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "seed_aligned_relations = load_seed_aligned_relations(seed_aligned_relations_path)\n",
    "benchmark = pd.read_csv(benchmark_path)\n",
    "concept_knn = pd.read_csv(concept_knn_path)\n",
    "\n",
    "print(seed_aligned_concepts['alignedCategoryName'].tolist())\n",
    "print(seed_aligned_relations['alignedRelationName'].tolist())\n",
    "print(set(concept_knn['concept'].tolist()))\n",
    "print(benchmark.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_EE(predictions_path,\n",
    "                seed_concepts_path,\n",
    "                seed_relations_path,\n",
    "                benchmark_path):\n",
    "    '''Format of prediction file: CSV, with column \"concept\" and \"neighbor\"(entity) '''\n",
    "    preds_df = pd.read_csv(predictions_path)\n",
    "    \n",
    "    all_benchmark_instances, _ = load_benchmark(benchmark_path, seed_concepts_path, seed_relations_path)\n",
    "    seed_aligned_concepts = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    \n",
    "    mrr_dict = dict()\n",
    "    for i, d in seed_aligned_concepts.iterrows():\n",
    "        a_concept = d[\"alignedCategoryName\"]\n",
    "        u_concept = d[\"unalignedCategoryName\"]\n",
    "        seed_instances = d[\"seedInstances\"]\n",
    "\n",
    "#         concept_knn_instances = concept_knn[concept_knn[\"concept\"] == a_concept][\"neighbor\"].to_list()\n",
    "        pred_instances = preds_df[preds_df[\"concept\"] == a_concept][\"neighbor\"].to_list()\n",
    "\n",
    "#         _b_head_instances = benchmark[benchmark[\"n_head_category\"] == a_concept][\"n_head\"].to_list()\n",
    "#         _b_tail_instances = benchmark[benchmark[\"n_tail_category\"] == a_concept][\"n_tail\"].to_list()\n",
    "#         benchmark_instances = list(set(_b_head_instances + _b_tail_instances))\n",
    "        benchmark_instances = all_benchmark_instances[a_concept]\n",
    "\n",
    "        print(f'Concept: {a_concept} / {u_concept}')\n",
    "        print(f'seeds: {seed_instances}')\n",
    "        b_inst_ranks = dict()\n",
    "        recip_ranks = []\n",
    "        for _inst in benchmark_instances:\n",
    "            if _inst in seed_instances:\n",
    "                b_inst_ranks[_inst] = -1\n",
    "            elif _inst in pred_instances:\n",
    "                _rank = pred_instances.index(_inst) + 1\n",
    "                b_inst_ranks[_inst] = _rank\n",
    "                recip_ranks.append(1.0 / _rank)\n",
    "            else:\n",
    "                b_inst_ranks[_inst] = float('nan')\n",
    "                recip_ranks.append(0.0)\n",
    "                \n",
    "        mrr = np.mean(recip_ranks) if len(recip_ranks) > 0 else 0.0\n",
    "        mrr_dict[a_concept] = mrr\n",
    "        print(json.dumps(b_inst_ranks, indent=4))\n",
    "        print('MRR:', mrr)\n",
    "        print()\n",
    "\n",
    "    print('--- Summary ---')\n",
    "    print(json.dumps(mrr_dict, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "\n",
    "evaluate_EE(predictions_path=concept_knn_path,\n",
    "            seed_concepts_path=seed_aligned_concepts_path,\n",
    "            seed_relations_path=seed_aligned_relations_path,\n",
    "            benchmark_path=benchmark_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: company / company\n",
      "seeds: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "{\n",
      "    \"electric\": NaN,\n",
      "    \"enterprise holdings\": NaN,\n",
      "    \"at&t\": NaN,\n",
      "    \"mcdonald\": NaN,\n",
      "    \"domino's\": NaN,\n",
      "    \"frito\": NaN,\n",
      "    \"applebee's\": NaN,\n",
      "    \"burger king\": NaN,\n",
      "    \"dunkin donuts\": NaN,\n",
      "    \"dd\": NaN,\n",
      "    \"frito lay\": NaN,\n",
      "    \"pepsi\": NaN,\n",
      "    \"teleperformance\": NaN,\n",
      "    \"starbucks\": 34,\n",
      "    \"amazon.com\": NaN,\n",
      "    \"alorica\": NaN,\n",
      "    \"geico\": NaN,\n",
      "    \"ups\": NaN,\n",
      "    \"lowes\": NaN,\n",
      "    \"walmart\": -1,\n",
      "    \"little caesars\": NaN,\n",
      "    \"allied universal security services, systems and solutions\": NaN,\n",
      "    \"chipotle mexican grill\": NaN,\n",
      "    \"foot locker\": NaN,\n",
      "    \"olive garden\": NaN,\n",
      "    \"concentrix\": NaN,\n",
      "    \"sitel\": 428,\n",
      "    \"tj maxx\": NaN,\n",
      "    \"frito-lay\": NaN,\n",
      "    \"subway\": -1,\n",
      "    \"hobby lobby\": NaN,\n",
      "    \"dick's sporting goods\": NaN,\n",
      "    \"home depot\": 228,\n",
      "    \"burlington stores\": NaN,\n",
      "    \"panera bread\": NaN,\n",
      "    \"whataburger\": NaN,\n",
      "    \"dollar general\": 251,\n",
      "    \"g4s\": NaN,\n",
      "    \"instacart\": NaN,\n",
      "    \"macy's\": NaN,\n",
      "    \"fedex\": NaN,\n",
      "    \"chilis\": NaN,\n",
      "    \"cvs\": 426,\n",
      "    \"old navy\": NaN,\n",
      "    \"family dollar\": NaN,\n",
      "    \"safeway\": NaN,\n",
      "    \"dollar tree\": NaN,\n",
      "    \"american eagle outfitters\": NaN,\n",
      "    \"sam's club\": NaN,\n",
      "    \"lowe's\": NaN,\n",
      "    \"heb\": NaN,\n",
      "    \"victoria's secret\": NaN,\n",
      "    \"subways\": NaN,\n",
      "    \"ihop\": NaN,\n",
      "    \"kfc\": NaN,\n",
      "    \"chick-fil-a\": NaN,\n",
      "    \"cvs health\": 375,\n",
      "    \"spectrum\": NaN,\n",
      "    \"kroger stores\": NaN,\n",
      "    \"walgreens\": NaN,\n",
      "    \"marriott international, inc.\": NaN,\n",
      "    \"t.j. maxx\": NaN,\n",
      "    \"tim hortons\": NaN,\n",
      "    \"menards\": NaN,\n",
      "    \"pizza hut\": NaN,\n",
      "    \"training\": NaN,\n",
      "    \"quiktrip\": NaN,\n",
      "    \"primark\": NaN,\n",
      "    \"wendys\": NaN,\n",
      "    \"jcpenney\": NaN,\n",
      "    \"the wendy's company\": NaN,\n",
      "    \"chipotle\": NaN,\n",
      "    \"aldi\": NaN,\n",
      "    \"costco\": NaN,\n",
      "    \"mcdonalds\": 295,\n",
      "    \"fedex ground\": NaN,\n",
      "    \"kohl's\": NaN,\n",
      "    \"t-mobile\": NaN,\n",
      "    \"barnes & noble\": NaN,\n",
      "    \"wells fargo\": NaN,\n",
      "    \"sonic drive-in\": NaN,\n",
      "    \"panera\": NaN,\n",
      "    \"pepsico\": NaN,\n",
      "    \"marshalls\": 272,\n",
      "    \"united states postal service\": NaN,\n",
      "    \"petsmart\": NaN,\n",
      "    \"best buy\": NaN,\n",
      "    \"taco bell\": NaN,\n",
      "    \"planet fitness\": NaN,\n",
      "    \"chili's\": NaN,\n",
      "    \"the home depot\": NaN,\n",
      "    \"kroger\": NaN,\n",
      "    \"goodwill industries\": NaN,\n",
      "    \"doordash\": NaN,\n",
      "    \"costco wholesale\": NaN,\n",
      "    \"ross dress for less\": NaN,\n",
      "    \"publix\": NaN,\n",
      "    \"whole foods market\": NaN,\n",
      "    \"mcdonald's\": NaN,\n",
      "    \"target\": -1,\n",
      "    \"cracker barrel\": NaN,\n",
      "    \"dunkin' donuts\": NaN,\n",
      "    \"ulta\": NaN,\n",
      "    \"verizon\": NaN,\n",
      "    \"amazon\": -1\n",
      "}\n",
      "MRR: 0.0005168180947036231\n",
      "R@100: 0.009900990099009901\n",
      "R@1k: 0.07920792079207921\n",
      "\n",
      "Concept: dress_code / dress code\n",
      "seeds: ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\n",
      "{\n",
      "    \"shoes\": -1,\n",
      "    \"blue collar\": 37,\n",
      "    \"professional\": 16,\n",
      "    \"skirts\": NaN,\n",
      "    \"casual\": NaN,\n",
      "    \"strict dress code\": 252,\n",
      "    \"hairnets\": NaN,\n",
      "    \"facial hair\": -1,\n",
      "    \"facial piercings\": 3,\n",
      "    \"wear jeans\": 198,\n",
      "    \"dress pants\": 27,\n",
      "    \"shorts\": NaN,\n",
      "    \"resistant shoes\": 76,\n",
      "    \"colorful hair\": 417,\n",
      "    \"shirts\": NaN,\n",
      "    \"black slacks\": NaN,\n",
      "    \"dress shirts\": 46,\n",
      "    \"wear shorts\": NaN,\n",
      "    \"black jeans\": 413,\n",
      "    \"pants\": NaN,\n",
      "    \"ponytail\": NaN,\n",
      "    \"red shirts\": NaN,\n",
      "    \"hat\": NaN,\n",
      "    \"scrubs\": 123,\n",
      "    \"non slip shoes\": NaN,\n",
      "    \"shirt\": NaN,\n",
      "    \"face tattoos\": 4,\n",
      "    \"natural colors\": 407,\n",
      "    \"unnatural hair color\": NaN,\n",
      "    \"unnatural hair colors\": NaN,\n",
      "    \"black pants\": 283,\n",
      "    \"jeans\": NaN,\n",
      "    \"polo shirts\": NaN,\n",
      "    \"hair net\": NaN,\n",
      "    \"wear fake nails\": NaN,\n",
      "    \"hair color\": -1,\n",
      "    \"nose rings\": 55,\n",
      "    \"fake nails\": 429,\n",
      "    \"color hair\": 36,\n",
      "    \"attire\": NaN,\n",
      "    \"casual dress code\": 82,\n",
      "    \"natural colored hair\": 47,\n",
      "    \"uniform policy\": 144,\n",
      "    \"uniform shirts\": 44,\n",
      "    \"uniforms\": NaN,\n",
      "    \"unnatural colored hair\": 142,\n",
      "    \"business casual\": -1,\n",
      "    \"hair colors\": NaN,\n",
      "    \"piercings\": -1,\n",
      "    \"jewelry\": NaN,\n",
      "    \"brown pants\": 264,\n",
      "    \"mustaches\": NaN,\n",
      "    \"uniform\": -1,\n",
      "    \"hats\": NaN,\n",
      "    \"lab coats\": NaN\n",
      "}\n",
      "MRR: 0.01826566099506606\n",
      "R@100: 0.24489795918367346\n",
      "R@1k: 0.46938775510204084\n",
      "\n",
      "Concept: job_position / job position\n",
      "seeds: ['delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher']\n",
      "{\n",
      "    \"shift leader\": 207,\n",
      "    \"cashier\": -1,\n",
      "    \"truck drivers\": NaN,\n",
      "    \"server\": NaN,\n",
      "    \"servers\": NaN\n",
      "}\n",
      "MRR: 0.0012077294685990338\n",
      "R@100: 0.0\n",
      "R@1k: 0.25\n",
      "\n",
      "Concept: pay_schedule / pay period\n",
      "seeds: ['weekly', 'biweekly', 'friday', 'saturday']\n",
      "{\n",
      "    \"tuesday\": NaN,\n",
      "    \"paid weekly\": 8,\n",
      "    \"tuesdays\": NaN,\n",
      "    \"paid bi weekly\": 21,\n",
      "    \"bi weekly\": 2,\n",
      "    \"week\": NaN,\n",
      "    \"fridays\": NaN,\n",
      "    \"biweekly\": -1,\n",
      "    \"friday\": -1,\n",
      "    \"weeks\": NaN,\n",
      "    \"weekly\": -1,\n",
      "    \"paid biweekly\": NaN\n",
      "}\n",
      "MRR: 0.07473544973544974\n",
      "R@100: 0.3333333333333333\n",
      "R@1k: 0.3333333333333333\n",
      "\n",
      "Concept: benefits / benefits\n",
      "seeds: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "{\n",
      "    \"healthcare\": 63,\n",
      "    \"health coverage\": NaN,\n",
      "    \"401k plan\": NaN,\n",
      "    \"401k\": -1,\n",
      "    \"breakfast\": NaN,\n",
      "    \"sick leave\": -1,\n",
      "    \"life insurance\": 8,\n",
      "    \"health\": 133,\n",
      "    \"pto\": NaN,\n",
      "    \"relocate\": NaN,\n",
      "    \"vacation\": NaN,\n",
      "    \"health insurance\": -1,\n",
      "    \"paid vacations\": 54,\n",
      "    \"relocation\": NaN,\n",
      "    \"retirement\": NaN,\n",
      "    \"schooling\": NaN,\n",
      "    \"tuition assistance\": 93,\n",
      "    \"health benefits\": 72,\n",
      "    \"sick days\": 22,\n",
      "    \"health plans\": NaN,\n",
      "    \"health care\": 37,\n",
      "    \"monthly bonus\": NaN,\n",
      "    \"vacations\": NaN,\n",
      "    \"retirement plan\": 105,\n",
      "    \"prescription drugs\": NaN,\n",
      "    \"discounts\": NaN,\n",
      "    \"pension\": NaN,\n",
      "    \"free lunch\": NaN,\n",
      "    \"discount\": NaN,\n",
      "    \"401 k\": NaN\n",
      "}\n",
      "MRR: 0.010131751498160353\n",
      "R@100: 0.25925925925925924\n",
      "R@1k: 0.3333333333333333\n",
      "\n",
      "Concept: compensation / compensation\n",
      "seeds: ['base pay', 'stock options', 'benefits', 'overtime pay', 'bonus']\n",
      "{\n",
      "    \"benfits\": NaN,\n",
      "    \"benefits\": -1,\n",
      "    \"compensation\": NaN\n",
      "}\n",
      "MRR: 0.0\n",
      "R@100: 0.0\n",
      "R@1k: 0.0\n",
      "\n",
      "Concept: payment_option / nan\n",
      "seeds: ['checks', 'direct deposit', 'prepaid card']\n",
      "{\n",
      "    \"checks\": -1,\n",
      "    \"paper checks\": NaN,\n",
      "    \"direct deposit\": -1,\n",
      "    \"paycheck\": NaN,\n",
      "    \"prepaid card\": -1,\n",
      "    \"direct deposits\": 19\n",
      "}\n",
      "MRR: 0.017543859649122806\n",
      "R@100: 0.3333333333333333\n",
      "R@1k: 0.3333333333333333\n",
      "\n",
      "Concept: background_screening / background screening\n",
      "seeds: ['drug test', 'criminal background check', 'employment verification']\n",
      "{\n",
      "    \"drug screened\": NaN,\n",
      "    \"drugs\": NaN,\n",
      "    \"social security number\": 61,\n",
      "    \"urine drug screen\": NaN,\n",
      "    \"pre employment drug screening\": NaN,\n",
      "    \"previous employer\": NaN,\n",
      "    \"mouth\": NaN,\n",
      "    \"criminal background checks\": NaN,\n",
      "    \"credit report\": 40,\n",
      "    \"background check\": 36,\n",
      "    \"urine\": NaN,\n",
      "    \"testing\": NaN,\n",
      "    \"drug\": NaN,\n",
      "    \"screening process\": NaN,\n",
      "    \"swab test\": NaN,\n",
      "    \"backround check\": NaN,\n",
      "    \"blood test\": 3,\n",
      "    \"saliva\": NaN,\n",
      "    \"social security\": NaN,\n",
      "    \"hair sample\": NaN,\n",
      "    \"urine testing\": NaN,\n",
      "    \"background report\": 119,\n",
      "    \"criminal records\": 99,\n",
      "    \"drug test\": -1,\n",
      "    \"credit history\": 105,\n",
      "    \"previous employment\": 78,\n",
      "    \"criminal history\": 218,\n",
      "    \"saliva test\": 23,\n",
      "    \"drug text\": NaN,\n",
      "    \"criminal background check\": -1,\n",
      "    \"backround checks\": NaN,\n",
      "    \"follicle test\": NaN,\n",
      "    \"drugged tested\": NaN,\n",
      "    \"social media\": NaN,\n",
      "    \"backround\": NaN,\n",
      "    \"cannabis\": NaN,\n",
      "    \"random tests\": 177,\n",
      "    \"urine drug test\": 18,\n",
      "    \"urine tests\": 71,\n",
      "    \"mouth swap\": NaN,\n",
      "    \"background checks\": 146,\n",
      "    \"random drug testing\": 106,\n",
      "    \"credit check\": 35,\n",
      "    \"mouth swabs\": NaN,\n",
      "    \"saliva drug test\": 27,\n",
      "    \"test\": 48,\n",
      "    \"previous employers\": NaN,\n",
      "    \"criminal record\": 50,\n",
      "    \"previously worked\": NaN,\n",
      "    \"drug testing\": 44,\n",
      "    \"drug screen\": NaN,\n",
      "    \"hair follicle test\": NaN,\n",
      "    \"criminal backgrounds\": NaN,\n",
      "    \"urine test\": 6,\n",
      "    \"screening\": NaN,\n",
      "    \"drug tested\": NaN,\n",
      "    \"alcohol\": NaN,\n",
      "    \"backgrounds\": NaN,\n",
      "    \"cheek swab\": NaN,\n",
      "    \"mouth swab\": NaN,\n",
      "    \"driving record\": 94,\n",
      "    \"previous jobs\": NaN,\n",
      "    \"dui\": NaN,\n",
      "    \"credit checks\": 182,\n",
      "    \"random drug test\": 9,\n",
      "    \"random drug tests\": 57,\n",
      "    \"drug screening\": 134,\n",
      "    \"urine sample\": NaN,\n",
      "    \"drug tests\": 14,\n",
      "    \"criminal background\": 100,\n",
      "    \"credit score\": 195,\n",
      "    \"drug screens\": NaN,\n",
      "    \"screen\": NaN\n",
      "}\n",
      "MRR: 0.01574133376603009\n",
      "R@100: 0.28169014084507044\n",
      "R@1k: 0.4084507042253521\n",
      "\n",
      "Concept: person / nan\n",
      "seeds: ['felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors']\n",
      "{\n",
      "    \"misdemeanor theft\": NaN,\n",
      "    \"high schoolers\": -1,\n",
      "    \"felonies\": NaN,\n",
      "    \"felony record\": NaN,\n",
      "    \"high school\": NaN,\n",
      "    \"disabled\": -1,\n",
      "    \"seniority\": NaN,\n",
      "    \"school students\": NaN,\n",
      "    \"misdemeanor\": -1,\n",
      "    \"pregnant women\": 361,\n",
      "    \"disabilities\": NaN,\n",
      "    \"criminals\": -1,\n",
      "    \"felony\": NaN,\n",
      "    \"ex felons\": NaN,\n",
      "    \"high school graduate\": NaN,\n",
      "    \"sex offenders\": 6,\n",
      "    \"felonys\": NaN,\n",
      "    \"senior citizens\": 30,\n",
      "    \"seniors\": -1,\n",
      "    \"misdemeanor charges\": NaN,\n",
      "    \"felons\": -1,\n",
      "    \"convicted felons\": NaN,\n",
      "    \"schoolers\": NaN,\n",
      "    \"high school students\": NaN,\n",
      "    \"pregnant\": -1\n",
      "}\n",
      "MRR: 0.01126500461680517\n",
      "R@100: 0.1111111111111111\n",
      "R@1k: 0.16666666666666666\n",
      "\n",
      "Concept: hire_prerequisite / qualification\n",
      "seeds: ['hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting']\n",
      "{\n",
      "    \"bachelor degree\": 6,\n",
      "    \"gpa\": NaN,\n",
      "    \"workers permit\": 179,\n",
      "    \"high school diploma\": 30,\n",
      "    \"college degree\": 14,\n",
      "    \"high school education\": 77,\n",
      "    \"working permit\": -1,\n",
      "    \"hs diploma\": 243,\n",
      "    \"ged\": NaN,\n",
      "    \"birth certificate\": 192,\n",
      "    \"diploma\": 205,\n",
      "    \"degrees\": NaN\n",
      "}\n",
      "MRR: 0.02765488954960228\n",
      "R@100: 0.36363636363636365\n",
      "R@1k: 0.7272727272727273\n",
      "\n",
      "Concept: shifts / work shift\n",
      "seeds: ['night shift', 'dinner shift', 'early morning shift', '8 hour shift']\n",
      "{\n",
      "    \"12 hour shifts\": 50,\n",
      "    \"weekend shift\": 2,\n",
      "    \"open 24 hours\": NaN,\n",
      "    \"night shifts\": 4,\n",
      "    \"3rd shift\": 31\n",
      "}\n",
      "MRR: 0.1604516129032258\n",
      "R@100: 0.8\n",
      "R@1k: 0.8\n",
      "\n",
      "Concept: schedule / nan\n",
      "seeds: ['christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend']\n",
      "{\n",
      "    \"christmas eve\": -1,\n",
      "    \"saturdays\": NaN,\n",
      "    \"open 7 days\": NaN,\n",
      "    \"weekend\": -1,\n",
      "    \"weekends\": NaN,\n",
      "    \"federal holidays\": NaN,\n",
      "    \"sunday\": -1,\n",
      "    \"saturday\": -1,\n",
      "    \"early morning\": -1,\n",
      "    \"hoildays\": NaN\n",
      "}\n",
      "MRR: 0.0\n",
      "R@100: 0.0\n",
      "R@1k: 0.0\n",
      "\n",
      "Concept: employee_type / nan\n",
      "seeds: ['full time', 'part time', 'seasonal']\n",
      "{\n",
      "    \"seasonal workers\": NaN,\n",
      "    \"seasonal\": -1,\n",
      "    \"seasonals\": NaN,\n",
      "    \"seasons\": NaN,\n",
      "    \"ft\": NaN,\n",
      "    \"seasonal employees\": 183,\n",
      "    \"season\": NaN,\n",
      "    \"fulltime\": NaN,\n",
      "    \"seasonal positions\": NaN\n",
      "}\n",
      "MRR: 0.0006830601092896175\n",
      "R@100: 0.0\n",
      "R@1k: 0.125\n",
      "\n",
      "Concept: onboarding_steps / onboarding process steps\n",
      "seeds: ['orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "{\n",
      "    \"training classes\": 179,\n",
      "    \"orientation\": -1,\n",
      "    \"training program\": 54,\n",
      "    \"training\": -1\n",
      "}\n",
      "MRR: 0.012052555348644734\n",
      "R@100: 0.5\n",
      "R@1k: 1.0\n",
      "\n",
      "--- Summary ---\n",
      "Concept                   MRR    R@100    R@1k  \n",
      "company                  0.0005  0.0099  0.0792  \n",
      "dress_code               0.0183  0.2449  0.4694  \n",
      "job_position             0.0012  0.0000  0.2500  \n",
      "pay_schedule             0.0747  0.3333  0.3333  \n",
      "benefits                 0.0101  0.2593  0.3333  \n",
      "compensation             0.0000  0.0000  0.0000  \n",
      "payment_option           0.0175  0.3333  0.3333  \n",
      "background_screening     0.0157  0.2817  0.4085  \n",
      "person                   0.0113  0.1111  0.1667  \n",
      "hire_prerequisite        0.0277  0.3636  0.7273  \n",
      "shifts                   0.1605  0.8000  0.8000  \n",
      "schedule                 0.0000  0.0000  0.0000  \n",
      "employee_type            0.0007  0.0000  0.1250  \n",
      "onboarding_steps         0.0121  0.5000  1.0000  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "!python eval_entities.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/ee_concept_corr_k=100.csv \\\n",
    "\n",
    "# -rank sim+margin \\\n",
    "# -rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: company / company\n",
      "seeds: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "{\n",
      "    \"home depot\": 1267,\n",
      "    \"doordash\": NaN,\n",
      "    \"dick's sporting goods\": NaN,\n",
      "    \"cvs health\": 206,\n",
      "    \"teleperformance\": NaN,\n",
      "    \"subways\": NaN,\n",
      "    \"tim hortons\": 449,\n",
      "    \"alorica\": NaN,\n",
      "    \"instacart\": NaN,\n",
      "    \"fedex\": 390,\n",
      "    \"chick-fil-a\": NaN,\n",
      "    \"taco bell\": 316,\n",
      "    \"ihop\": 3647,\n",
      "    \"pizza hut\": 397,\n",
      "    \"quiktrip\": NaN,\n",
      "    \"panera\": NaN,\n",
      "    \"safeway\": 3807,\n",
      "    \"target\": -1,\n",
      "    \"t.j. maxx\": NaN,\n",
      "    \"walmart\": -1,\n",
      "    \"costco\": 1328,\n",
      "    \"chilis\": 1574,\n",
      "    \"ulta\": NaN,\n",
      "    \"domino's\": NaN,\n",
      "    \"verizon\": 1987,\n",
      "    \"hobby lobby\": 1345,\n",
      "    \"best buy\": 249,\n",
      "    \"dunkin' donuts\": NaN,\n",
      "    \"sam's club\": NaN,\n",
      "    \"subway\": -1,\n",
      "    \"kroger stores\": NaN,\n",
      "    \"united states postal service\": 1794,\n",
      "    \"lowe's\": NaN,\n",
      "    \"little caesars\": 462,\n",
      "    \"panera bread\": 1209,\n",
      "    \"the home depot\": NaN,\n",
      "    \"applebee's\": NaN,\n",
      "    \"cvs\": 761,\n",
      "    \"dollar tree\": 361,\n",
      "    \"amazon\": -1,\n",
      "    \"ross dress for less\": NaN,\n",
      "    \"mcdonald's\": NaN,\n",
      "    \"the wendy's company\": NaN,\n",
      "    \"american eagle outfitters\": 1051,\n",
      "    \"g4s\": 229,\n",
      "    \"chili's\": NaN,\n",
      "    \"sitel\": 2411,\n",
      "    \"burlington stores\": NaN,\n",
      "    \"walgreens\": 5558,\n",
      "    \"goodwill industries\": 324,\n",
      "    \"dd\": 1616,\n",
      "    \"primark\": 997,\n",
      "    \"burger king\": 325,\n",
      "    \"kohl's\": NaN,\n",
      "    \"victoria's secret\": NaN,\n",
      "    \"frito-lay\": NaN,\n",
      "    \"wendys\": NaN,\n",
      "    \"at&t\": NaN,\n",
      "    \"aldi\": 3657,\n",
      "    \"wells fargo\": 2170,\n",
      "    \"dollar general\": 118,\n",
      "    \"publix\": 2335,\n",
      "    \"fedex ground\": NaN,\n",
      "    \"pepsico\": 42,\n",
      "    \"lowes\": NaN,\n",
      "    \"old navy\": 1554,\n",
      "    \"sonic drive-in\": NaN,\n",
      "    \"family dollar\": 336,\n",
      "    \"concentrix\": NaN,\n",
      "    \"whole foods market\": NaN,\n",
      "    \"barnes & noble\": 151,\n",
      "    \"olive garden\": 2930,\n",
      "    \"mcdonald\": 309,\n",
      "    \"amazon.com\": NaN,\n",
      "    \"spectrum\": 501,\n",
      "    \"mcdonalds\": 395,\n",
      "    \"cracker barrel\": 1295,\n",
      "    \"starbucks\": 5,\n",
      "    \"t-mobile\": NaN,\n",
      "    \"kfc\": 704,\n",
      "    \"heb\": NaN,\n",
      "    \"macy's\": NaN,\n",
      "    \"whataburger\": NaN,\n",
      "    \"chipotle mexican grill\": 1491,\n",
      "    \"marshalls\": 162,\n",
      "    \"chipotle\": 1518,\n",
      "    \"training\": 6701,\n",
      "    \"frito\": NaN,\n",
      "    \"frito lay\": 4142,\n",
      "    \"geico\": 68,\n",
      "    \"jcpenney\": 2680,\n",
      "    \"tj maxx\": 404,\n",
      "    \"pepsi\": 9,\n",
      "    \"menards\": 6721,\n",
      "    \"costco wholesale\": 706,\n",
      "    \"marriott international, inc.\": NaN,\n",
      "    \"electric\": NaN,\n",
      "    \"kroger\": 733,\n",
      "    \"ups\": NaN,\n",
      "    \"planet fitness\": 455,\n",
      "    \"petsmart\": 832,\n",
      "    \"foot locker\": 4059,\n",
      "    \"allied universal security services, systems and solutions\": NaN,\n",
      "    \"enterprise holdings\": NaN,\n",
      "    \"dunkin donuts\": 4136\n",
      "}\n",
      "MRR: 0.004376238593670204\n",
      "R@100: 0.039603960396039604\n",
      "R@1k: 0.297029702970297\n",
      "\n",
      "Concept: dress_code / dress code\n",
      "seeds: ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\n",
      "{\n",
      "    \"hair colors\": NaN,\n",
      "    \"jewelry\": NaN,\n",
      "    \"shoes\": -1,\n",
      "    \"shorts\": NaN,\n",
      "    \"unnatural hair color\": NaN,\n",
      "    \"business casual\": -1,\n",
      "    \"natural colors\": 185,\n",
      "    \"uniforms\": NaN,\n",
      "    \"brown pants\": 53,\n",
      "    \"jeans\": 32,\n",
      "    \"piercings\": -1,\n",
      "    \"dress pants\": 11,\n",
      "    \"hairnets\": NaN,\n",
      "    \"wear shorts\": NaN,\n",
      "    \"ponytail\": 99,\n",
      "    \"hair color\": -1,\n",
      "    \"mustaches\": NaN,\n",
      "    \"polo shirts\": NaN,\n",
      "    \"face tattoos\": 6,\n",
      "    \"lab coats\": 386,\n",
      "    \"professional\": 5813,\n",
      "    \"skirts\": NaN,\n",
      "    \"strict dress code\": 252,\n",
      "    \"unnatural hair colors\": NaN,\n",
      "    \"wear fake nails\": NaN,\n",
      "    \"blue collar\": 82,\n",
      "    \"casual\": NaN,\n",
      "    \"resistant shoes\": 260,\n",
      "    \"color hair\": 17,\n",
      "    \"hat\": NaN,\n",
      "    \"uniform policy\": 922,\n",
      "    \"hats\": NaN,\n",
      "    \"facial hair\": -1,\n",
      "    \"uniform\": -1,\n",
      "    \"natural colored hair\": 178,\n",
      "    \"casual dress code\": 102,\n",
      "    \"scrubs\": 80,\n",
      "    \"facial piercings\": 7,\n",
      "    \"black pants\": 24,\n",
      "    \"hair net\": NaN,\n",
      "    \"non slip shoes\": NaN,\n",
      "    \"shirt\": NaN,\n",
      "    \"unnatural colored hair\": 518,\n",
      "    \"colorful hair\": 58,\n",
      "    \"wear jeans\": 121,\n",
      "    \"red shirts\": NaN,\n",
      "    \"black slacks\": NaN,\n",
      "    \"uniform shirts\": 59,\n",
      "    \"black jeans\": 70,\n",
      "    \"fake nails\": 138,\n",
      "    \"nose rings\": 21,\n",
      "    \"pants\": NaN,\n",
      "    \"dress shirts\": 16,\n",
      "    \"attire\": NaN,\n",
      "    \"shirts\": NaN\n",
      "}\n",
      "MRR: 0.01621148573885969\n",
      "R@100: 0.30612244897959184\n",
      "R@1k: 0.5102040816326531\n",
      "\n",
      "Concept: job_position / job position\n",
      "seeds: ['delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher']\n",
      "{\n",
      "    \"servers\": NaN,\n",
      "    \"cashier\": -1,\n",
      "    \"shift leader\": 235,\n",
      "    \"truck drivers\": NaN,\n",
      "    \"server\": NaN\n",
      "}\n",
      "MRR: 0.0010638297872340426\n",
      "R@100: 0.0\n",
      "R@1k: 0.25\n",
      "\n",
      "Concept: pay_schedule / pay period\n",
      "seeds: ['weekly', 'biweekly', 'friday', 'saturday']\n",
      "{\n",
      "    \"bi weekly\": 198,\n",
      "    \"paid biweekly\": NaN,\n",
      "    \"tuesday\": NaN,\n",
      "    \"biweekly\": -1,\n",
      "    \"weeks\": NaN,\n",
      "    \"week\": NaN,\n",
      "    \"friday\": -1,\n",
      "    \"weekly\": -1,\n",
      "    \"paid bi weekly\": 77,\n",
      "    \"tuesdays\": NaN,\n",
      "    \"fridays\": NaN,\n",
      "    \"paid weekly\": 39\n",
      "}\n",
      "MRR: 0.004853171519838186\n",
      "R@100: 0.2222222222222222\n",
      "R@1k: 0.3333333333333333\n",
      "\n",
      "Concept: benefits / benefits\n",
      "seeds: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "{\n",
      "    \"retirement plan\": 125,\n",
      "    \"health benefits\": 14,\n",
      "    \"healthcare\": 102,\n",
      "    \"401 k\": 3308,\n",
      "    \"vacation\": NaN,\n",
      "    \"pto\": NaN,\n",
      "    \"health insurance\": -1,\n",
      "    \"health plans\": NaN,\n",
      "    \"health coverage\": NaN,\n",
      "    \"sick leave\": -1,\n",
      "    \"breakfast\": NaN,\n",
      "    \"health care\": 23,\n",
      "    \"pension\": 2,\n",
      "    \"tuition assistance\": 126,\n",
      "    \"life insurance\": 17,\n",
      "    \"free lunch\": NaN,\n",
      "    \"discounts\": NaN,\n",
      "    \"monthly bonus\": 143,\n",
      "    \"relocate\": NaN,\n",
      "    \"paid vacations\": 71,\n",
      "    \"relocation\": NaN,\n",
      "    \"vacations\": NaN,\n",
      "    \"schooling\": NaN,\n",
      "    \"prescription drugs\": 323,\n",
      "    \"retirement\": NaN,\n",
      "    \"health\": 10,\n",
      "    \"discount\": NaN,\n",
      "    \"401k\": -1,\n",
      "    \"401k plan\": 673,\n",
      "    \"sick days\": 495\n",
      "}\n",
      "MRR: 0.030646394965349585\n",
      "R@100: 0.2222222222222222\n",
      "R@1k: 0.48148148148148145\n",
      "\n",
      "Concept: compensation / compensation\n",
      "seeds: ['base pay', 'stock options', 'benefits', 'overtime pay', 'bonus']\n",
      "{\n",
      "    \"compensation\": NaN,\n",
      "    \"benfits\": NaN,\n",
      "    \"benefits\": -1\n",
      "}\n",
      "MRR: 0.0\n",
      "R@100: 0.0\n",
      "R@1k: 0.0\n",
      "\n",
      "Concept: payment_option / nan\n",
      "seeds: ['checks', 'direct deposit', 'prepaid card']\n",
      "{\n",
      "    \"direct deposit\": -1,\n",
      "    \"direct deposits\": 54,\n",
      "    \"checks\": -1,\n",
      "    \"prepaid card\": -1,\n",
      "    \"paper checks\": NaN,\n",
      "    \"paycheck\": 1780\n",
      "}\n",
      "MRR: 0.006360105423775835\n",
      "R@100: 0.3333333333333333\n",
      "R@1k: 0.3333333333333333\n",
      "\n",
      "Concept: background_screening / background screening\n",
      "seeds: ['drug test', 'criminal background check', 'employment verification']\n",
      "{\n",
      "    \"previously worked\": NaN,\n",
      "    \"urine drug screen\": NaN,\n",
      "    \"criminal history\": 77,\n",
      "    \"background report\": 18,\n",
      "    \"criminal record\": 35,\n",
      "    \"drug text\": NaN,\n",
      "    \"hair sample\": NaN,\n",
      "    \"swab test\": 963,\n",
      "    \"mouth\": 5512,\n",
      "    \"drug screened\": NaN,\n",
      "    \"drug screen\": NaN,\n",
      "    \"credit history\": 108,\n",
      "    \"random drug testing\": 73,\n",
      "    \"cannabis\": 2826,\n",
      "    \"social media\": 413,\n",
      "    \"urine sample\": NaN,\n",
      "    \"previous employer\": 1323,\n",
      "    \"random drug tests\": 100,\n",
      "    \"background check\": 21,\n",
      "    \"drugs\": 877,\n",
      "    \"urine tests\": 106,\n",
      "    \"previous employment\": 540,\n",
      "    \"criminal records\": 62,\n",
      "    \"background checks\": 167,\n",
      "    \"cheek swab\": 6899,\n",
      "    \"drug screening\": 8,\n",
      "    \"drug test\": -1,\n",
      "    \"testing\": NaN,\n",
      "    \"credit report\": 6,\n",
      "    \"urine test\": 29,\n",
      "    \"follicle test\": 1183,\n",
      "    \"urine\": 184,\n",
      "    \"credit checks\": 109,\n",
      "    \"random tests\": 463,\n",
      "    \"drug tests\": 31,\n",
      "    \"screen\": NaN,\n",
      "    \"urine testing\": NaN,\n",
      "    \"dui\": 6514,\n",
      "    \"drug screens\": NaN,\n",
      "    \"urine drug test\": 9,\n",
      "    \"backgrounds\": NaN,\n",
      "    \"saliva drug test\": 15,\n",
      "    \"backround\": NaN,\n",
      "    \"criminal backgrounds\": 699,\n",
      "    \"previous employers\": 1926,\n",
      "    \"mouth swabs\": NaN,\n",
      "    \"backround check\": 2200,\n",
      "    \"screening\": NaN,\n",
      "    \"mouth swab\": 6281,\n",
      "    \"social security\": 340,\n",
      "    \"drug testing\": 11,\n",
      "    \"mouth swap\": NaN,\n",
      "    \"saliva test\": 61,\n",
      "    \"credit check\": 10,\n",
      "    \"credit score\": 138,\n",
      "    \"criminal background\": 120,\n",
      "    \"criminal background checks\": NaN,\n",
      "    \"driving record\": 107,\n",
      "    \"drug\": 322,\n",
      "    \"drug tested\": NaN,\n",
      "    \"test\": 924,\n",
      "    \"backround checks\": 3000,\n",
      "    \"criminal background check\": -1,\n",
      "    \"drugged tested\": 2572,\n",
      "    \"screening process\": 310,\n",
      "    \"hair follicle test\": 998,\n",
      "    \"social security number\": 125,\n",
      "    \"blood test\": 38,\n",
      "    \"alcohol\": 431,\n",
      "    \"random drug test\": 23,\n",
      "    \"previous jobs\": 2176,\n",
      "    \"pre employment drug screening\": NaN,\n",
      "    \"saliva\": 469\n",
      "}\n",
      "MRR: 0.015502245891109873\n",
      "R@100: 0.2535211267605634\n",
      "R@1k: 0.5633802816901409\n",
      "\n",
      "Concept: person / nan\n",
      "seeds: ['felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors']\n",
      "{\n",
      "    \"seniority\": NaN,\n",
      "    \"ex felons\": 277,\n",
      "    \"misdemeanor theft\": 3905,\n",
      "    \"high school\": 25,\n",
      "    \"felonys\": NaN,\n",
      "    \"pregnant women\": 11,\n",
      "    \"felony\": 2032,\n",
      "    \"convicted felons\": 382,\n",
      "    \"felonies\": 2060,\n",
      "    \"high school graduate\": NaN,\n",
      "    \"felons\": -1,\n",
      "    \"schoolers\": NaN,\n",
      "    \"seniors\": -1,\n",
      "    \"high school students\": NaN,\n",
      "    \"disabled\": -1,\n",
      "    \"misdemeanor charges\": NaN,\n",
      "    \"criminals\": -1,\n",
      "    \"sex offenders\": 56,\n",
      "    \"disabilities\": NaN,\n",
      "    \"school students\": NaN,\n",
      "    \"senior citizens\": 12,\n",
      "    \"high schoolers\": -1,\n",
      "    \"pregnant\": -1,\n",
      "    \"misdemeanor\": -1,\n",
      "    \"felony record\": NaN\n",
      "}\n",
      "MRR: 0.013308951181867514\n",
      "R@100: 0.2222222222222222\n",
      "R@1k: 0.3333333333333333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: hire_prerequisite / qualification\n",
      "seeds: ['hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting']\n",
      "{\n",
      "    \"bachelor degree\": 368,\n",
      "    \"workers permit\": 24,\n",
      "    \"diploma\": 240,\n",
      "    \"college degree\": 213,\n",
      "    \"high school diploma\": 155,\n",
      "    \"hs diploma\": 1562,\n",
      "    \"ged\": 4317,\n",
      "    \"gpa\": NaN,\n",
      "    \"working permit\": -1,\n",
      "    \"birth certificate\": 114,\n",
      "    \"high school education\": 170,\n",
      "    \"degrees\": NaN\n",
      "}\n",
      "MRR: 0.0068384821088339565\n",
      "R@100: 0.09090909090909091\n",
      "R@1k: 0.6363636363636364\n",
      "\n",
      "Concept: shifts / work shift\n",
      "seeds: ['night shift', 'dinner shift', 'early morning shift', '8 hour shift']\n",
      "{\n",
      "    \"open 24 hours\": NaN,\n",
      "    \"night shifts\": 13,\n",
      "    \"3rd shift\": 30,\n",
      "    \"12 hour shifts\": 9,\n",
      "    \"weekend shift\": 3\n",
      "}\n",
      "MRR: 0.11094017094017095\n",
      "R@100: 0.8\n",
      "R@1k: 0.8\n",
      "\n",
      "Concept: schedule / nan\n",
      "seeds: ['christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend']\n",
      "{\n",
      "    \"weekends\": NaN,\n",
      "    \"saturday\": -1,\n",
      "    \"weekend\": -1,\n",
      "    \"open 7 days\": NaN,\n",
      "    \"federal holidays\": NaN,\n",
      "    \"sunday\": -1,\n",
      "    \"hoildays\": NaN,\n",
      "    \"early morning\": -1,\n",
      "    \"saturdays\": NaN,\n",
      "    \"christmas eve\": -1\n",
      "}\n",
      "MRR: 0.0\n",
      "R@100: 0.0\n",
      "R@1k: 0.0\n",
      "\n",
      "Concept: employee_type / nan\n",
      "seeds: ['full time', 'part time', 'seasonal']\n",
      "{\n",
      "    \"seasonal workers\": 55,\n",
      "    \"seasonals\": NaN,\n",
      "    \"season\": 1685,\n",
      "    \"seasonal positions\": NaN,\n",
      "    \"seasonal\": -1,\n",
      "    \"seasons\": NaN,\n",
      "    \"seasonal employees\": 5,\n",
      "    \"ft\": NaN,\n",
      "    \"fulltime\": NaN\n",
      "}\n",
      "MRR: 0.0273469112489884\n",
      "R@100: 0.25\n",
      "R@1k: 0.25\n",
      "\n",
      "Concept: onboarding_steps / onboarding process steps\n",
      "seeds: ['orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "{\n",
      "    \"training classes\": 6,\n",
      "    \"training\": -1,\n",
      "    \"training program\": 9,\n",
      "    \"orientation\": -1\n",
      "}\n",
      "MRR: 0.1388888888888889\n",
      "R@100: 1.0\n",
      "R@1k: 1.0\n",
      "\n",
      "--- Summary ---\n",
      "Concept                   MRR    R@100    R@1k  \n",
      "company                  0.0044  0.0396  0.2970  \n",
      "dress_code               0.0162  0.3061  0.5102  \n",
      "job_position             0.0011  0.0000  0.2500  \n",
      "pay_schedule             0.0049  0.2222  0.3333  \n",
      "benefits                 0.0306  0.2222  0.4815  \n",
      "compensation             0.0000  0.0000  0.0000  \n",
      "payment_option           0.0064  0.3333  0.3333  \n",
      "background_screening     0.0155  0.2535  0.5634  \n",
      "person                   0.0133  0.2222  0.3333  \n",
      "hire_prerequisite        0.0068  0.0909  0.6364  \n",
      "shifts                   0.1109  0.8000  0.8000  \n",
      "schedule                 0.0000  0.0000  0.0000  \n",
      "employee_type            0.0273  0.2500  0.2500  \n",
      "onboarding_steps         0.1389  1.0000  1.0000  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "!python eval_entities.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/ee_LM_bert_k=None.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LM probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probe_gpt2 = LMProbe_GPT2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1356, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_100.csv')\n",
    "ee_df = pd.read_csv(ee_path)\n",
    "ee_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company dress_code\n"
     ]
    }
   ],
   "source": [
    "_r = 'has_dress_code'\n",
    "\n",
    "_r_row = seed_relations_df[seed_relations_df['alignedRelationName'] == _r].iloc[0]\n",
    "_h_type = _r_row['domain']\n",
    "_t_type = _r_row['range']\n",
    "print(_h_type, _t_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['walmart', 'amazon', 'subway', 'microsoft', 'target'],\n",
       " ['business casual',\n",
       "  'uniform',\n",
       "  'hair color',\n",
       "  'tattoos',\n",
       "  'facial hair',\n",
       "  'shoes',\n",
       "  'piercings'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _h_type]['seedInstances'].item()\n",
    "_seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _t_type]['seedInstances'].item()\n",
    "_seed_heads, _seed_tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 94)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cand_heads = ee_df[ee_df['concept'] == _h_type]['neighbor'].tolist()\n",
    "_cand_tails = ee_df[ee_df['concept'] == _t_type]['neighbor'].tolist()\n",
    "len(_cand_heads), len(_cand_tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'body piercings', 'score': 0.002457509326813575}),\n",
       " (1, {'cand': 'facial piercings', 'score': 0.0021192399895008725}),\n",
       " (2, {'cand': 'ear piercings', 'score': 0.0019278434892669512}),\n",
       " (3, {'cand': 'face piercings', 'score': 0.0017361913249576018}),\n",
       " (4, {'cand': 'nose piercings', 'score': 0.0017143651784431442}),\n",
       " (5, {'cand': 'visible piercings', 'score': 0.0012390717683459865}),\n",
       " (6, {'cand': 'leggings', 'score': 0.0011862801946265714}),\n",
       " (7, {'cand': 'flip flops', 'score': 0.0011396856372157989}),\n",
       " (8, {'cand': 'chilis', 'score': 0.001127743414615599}),\n",
       " (9, {'cand': 'little caesars', 'score': 0.0008004799350692819}),\n",
       " (10, {'cand': 'common sense', 'score': 0.0007569520623752813}),\n",
       " (11, {'cand': 'kroger', 'score': 0.0007509511175223724}),\n",
       " (12, {'cand': 'strict dress code', 'score': 0.0007379959875833076}),\n",
       " (13, {'cand': 'publix', 'score': 0.0006212025041699539}),\n",
       " (14, {'cand': 'casual wear', 'score': 0.0005990662535303998}),\n",
       " (15, {'cand': 'cell phones', 'score': 0.000569988479251344}),\n",
       " (16, {'cand': 'drug tests', 'score': 0.0005496229622352319}),\n",
       " (17, {'cand': 'dress codes', 'score': 0.0004961209854635662}),\n",
       " (18, {'cand': 'clean shaven', 'score': 0.000494140137213682}),\n",
       " (19, {'cand': 'walgreens', 'score': 0.0004825336843859673}),\n",
       " (20, {'cand': 'skinny jeans', 'score': 0.0004526465762028732}),\n",
       " (21, {'cand': 'food safety', 'score': 0.00044543370372485727}),\n",
       " (22, {'cand': 'dress code', 'score': 0.0004279255700331405}),\n",
       " (23, {'cand': 'bright colors', 'score': 0.00040560681456752084}),\n",
       " (24, {'cand': 'pretty much', 'score': 0.0003751698810280913}),\n",
       " (25, {'cand': 't shirts', 'score': 0.00037285286242344187}),\n",
       " (26, {'cand': \"mcdonald 's\", 'score': 0.00036794624642891565}),\n",
       " (27, {'cand': 'cvs', 'score': 0.00036707283968467983}),\n",
       " (28, {'cand': 'nail polish', 'score': 0.0003450338471108416}),\n",
       " (29, {'cand': 'pharmacist', 'score': 0.00033938685307048893}),\n",
       " (30, {'cand': 'casual dress', 'score': 0.0003050096446559058}),\n",
       " (31, {'cand': 'ripped jeans', 'score': 0.00029682300647225745}),\n",
       " (32, {'cand': 'regular clothes', 'score': 0.0002875132643591797}),\n",
       " (33, {'cand': 'security', 'score': 0.00025959379412628363}),\n",
       " (34, {'cand': 'natural colors', 'score': 0.00024257290354743954}),\n",
       " (35, {'cand': 'casual clothing', 'score': 0.00024109755491906896}),\n",
       " (36, {'cand': 'dyed hair', 'score': 0.00021938808647572236}),\n",
       " (37, {'cand': 'uniform policy', 'score': 0.00021878467664183956}),\n",
       " (38, {'cand': 'casual clothes', 'score': 0.00021001205122873947}),\n",
       " (39, {'cand': 'nonslip shoes', 'score': 0.0002097632468338312}),\n",
       " (40, {'cand': 'clean cut', 'score': 0.0001948613208822614}),\n",
       " (41, {'cand': 'cracker barrel', 'score': 0.0001910101892494337}),\n",
       " (42, {'cand': 'colored hair', 'score': 0.0001858654598424991}),\n",
       " (43, {'cand': 'safety', 'score': 0.0001851373078387201}),\n",
       " (44, {'cand': 'nose rings', 'score': 0.0001809619554593381}),\n",
       " (45, {'cand': 'colorful hair', 'score': 0.00017237828442316812}),\n",
       " (46, {'cand': 'scrubs', 'score': 0.00016602455436735006}),\n",
       " (47, {'cand': 'color hair', 'score': 0.00016528898855175408}),\n",
       " (48, {'cand': 'facial piercing', 'score': 0.0001616338565189581}),\n",
       " (49, {'cand': 'visible tattoos', 'score': 0.00015386423640663963}),\n",
       " (50, {'cand': 'fake nails', 'score': 0.00014217296924295473}),\n",
       " (51, {'cand': 'facial jewelry', 'score': 0.0001405515841805644}),\n",
       " (52, {'cand': 'american eagle', 'score': 0.00013775593215621144}),\n",
       " (53, {'cand': 'chipotle', 'score': 0.00013700351194869087}),\n",
       " (54, {'cand': 'menards', 'score': 0.00013409006415571222}),\n",
       " (55, {'cand': 'cover', 'score': 0.00013383493431284876}),\n",
       " (56, {'cand': 'unnatural hair', 'score': 0.00013208309640977284}),\n",
       " (57, {'cand': 'food', 'score': 0.00012811190347792985}),\n",
       " (58, {'cand': 'long', 'score': 0.0001276731856056876}),\n",
       " (59, {'cand': 'cargo', 'score': 0.00012603252774175212}),\n",
       " (60, {'cand': 'short', 'score': 0.00012301428541516965}),\n",
       " (61, {'cand': 'light', 'score': 0.00012233036688078525}),\n",
       " (62, {'cand': 'toe shoes', 'score': 0.00012190179830521799}),\n",
       " (63, {'cand': 'unnatural colors', 'score': 0.00011730025591361592}),\n",
       " (64, {'cand': 'acrylic nails', 'score': 0.00010731952741675135}),\n",
       " (65, {'cand': 'sports', 'score': 0.00010226730141388031}),\n",
       " (66, {'cand': 'watch', 'score': 0.0001014173705462452}),\n",
       " (67, {'cand': 'professional', 'score': 8.867208305981268e-05}),\n",
       " (68, {'cand': 'skin', 'score': 8.820685118754456e-05}),\n",
       " (69, {'cand': 'drugs', 'score': 8.814311080755721e-05}),\n",
       " (70, {'cand': 'clothing', 'score': 8.474950747975283e-05}),\n",
       " (71, {'cand': 'brand', 'score': 8.160406841509285e-05}),\n",
       " (72, {'cand': 'arms', 'score': 8.094477767081636e-05}),\n",
       " (73, {'cand': 'language', 'score': 7.69400055409942e-05}),\n",
       " (74, {'cand': 'caps', 'score': 7.674917225218306e-05}),\n",
       " (75, {'cand': 'footwear', 'score': 7.62770669273005e-05}),\n",
       " (76, {'cand': 'hair', 'score': 7.441914037034387e-05}),\n",
       " (77, {'cand': 'nice', 'score': 6.957224055942572e-05}),\n",
       " (78, {'cand': 'weather', 'score': 6.757863819214087e-05}),\n",
       " (79, {'cand': 'old navy', 'score': 6.533663075762442e-05}),\n",
       " (80, {'cand': 'gym', 'score': 6.512797734456895e-05}),\n",
       " (81, {'cand': 'pizza hut', 'score': 6.257702034528578e-05}),\n",
       " (82, {'cand': 'cap', 'score': 6.192357914723525e-05}),\n",
       " (83, {'cand': 'tattoo', 'score': 5.9476291617200126e-05}),\n",
       " (84, {'cand': 'hygiene', 'score': 5.8028255761638235e-05}),\n",
       " (85, {'cand': 'dd', 'score': 5.21891097082135e-05}),\n",
       " (86, {'cand': 'cotton', 'score': 5.160578823795412e-05}),\n",
       " (87, {'cand': 'logo', 'score': 5.079621892400359e-05}),\n",
       " (88, {'cand': 'logos', 'score': 4.815140685250753e-05}),\n",
       " (89, {'cand': 'religious', 'score': 4.595743683103463e-05}),\n",
       " (90, {'cand': 'band', 'score': 4.5613232791992766e-05}),\n",
       " (91, {'cand': 'polish', 'score': 4.2181321298528996e-05}),\n",
       " (92, {'cand': 'knee', 'score': 3.035689749675966e-05}),\n",
       " (93, {'cand': 'ankle', 'score': 2.7967284662884168e-05})]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'walmart allows [MASK].'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'leggings', 'score': 0.0026494025030625867}),\n",
       " (1, {'cand': 'body piercings', 'score': 0.002413165540068098}),\n",
       " (2, {'cand': 'facial piercings', 'score': 0.002037490574634625}),\n",
       " (3, {'cand': 'ear piercings', 'score': 0.0019686087207748102}),\n",
       " (4, {'cand': 'face piercings', 'score': 0.0017579750998315724}),\n",
       " (5, {'cand': 'skinny jeans', 'score': 0.0017518271213956627}),\n",
       " (6, {'cand': 'nose piercings', 'score': 0.0017098611068448854}),\n",
       " (7, {'cand': 'chilis', 'score': 0.0014580513443831775}),\n",
       " (8, {'cand': 't shirts', 'score': 0.001452686930789666}),\n",
       " (9, {'cand': 'ripped jeans', 'score': 0.001436489871252126}),\n",
       " (10, {'cand': 'flip flops', 'score': 0.0013027341342922597}),\n",
       " (11, {'cand': 'visible piercings', 'score': 0.0012349110164999871}),\n",
       " (12, {'cand': 'clean shaven', 'score': 0.0011952109489552396}),\n",
       " (13, {'cand': 'casual dress', 'score': 0.0010492319432645972}),\n",
       " (14, {'cand': 'strict dress code', 'score': 0.0010215963984162532}),\n",
       " (15, {'cand': 'little caesars', 'score': 0.0010173205311874078}),\n",
       " (16, {'cand': 'kroger', 'score': 0.0009613438930876284}),\n",
       " (17, {'cand': 'casual wear', 'score': 0.0009394833030125308}),\n",
       " (18, {'cand': 'dress code', 'score': 0.0009341126426225727}),\n",
       " (19, {'cand': 'dress codes', 'score': 0.0009088030027112891}),\n",
       " (20, {'cand': 'regular clothes', 'score': 0.000889343262360916}),\n",
       " (21, {'cand': 'casual clothing', 'score': 0.0008411348452836239}),\n",
       " (22, {'cand': 'casual clothes', 'score': 0.0008334858621860611}),\n",
       " (23, {'cand': 'walgreens', 'score': 0.0007546905309754873}),\n",
       " (24, {'cand': 'dyed hair', 'score': 0.0006398076731542155}),\n",
       " (25, {'cand': 'colorful hair', 'score': 0.0006078514425329421}),\n",
       " (26, {'cand': 'nail polish', 'score': 0.0006005180049349828}),\n",
       " (27, {'cand': 'cell phones', 'score': 0.0005721145841827478}),\n",
       " (28, {'cand': 'colored hair', 'score': 0.0005699922843476581}),\n",
       " (29, {'cand': 'nonslip shoes', 'score': 0.0005312519627102852}),\n",
       " (30, {'cand': 'bright colors', 'score': 0.0004946630285485082}),\n",
       " (31, {'cand': 'scrubs', 'score': 0.00046995493775927477}),\n",
       " (32, {'cand': 'clean cut', 'score': 0.00045836499759079107}),\n",
       " (33, {'cand': 'color hair', 'score': 0.00045649897870813185}),\n",
       " (34, {'cand': 'menards', 'score': 0.0004333389155205767}),\n",
       " (35, {'cand': 'common sense', 'score': 0.00042908410357991574}),\n",
       " (36, {'cand': 'drug tests', 'score': 0.0003990514080435584}),\n",
       " (37, {'cand': 'toe shoes', 'score': 0.0003906767665225052}),\n",
       " (38, {'cand': 'hair', 'score': 0.0003809253393647897}),\n",
       " (39, {'cand': 'unnatural hair', 'score': 0.00037165789845841683}),\n",
       " (40, {'cand': 'facial jewelry', 'score': 0.00036627782240548006}),\n",
       " (41, {'cand': 'publix', 'score': 0.0003608527502327888}),\n",
       " (42, {'cand': 'cracker barrel', 'score': 0.0003522372053665923}),\n",
       " (43, {'cand': 'footwear', 'score': 0.0003517538131721426}),\n",
       " (44, {'cand': 'nose rings', 'score': 0.000350651884056811}),\n",
       " (45, {'cand': 'arms', 'score': 0.0003497321336162667}),\n",
       " (46, {'cand': \"mcdonald 's\", 'score': 0.000346964499644113}),\n",
       " (47, {'cand': 'caps', 'score': 0.0003404973788527103}),\n",
       " (48, {'cand': 'food safety', 'score': 0.00033565319561632755}),\n",
       " (49, {'cand': 'clothing', 'score': 0.00032866781773251656}),\n",
       " (50, {'cand': 'visible tattoos', 'score': 0.00032685830127199213}),\n",
       " (51, {'cand': 'natural colors', 'score': 0.0003058666148595594}),\n",
       " (52, {'cand': 'food', 'score': 0.00030395586618252725}),\n",
       " (53, {'cand': 'fake nails', 'score': 0.00029754004452649263}),\n",
       " (54, {'cand': 'cover', 'score': 0.0002934967171305256}),\n",
       " (55, {'cand': 'cargo', 'score': 0.00028762159139762873}),\n",
       " (56, {'cand': 'cvs', 'score': 0.0002732537803456791}),\n",
       " (57, {'cand': 'pretty much', 'score': 0.00026700253348833886}),\n",
       " (58, {'cand': 'facial piercing', 'score': 0.0002656852645019499}),\n",
       " (59, {'cand': 'pharmacist', 'score': 0.00026250280387641917}),\n",
       " (60, {'cand': 'old navy', 'score': 0.00025059207234590737}),\n",
       " (61, {'cand': 'cotton', 'score': 0.00025041624240867803}),\n",
       " (62, {'cand': 'security', 'score': 0.00024658233646515627}),\n",
       " (63, {'cand': 'long', 'score': 0.00022608685203386118}),\n",
       " (64, {'cand': 'chipotle', 'score': 0.0002227762249667668}),\n",
       " (65, {'cand': 'light', 'score': 0.00021965144920271437}),\n",
       " (66, {'cand': 'skin', 'score': 0.00021957353797190455}),\n",
       " (67, {'cand': 'cap', 'score': 0.0002192144986162735}),\n",
       " (68, {'cand': 'acrylic nails', 'score': 0.00021598678945678308}),\n",
       " (69, {'cand': 'uniform policy', 'score': 0.00021568318099091097}),\n",
       " (70, {'cand': 'watch', 'score': 0.00021330949505391576}),\n",
       " (71, {'cand': 'tattoo', 'score': 0.0002083568594538555}),\n",
       " (72, {'cand': 'american eagle', 'score': 0.0002049261691737818}),\n",
       " (73, {'cand': 'sports', 'score': 0.0001963815837834677}),\n",
       " (74, {'cand': 'brand', 'score': 0.00019481115209758426}),\n",
       " (75, {'cand': 'nice', 'score': 0.00019418994601897563}),\n",
       " (76, {'cand': 'safety', 'score': 0.0001899500475891728}),\n",
       " (77, {'cand': 'band', 'score': 0.0001868472007824465}),\n",
       " (78, {'cand': 'gym', 'score': 0.0001834318664870997}),\n",
       " (79, {'cand': 'unnatural colors', 'score': 0.00017370491655358433}),\n",
       " (80, {'cand': 'professional', 'score': 0.00016710567599705154}),\n",
       " (81, {'cand': 'logo', 'score': 0.00016087339880206883}),\n",
       " (82, {'cand': 'hygiene', 'score': 0.00015557538308973547}),\n",
       " (83, {'cand': 'language', 'score': 0.00014474567763480748}),\n",
       " (84, {'cand': 'pizza hut', 'score': 0.0001412527503254208}),\n",
       " (85, {'cand': 'polish', 'score': 0.00013939610596768606}),\n",
       " (86, {'cand': 'weather', 'score': 0.00013365445267625198}),\n",
       " (87, {'cand': 'logos', 'score': 0.0001275112276701323}),\n",
       " (88, {'cand': 'short', 'score': 0.00011920054219832459}),\n",
       " (89, {'cand': 'drugs', 'score': 0.00011295909859637672}),\n",
       " (90, {'cand': 'ankle', 'score': 0.00011056466425478501}),\n",
       " (91, {'cand': 'knee', 'score': 8.786941753576854e-05}),\n",
       " (92, {'cand': 'religious', 'score': 7.702516845890643e-05}),\n",
       " (93, {'cand': 'dd', 'score': 4.134341447779844e-05})]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'walmart allows [MASK] and jeans.'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'leggings', 'score': 0.007950546441326894}),\n",
       " (1, {'cand': 'flip flops', 'score': 0.007075774192646608}),\n",
       " (2, {'cand': 'body piercings', 'score': 0.004914083630190951}),\n",
       " (3, {'cand': 'facial piercings', 'score': 0.004597808759751709}),\n",
       " (4, {'cand': 'face piercings', 'score': 0.0043870840422136044}),\n",
       " (5, {'cand': 'ear piercings', 'score': 0.0041138407839033326}),\n",
       " (6, {'cand': 'nose piercings', 'score': 0.00399272590388933}),\n",
       " (7, {'cand': 'skinny jeans', 'score': 0.0034459863528698465}),\n",
       " (8, {'cand': 'chilis', 'score': 0.0031630352135805905}),\n",
       " (9, {'cand': 't shirts', 'score': 0.002985829794833979}),\n",
       " (10, {'cand': 'clean shaven', 'score': 0.0029825413102062613}),\n",
       " (11, {'cand': 'casual wear', 'score': 0.002949264294126706}),\n",
       " (12, {'cand': 'casual clothes', 'score': 0.002920548747288794}),\n",
       " (13, {'cand': 'scrubs', 'score': 0.002811236868204438}),\n",
       " (14, {'cand': 'casual clothing', 'score': 0.0026647520828171887}),\n",
       " (15, {'cand': 'ripped jeans', 'score': 0.0026136734470758104}),\n",
       " (16, {'cand': 'visible piercings', 'score': 0.0025994385172912224}),\n",
       " (17, {'cand': 'kroger', 'score': 0.002349871120984731}),\n",
       " (18, {'cand': 'casual dress', 'score': 0.0023397590857442184}),\n",
       " (19, {'cand': 'bright colors', 'score': 0.0021139110896663776}),\n",
       " (20, {'cand': 'cell phones', 'score': 0.0020565604600298257}),\n",
       " (21, {'cand': 'little caesars', 'score': 0.0020225111545273742}),\n",
       " (22, {'cand': 'caps', 'score': 0.0019566401433540213}),\n",
       " (23, {'cand': 'regular clothes', 'score': 0.001956131725114353}),\n",
       " (24, {'cand': 'nail polish', 'score': 0.001791198895047793}),\n",
       " (25, {'cand': 'dress code', 'score': 0.00172051376556669}),\n",
       " (26, {'cand': 'strict dress code', 'score': 0.0017082841799791247}),\n",
       " (27, {'cand': 'menards', 'score': 0.0017055575375321745}),\n",
       " (28, {'cand': 'dress codes', 'score': 0.00166792346338582}),\n",
       " (29, {'cand': 'nose rings', 'score': 0.0016239698490986265}),\n",
       " (30, {'cand': 'walgreens', 'score': 0.001616902118935021}),\n",
       " (31, {'cand': 'toe shoes', 'score': 0.001611547934311881}),\n",
       " (32, {'cand': 'nonslip shoes', 'score': 0.0014984450083332073}),\n",
       " (33, {'cand': 'footwear', 'score': 0.0014413669107857761}),\n",
       " (34, {'cand': 'facial jewelry', 'score': 0.0014060065603874992}),\n",
       " (35, {'cand': 'clean cut', 'score': 0.0013296501042966127}),\n",
       " (36, {'cand': 'clothing', 'score': 0.0013006200713927894}),\n",
       " (37, {'cand': 'cotton', 'score': 0.0012853019004169834}),\n",
       " (38, {'cand': 'publix', 'score': 0.0012507117949614975}),\n",
       " (39, {'cand': 'cvs', 'score': 0.0012485142567517453}),\n",
       " (40, {'cand': 'natural colors', 'score': 0.0012326324994156475}),\n",
       " (41, {'cand': 'logos', 'score': 0.0011937625182304643}),\n",
       " (42, {'cand': 'colored hair', 'score': 0.001145388635334243}),\n",
       " (43, {'cand': 'short', 'score': 0.001139456870061024}),\n",
       " (44, {'cand': 'hair', 'score': 0.0011370578566925343}),\n",
       " (45, {'cand': 'cap', 'score': 0.0011356409096843938}),\n",
       " (46, {'cand': \"mcdonald 's\", 'score': 0.0010946205269024441}),\n",
       " (47, {'cand': 'sports', 'score': 0.0010600364138730336}),\n",
       " (48, {'cand': 'common sense', 'score': 0.001007620517940622}),\n",
       " (49, {'cand': 'visible tattoos', 'score': 0.0009879857897197577}),\n",
       " (50, {'cand': 'skin', 'score': 0.0009741013085095619}),\n",
       " (51, {'cand': 'colorful hair', 'score': 0.0009524591519788532}),\n",
       " (52, {'cand': 'arms', 'score': 0.0009473399528185188}),\n",
       " (53, {'cand': 'dyed hair', 'score': 0.0009245590314089859}),\n",
       " (54, {'cand': 'ankle', 'score': 0.0009094554301042356}),\n",
       " (55, {'cand': 'old navy', 'score': 0.0008912914591240424}),\n",
       " (56, {'cand': 'american eagle', 'score': 0.0008833186161301612}),\n",
       " (57, {'cand': 'facial piercing', 'score': 0.0008598029068642302}),\n",
       " (58, {'cand': 'watch', 'score': 0.0008568197064018965}),\n",
       " (59, {'cand': 'pretty much', 'score': 0.0008426876711272263}),\n",
       " (60, {'cand': 'light', 'score': 0.0008391174077588029}),\n",
       " (61, {'cand': 'logo', 'score': 0.0008207826136846629}),\n",
       " (62, {'cand': 'long', 'score': 0.0008087336784529791}),\n",
       " (63, {'cand': 'fake nails', 'score': 0.000795400822942518}),\n",
       " (64, {'cand': 'cargo', 'score': 0.0007833389148839942}),\n",
       " (65, {'cand': 'polish', 'score': 0.0007571538563328835}),\n",
       " (66, {'cand': 'security', 'score': 0.0007553266794885751}),\n",
       " (67, {'cand': 'gym', 'score': 0.0007523962905193874}),\n",
       " (68, {'cand': 'cover', 'score': 0.0007389770433816242}),\n",
       " (69, {'cand': 'unnatural hair', 'score': 0.0007322074671527962}),\n",
       " (70, {'cand': 'food', 'score': 0.0007244939025117333}),\n",
       " (71, {'cand': 'safety', 'score': 0.0007236766466985905}),\n",
       " (72, {'cand': 'uniform policy', 'score': 0.0007042023697577891}),\n",
       " (73, {'cand': 'knee', 'score': 0.000700053865407639}),\n",
       " (74, {'cand': 'acrylic nails', 'score': 0.0006898982556334126}),\n",
       " (75, {'cand': 'food safety', 'score': 0.000679294683484613}),\n",
       " (76, {'cand': 'band', 'score': 0.0006781244234665821}),\n",
       " (77, {'cand': 'unnatural colors', 'score': 0.0006776398876256413}),\n",
       " (78, {'cand': 'color hair', 'score': 0.0006510919359534317}),\n",
       " (79, {'cand': 'hygiene', 'score': 0.0006190403703067018}),\n",
       " (80, {'cand': 'weather', 'score': 0.0006072830303096448}),\n",
       " (81, {'cand': 'cracker barrel', 'score': 0.0006068676321571363}),\n",
       " (82, {'cand': 'language', 'score': 0.0006020192031196061}),\n",
       " (83, {'cand': 'tattoo', 'score': 0.0005798024232199439}),\n",
       " (84, {'cand': 'nice', 'score': 0.0005740430153473579}),\n",
       " (85, {'cand': 'drugs', 'score': 0.0005639703919869237}),\n",
       " (86, {'cand': 'drug tests', 'score': 0.0005523053299512944}),\n",
       " (87, {'cand': 'chipotle', 'score': 0.0005511672101307721}),\n",
       " (88, {'cand': 'pharmacist', 'score': 0.0004919337430367757}),\n",
       " (89, {'cand': 'religious', 'score': 0.0004796004751139974}),\n",
       " (90, {'cand': 'pizza hut', 'score': 0.0004563000664895362}),\n",
       " (91, {'cand': 'brand', 'score': 0.0004427323498393523}),\n",
       " (92, {'cand': 'dd', 'score': 0.00032676698113568375}),\n",
       " (93, {'cand': 'professional', 'score': 0.0003210998601721616})]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'walmart allows jeans, [MASK] and shirts.'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'strict dress code', 'score': 0.001481640258458578}),\n",
       " (1, {'cand': 'dress code', 'score': 0.0014614049244089245}),\n",
       " (2, {'cand': 'body piercings', 'score': 0.0012826025523101547}),\n",
       " (3, {'cand': 'facial piercings', 'score': 0.001111195240394938}),\n",
       " (4, {'cand': 'chilis', 'score': 0.0010555130843792743}),\n",
       " (5, {'cand': 'face piercings', 'score': 0.0010318043150511994}),\n",
       " (6, {'cand': 'ear piercings', 'score': 0.0010116660144114564}),\n",
       " (7, {'cand': 'clean shaven', 'score': 0.0009866746238043995}),\n",
       " (8, {'cand': 'leggings', 'score': 0.000976672849359097}),\n",
       " (9, {'cand': 'pretty much', 'score': 0.0009054636827680127}),\n",
       " (10, {'cand': 'nose piercings', 'score': 0.000851258895619425}),\n",
       " (11, {'cand': 'kroger', 'score': 0.0008211024331508483}),\n",
       " (12, {'cand': 'common sense', 'score': 0.0008111552234457245}),\n",
       " (13, {'cand': \"mcdonald 's\", 'score': 0.0007937432171385823}),\n",
       " (14, {'cand': 'casual wear', 'score': 0.0007158583567161564}),\n",
       " (15, {'cand': 'visible piercings', 'score': 0.0006676884402811128}),\n",
       " (16, {'cand': 'walgreens', 'score': 0.0006529368431447874}),\n",
       " (17, {'cand': 'casual dress', 'score': 0.0006494658922290558}),\n",
       " (18, {'cand': 'clean cut', 'score': 0.0006492900124288944}),\n",
       " (19, {'cand': 'pharmacist', 'score': 0.0006089974137265536}),\n",
       " (20, {'cand': 'flip flops', 'score': 0.0006071883466292405}),\n",
       " (21, {'cand': 'dress codes', 'score': 0.0005707867463155691}),\n",
       " (22, {'cand': 'professional', 'score': 0.000562181944033713}),\n",
       " (23, {'cand': 'little caesars', 'score': 0.000559247302359841}),\n",
       " (24, {'cand': 'religious', 'score': 0.0005362623128700558}),\n",
       " (25, {'cand': 'publix', 'score': 0.0005065762064027447}),\n",
       " (26, {'cand': 'casual clothing', 'score': 0.0005005560137146556}),\n",
       " (27, {'cand': 'regular clothes', 'score': 0.0004945028962221312}),\n",
       " (28, {'cand': 'short', 'score': 0.00045641039330439315}),\n",
       " (29, {'cand': 'sports', 'score': 0.00044687162680063694}),\n",
       " (30, {'cand': 'long', 'score': 0.00044489389954812216}),\n",
       " (31, {'cand': 'nice', 'score': 0.00043498558796524435}),\n",
       " (32, {'cand': 'uniform policy', 'score': 0.00042755068894122456}),\n",
       " (33, {'cand': 'casual clothes', 'score': 0.00042241887975221626}),\n",
       " (34, {'cand': 'skinny jeans', 'score': 0.00041693871401084367}),\n",
       " (35, {'cand': 'security', 'score': 0.00041189970887852415}),\n",
       " (36, {'cand': 'american eagle', 'score': 0.00034750659146447096}),\n",
       " (37, {'cand': 't shirts', 'score': 0.00033198435733986035}),\n",
       " (38, {'cand': 'brand', 'score': 0.0003292036130183525}),\n",
       " (39, {'cand': 'food safety', 'score': 0.00031844490490899846}),\n",
       " (40, {'cand': 'cvs', 'score': 0.00031147660556622215}),\n",
       " (41, {'cand': 'colored hair', 'score': 0.0002858256371307642}),\n",
       " (42, {'cand': 'safety', 'score': 0.00028359158786417696}),\n",
       " (43, {'cand': 'cover', 'score': 0.00027705865628165}),\n",
       " (44, {'cand': 'chipotle', 'score': 0.00027641443630671087}),\n",
       " (45, {'cand': 'gym', 'score': 0.00027295452055195186}),\n",
       " (46, {'cand': 'light', 'score': 0.0002691839288554859}),\n",
       " (47, {'cand': 'dyed hair', 'score': 0.00026769833324041104}),\n",
       " (48, {'cand': 'unnatural hair', 'score': 0.0002667640485077319}),\n",
       " (49, {'cand': 'ripped jeans', 'score': 0.00026546668992519234}),\n",
       " (50, {'cand': 'colorful hair', 'score': 0.00025550750919801034}),\n",
       " (51, {'cand': 'menards', 'score': 0.0002532472833219469}),\n",
       " (52, {'cand': 'nail polish', 'score': 0.0002522469750781598}),\n",
       " (53, {'cand': 'clothing', 'score': 0.00024976274202457395}),\n",
       " (54, {'cand': 'cell phones', 'score': 0.0002462866835259417}),\n",
       " (55, {'cand': 'hair', 'score': 0.00023926740742454575}),\n",
       " (56, {'cand': 'watch', 'score': 0.0002329999336363395}),\n",
       " (57, {'cand': 'cracker barrel', 'score': 0.0002321130239307431}),\n",
       " (58, {'cand': 'color hair', 'score': 0.00022482216550355494}),\n",
       " (59, {'cand': 'old navy', 'score': 0.00021424323203477662}),\n",
       " (60, {'cand': 'language', 'score': 0.00021394207445395811}),\n",
       " (61, {'cand': 'skin', 'score': 0.00020937092422798005}),\n",
       " (62, {'cand': 'band', 'score': 0.00020896279428960098}),\n",
       " (63, {'cand': 'logo', 'score': 0.0002069117481483374}),\n",
       " (64, {'cand': 'tattoo', 'score': 0.0002036731869281251}),\n",
       " (65, {'cand': 'scrubs', 'score': 0.0001922488791108399}),\n",
       " (66, {'cand': 'arms', 'score': 0.00019125918402427292}),\n",
       " (67, {'cand': 'food', 'score': 0.00018840768806295899}),\n",
       " (68, {'cand': 'footwear', 'score': 0.00018251784565969224}),\n",
       " (69, {'cand': 'nonslip shoes', 'score': 0.00018091726307789668}),\n",
       " (70, {'cand': 'drug tests', 'score': 0.0001784847857056839}),\n",
       " (71, {'cand': 'cotton', 'score': 0.0001773491558206013}),\n",
       " (72, {'cand': 'pizza hut', 'score': 0.00017489875552427603}),\n",
       " (73, {'cand': 'bright colors', 'score': 0.00017313730798160205}),\n",
       " (74, {'cand': 'cargo', 'score': 0.000171162632670339}),\n",
       " (75, {'cand': 'facial piercing', 'score': 0.0001518831008391836}),\n",
       " (76, {'cand': 'ankle', 'score': 0.00014397141756642226}),\n",
       " (77, {'cand': 'cap', 'score': 0.00014169528801893534}),\n",
       " (78, {'cand': 'facial jewelry', 'score': 0.00014153889251316277}),\n",
       " (79, {'cand': 'visible tattoos', 'score': 0.00013557095573862873}),\n",
       " (80, {'cand': 'natural colors', 'score': 0.0001283575924216251}),\n",
       " (81, {'cand': 'knee', 'score': 0.00012565208816237646}),\n",
       " (82, {'cand': 'nose rings', 'score': 0.00011403335706823788}),\n",
       " (83, {'cand': 'caps', 'score': 0.00011303507109795633}),\n",
       " (84, {'cand': 'weather', 'score': 0.00010989188634275839}),\n",
       " (85, {'cand': 'drugs', 'score': 0.00010183479658549429}),\n",
       " (86, {'cand': 'toe shoes', 'score': 0.0001010774899655146}),\n",
       " (87, {'cand': 'fake nails', 'score': 9.678872929563285e-05}),\n",
       " (88, {'cand': 'hygiene', 'score': 9.599943508571079e-05}),\n",
       " (89, {'cand': 'logos', 'score': 9.597600058440262e-05}),\n",
       " (90, {'cand': 'polish', 'score': 7.835372567715017e-05}),\n",
       " (91, {'cand': 'unnatural colors', 'score': 7.632691249032289e-05}),\n",
       " (92, {'cand': 'acrylic nails', 'score': 7.270340395364323e-05}),\n",
       " (93, {'cand': 'dd', 'score': 6.839010276759115e-05})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'walmart allows [MASK] dress code.'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'facial piercings', 'score': 0.0024681891038005298}),\n",
       " (1, {'cand': 'leggings', 'score': 0.0024557826536680217}),\n",
       " (2, {'cand': 'body piercings', 'score': 0.0023139781380786006}),\n",
       " (3, {'cand': 'ear piercings', 'score': 0.0020149633466706694}),\n",
       " (4, {'cand': 'dress codes', 'score': 0.0018968910464227896}),\n",
       " (5, {'cand': 'face piercings', 'score': 0.0017684080012686362}),\n",
       " (6, {'cand': 'nose piercings', 'score': 0.0015449002044813037}),\n",
       " (7, {'cand': 'dress code', 'score': 0.0014614049244089245}),\n",
       " (8, {'cand': 'flip flops', 'score': 0.0013433120763974267}),\n",
       " (9, {'cand': 'visible piercings', 'score': 0.0012572251272025877}),\n",
       " (10, {'cand': 'chilis', 'score': 0.0011977886276130956}),\n",
       " (11, {'cand': 'strict dress code', 'score': 0.0010226954789166708}),\n",
       " (12, {'cand': 'casual wear', 'score': 0.0009943724307336559}),\n",
       " (13, {'cand': 'kroger', 'score': 0.0009048788386481821}),\n",
       " (14, {'cand': 'uniform policy', 'score': 0.0008681796947668647}),\n",
       " (15, {'cand': 't shirts', 'score': 0.0008637144338777857}),\n",
       " (16, {'cand': 'safety', 'score': 0.0007744505242754482}),\n",
       " (17, {'cand': 'little caesars', 'score': 0.0007729010718438835}),\n",
       " (18, {'cand': 'casual clothing', 'score': 0.0007702880712554374}),\n",
       " (19, {'cand': 'scrubs', 'score': 0.0007654574666874391}),\n",
       " (20, {'cand': 'drug tests', 'score': 0.0007450762595571064}),\n",
       " (21, {'cand': 'security', 'score': 0.0007209223294117937}),\n",
       " (22, {'cand': 'casual dress', 'score': 0.0007174504642625953}),\n",
       " (23, {'cand': 'pretty much', 'score': 0.0007121459591452254}),\n",
       " (24, {'cand': 'skinny jeans', 'score': 0.0007067889968751355}),\n",
       " (25, {'cand': 'casual clothes', 'score': 0.0006948955443302095}),\n",
       " (26, {'cand': 'clean shaven', 'score': 0.0006360949362151734}),\n",
       " (27, {'cand': 'cell phones', 'score': 0.0006200705242234815}),\n",
       " (28, {'cand': 'walgreens', 'score': 0.0006095331331650344}),\n",
       " (29, {'cand': 'publix', 'score': 0.0005755526744993431}),\n",
       " (30, {'cand': 'regular clothes', 'score': 0.0005499698043291568}),\n",
       " (31, {'cand': 'common sense', 'score': 0.0005488812507478412}),\n",
       " (32, {'cand': 'nail polish', 'score': 0.0005074373541484385}),\n",
       " (33, {'cand': 'bright colors', 'score': 0.0005071018596687175}),\n",
       " (34, {'cand': 'menards', 'score': 0.0005048631073964657}),\n",
       " (35, {'cand': 'cover', 'score': 0.0004891313451057646}),\n",
       " (36, {'cand': 'language', 'score': 0.0004681071320692668}),\n",
       " (37, {'cand': 'dyed hair', 'score': 0.0004606408684902233}),\n",
       " (38, {'cand': 'nonslip shoes', 'score': 0.000447619967949415}),\n",
       " (39, {'cand': \"mcdonald 's\", 'score': 0.00042596933086974653}),\n",
       " (40, {'cand': 'caps', 'score': 0.0004155917570789318}),\n",
       " (41, {'cand': 'nose rings', 'score': 0.0004111079601354632}),\n",
       " (42, {'cand': 'hygiene', 'score': 0.00040965578085466216}),\n",
       " (43, {'cand': 'clothing', 'score': 0.0004089956764300665}),\n",
       " (44, {'cand': 'toe shoes', 'score': 0.0003934839361157464}),\n",
       " (45, {'cand': 'food safety', 'score': 0.0003867017822513292}),\n",
       " (46, {'cand': 'natural colors', 'score': 0.00038460723019773585}),\n",
       " (47, {'cand': 'facial jewelry', 'score': 0.00038262125563165607}),\n",
       " (48, {'cand': 'color hair', 'score': 0.00036841060562068864}),\n",
       " (49, {'cand': 'cvs', 'score': 0.00035996528417194434}),\n",
       " (50, {'cand': 'facial piercing', 'score': 0.0003529756577445633}),\n",
       " (51, {'cand': 'ripped jeans', 'score': 0.0003514272282202311}),\n",
       " (52, {'cand': 'pharmacist', 'score': 0.0003513226778733399}),\n",
       " (53, {'cand': 'colored hair', 'score': 0.0003381378698724095}),\n",
       " (54, {'cand': 'hair', 'score': 0.0003329723656597614}),\n",
       " (55, {'cand': 'footwear', 'score': 0.0003298761585570737}),\n",
       " (56, {'cand': 'logos', 'score': 0.0003201937971675066}),\n",
       " (57, {'cand': 'light', 'score': 0.0003136804357420198}),\n",
       " (58, {'cand': 'arms', 'score': 0.00030490378276065445}),\n",
       " (59, {'cand': 'clean cut', 'score': 0.00030146566201464525}),\n",
       " (60, {'cand': 'colorful hair', 'score': 0.0002927065047356098}),\n",
       " (61, {'cand': 'watch', 'score': 0.0002781361365835273}),\n",
       " (62, {'cand': 'sports', 'score': 0.00027302871890394877}),\n",
       " (63, {'cand': 'chipotle', 'score': 0.0002686625353088457}),\n",
       " (64, {'cand': 'visible tattoos', 'score': 0.00026829178977434703}),\n",
       " (65, {'cand': 'cracker barrel', 'score': 0.00026519366132808636}),\n",
       " (66, {'cand': 'american eagle', 'score': 0.00026375197005248284}),\n",
       " (67, {'cand': 'tattoo', 'score': 0.00025898944267394925}),\n",
       " (68, {'cand': 'short', 'score': 0.00025350245208194085}),\n",
       " (69, {'cand': 'long', 'score': 0.00025144285971873093}),\n",
       " (70, {'cand': 'food', 'score': 0.00024611575220631675}),\n",
       " (71, {'cand': 'professional', 'score': 0.00023917683584827928}),\n",
       " (72, {'cand': 'cap', 'score': 0.00023818939585365206}),\n",
       " (73, {'cand': 'logo', 'score': 0.00022776447935745343}),\n",
       " (74, {'cand': 'weather', 'score': 0.00022527630905106897}),\n",
       " (75, {'cand': 'skin', 'score': 0.00021344115344625907}),\n",
       " (76, {'cand': 'polish', 'score': 0.000207299265014412}),\n",
       " (77, {'cand': 'band', 'score': 0.00020179815211134443}),\n",
       " (78, {'cand': 'drugs', 'score': 0.00020061919840277178}),\n",
       " (79, {'cand': 'acrylic nails', 'score': 0.00019742320119991416}),\n",
       " (80, {'cand': 'religious', 'score': 0.0001948256439751781}),\n",
       " (81, {'cand': 'fake nails', 'score': 0.00018447533217290547}),\n",
       " (82, {'cand': 'unnatural colors', 'score': 0.00017871745276498398}),\n",
       " (83, {'cand': 'brand', 'score': 0.00017662252944130355}),\n",
       " (84, {'cand': 'cotton', 'score': 0.0001763604624011853}),\n",
       " (85, {'cand': 'unnatural hair', 'score': 0.00017235855842281318}),\n",
       " (86, {'cand': 'knee', 'score': 0.00016540772797400037}),\n",
       " (87, {'cand': 'nice', 'score': 0.0001614793219438353}),\n",
       " (88, {'cand': 'ankle', 'score': 0.00014682934177917174}),\n",
       " (89, {'cand': 'old navy', 'score': 0.0001423314227529972}),\n",
       " (90, {'cand': 'gym', 'score': 0.00013492835804129895}),\n",
       " (91, {'cand': 'pizza hut', 'score': 0.00013289312700198348}),\n",
       " (92, {'cand': 'cargo', 'score': 0.00012040911911730286}),\n",
       " (93, {'cand': 'dd', 'score': 9.6765840381021e-05})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'walmart allows dress code [MASK].'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'ear piercings', 'score': 0.0028285219463860057}),\n",
       " (1, {'cand': 'facial piercings', 'score': 0.002760509035081923}),\n",
       " (2, {'cand': 'body piercings', 'score': 0.002678974198245505}),\n",
       " (3, {'cand': 'leggings', 'score': 0.0026481382079254147}),\n",
       " (4, {'cand': 'flip flops', 'score': 0.0023722809729632035}),\n",
       " (5, {'cand': 'face piercings', 'score': 0.0022416971554271286}),\n",
       " (6, {'cand': 'visible piercings', 'score': 0.0020508082141699894}),\n",
       " (7, {'cand': 'nose piercings', 'score': 0.0018044117899724422}),\n",
       " (8, {'cand': 'chilis', 'score': 0.0011598017129516335}),\n",
       " (9, {'cand': 'strict dress code', 'score': 0.0009696177402124964}),\n",
       " (10, {'cand': 'skinny jeans', 'score': 0.0008879986995992568}),\n",
       " (11, {'cand': 'cell phones', 'score': 0.0008738993766711747}),\n",
       " (12, {'cand': 'little caesars', 'score': 0.0008699902601876318}),\n",
       " (13, {'cand': 'casual clothes', 'score': 0.0008195209935461452}),\n",
       " (14, {'cand': 'casual clothing', 'score': 0.000776383193831136}),\n",
       " (15, {'cand': 'nail polish', 'score': 0.0007672579287616886}),\n",
       " (16, {'cand': 'regular clothes', 'score': 0.0007363052694242289}),\n",
       " (17, {'cand': 'bright colors', 'score': 0.0006769568251188164}),\n",
       " (18, {'cand': 'nonslip shoes', 'score': 0.0006717575703592431}),\n",
       " (19, {'cand': 'kroger', 'score': 0.0006642578391995313}),\n",
       " (20, {'cand': 'common sense', 'score': 0.0006483621688037509}),\n",
       " (21, {'cand': 'clean shaven', 'score': 0.0005944181713898792}),\n",
       " (22, {'cand': 'dress code', 'score': 0.0005647650781356957}),\n",
       " (23, {'cand': 'casual wear', 'score': 0.000562465364639397}),\n",
       " (24, {'cand': 'walgreens', 'score': 0.0005484600320239502}),\n",
       " (25, {'cand': 'scrubs', 'score': 0.0005322789027380931}),\n",
       " (26, {'cand': 'ripped jeans', 'score': 0.0005049163131850164}),\n",
       " (27, {'cand': 'casual dress', 'score': 0.0004956839986614504}),\n",
       " (28, {'cand': 'dress codes', 'score': 0.0004708023202951403}),\n",
       " (29, {'cand': 'visible tattoos', 'score': 0.0004360761008461185}),\n",
       " (30, {'cand': 'facial jewelry', 'score': 0.00042406914731224135}),\n",
       " (31, {'cand': 'toe shoes', 'score': 0.00041712404785437633}),\n",
       " (32, {'cand': 't shirts', 'score': 0.00040294231394977817}),\n",
       " (33, {'cand': 'nose rings', 'score': 0.00039949158386541167}),\n",
       " (34, {'cand': 'natural colors', 'score': 0.00038678532165541325}),\n",
       " (35, {'cand': 'publix', 'score': 0.0003825968083763922}),\n",
       " (36, {'cand': 'colored hair', 'score': 0.00038003181513204863}),\n",
       " (37, {'cand': 'fake nails', 'score': 0.00037564604348351804}),\n",
       " (38, {'cand': 'dyed hair', 'score': 0.0003076103732889835}),\n",
       " (39, {'cand': \"mcdonald 's\", 'score': 0.0002899609350182622}),\n",
       " (40, {'cand': 'clothing', 'score': 0.0002829534944314914}),\n",
       " (41, {'cand': 'drug tests', 'score': 0.00027682966899286303}),\n",
       " (42, {'cand': 'facial piercing', 'score': 0.0002675793912583749}),\n",
       " (43, {'cand': 'unnatural hair', 'score': 0.0002591737639514906}),\n",
       " (44, {'cand': 'footwear', 'score': 0.0002551386142669464}),\n",
       " (45, {'cand': 'colorful hair', 'score': 0.00024173483790439535}),\n",
       " (46, {'cand': 'acrylic nails', 'score': 0.0002357525334859138}),\n",
       " (47, {'cand': 'american eagle', 'score': 0.00023016574187253075}),\n",
       " (48, {'cand': 'caps', 'score': 0.00022003134776507258}),\n",
       " (49, {'cand': 'cracker barrel', 'score': 0.00020888767831018072}),\n",
       " (50, {'cand': 'color hair', 'score': 0.00020714413174259408}),\n",
       " (51, {'cand': 'unnatural colors', 'score': 0.00020163809745530172}),\n",
       " (52, {'cand': 'menards', 'score': 0.00019819192450097614}),\n",
       " (53, {'cand': 'pharmacist', 'score': 0.00019579663212062232}),\n",
       " (54, {'cand': 'uniform policy', 'score': 0.00019545540754600056}),\n",
       " (55, {'cand': 'cvs', 'score': 0.00018746315225490429}),\n",
       " (56, {'cand': 'pretty much', 'score': 0.0001841199457150128}),\n",
       " (57, {'cand': 'food safety', 'score': 0.00017867655226715012}),\n",
       " (58, {'cand': 'cotton', 'score': 0.00017743746540066645}),\n",
       " (59, {'cand': 'light', 'score': 0.0001734984639147595}),\n",
       " (60, {'cand': 'logos', 'score': 0.00016420427306132677}),\n",
       " (61, {'cand': 'hair', 'score': 0.00016308592188369264}),\n",
       " (62, {'cand': 'drugs', 'score': 0.00016156604648171063}),\n",
       " (63, {'cand': 'chipotle', 'score': 0.00015541641360301367}),\n",
       " (64, {'cand': 'arms', 'score': 0.00014351574885907112}),\n",
       " (65, {'cand': 'clean cut', 'score': 0.00014122796602191083}),\n",
       " (66, {'cand': 'food', 'score': 0.00013820201170355322}),\n",
       " (67, {'cand': 'cap', 'score': 0.0001378715900605096}),\n",
       " (68, {'cand': 'sports', 'score': 0.00013274416811568694}),\n",
       " (69, {'cand': 'old navy', 'score': 0.00013087723637016257}),\n",
       " (70, {'cand': 'security', 'score': 0.00012515016191274206}),\n",
       " (71, {'cand': 'long', 'score': 0.00012275107664815973}),\n",
       " (72, {'cand': 'watch', 'score': 0.00012021704524112011}),\n",
       " (73, {'cand': 'skin', 'score': 0.00011699514670700726}),\n",
       " (74, {'cand': 'cargo', 'score': 0.00011217607032727039}),\n",
       " (75, {'cand': 'logo', 'score': 0.00010729977609426224}),\n",
       " (76, {'cand': 'band', 'score': 0.00010093665866789937}),\n",
       " (77, {'cand': 'polish', 'score': 0.00010001038279884938}),\n",
       " (78, {'cand': 'safety', 'score': 9.929997239664634e-05}),\n",
       " (79, {'cand': 'short', 'score': 9.224017293859193e-05}),\n",
       " (80, {'cand': 'cover', 'score': 9.21739575024888e-05}),\n",
       " (81, {'cand': 'nice', 'score': 8.660288100651943e-05}),\n",
       " (82, {'cand': 'brand', 'score': 8.005699954037321e-05}),\n",
       " (83, {'cand': 'language', 'score': 7.996878953297625e-05}),\n",
       " (84, {'cand': 'ankle', 'score': 7.784873177503894e-05}),\n",
       " (85, {'cand': 'tattoo', 'score': 7.74259601780676e-05}),\n",
       " (86, {'cand': 'pizza hut', 'score': 7.719253799725543e-05}),\n",
       " (87, {'cand': 'knee', 'score': 7.705610003332918e-05}),\n",
       " (88, {'cand': 'gym', 'score': 7.305285935205718e-05}),\n",
       " (89, {'cand': 'professional', 'score': 6.489194995146916e-05}),\n",
       " (90, {'cand': 'religious', 'score': 6.397448084657232e-05}),\n",
       " (91, {'cand': 'weather', 'score': 5.019384497700115e-05}),\n",
       " (92, {'cand': 'hygiene', 'score': 4.880363477568962e-05}),\n",
       " (93, {'cand': 'dd', 'score': 4.678830670260647e-05})]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'walmart allows wearing [MASK].'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'facial piercings', 'score': 0.005131491638383358}),\n",
       " (1, {'cand': 'ear piercings', 'score': 0.004585294029525217}),\n",
       " (2, {'cand': 'body piercings', 'score': 0.003921686298146271}),\n",
       " (3, {'cand': 'face piercings', 'score': 0.0031354570810024963}),\n",
       " (4, {'cand': 'nose piercings', 'score': 0.0027180962206184954}),\n",
       " (5, {'cand': 'visible piercings', 'score': 0.0024973917008433094}),\n",
       " (6, {'cand': 'flip flops', 'score': 0.002464597392923424}),\n",
       " (7, {'cand': 'leggings', 'score': 0.002399294901892428}),\n",
       " (8, {'cand': 'common sense', 'score': 0.0023571218728802986}),\n",
       " (9, {'cand': 'kroger', 'score': 0.002186137623079781}),\n",
       " (10, {'cand': 'chilis', 'score': 0.00146357862761529}),\n",
       " (11, {'cand': 'walgreens', 'score': 0.001443502549508646}),\n",
       " (12, {'cand': 'cell phones', 'score': 0.0014306609753049991}),\n",
       " (13, {'cand': 'little caesars', 'score': 0.0011527207685542477}),\n",
       " (14, {'cand': 'pretty much', 'score': 0.001133674745327496}),\n",
       " (15, {'cand': 'dress codes', 'score': 0.0010702583681541677}),\n",
       " (16, {'cand': 'scrubs', 'score': 0.0010692478640202802}),\n",
       " (17, {'cand': 'publix', 'score': 0.0010683931754158994}),\n",
       " (18, {'cand': 'cvs', 'score': 0.0010352767957789134}),\n",
       " (19, {'cand': 'food safety', 'score': 0.0009846292043066338}),\n",
       " (20, {'cand': 'drug tests', 'score': 0.0009362062303646826}),\n",
       " (21, {'cand': 'casual wear', 'score': 0.0008703296685098769}),\n",
       " (22, {'cand': 'strict dress code', 'score': 0.0008701226053879435}),\n",
       " (23, {'cand': 'bright colors', 'score': 0.0008565676598174496}),\n",
       " (24, {'cand': 'security', 'score': 0.0008386965845941151}),\n",
       " (25, {'cand': 'skinny jeans', 'score': 0.0008109467709896824}),\n",
       " (26, {'cand': 'nail polish', 'score': 0.0007415570214964077}),\n",
       " (27, {'cand': 'natural colors', 'score': 0.0006820476766291054}),\n",
       " (28, {'cand': 'dress code', 'score': 0.0005874195982320019}),\n",
       " (29, {'cand': 't shirts', 'score': 0.0005859707320001232}),\n",
       " (30, {'cand': \"mcdonald 's\", 'score': 0.0005386343936168047}),\n",
       " (31, {'cand': 'pharmacist', 'score': 0.0005268224744075912}),\n",
       " (32, {'cand': 'clean shaven', 'score': 0.000508207628804578}),\n",
       " (33, {'cand': 'uniform policy', 'score': 0.0004469119016797989}),\n",
       " (34, {'cand': 'menards', 'score': 0.0004364293213389427}),\n",
       " (35, {'cand': 'safety', 'score': 0.0004119778871131539}),\n",
       " (36, {'cand': 'nose rings', 'score': 0.0003594639158373666}),\n",
       " (37, {'cand': 'long', 'score': 0.00035747308641662665}),\n",
       " (38, {'cand': 'facial piercing', 'score': 0.0003555610942936538}),\n",
       " (39, {'cand': 'american eagle', 'score': 0.00034436849242887584}),\n",
       " (40, {'cand': 'unnatural colors', 'score': 0.00034071680031673153}),\n",
       " (41, {'cand': 'clean cut', 'score': 0.0003249437575787559}),\n",
       " (42, {'cand': 'nonslip shoes', 'score': 0.0003205191714145242}),\n",
       " (43, {'cand': 'cover', 'score': 0.0003105802211224197}),\n",
       " (44, {'cand': 'casual dress', 'score': 0.0003102634569213208}),\n",
       " (45, {'cand': 'dyed hair', 'score': 0.00030350978648160406}),\n",
       " (46, {'cand': 'visible tattoos', 'score': 0.000302499556083856}),\n",
       " (47, {'cand': 'short', 'score': 0.0003000756511736059}),\n",
       " (48, {'cand': 'light', 'score': 0.00027600166895563313}),\n",
       " (49, {'cand': 'color hair', 'score': 0.00026716019813127865}),\n",
       " (50, {'cand': 'language', 'score': 0.00025713625805740995}),\n",
       " (51, {'cand': 'regular clothes', 'score': 0.0002561875234346553}),\n",
       " (52, {'cand': 'colorful hair', 'score': 0.00024351185642901675}),\n",
       " (53, {'cand': 'cracker barrel', 'score': 0.0002434909565356662}),\n",
       " (54, {'cand': 'colored hair', 'score': 0.00023915722032741667}),\n",
       " (55, {'cand': 'watch', 'score': 0.0002379564486960156}),\n",
       " (56, {'cand': 'facial jewelry', 'score': 0.0002186851735467175}),\n",
       " (57, {'cand': 'skin', 'score': 0.0002142473184391046}),\n",
       " (58, {'cand': 'fake nails', 'score': 0.0002108151157074887}),\n",
       " (59, {'cand': 'unnatural hair', 'score': 0.00020589486684475286}),\n",
       " (60, {'cand': 'toe shoes', 'score': 0.00020515338799085404}),\n",
       " (61, {'cand': 'sports', 'score': 0.0002048095289849957}),\n",
       " (62, {'cand': 'weather', 'score': 0.00020331590870861725}),\n",
       " (63, {'cand': 'caps', 'score': 0.00020095103942514316}),\n",
       " (64, {'cand': 'cargo', 'score': 0.00019632915124393109}),\n",
       " (65, {'cand': 'casual clothing', 'score': 0.0001957712390015742}),\n",
       " (66, {'cand': 'professional', 'score': 0.00019195685267759405}),\n",
       " (67, {'cand': 'dd', 'score': 0.0001917266958524537}),\n",
       " (68, {'cand': 'casual clothes', 'score': 0.00018197418919628722}),\n",
       " (69, {'cand': 'hygiene', 'score': 0.0001643930813921205}),\n",
       " (70, {'cand': 'cap', 'score': 0.00014748669710380665}),\n",
       " (71, {'cand': 'acrylic nails', 'score': 0.0001435851573504978}),\n",
       " (72, {'cand': 'nice', 'score': 0.00013667048139760172}),\n",
       " (73, {'cand': 'brand', 'score': 0.0001315063094849264}),\n",
       " (74, {'cand': 'chipotle', 'score': 0.00013075235691317145}),\n",
       " (75, {'cand': 'food', 'score': 0.00013028744895986983}),\n",
       " (76, {'cand': 'band', 'score': 0.00012617311286067907}),\n",
       " (77, {'cand': 'ripped jeans', 'score': 0.0001256831282685417}),\n",
       " (78, {'cand': 'logos', 'score': 0.00012100680058924419}),\n",
       " (79, {'cand': 'arms', 'score': 0.0001204505802753982}),\n",
       " (80, {'cand': 'polish', 'score': 0.00011891668447856707}),\n",
       " (81, {'cand': 'drugs', 'score': 0.00011844460014098311}),\n",
       " (82, {'cand': 'footwear', 'score': 0.00010980975301278013}),\n",
       " (83, {'cand': 'logo', 'score': 0.00010974840263099633}),\n",
       " (84, {'cand': 'hair', 'score': 0.00010895447938315896}),\n",
       " (85, {'cand': 'clothing', 'score': 9.943320966896605e-05}),\n",
       " (86, {'cand': 'gym', 'score': 8.800536045184762e-05}),\n",
       " (87, {'cand': 'tattoo', 'score': 7.4719814162925e-05}),\n",
       " (88, {'cand': 'pizza hut', 'score': 7.344860021863516e-05}),\n",
       " (89, {'cand': 'religious', 'score': 6.849891411893272e-05}),\n",
       " (90, {'cand': 'cotton', 'score': 6.757432031331435e-05}),\n",
       " (91, {'cand': 'old navy', 'score': 5.454406682391816e-05}),\n",
       " (92, {'cand': 'knee', 'score': 4.5788264436897234e-05}),\n",
       " (93, {'cand': 'ankle', 'score': 3.0685340051890673e-05})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Microsoft \n",
    "_template = 'microsoft allows [MASK].'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'leggings', 'score': 0.011639003395122744}),\n",
       " (1, {'cand': 'flip flops', 'score': 0.010187015990838816}),\n",
       " (2, {'cand': 'body piercings', 'score': 0.006771256912652817}),\n",
       " (3, {'cand': 'facial piercings', 'score': 0.006146955837318614}),\n",
       " (4, {'cand': 'face piercings', 'score': 0.005689742589356696}),\n",
       " (5, {'cand': 'ear piercings', 'score': 0.005570401935557938}),\n",
       " (6, {'cand': 'nose piercings', 'score': 0.005167720282261649}),\n",
       " (7, {'cand': 'skinny jeans', 'score': 0.0046533507278853185}),\n",
       " (8, {'cand': 't shirts', 'score': 0.004396851636340999}),\n",
       " (9, {'cand': 'scrubs', 'score': 0.004259382685681133}),\n",
       " (10, {'cand': 'casual wear', 'score': 0.0040216165931792796}),\n",
       " (11, {'cand': 'casual clothes', 'score': 0.004000789351740254}),\n",
       " (12, {'cand': 'chilis', 'score': 0.003826438920917085}),\n",
       " (13, {'cand': 'clean shaven', 'score': 0.0037780096027934633}),\n",
       " (14, {'cand': 'casual clothing', 'score': 0.003673589683874928}),\n",
       " (15, {'cand': 'ripped jeans', 'score': 0.003457362711268456}),\n",
       " (16, {'cand': 'visible piercings', 'score': 0.0033380029681436296}),\n",
       " (17, {'cand': 'casual dress', 'score': 0.0030216121672201677}),\n",
       " (18, {'cand': 'kroger', 'score': 0.0028099636795111504}),\n",
       " (19, {'cand': 'caps', 'score': 0.0026229436003505865}),\n",
       " (20, {'cand': 'bright colors', 'score': 0.002615503651006315}),\n",
       " (21, {'cand': 'cell phones', 'score': 0.002517965735532257}),\n",
       " (22, {'cand': 'regular clothes', 'score': 0.0024456171492717544}),\n",
       " (23, {'cand': 'nail polish', 'score': 0.0024381976479797797}),\n",
       " (24, {'cand': 'little caesars', 'score': 0.002434100522069197}),\n",
       " (25, {'cand': 'dress codes', 'score': 0.0021923269453451685}),\n",
       " (26, {'cand': 'menards', 'score': 0.0021808796764202403}),\n",
       " (27, {'cand': 'toe shoes', 'score': 0.0021791966884241155}),\n",
       " (28, {'cand': 'nose rings', 'score': 0.002153850386055808}),\n",
       " (29, {'cand': 'dress code', 'score': 0.0021154690101124435}),\n",
       " (30, {'cand': 'strict dress code', 'score': 0.002052918632973429}),\n",
       " (31, {'cand': 'walgreens', 'score': 0.0020363289306535807}),\n",
       " (32, {'cand': 'footwear', 'score': 0.0018819767596059656}),\n",
       " (33, {'cand': 'nonslip shoes', 'score': 0.0018245676575213458}),\n",
       " (34, {'cand': 'clothing', 'score': 0.0018102271917181101}),\n",
       " (35, {'cand': 'cotton', 'score': 0.0017402294477038068}),\n",
       " (36, {'cand': 'facial jewelry', 'score': 0.001705699052941263}),\n",
       " (37, {'cand': 'cvs', 'score': 0.001660121309726525}),\n",
       " (38, {'cand': 'logos', 'score': 0.0016389841560812365}),\n",
       " (39, {'cand': 'hair', 'score': 0.0016150173547080208}),\n",
       " (40, {'cand': 'publix', 'score': 0.001612296574490354}),\n",
       " (41, {'cand': 'clean cut', 'score': 0.0015759934947003026}),\n",
       " (42, {'cand': 'natural colors', 'score': 0.0014751933722280902}),\n",
       " (43, {'cand': 'short', 'score': 0.0014087741594809322}),\n",
       " (44, {'cand': 'colored hair', 'score': 0.0013773367041708476}),\n",
       " (45, {'cand': 'skin', 'score': 0.0013518551214145589}),\n",
       " (46, {'cand': 'cap', 'score': 0.0012876151489509176}),\n",
       " (47, {'cand': 'arms', 'score': 0.0012806347353744127}),\n",
       " (48, {'cand': \"mcdonald 's\", 'score': 0.0012756195077760204}),\n",
       " (49, {'cand': 'visible tattoos', 'score': 0.0011927167312346372}),\n",
       " (50, {'cand': 'pretty much', 'score': 0.001173357266248146}),\n",
       " (51, {'cand': 'sports', 'score': 0.00115142759460277}),\n",
       " (52, {'cand': 'colorful hair', 'score': 0.0011335012329908559}),\n",
       " (53, {'cand': 'dyed hair', 'score': 0.0011208635406216249}),\n",
       " (54, {'cand': 'ankle', 'score': 0.0010960636410592929}),\n",
       " (55, {'cand': 'common sense', 'score': 0.00108931729590032}),\n",
       " (56, {'cand': 'old navy', 'score': 0.0010632788645363292}),\n",
       " (57, {'cand': 'long', 'score': 0.0010407471105463894}),\n",
       " (58, {'cand': 'light', 'score': 0.0010254999439632195}),\n",
       " (59, {'cand': 'american eagle', 'score': 0.0010247652455608255}),\n",
       " (60, {'cand': 'cargo', 'score': 0.0010078617432047572}),\n",
       " (61, {'cand': 'facial piercing', 'score': 0.0009784194392239414}),\n",
       " (62, {'cand': 'logo', 'score': 0.0009757749002730276}),\n",
       " (63, {'cand': 'polish', 'score': 0.0009451556649801562}),\n",
       " (64, {'cand': 'watch', 'score': 0.0009385233235125771}),\n",
       " (65, {'cand': 'fake nails', 'score': 0.0008881879933292136}),\n",
       " (66, {'cand': 'knee', 'score': 0.0008847438389718847}),\n",
       " (67, {'cand': 'uniform policy', 'score': 0.0008732520527773586}),\n",
       " (68, {'cand': 'color hair', 'score': 0.000857238177556658}),\n",
       " (69, {'cand': 'unnatural hair', 'score': 0.0008520146328832319}),\n",
       " (70, {'cand': 'band', 'score': 0.0008504575970429245}),\n",
       " (71, {'cand': 'acrylic nails', 'score': 0.0008458846107073174}),\n",
       " (72, {'cand': 'cover', 'score': 0.0008372644892984712}),\n",
       " (73, {'cand': 'gym', 'score': 0.0008280314768908651}),\n",
       " (74, {'cand': 'security', 'score': 0.0008116307263838191}),\n",
       " (75, {'cand': 'food safety', 'score': 0.0008115382349045824}),\n",
       " (76, {'cand': 'weather', 'score': 0.0007926199085525002}),\n",
       " (77, {'cand': 'food', 'score': 0.0007874738807847267}),\n",
       " (78, {'cand': 'unnatural colors', 'score': 0.0007632560470382352}),\n",
       " (79, {'cand': 'safety', 'score': 0.0007623412643285791}),\n",
       " (80, {'cand': 'language', 'score': 0.000705124716421081}),\n",
       " (81, {'cand': 'hygiene', 'score': 0.0006953287563964397}),\n",
       " (82, {'cand': 'tattoo', 'score': 0.0006892843435892012}),\n",
       " (83, {'cand': 'nice', 'score': 0.0006498621058697596}),\n",
       " (84, {'cand': 'drugs', 'score': 0.0006443877412066483}),\n",
       " (85, {'cand': 'cracker barrel', 'score': 0.0006333510294308334}),\n",
       " (86, {'cand': 'chipotle', 'score': 0.0006191268645138962}),\n",
       " (87, {'cand': 'pharmacist', 'score': 0.0005471897039126925}),\n",
       " (88, {'cand': 'drug tests', 'score': 0.0005166507892023749}),\n",
       " (89, {'cand': 'brand', 'score': 0.0004595487440899365}),\n",
       " (90, {'cand': 'pizza hut', 'score': 0.00045419895403409023}),\n",
       " (91, {'cand': 'religious', 'score': 0.0004511023004672416}),\n",
       " (92, {'cand': 'dd', 'score': 0.0003687763602131124}),\n",
       " (93, {'cand': 'professional', 'score': 0.0003300190153477463})]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'microsoft allows jeans, [MASK] and shirts.'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_background_screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company background_screening\n",
      "['walmart', 'amazon', 'subway', 'microsoft', 'target'] ['drug test', 'criminal background check', 'employment verification']\n",
      "97 98\n"
     ]
    }
   ],
   "source": [
    "_r = 'has_background_screening'\n",
    "\n",
    "_r_row = seed_relations_df[seed_relations_df['alignedRelationName'] == _r].iloc[0]\n",
    "_h_type = _r_row['domain']\n",
    "_t_type = _r_row['range']\n",
    "print(_h_type, _t_type)\n",
    "\n",
    "_seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _h_type]['seedInstances'].item()\n",
    "_seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _t_type]['seedInstances'].item()\n",
    "print(_seed_heads, _seed_tails)\n",
    "\n",
    "_cand_heads = ee_df[ee_df['concept'] == _h_type]['neighbor'].tolist()\n",
    "_cand_tails = ee_df[ee_df['concept'] == _t_type]['neighbor'].tolist()\n",
    "print(len(_cand_heads), len(_cand_tails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'social security number', 'score': 0.00967370585243785}),\n",
       " (1, {'cand': 'social media', 'score': 0.006814719668781803}),\n",
       " (2, {'cand': '3rd party', 'score': 0.005623028742419336}),\n",
       " (3, {'cand': 'medical marijuana', 'score': 0.005576631489645706}),\n",
       " (4, {'cand': 'security', 'score': 0.005313690267456273}),\n",
       " (5, {'cand': 'pepsi', 'score': 0.004624428986203844}),\n",
       " (6, {'cand': 'dmv', 'score': 0.004621810069762703}),\n",
       " (7, {'cand': 'criminal history', 'score': 0.004327335073637574}),\n",
       " (8, {'cand': 'prescription drugs', 'score': 0.004281529567134396}),\n",
       " (9, {'cand': 'credit history', 'score': 0.004206326165478303}),\n",
       " (10, {'cand': 'background check', 'score': 0.0037203841976300744}),\n",
       " (11, {'cand': 'information', 'score': 0.003274573554407912}),\n",
       " (12, {'cand': 'criminal record', 'score': 0.003207046246963472}),\n",
       " (13, {'cand': 'driving records', 'score': 0.0031807310871282118}),\n",
       " (14, {'cand': 'red flag', 'score': 0.0031463603404955375}),\n",
       " (15, {'cand': 'results', 'score': 0.003109371997724171}),\n",
       " (16, {'cand': 'walmart', 'score': 0.003095379058551794}),\n",
       " (17, {'cand': 'history', 'score': 0.0030744643852048796}),\n",
       " (18, {'cand': 'potential employees', 'score': 0.002916839755697584}),\n",
       " (19, {'cand': 'checks', 'score': 0.002907011859911744}),\n",
       " (20, {'cand': 'felonies', 'score': 0.0029003257396693037}),\n",
       " (21, {'cand': 'drug tests', 'score': 0.002743406721280758}),\n",
       " (22, {'cand': 'state', 'score': 0.002681114755658727}),\n",
       " (23, {'cand': 'criminal background', 'score': 0.0026540505897481304}),\n",
       " (24, {'cand': 'tests', 'score': 0.0025583863689599743}),\n",
       " (25, {'cand': 'past employment', 'score': 0.0025520055466461506}),\n",
       " (26, {'cand': 'previous experience', 'score': 0.0025464382669770002}),\n",
       " (27, {'cand': 'random drug tests', 'score': 0.0025008284724049082}),\n",
       " (28, {'cand': 'theft', 'score': 0.0024963903974832263}),\n",
       " (29, {'cand': 'urinalysis', 'score': 0.0024391511854421214}),\n",
       " (30, {'cand': 'g4s', 'score': 0.002434901515839761}),\n",
       " (31, {'cand': 'fingerprints', 'score': 0.0024339008950885867}),\n",
       " (32, {'cand': 'previous employment', 'score': 0.002416871293270515}),\n",
       " (33, {'cand': 'mail', 'score': 0.0023897289789853843}),\n",
       " (34, {'cand': 'job description', 'score': 0.0023699496019758503}),\n",
       " (35, {'cand': 'drugs', 'score': 0.002326472339885376}),\n",
       " (36, {'cand': 'credit check', 'score': 0.002126667250291563}),\n",
       " (37, {'cand': 'little caesars', 'score': 0.002096257671112352}),\n",
       " (38, {'cand': 'extensive background check', 'score': 0.0019960450254880423}),\n",
       " (39, {'cand': 'motor vehicle', 'score': 0.001953916751143503}),\n",
       " (40, {'cand': 'credit report', 'score': 0.0018174950744032222}),\n",
       " (41, {'cand': 'application process', 'score': 0.0017941394451664531}),\n",
       " (42, {'cand': 'employment', 'score': 0.001789441998464359}),\n",
       " (43, {'cand': 'driving record', 'score': 0.0017718652983137145}),\n",
       " (44, {'cand': 'ua', 'score': 0.0016869464085611879}),\n",
       " (45, {'cand': 'jcp', 'score': 0.0016827406327039863}),\n",
       " (46, {'cand': 'home depot', 'score': 0.0016757574908223879}),\n",
       " (47, {'cand': 'background screening', 'score': 0.0016562785515210263}),\n",
       " (48, {'cand': 'job offer', 'score': 0.0015955664169463172}),\n",
       " (49, {'cand': 'verizon', 'score': 0.00157399504194833}),\n",
       " (50, {'cand': 'usps', 'score': 0.0014639806667004218}),\n",
       " (51, {'cand': 'home office', 'score': 0.0014292536230352307}),\n",
       " (52, {'cand': 'drivers license', 'score': 0.0014201713454042595}),\n",
       " (53, {'cand': 'test', 'score': 0.0013784135632774954}),\n",
       " (54, {'cand': 'random drug test', 'score': 0.001286734998640447}),\n",
       " (55, {'cand': 'property', 'score': 0.0012671581713833858}),\n",
       " (56, {'cand': 'law', 'score': 0.0011701757922687485}),\n",
       " (57, {'cand': 'bankruptcy', 'score': 0.0011597320324392454}),\n",
       " (58, {'cand': 'finger printing', 'score': 0.0011239924076220378}),\n",
       " (59, {'cand': 'dui', 'score': 0.0011228610270513962}),\n",
       " (60, {'cand': 'private', 'score': 0.0011184466072989118}),\n",
       " (61, {'cand': 'contract', 'score': 0.0010713203997742247}),\n",
       " (62, {'cand': 'general manager', 'score': 0.0010529011338212173}),\n",
       " (63, {'cand': 'report', 'score': 0.0010477380731614494}),\n",
       " (64, {'cand': 'pass', 'score': 0.0010443826454178714}),\n",
       " (65, {'cand': 'back ground', 'score': 0.0009855118047830014}),\n",
       " (66, {'cand': 'paper', 'score': 0.0009818559784877188}),\n",
       " (67, {'cand': 'police', 'score': 0.0009582678881678227}),\n",
       " (68, {'cand': 'company', 'score': 0.0009460367145278799}),\n",
       " (69, {'cand': 'government', 'score': 0.0008877971694216575}),\n",
       " (70, {'cand': 'manager', 'score': 0.0008772954588185362}),\n",
       " (71, {'cand': 'ad', 'score': 0.0008703130684471546}),\n",
       " (72, {'cand': 'tj maxx', 'score': 0.0008527137077670642}),\n",
       " (73, {'cand': 'back round check', 'score': 0.0008511988227820201}),\n",
       " (74, {'cand': 'drug', 'score': 0.0008152301900061761}),\n",
       " (75, {'cand': 'back ground check', 'score': 0.0007847060878695434}),\n",
       " (76, {'cand': 'initial interview', 'score': 0.0007575160651528191}),\n",
       " (77, {'cand': 'criminal back ground', 'score': 0.0007564959680500856}),\n",
       " (78, {'cand': 'military', 'score': 0.0006741176525368865}),\n",
       " (79, {'cand': 'carrier', 'score': 0.000658555429798602}),\n",
       " (80, {'cand': 'county', 'score': 0.0005428348825135364}),\n",
       " (81, {'cand': 'spectrum', 'score': 0.0005424459795952143}),\n",
       " (82, {'cand': 'planet fitness', 'score': 0.0005118676034503209}),\n",
       " (83, {'cand': \"macy 's\", 'score': 0.00047268307833487824}),\n",
       " (84, {'cand': 'ap', 'score': 0.0004639056297638643}),\n",
       " (85, {'cand': 'fed ex', 'score': 0.0004600258182524514}),\n",
       " (86, {'cand': 'wal mart', 'score': 0.0004311870370907757}),\n",
       " (87, {'cand': 'felony', 'score': 0.0004307092680248844}),\n",
       " (88, {'cand': 'center', 'score': 0.00042794352688140837}),\n",
       " (89, {'cand': 'old navy', 'score': 0.0003819739308648887}),\n",
       " (90, {'cand': 'cash office', 'score': 0.0003808354384936823}),\n",
       " (91, {'cand': 'misdemeanor', 'score': 0.0003674984187457757}),\n",
       " (92, {'cand': 'dollar general', 'score': 0.00035350236166430593}),\n",
       " (93, {'cand': 'assessment test', 'score': 0.0003399829186199349}),\n",
       " (94, {'cand': 'dollar generals', 'score': 0.00029902009749857523}),\n",
       " (95, {'cand': 'frito lay', 'score': 0.0002736955852428885}),\n",
       " (96, {'cand': 'pizza hut', 'score': 0.0002462040205972539}),\n",
       " (97, {'cand': 'fir', 'score': 0.0001887947555591427})]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Microsoft \n",
    "_template = 'microsoft checks for [MASK].'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'cand': 'felonies', 'score': 0.01516646935956221}),\n",
       " (1, {'cand': 'prescription drugs', 'score': 0.011885881149477627}),\n",
       " (2, {'cand': 'medical marijuana', 'score': 0.010467892956586459}),\n",
       " (3, {'cand': 'driving records', 'score': 0.010466824834294093}),\n",
       " (4, {'cand': 'criminal history', 'score': 0.009802336845795}),\n",
       " (5, {'cand': 'urinalysis', 'score': 0.00935846962827782}),\n",
       " (6, {'cand': 'social media', 'score': 0.00902758474867163}),\n",
       " (7, {'cand': 'random drug tests', 'score': 0.008979560701904594}),\n",
       " (8, {'cand': 'theft', 'score': 0.008648832614668301}),\n",
       " (9, {'cand': 'social security number', 'score': 0.008124969683677905}),\n",
       " (10, {'cand': 'drugs', 'score': 0.007956045460315156}),\n",
       " (11, {'cand': 'driving record', 'score': 0.007886045868525577}),\n",
       " (12, {'cand': 'criminal record', 'score': 0.00782942356684066}),\n",
       " (13, {'cand': 'drug tests', 'score': 0.007756816207904721}),\n",
       " (14, {'cand': 'background check', 'score': 0.007601147598827872}),\n",
       " (15, {'cand': 'police', 'score': 0.006887225580663118}),\n",
       " (16, {'cand': 'misdemeanor', 'score': 0.006868967323529662}),\n",
       " (17, {'cand': 'property', 'score': 0.006636091713287931}),\n",
       " (18, {'cand': 'motor vehicle', 'score': 0.006608571753837236}),\n",
       " (19, {'cand': 'employment', 'score': 0.006076494727611058}),\n",
       " (20, {'cand': 'extensive background check', 'score': 0.006063227100204413}),\n",
       " (21, {'cand': 'credit history', 'score': 0.005966658622597804}),\n",
       " (22, {'cand': 'criminal background', 'score': 0.005749996778136797}),\n",
       " (23, {'cand': 'drivers license', 'score': 0.005646937359423744}),\n",
       " (24, {'cand': 'fingerprints', 'score': 0.005622623885368902}),\n",
       " (25, {'cand': 'random drug test', 'score': 0.005589908426252751}),\n",
       " (26, {'cand': 'tests', 'score': 0.005498893182708272}),\n",
       " (27, {'cand': 'felony', 'score': 0.0053943892308047255}),\n",
       " (28, {'cand': 'military', 'score': 0.005254764798763203}),\n",
       " (29, {'cand': 'history', 'score': 0.004972431320220852}),\n",
       " (30, {'cand': 'security', 'score': 0.004917714615162396}),\n",
       " (31, {'cand': 'credit check', 'score': 0.004909008500025812}),\n",
       " (32, {'cand': 'information', 'score': 0.004890879807722071}),\n",
       " (33, {'cand': 'past employment', 'score': 0.004797731834912342}),\n",
       " (34, {'cand': 'government', 'score': 0.004744335722013062}),\n",
       " (35, {'cand': 'bankruptcy', 'score': 0.004738816719933733}),\n",
       " (36, {'cand': 'credit report', 'score': 0.004624473088405661}),\n",
       " (37, {'cand': 'potential employees', 'score': 0.004592493057856192}),\n",
       " (38, {'cand': '3rd party', 'score': 0.0045733890479084036}),\n",
       " (39, {'cand': 'drug', 'score': 0.004534967133321074}),\n",
       " (40, {'cand': 'g4s', 'score': 0.0044572543775660955}),\n",
       " (41, {'cand': 'red flag', 'score': 0.004404342809270577}),\n",
       " (42, {'cand': 'dmv', 'score': 0.004382517656853897}),\n",
       " (43, {'cand': 'job offer', 'score': 0.004237402896441049}),\n",
       " (44, {'cand': 'previous employment', 'score': 0.004213422409375921}),\n",
       " (45, {'cand': 'home office', 'score': 0.004174129643599905}),\n",
       " (46, {'cand': 'law', 'score': 0.004147306260325496}),\n",
       " (47, {'cand': 'pepsi', 'score': 0.0041078268965110895}),\n",
       " (48, {'cand': 'background screening', 'score': 0.003942833033160861}),\n",
       " (49, {'cand': 'mail', 'score': 0.003926167520263764}),\n",
       " (50, {'cand': 'test', 'score': 0.0038822030079753637}),\n",
       " (51, {'cand': 'state', 'score': 0.0038218929249553314}),\n",
       " (52, {'cand': 'job description', 'score': 0.0037446606575327226}),\n",
       " (53, {'cand': 'dui', 'score': 0.003727366177452249}),\n",
       " (54, {'cand': 'usps', 'score': 0.0036448903472252507}),\n",
       " (55, {'cand': 'home depot', 'score': 0.0036447860675676825}),\n",
       " (56, {'cand': 'previous experience', 'score': 0.003585208921827212}),\n",
       " (57, {'cand': 'finger printing', 'score': 0.003480741047534669}),\n",
       " (58, {'cand': 'ua', 'score': 0.003451034592224979}),\n",
       " (59, {'cand': 'paper', 'score': 0.0034020834611283605}),\n",
       " (60, {'cand': 'little caesars', 'score': 0.003320253708300868}),\n",
       " (61, {'cand': 'results', 'score': 0.0031984390279156815}),\n",
       " (62, {'cand': 'private', 'score': 0.0031499165630293176}),\n",
       " (63, {'cand': 'walmart', 'score': 0.0031113356648001904}),\n",
       " (64, {'cand': 'pass', 'score': 0.0030756858214800787}),\n",
       " (65, {'cand': 'checks', 'score': 0.0030694312686867686}),\n",
       " (66, {'cand': 'county', 'score': 0.0029903964169197225}),\n",
       " (67, {'cand': 'criminal back ground', 'score': 0.0029271530734767477}),\n",
       " (68, {'cand': 'spectrum', 'score': 0.002921437377945788}),\n",
       " (69, {'cand': 'report', 'score': 0.0029199499794255943}),\n",
       " (70, {'cand': 'contract', 'score': 0.0029036080314243542}),\n",
       " (71, {'cand': 'back ground', 'score': 0.002896708730211002}),\n",
       " (72, {'cand': 'application process', 'score': 0.002712019181125309}),\n",
       " (73, {'cand': 'ad', 'score': 0.0026004551133039966}),\n",
       " (74, {'cand': 'assessment test', 'score': 0.0025305005015761254}),\n",
       " (75, {'cand': 'fir', 'score': 0.002470275494951086}),\n",
       " (76, {'cand': 'dollar general', 'score': 0.0024160750787107633}),\n",
       " (77, {'cand': 'back ground check', 'score': 0.0023236031168260285}),\n",
       " (78, {'cand': 'center', 'score': 0.002272271930293031}),\n",
       " (79, {'cand': 'tj maxx', 'score': 0.0021659054518840116}),\n",
       " (80, {'cand': 'back round check', 'score': 0.0021437843806489895}),\n",
       " (81, {'cand': 'cash office', 'score': 0.0020791977770633543}),\n",
       " (82, {'cand': 'company', 'score': 0.0020109339031655466}),\n",
       " (83, {'cand': 'initial interview', 'score': 0.0019825299065109507}),\n",
       " (84, {'cand': 'carrier', 'score': 0.0018763495395662387}),\n",
       " (85, {'cand': 'planet fitness', 'score': 0.001871482360438834}),\n",
       " (86, {'cand': \"macy 's\", 'score': 0.001852286181480035}),\n",
       " (87, {'cand': 'ap', 'score': 0.0018093055463436441}),\n",
       " (88, {'cand': 'old navy', 'score': 0.0018069087066888893}),\n",
       " (89, {'cand': 'wal mart', 'score': 0.0017952271309371046}),\n",
       " (90, {'cand': 'manager', 'score': 0.0017200896685135411}),\n",
       " (91, {'cand': 'dollar generals', 'score': 0.0017141518312612572}),\n",
       " (92, {'cand': 'frito lay', 'score': 0.0017100820742809119}),\n",
       " (93, {'cand': 'jcp', 'score': 0.0016652842697154635}),\n",
       " (94, {'cand': 'general manager', 'score': 0.0015915459638123}),\n",
       " (95, {'cand': 'verizon', 'score': 0.0014404668324698245}),\n",
       " (96, {'cand': 'fed ex', 'score': 0.001293352052520812}),\n",
       " (97, {'cand': 'pizza hut', 'score': 0.001182992602970833})]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'microsoft checks for drugs, [MASK] and felonies.'\n",
    "_res = lm_probe_gpt2.score_candidates(input_txt=_template, cands=_cand_tails)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMI-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe_pmi = LMProbe_PMI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('skinny jeans', 1.7007861824747987)),\n",
       " (1, ('ripped jeans', 1.6993845223320854)),\n",
       " (2, ('toe shoes', 1.6054258767986518)),\n",
       " (3, ('footwear', 1.5746784908726603)),\n",
       " (4, ('walgreens', 1.2629208308137088)),\n",
       " (5, ('clothing', 1.1406507913653137)),\n",
       " (6, ('food', 1.0607585856806026)),\n",
       " (7, ('chilis', 1.0425372959880317)),\n",
       " (8, ('cotton', 1.0241613351869407)),\n",
       " (9, ('kroger', 0.9855455156929835)),\n",
       " (10, ('drugs', 0.9373130204554361)),\n",
       " (11, ('t shirts', 0.8552137597299598)),\n",
       " (12, ('logos', 0.8480405204208097)),\n",
       " (13, ('flip flops', 0.8030754786973962)),\n",
       " (14, ('body piercings', 0.7505834320845839)),\n",
       " (15, ('cell phones', 0.7472124673710514)),\n",
       " (16, ('menards', 0.7390790543684655)),\n",
       " (17, (\"mcdonald 's\", 0.6566597240635872)),\n",
       " (18, ('casual clothing', 0.6487234682393588)),\n",
       " (19, ('clean shaven', 0.6099347481461752)),\n",
       " (20, ('facial piercings', 0.6082469269685653)),\n",
       " (21, ('casual clothes', 0.5855459290520759)),\n",
       " (22, ('nonslip shoes', 0.5829083852322086)),\n",
       " (23, ('logo', 0.5687275217164505)),\n",
       " (24, ('regular clothes', 0.5584216078311997)),\n",
       " (25, ('american eagle', 0.5466733887046917)),\n",
       " (26, ('facial jewelry', 0.5414531625120684)),\n",
       " (27, ('ear piercings', 0.515696472711916)),\n",
       " (28, ('cracker barrel', 0.514522502106427)),\n",
       " (29, ('colored hair', 0.4761563506076456)),\n",
       " (30, ('publix', 0.46321359160556064)),\n",
       " (31, ('casual wear', 0.4619182474180539)),\n",
       " (32, ('face piercings', 0.4532980753813618)),\n",
       " (33, ('dyed hair', 0.4301880267249967)),\n",
       " (34, ('little caesars', 0.42105390820729216)),\n",
       " (35, ('brand', 0.37841233020558107)),\n",
       " (36, ('gym', 0.3698892314946285)),\n",
       " (37, ('cvs', 0.36697964248946846)),\n",
       " (38, ('scrubs', 0.3655009936703131)),\n",
       " (39, ('leggings', 0.3602138095534215)),\n",
       " (40, ('acrylic nails', 0.28570184597313464)),\n",
       " (41, ('pizza hut', 0.2820508923302487)),\n",
       " (42, ('nose piercings', 0.27737948836063175)),\n",
       " (43, ('pharmacist', 0.2644271636391782)),\n",
       " (44, ('watch', 0.2219973321028874)),\n",
       " (45, ('cap', 0.20975115496025865)),\n",
       " (46, ('visible piercings', 0.1820975517053931)),\n",
       " (47, ('color hair', 0.17776143430593727)),\n",
       " (48, ('strict dress code', 0.12947526826968847)),\n",
       " (49, ('fake nails', 0.10536967683597531)),\n",
       " (50, ('chipotle', 0.06987595112462941)),\n",
       " (51, ('bright colors', 0.06037235851606226)),\n",
       " (52, ('drug tests', 0.0298488158551784)),\n",
       " (53, ('dress codes', -0.012993968680927281)),\n",
       " (54, ('cargo', -0.045120296361332635)),\n",
       " (55, ('clean cut', -0.045876406597864516)),\n",
       " (56, ('tattoo', -0.06722916730707418)),\n",
       " (57, ('caps', -0.07002062370322903)),\n",
       " (58, ('religious', -0.07305990648209004)),\n",
       " (59, ('hygiene', -0.14918319278666736)),\n",
       " (60, ('visible tattoos', -0.19105519538820914)),\n",
       " (61, ('casual dress', -0.28428283229092166)),\n",
       " (62, ('nose rings', -0.33587346915247984)),\n",
       " (63, ('uniform policy', -0.43094624371750534)),\n",
       " (64, ('dd', -0.43859279925911565)),\n",
       " (65, ('dress code', -0.4430727302358868)),\n",
       " (66, ('colorful hair', -0.44636545829775365)),\n",
       " (67, ('facial piercing', -0.48121803364629834)),\n",
       " (68, ('unnatural colors', -0.483405762307866)),\n",
       " (69, ('natural colors', -0.706279515296778)),\n",
       " (70, ('sports', -0.7441519734682291)),\n",
       " (71, ('nice', -0.7749194874403766)),\n",
       " (72, ('cover', -0.7921275210914249)),\n",
       " (73, ('pretty much', -0.8225466242569262)),\n",
       " (74, ('band', -0.8494853230128054)),\n",
       " (75, ('nail polish', -0.8821591664343327)),\n",
       " (76, ('food safety', -0.9217841801383386)),\n",
       " (77, ('unnatural hair', -0.9554172808268024)),\n",
       " (78, ('long', -1.0723212859263125)),\n",
       " (79, ('weather', -1.1353386566657484)),\n",
       " (80, ('old navy', -1.2994440966027394)),\n",
       " (81, ('professional', -1.306914223876026)),\n",
       " (82, ('polish', -1.4719676067088976)),\n",
       " (83, ('ankle', -1.6188382540223873)),\n",
       " (84, ('hair', -1.6458224235675054)),\n",
       " (85, ('security', -1.7852801791459143)),\n",
       " (86, ('short', -1.8398646884749095)),\n",
       " (87, ('skin', -1.9470537423711871)),\n",
       " (88, ('common sense', -2.0646884476344134)),\n",
       " (89, ('knee', -2.1347455901249255)),\n",
       " (90, ('arms', -2.735285651483924)),\n",
       " (91, ('light', -2.8121360994017026)),\n",
       " (92, ('language', -3.0292319515660617)),\n",
       " (93, ('safety', -3.3007745620427125))]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = '[HEAD] allows [TAIL].'\n",
    "_res = []\n",
    "for _t in _cand_tails:\n",
    "    _pmi = lm_probe_pmi.score_candidate_pair(input_txt=_template, head='walmart', tail=_t)\n",
    "    _res.append((_t, _pmi))\n",
    "_res.sort(key=lambda p: p[1], reverse=True)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('clothing', 2.839382282949322)),\n",
       " (1, ('casual clothing', 2.7114202058740293)),\n",
       " (2, ('skinny jeans', 2.6998737773366663)),\n",
       " (3, ('t shirts', 2.4980212564410333)),\n",
       " (4, ('casual clothes', 2.348157078772047)),\n",
       " (5, ('footwear', 2.247782385738841)),\n",
       " (6, ('ripped jeans', 2.0088285198090468)),\n",
       " (7, ('facial jewelry', 1.9817987887398303)),\n",
       " (8, ('brand', 1.9788341990932885)),\n",
       " (9, ('casual wear', 1.950882851612361)),\n",
       " (10, ('food', 1.913408348501651)),\n",
       " (11, ('weather', 1.8836279328446537)),\n",
       " (12, ('cotton', 1.8032085420055193)),\n",
       " (13, ('casual dress', 1.7832829068012988)),\n",
       " (14, ('bright colors', 1.7270256765349714)),\n",
       " (15, ('regular clothes', 1.6546217254208457)),\n",
       " (16, ('colored hair', 1.642594930169631)),\n",
       " (17, ('dyed hair', 1.5812794404145674)),\n",
       " (18, ('natural colors', 1.5811907154970974)),\n",
       " (19, ('dress codes', 1.56775725985516)),\n",
       " (20, ('watch', 1.526584788796617)),\n",
       " (21, ('color hair', 1.5223552029821104)),\n",
       " (22, ('logos', 1.5118594931207578)),\n",
       " (23, ('drugs', 1.482095781640778)),\n",
       " (24, ('unnatural colors', 1.4774801083372857)),\n",
       " (25, ('toe shoes', 1.2925898261333426)),\n",
       " (26, ('logo', 1.1667729124672128)),\n",
       " (27, ('hair', 1.1295286108677356)),\n",
       " (28, ('pizza hut', 1.1202665318089817)),\n",
       " (29, ('nose rings', 1.0931836571865752)),\n",
       " (30, ('dress code', 1.0496477580110524)),\n",
       " (31, ('religious', 1.0400973153581994)),\n",
       " (32, ('chilis', 1.035185549437033)),\n",
       " (33, ('tattoo', 1.0269900569986028)),\n",
       " (34, ('flip flops', 0.9974872597105904)),\n",
       " (35, ('colorful hair', 0.991300664132428)),\n",
       " (36, ('kroger', 0.9836021366598207)),\n",
       " (37, ('cover', 0.9564930323147038)),\n",
       " (38, ('visible tattoos', 0.9527279751551934)),\n",
       " (39, ('cvs', 0.9432308002534704)),\n",
       " (40, ('hygiene', 0.9397364910757595)),\n",
       " (41, ('dd', 0.9269067314469908)),\n",
       " (42, ('walgreens', 0.9141419286888279)),\n",
       " (43, ('cell phones', 0.9063655187631987)),\n",
       " (44, ('sports', 0.8847552712494462)),\n",
       " (45, ('uniform policy', 0.8839663467268872)),\n",
       " (46, ('publix', 0.8743286269278485)),\n",
       " (47, ('gym', 0.8662024944248472)),\n",
       " (48, ('facial piercings', 0.8289129286330903)),\n",
       " (49, ('drug tests', 0.7972973486803188)),\n",
       " (50, ('face piercings', 0.7945250104375443)),\n",
       " (51, ('nice', 0.7869683950533997)),\n",
       " (52, ('visible piercings', 0.7744126644818863)),\n",
       " (53, ('american eagle', 0.7682760724777271)),\n",
       " (54, (\"mcdonald 's\", 0.7356016950310167)),\n",
       " (55, ('menards', 0.6931435355901279)),\n",
       " (56, ('food safety', 0.6898192032931849)),\n",
       " (57, ('band', 0.6370698257897534)),\n",
       " (58, ('cracker barrel', 0.6123596456279259)),\n",
       " (59, ('acrylic nails', 0.601420287735916)),\n",
       " (60, ('nose piercings', 0.5992875556890471)),\n",
       " (61, ('unnatural hair', 0.5954067063118575)),\n",
       " (62, ('cargo', 0.5807830105343825)),\n",
       " (63, ('pretty much', 0.5780592650009666)),\n",
       " (64, ('facial piercing', 0.5774918908404079)),\n",
       " (65, ('fake nails', 0.5676929035659786)),\n",
       " (66, ('little caesars', 0.5634618071075774)),\n",
       " (67, ('body piercings', 0.561834227361329)),\n",
       " (68, ('skin', 0.5604087208244319)),\n",
       " (69, ('leggings', 0.5505700371166711)),\n",
       " (70, ('nonslip shoes', 0.5017266540099978)),\n",
       " (71, ('clean shaven', 0.4783436441910247)),\n",
       " (72, ('ear piercings', 0.47429169091438794)),\n",
       " (73, ('scrubs', 0.3473808157251437)),\n",
       " (74, ('clean cut', 0.2566520050892862)),\n",
       " (75, ('chipotle', 0.2225064817275495)),\n",
       " (76, ('long', 0.1585875282971312)),\n",
       " (77, ('arms', 0.08384137964054084)),\n",
       " (78, ('caps', 0.04418916043405474)),\n",
       " (79, ('security', 0.0007382901992301072)),\n",
       " (80, ('professional', -0.04498851437363527)),\n",
       " (81, ('light', -0.05023173773872003)),\n",
       " (82, ('nail polish', -0.10826525794623443)),\n",
       " (83, ('short', -0.10869966288481514)),\n",
       " (84, ('pharmacist', -0.14318836518198097)),\n",
       " (85, ('cap', -0.1719788841465153)),\n",
       " (86, ('ankle', -0.2237863083768179)),\n",
       " (87, ('polish', -0.28420823206748125)),\n",
       " (88, ('knee', -0.30090141418701144)),\n",
       " (89, ('strict dress code', -0.39079918545451964)),\n",
       " (90, ('old navy', -0.4895151766273038)),\n",
       " (91, ('safety', -0.5517538832617781)),\n",
       " (92, ('language', -0.6044440020035999)),\n",
       " (93, ('common sense', -0.9091599805205881))]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = '[HEAD] allows dress code [TAIL].'\n",
    "_res = []\n",
    "for _t in _cand_tails:\n",
    "    _pmi = lm_probe_pmi.score_candidate_pair(input_txt=_template, head='walmart', tail=_t)\n",
    "    _res.append((_t, _pmi))\n",
    "_res.sort(key=lambda p: p[1], reverse=True)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('cap', 1.8354876631325787)),\n",
       " (1, ('caps', 1.707747239455344)),\n",
       " (2, ('publix', 1.6758239729029611)),\n",
       " (3, ('logos', 1.668547425072024)),\n",
       " (4, ('logo', 1.666601080505222)),\n",
       " (5, ('flip flops', 1.3733281777299897)),\n",
       " (6, ('walgreens', 1.3654359143761834)),\n",
       " (7, ('kroger', 1.256029700606529)),\n",
       " (8, ('chipotle', 1.23321206797557)),\n",
       " (9, ('cvs', 1.1247991124453485)),\n",
       " (10, ('clean shaven', 0.9918629326613946)),\n",
       " (11, ('t shirts', 0.9024144092564246)),\n",
       " (12, ('dd', 0.8902223730000021)),\n",
       " (13, (\"mcdonald 's\", 0.8179853290218908)),\n",
       " (14, ('pharmacist', 0.8069473747021867)),\n",
       " (15, ('strict dress code', 0.803854084518866)),\n",
       " (16, ('scrubs', 0.7737434868954356)),\n",
       " (17, ('leggings', 0.7088003146637458)),\n",
       " (18, ('chilis', 0.6796830440020738)),\n",
       " (19, ('nonslip shoes', 0.6422482602655784)),\n",
       " (20, ('cracker barrel', 0.4757341749201007)),\n",
       " (21, ('face piercings', 0.38605877757896856)),\n",
       " (22, ('acrylic nails', 0.3774815865780621)),\n",
       " (23, ('american eagle', 0.3289561379208763)),\n",
       " (24, ('body piercings', 0.27187501226061883)),\n",
       " (25, ('ear piercings', 0.24831705954293248)),\n",
       " (26, ('facial piercings', 0.21279772703280564)),\n",
       " (27, ('cell phones', 0.20783001790406885)),\n",
       " (28, ('little caesars', 0.19949779305221327)),\n",
       " (29, ('professional', 0.16941438546441567)),\n",
       " (30, ('dress code', 0.10682582301280164)),\n",
       " (31, ('bright colors', 0.10194823092147232)),\n",
       " (32, ('nose piercings', 0.09487403711970543)),\n",
       " (33, ('cotton', 0.03472027212311346)),\n",
       " (34, ('natural colors', 0.018953347134061715)),\n",
       " (35, ('visible piercings', 0.0024292714117066794)),\n",
       " (36, ('security', -0.008559960675777134)),\n",
       " (37, ('fake nails', -0.012869870384076165)),\n",
       " (38, ('uniform policy', -0.13960248044178059)),\n",
       " (39, ('dress codes', -0.1486101125930066)),\n",
       " (40, ('drug tests', -0.1690538282634666)),\n",
       " (41, ('unnatural colors', -0.20601366662580034)),\n",
       " (42, ('clean cut', -0.25822332497362055)),\n",
       " (43, ('nail polish', -0.3077039355145921)),\n",
       " (44, ('menards', -0.32291055557490544)),\n",
       " (45, ('ripped jeans', -0.3409864328457246)),\n",
       " (46, ('skinny jeans', -0.347934973103623)),\n",
       " (47, ('pretty much', -0.38520665448978164)),\n",
       " (48, ('common sense', -0.39900187507682894)),\n",
       " (49, ('visible tattoos', -0.4000325237876794)),\n",
       " (50, ('nose rings', -0.42543175850097015)),\n",
       " (51, ('dyed hair', -0.4772422900001132)),\n",
       " (52, ('pizza hut', -0.49660949156983136)),\n",
       " (53, ('brand', -0.5737839993008986)),\n",
       " (54, ('color hair', -0.5878515815501082)),\n",
       " (55, ('polish', -0.5924866176011285)),\n",
       " (56, ('facial jewelry', -0.6379837746823007)),\n",
       " (57, ('tattoo', -0.6910240705577113)),\n",
       " (58, ('casual wear', -0.7943315996366742)),\n",
       " (59, ('watch', -0.8433039034676568)),\n",
       " (60, ('colored hair', -0.8647053848736022)),\n",
       " (61, ('toe shoes', -0.8877529929441632)),\n",
       " (62, ('regular clothes', -0.9087366755456525)),\n",
       " (63, ('colorful hair', -0.9173787051181304)),\n",
       " (64, ('old navy', -0.9337761518663328)),\n",
       " (65, ('nice', -1.1589987127955776)),\n",
       " (66, ('casual clothes', -1.1612999475976977)),\n",
       " (67, ('casual dress', -1.1665382753755402)),\n",
       " (68, ('band', -1.1933882117362398)),\n",
       " (69, ('short', -1.206572718548479)),\n",
       " (70, ('casual clothing', -1.2510551016160978)),\n",
       " (71, ('footwear', -1.314065003284945)),\n",
       " (72, ('religious', -1.3181259147152655)),\n",
       " (73, ('cover', -1.3674651522590207)),\n",
       " (74, ('facial piercing', -1.3768531882457467)),\n",
       " (75, ('long', -1.4243255846368914)),\n",
       " (76, ('unnatural hair', -1.4411795262234897)),\n",
       " (77, ('language', -1.6348865008718994)),\n",
       " (78, ('weather', -1.7176195359158761)),\n",
       " (79, ('food safety', -1.915416219949348)),\n",
       " (80, ('gym', -2.0002509845435537)),\n",
       " (81, ('ankle', -2.0115835339573405)),\n",
       " (82, ('knee', -2.089531057318185)),\n",
       " (83, ('hair', -2.385595424654829)),\n",
       " (84, ('sports', -2.395166533028272)),\n",
       " (85, ('clothing', -2.396186071571588)),\n",
       " (86, ('cargo', -2.484575417039558)),\n",
       " (87, ('safety', -2.5855514536607647)),\n",
       " (88, ('skin', -2.6387187250052015)),\n",
       " (89, ('arms', -2.783301427317742)),\n",
       " (90, ('drugs', -2.931168260566647)),\n",
       " (91, ('light', -3.189393228391249)),\n",
       " (92, ('hygiene', -3.3674194118496352)),\n",
       " (93, ('food', -3.559955271640348))]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = '[HEAD] allows [TAIL].'\n",
    "_res = []\n",
    "for _t in _cand_tails:\n",
    "    _pmi = lm_probe_pmi.score_candidate_pair(input_txt=_template, head='microsoft', tail=_t)\n",
    "    _res.append((_t, _pmi))\n",
    "_res.sort(key=lambda p: p[1], reverse=True)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('brand', 3.3570923076434482)),\n",
       " (1, ('weather', 2.5939279146985488)),\n",
       " (2, ('professional', 1.8889908937316182)),\n",
       " (3, ('security', 1.819708254432995)),\n",
       " (4, ('dd', 1.5471662294419346)),\n",
       " (5, ('pretty much', 1.4610388439833581)),\n",
       " (6, ('cell phones', 1.4162957518953014)),\n",
       " (7, ('logo', 1.4054664955015994)),\n",
       " (8, ('cargo', 1.3759941875578487)),\n",
       " (9, ('bright colors', 1.2964571219129954)),\n",
       " (10, ('chipotle', 1.229967249658598)),\n",
       " (11, ('watch', 1.1556858305979514)),\n",
       " (12, ('nice', 1.062043640044811)),\n",
       " (13, ('logos', 1.0234360949811077)),\n",
       " (14, ('polish', 0.9666419124743548)),\n",
       " (15, ('natural colors', 0.8952257936140668)),\n",
       " (16, ('kroger', 0.8834695666335985)),\n",
       " (17, ('flip flops', 0.8453092605796702)),\n",
       " (18, ('cvs', 0.8054650053453969)),\n",
       " (19, ('pizza hut', 0.753401510947791)),\n",
       " (20, ('language', 0.6543601791398963)),\n",
       " (21, ('band', 0.6068158272919639)),\n",
       " (22, ('t shirts', 0.5511307777824772)),\n",
       " (23, ('walgreens', 0.5000878910095068)),\n",
       " (24, ('facial jewelry', 0.49054453303066303)),\n",
       " (25, ('safety', 0.4764709744101907)),\n",
       " (26, ('publix', 0.3993018799335566)),\n",
       " (27, ('chilis', 0.3933985895861518)),\n",
       " (28, ('unnatural colors', 0.38745949221008935)),\n",
       " (29, ('cotton', 0.3739590210617685)),\n",
       " (30, ('cover', 0.30028198939441886)),\n",
       " (31, ('acrylic nails', 0.28135707851426517)),\n",
       " (32, ('fake nails', 0.2256648891128954)),\n",
       " (33, ('leggings', 0.2119420293391734)),\n",
       " (34, ('casual wear', 0.18383795331907749)),\n",
       " (35, ('clothing', 0.1817507284611981)),\n",
       " (36, ('scrubs', 0.17181659064209498)),\n",
       " (37, ('menards', 0.16951586287142106)),\n",
       " (38, ('nonslip shoes', 0.16505664022096056)),\n",
       " (39, ('casual clothes', 0.16028308938232527)),\n",
       " (40, ('long', 0.15777051886005822)),\n",
       " (41, ('skin', 0.12356134039658606)),\n",
       " (42, ('uniform policy', 0.12348887099749284)),\n",
       " (43, ('casual clothing', 0.09965187989162416)),\n",
       " (44, ('cracker barrel', 0.010986794596419713)),\n",
       " (45, ('visible tattoos', -0.003971081882641059)),\n",
       " (46, ('face piercings', -0.017789849501140154)),\n",
       " (47, ('facial piercings', -0.024201368926503264)),\n",
       " (48, ('religious', -0.03809122985657254)),\n",
       " (49, ('light', -0.043437527257424335)),\n",
       " (50, ('regular clothes', -0.07044750130106259)),\n",
       " (51, ('drug tests', -0.07288763270296172)),\n",
       " (52, ('skinny jeans', -0.07365200835015351)),\n",
       " (53, ('visible piercings', -0.07570108361297123)),\n",
       " (54, ('arms', -0.07708120524425865)),\n",
       " (55, ('clean shaven', -0.12092349992840212)),\n",
       " (56, (\"mcdonald 's\", -0.1482612476930143)),\n",
       " (57, ('nose rings', -0.15013911194488294)),\n",
       " (58, ('little caesars', -0.18698276977807282)),\n",
       " (59, ('nail polish', -0.2100955631556527)),\n",
       " (60, ('sports', -0.24459121060383815)),\n",
       " (61, ('cap', -0.24676183488364956)),\n",
       " (62, ('ear piercings', -0.2613125031047865)),\n",
       " (63, ('dress codes', -0.28829955856608525)),\n",
       " (64, ('short', -0.29715204618789315)),\n",
       " (65, ('hygiene', -0.30118414614555356)),\n",
       " (66, ('ripped jeans', -0.30470919980736433)),\n",
       " (67, ('color hair', -0.30782918517263624)),\n",
       " (68, ('dress code', -0.31057451677548187)),\n",
       " (69, ('tattoo', -0.3214659097954975)),\n",
       " (70, ('gym', -0.325780352007941)),\n",
       " (71, ('american eagle', -0.3521607518996266)),\n",
       " (72, ('facial piercing', -0.4078342796376617)),\n",
       " (73, ('casual dress', -0.43250744587883005)),\n",
       " (74, ('footwear', -0.4357202114150631)),\n",
       " (75, ('colored hair', -0.46834161354428616)),\n",
       " (76, ('nose piercings', -0.47489866190660734)),\n",
       " (77, ('old navy', -0.49432395960432274)),\n",
       " (78, ('dyed hair', -0.5276892841184075)),\n",
       " (79, ('pharmacist', -0.5296400576091944)),\n",
       " (80, ('body piercings', -0.5389006832430443)),\n",
       " (81, ('caps', -0.5572242753897108)),\n",
       " (82, ('knee', -0.7076763977111753)),\n",
       " (83, ('strict dress code', -0.7632387747881246)),\n",
       " (84, ('common sense', -0.78532667885462)),\n",
       " (85, ('toe shoes', -0.8165848722207514)),\n",
       " (86, ('food safety', -0.8166401404907191)),\n",
       " (87, ('hair', -0.9416356348565031)),\n",
       " (88, ('colorful hair', -0.9629057293006653)),\n",
       " (89, ('clean cut', -0.9795489379322024)),\n",
       " (90, ('food', -1.317024718455274)),\n",
       " (91, ('unnatural hair', -1.3865440993923457)),\n",
       " (92, ('ankle', -1.4960255313170077)),\n",
       " (93, ('drugs', -1.9803691011172475))]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = '[HEAD] allows dress code [TAIL].'\n",
    "_res = []\n",
    "for _t in _cand_tails:\n",
    "    _pmi = lm_probe_pmi.score_candidate_pair(input_txt=_template, head='microsoft', tail=_t)\n",
    "    _res.append((_t, _pmi))\n",
    "_res.sort(key=lambda p: p[1], reverse=True)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('brand', 2.836499242328607)),\n",
       " (1, ('gym', 2.0836396393135566)),\n",
       " (2, ('clothing', 1.989636515387236)),\n",
       " (3, ('polish', 1.4944544274602016)),\n",
       " (4, ('logos', 1.1038919461611947)),\n",
       " (5, ('ripped jeans', 0.7089294700635325)),\n",
       " (6, ('food', 0.6784839985753788)),\n",
       " (7, ('dyed hair', 0.6750289119839437)),\n",
       " (8, ('logo', 0.6096959703662908)),\n",
       " (9, ('professional', 0.6000085476653769)),\n",
       " (10, ('skinny jeans', 0.554691466100742)),\n",
       " (11, ('cotton', 0.5087695812951498)),\n",
       " (12, ('long', 0.4946422066865832)),\n",
       " (13, ('toe shoes', 0.4897722315410675)),\n",
       " (14, ('watch', 0.4710102486487546)),\n",
       " (15, ('pretty much', 0.4091548613211806)),\n",
       " (16, ('nice', 0.36440043935617794)),\n",
       " (17, ('casual wear', 0.3626817908491802)),\n",
       " (18, ('ankle', 0.311855853140921)),\n",
       " (19, ('skin', 0.2848392226589773)),\n",
       " (20, ('t shirts', 0.2535049107879921)),\n",
       " (21, ('tattoo', 0.24953514533054566)),\n",
       " (22, ('casual clothing', 0.20594327763005538)),\n",
       " (23, ('casual dress', 0.14932458134851956)),\n",
       " (24, ('band', 0.14142856476581223)),\n",
       " (25, ('casual clothes', -0.0020062046426474467)),\n",
       " (26, ('hygiene', -0.06260909448289453)),\n",
       " (27, ('sports', -0.16678277398523278)),\n",
       " (28, ('short', -0.2007503242752371)),\n",
       " (29, ('bright colors', -0.21437868604675536)),\n",
       " (30, ('colored hair', -0.2147289512585111)),\n",
       " (31, ('clean cut', -0.24130307777151394)),\n",
       " (32, ('weather', -0.28216981276630904)),\n",
       " (33, ('hair', -0.2937073349099304)),\n",
       " (34, ('regular clothes', -0.3252341107903334)),\n",
       " (35, ('safety', -0.3621287539350053)),\n",
       " (36, ('footwear', -0.3899062171499956)),\n",
       " (37, ('visible tattoos', -0.4672104279576015)),\n",
       " (38, ('dress codes', -0.5487673961362365)),\n",
       " (39, ('nail polish', -0.5734506700589801)),\n",
       " (40, ('menards', -0.629385146001308)),\n",
       " (41, ('nonslip shoes', -0.6343964188326012)),\n",
       " (42, ('color hair', -0.6476665966467241)),\n",
       " (43, ('unnatural colors', -0.704103828668714)),\n",
       " (44, ('uniform policy', -0.7054093510109549)),\n",
       " (45, ('acrylic nails', -0.7326940938844331)),\n",
       " (46, ('dress code', -0.758461061267484)),\n",
       " (47, ('colorful hair', -0.8160377466242359)),\n",
       " (48, ('cover', -0.8618044129190103)),\n",
       " (49, ('cargo', -0.8641041794062101)),\n",
       " (50, ('nose rings', -0.8834265364110472)),\n",
       " (51, ('natural colors', -0.8940464157478907)),\n",
       " (52, ('unnatural hair', -0.8984988822463151)),\n",
       " (53, ('chipotle', -0.9577521608424817)),\n",
       " (54, ('religious', -1.0029883335259147)),\n",
       " (55, (\"mcdonald 's\", -1.005748756549206)),\n",
       " (56, ('drugs', -1.0706085638839404)),\n",
       " (57, ('arms', -1.0734305811194709)),\n",
       " (58, ('food safety', -1.1222370018519463)),\n",
       " (59, ('knee', -1.2343754301527454)),\n",
       " (60, ('facial jewelry', -1.2790416121817465)),\n",
       " (61, ('security', -1.2943782941973208)),\n",
       " (62, ('fake nails', -1.3284132867353797)),\n",
       " (63, ('strict dress code', -1.3779661226549784)),\n",
       " (64, ('caps', -1.4214452689157469)),\n",
       " (65, ('pizza hut', -1.4548357869491433)),\n",
       " (66, ('old navy', -1.505082665347528)),\n",
       " (67, ('facial piercing', -1.5351809191104238)),\n",
       " (68, ('flip flops', -1.5421454087869169)),\n",
       " (69, ('pharmacist', -1.5506594484825111)),\n",
       " (70, ('nose piercings', -1.5646886453361777)),\n",
       " (71, ('little caesars', -1.5882256140129343)),\n",
       " (72, ('american eagle', -1.6229542522053837)),\n",
       " (73, ('body piercings', -1.6394621075904023)),\n",
       " (74, ('dd', -1.7538198810070043)),\n",
       " (75, ('face piercings', -1.7575597162718122)),\n",
       " (76, ('light', -1.7813900842041601)),\n",
       " (77, ('ear piercings', -1.7979103447175895)),\n",
       " (78, ('visible piercings', -1.7982757487499077)),\n",
       " (79, ('kroger', -1.8258644536991575)),\n",
       " (80, ('drug tests', -1.8592482433556254)),\n",
       " (81, ('clean shaven', -1.910995547666971)),\n",
       " (82, ('cap', -1.9146899559216415)),\n",
       " (83, ('facial piercings', -1.923106934722096)),\n",
       " (84, ('cell phones', -2.0800984318708498)),\n",
       " (85, ('cracker barrel', -2.0850879138547658)),\n",
       " (86, ('walgreens', -2.222146729406427)),\n",
       " (87, ('language', -2.2366041341391725)),\n",
       " (88, ('publix', -2.3407053382301584)),\n",
       " (89, ('common sense', -2.42313683854335)),\n",
       " (90, ('chilis', -2.44256696342031)),\n",
       " (91, ('leggings', -2.5608473829351004)),\n",
       " (92, ('cvs', -3.094843028997647)),\n",
       " (93, ('scrubs', -3.3357695458334886))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To generate prompts? (not working: high-PMI prompts not ruling out \"close\" wrong entities)\n",
    "\n",
    "_template = 'microsoft allows [HEAD] [TAIL].'\n",
    "_res = []\n",
    "\n",
    "for _t in _cand_tails:\n",
    "    _pmi = lm_probe_pmi.score_candidate_pair(input_txt=_template, head='jeans', tail=_t)\n",
    "    _res.append((_t, _pmi))\n",
    "_res.sort(key=lambda p: p[1], reverse=True)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('casual wear', 1.674703276385717)),\n",
       " (1, ('casual dress', 1.5428160622004299)),\n",
       " (2, ('casual clothing', 1.4830445215717383)),\n",
       " (3, ('casual clothes', 1.3942031134928747)),\n",
       " (4, ('nice', 1.0670218352365133)),\n",
       " (5, ('professional', 0.6009544473080837)),\n",
       " (6, ('sports', 0.5757313147716605)),\n",
       " (7, ('clothing', 0.49017770176774)),\n",
       " (8, ('brand', 0.32945999320439157)),\n",
       " (9, ('watch', -0.3176078460514322)),\n",
       " (10, ('logos', -0.31877757536699747)),\n",
       " (11, ('long', -0.36164522460447657)),\n",
       " (12, ('uniform policy', -0.3968619276385592)),\n",
       " (13, ('pretty much', -0.4295946856411206)),\n",
       " (14, ('cvs', -0.8067561968759858)),\n",
       " (15, ('clean cut', -0.9098555061384843)),\n",
       " (16, ('skin', -0.9939743048209415)),\n",
       " (17, ('gym', -1.0554833061261242)),\n",
       " (18, ('american eagle', -1.0584207603115594)),\n",
       " (19, ('drugs', -1.1603808805664215)),\n",
       " (20, ('cotton', -1.1689905805022232)),\n",
       " (21, ('ripped jeans', -1.2244442556977617)),\n",
       " (22, ('nonslip shoes', -1.2359739874603903)),\n",
       " (23, ('menards', -1.2372464260858855)),\n",
       " (24, ('chipotle', -1.2645615968710544)),\n",
       " (25, ('cover', -1.3184027625239452)),\n",
       " (26, ('little caesars', -1.3186641658179994)),\n",
       " (27, (\"mcdonald 's\", -1.3271932287120158)),\n",
       " (28, ('acrylic nails', -1.3394941902646273)),\n",
       " (29, ('security', -1.3536324274218634)),\n",
       " (30, ('pizza hut', -1.3739859664527323)),\n",
       " (31, ('skinny jeans', -1.3918989779896371)),\n",
       " (32, ('hygiene', -1.3998255112450675)),\n",
       " (33, ('short', -1.407715302164183)),\n",
       " (34, ('dress codes', -1.4411648963341612)),\n",
       " (35, ('dress code', -1.4460548462654046)),\n",
       " (36, ('strict dress code', -1.4578174780926076)),\n",
       " (37, ('flip flops', -1.4964200262229443)),\n",
       " (38, ('t shirts', -1.545524910036832)),\n",
       " (39, ('cargo', -1.599661325767455)),\n",
       " (40, ('clean shaven', -1.611897421216094)),\n",
       " (41, ('fake nails', -1.625783404483176)),\n",
       " (42, ('kroger', -1.649821792566664)),\n",
       " (43, ('language', -1.6902207216736693)),\n",
       " (44, ('bright colors', -1.7179128209597465)),\n",
       " (45, ('chilis', -1.7462254904264682)),\n",
       " (46, ('regular clothes', -1.7874420357192466)),\n",
       " (47, ('ear piercings', -1.8142766036704625)),\n",
       " (48, ('hair', -1.8161272577461798)),\n",
       " (49, ('food safety', -1.882984751096302)),\n",
       " (50, ('cell phones', -1.8943699682584878)),\n",
       " (51, ('cracker barrel', -1.9883516853440142)),\n",
       " (52, ('common sense', -2.069409253593415)),\n",
       " (53, ('facial jewelry', -2.138272473408721)),\n",
       " (54, ('visible tattoos', -2.173490641029556)),\n",
       " (55, ('toe shoes', -2.2335425612390907)),\n",
       " (56, ('drug tests', -2.2401889911595045)),\n",
       " (57, ('facial piercings', -2.269933309487387)),\n",
       " (58, ('facial piercing', -2.278817787931411)),\n",
       " (59, ('scrubs', -2.2821947641026945)),\n",
       " (60, ('pharmacist', -2.2849932368670114)),\n",
       " (61, ('nail polish', -2.2911764070216325)),\n",
       " (62, ('arms', -2.359081244149264)),\n",
       " (63, ('old navy', -2.3677428222522074)),\n",
       " (64, ('color hair', -2.3965452754635503)),\n",
       " (65, ('walgreens', -2.3993327351446574)),\n",
       " (66, ('safety', -2.4459548600411107)),\n",
       " (67, ('body piercings', -2.4569448273146577)),\n",
       " (68, ('visible piercings', -2.4672787353847276)),\n",
       " (69, ('face piercings', -2.4718347246005496)),\n",
       " (70, ('publix', -2.482005167329019)),\n",
       " (71, ('nose piercings', -2.4844661494334606)),\n",
       " (72, ('weather', -2.4988261405160372)),\n",
       " (73, ('colored hair', -2.571099203151144)),\n",
       " (74, ('logo', -2.599314235865906)),\n",
       " (75, ('footwear', -2.649147436898266)),\n",
       " (76, ('nose rings', -2.6831119595959336)),\n",
       " (77, ('leggings', -2.712090099195822)),\n",
       " (78, ('food', -2.8092422777853514)),\n",
       " (79, ('light', -2.8245478245079525)),\n",
       " (80, ('religious', -2.8265480186709944)),\n",
       " (81, ('dyed hair', -2.8458822941701367)),\n",
       " (82, ('tattoo', -2.8662972986553505)),\n",
       " (83, ('colorful hair', -2.8729418562006455)),\n",
       " (84, ('cap', -2.9658966106038633)),\n",
       " (85, ('polish', -2.9908948310259724)),\n",
       " (86, ('band', -3.0682020822230704)),\n",
       " (87, ('unnatural hair', -3.1083696913461765)),\n",
       " (88, ('natural colors', -3.1958657876015337)),\n",
       " (89, ('unnatural colors', -3.275835630906661)),\n",
       " (90, ('caps', -3.551824170309141)),\n",
       " (91, ('dd', -3.5976548534190016)),\n",
       " (92, ('knee', -3.6775365048361763)),\n",
       " (93, ('ankle', -3.9233106761577385))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = 'microsoft allows [HEAD] [TAIL].'\n",
    "_res = []\n",
    "\n",
    "for _t in _cand_tails:\n",
    "    _pmi = lm_probe_pmi.score_candidate_pair(input_txt=_template, head='business casual', tail=_t)\n",
    "    _res.append((_t, _pmi))\n",
    "_res.sort(key=lambda p: p[1], reverse=True)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('dd', 3.4354041911906847)),\n",
       " (1, ('logo', 3.218013248069047)),\n",
       " (2, ('cell phones', 3.0525003706881026)),\n",
       " (3, ('tattoo', 2.866432679182555)),\n",
       " (4, ('logos', 2.774819810578707)),\n",
       " (5, ('brand', 2.638744791655915)),\n",
       " (6, ('publix', 2.572774862079383)),\n",
       " (7, ('kroger', 2.5235999124554507)),\n",
       " (8, ('chipotle', 2.4866423469629577)),\n",
       " (9, ('walgreens', 2.460500894906213)),\n",
       " (10, ('flip flops', 2.3273731935258937)),\n",
       " (11, ('casual clothing', 2.1134527127540164)),\n",
       " (12, ('fake nails', 1.9733734444249844)),\n",
       " (13, ('band', 1.9603933558273994)),\n",
       " (14, ('facial jewelry', 1.9083648274721394)),\n",
       " (15, ('facial piercings', 1.8699574963509278)),\n",
       " (16, ('face piercings', 1.858510538621287)),\n",
       " (17, ('strict dress code', 1.8192156140435465)),\n",
       " (18, ('visible tattoos', 1.8170276819736113)),\n",
       " (19, ('pizza hut', 1.8047631043589938)),\n",
       " (20, ('skinny jeans', 1.7926869884214334)),\n",
       " (21, ('natural colors', 1.7770176991835456)),\n",
       " (22, ('body piercings', 1.7397680559165103)),\n",
       " (23, ('casual wear', 1.6851771636347443)),\n",
       " (24, ('ear piercings', 1.6723148552203124)),\n",
       " (25, ('colored hair', 1.6339427020283495)),\n",
       " (26, ('dyed hair', 1.6287857000204902)),\n",
       " (27, ('dress code', 1.608608034124929)),\n",
       " (28, ('casual clothes', 1.5623078952817329)),\n",
       " (29, ('visible piercings', 1.5560479420817313)),\n",
       " (30, ('pharmacist', 1.554892135724847)),\n",
       " (31, ('professional', 1.554125754457023)),\n",
       " (32, ('bright colors', 1.5483246850984198)),\n",
       " (33, ('casual dress', 1.529414750237013)),\n",
       " (34, ('facial piercing', 1.515394295850573)),\n",
       " (35, ('nonslip shoes', 1.4311133196107502)),\n",
       " (36, ('t shirts', 1.4086363542276512)),\n",
       " (37, ('cracker barrel', 1.406352505075061)),\n",
       " (38, ('little caesars', 1.4032863297625955)),\n",
       " (39, ('leggings', 1.4029143016332508)),\n",
       " (40, (\"mcdonald 's\", 1.4027362453048724)),\n",
       " (41, ('american eagle', 1.4014853104581437)),\n",
       " (42, ('scrubs', 1.3913444620281634)),\n",
       " (43, ('language', 1.3608774318079266)),\n",
       " (44, ('cvs', 1.3403348349515305)),\n",
       " (45, ('colorful hair', 1.312356757958561)),\n",
       " (46, ('regular clothes', 1.3085936449377638)),\n",
       " (47, ('sports', 1.3042653936551423)),\n",
       " (48, ('ripped jeans', 1.294154270752621)),\n",
       " (49, ('acrylic nails', 1.292066617462675)),\n",
       " (50, ('clean cut', 1.255519161367074)),\n",
       " (51, ('cotton', 1.246590508789013)),\n",
       " (52, ('dress codes', 1.2323451146814381)),\n",
       " (53, ('common sense', 1.2174044373553983)),\n",
       " (54, ('watch', 1.1442418101746412)),\n",
       " (55, ('clean shaven', 1.1165358042822895)),\n",
       " (56, ('color hair', 1.0478293456459813)),\n",
       " (57, ('nose piercings', 1.033214937882308)),\n",
       " (58, ('polish', 1.0303563560076388)),\n",
       " (59, ('drug tests', 0.9714087179135049)),\n",
       " (60, ('nail polish', 0.95661194606447)),\n",
       " (61, ('unnatural hair', 0.9267134703475488)),\n",
       " (62, ('unnatural colors', 0.9088359380487869)),\n",
       " (63, ('weather', 0.8827013441237668)),\n",
       " (64, ('clothing', 0.8086829268162594)),\n",
       " (65, ('footwear', 0.7811587431826101)),\n",
       " (66, ('uniform policy', 0.715203021119132)),\n",
       " (67, ('security', 0.5151433391422042)),\n",
       " (68, ('nose rings', 0.5067680656386724)),\n",
       " (69, ('hair', 0.4353197925420442)),\n",
       " (70, ('old navy', 0.4029639653085475)),\n",
       " (71, ('chilis', 0.38064660768452896)),\n",
       " (72, ('gym', 0.31648010057392284)),\n",
       " (73, ('religious', 0.31050821665568584)),\n",
       " (74, ('knee', 0.2909768861727233)),\n",
       " (75, ('safety', 0.2814530887464066)),\n",
       " (76, ('cover', 0.26095149646005567)),\n",
       " (77, ('toe shoes', 0.17540774776540857)),\n",
       " (78, ('ankle', 0.12505768707076115)),\n",
       " (79, ('arms', -0.10988189445176921)),\n",
       " (80, ('food safety', -0.18025056165693876)),\n",
       " (81, ('short', -0.21246651220662116)),\n",
       " (82, ('skin', -0.24825006175230335)),\n",
       " (83, ('caps', -0.3363700683474402)),\n",
       " (84, ('food', -0.3437081338851531)),\n",
       " (85, ('pretty much', -0.37842981077518445)),\n",
       " (86, ('nice', -0.5443511233869414)),\n",
       " (87, ('cap', -0.5628524014368832)),\n",
       " (88, ('long', -0.5678142048464396)),\n",
       " (89, ('hygiene', -0.6990533217678898)),\n",
       " (90, ('cargo', -0.8605300095721251)),\n",
       " (91, ('drugs', -1.1839365744789827)),\n",
       " (92, ('light', -1.2287803693313908)),\n",
       " (93, ('menards', -1.2297115139046095))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_template = '[HEAD] allows [TAIL] clothing.'\n",
    "_res = []\n",
    "for _t in _cand_tails:\n",
    "    _pmi = lm_probe_pmi.score_candidate_pair(input_txt=_template, head='microsoft', tail=_t)\n",
    "    _res.append((_t, _pmi))\n",
    "_res.sort(key=lambda p: p[1], reverse=True)\n",
    "list(enumerate(_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM correlation-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')\n",
    "\n",
    "# with open(corpus_path, 'r') as f:\n",
    "#     sent_dicts = [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_file_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sent_segmentation.txt')\n",
    "# ent_freq, dedup_context = get_masked_contexts(input_file_path)\n",
    "\n",
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')\n",
    "embed_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "\n",
    "entities, dedup_context = get_masked_contexts(corpus_path, embed_num_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8064, 8064, 7921)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities), len(set(entities)), len(dedup_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2372, 4132, 1144, 314, 55]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ents_tokenized = [tuple(lm_probe.tokenizer.tokenize(e)) for e in entities]\n",
    "all_ents_tokenized = list(set(all_ents_tokenized))\n",
    "[sum([len(e_t) == _l for e_t in all_ents_tokenized]) for _l in (1,2,3,4,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: keep rank in output\n",
    "\n",
    "def entity_expansion_corr(seed_concepts_path=seed_aligned_concepts_path,\n",
    "                          all_contexts=dedup_context, \n",
    "                          all_ents_tokenized=all_ents_tokenized, \n",
    "                          lm_probe=lm_probe,\n",
    "                          max_allowed_ngrams=3,\n",
    "                          max_contexts=50,\n",
    "                          top_k=100):\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "        \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    \n",
    "#     if contexts is None:\n",
    "#         try:\n",
    "#             contexts = dedup_context[entity]\n",
    "#         except KeyError:\n",
    "#             print(f'\"{entity}\" not an extracted entity!')\n",
    "#             return None\n",
    "\n",
    "    _out_records = []\n",
    "\n",
    "    for i, (a_concept, u_concept, gnrl, seed_instances) in tqdm(seed_concepts_df.iterrows(), total=seed_concepts_df.shape[0]):\n",
    "        _expand_set = set()\n",
    "        _expand_records = []\n",
    "        \n",
    "        for _inst in seed_instances:\n",
    "            print(f'{a_concept} :: {_inst}')\n",
    "            try:\n",
    "                contexts = all_contexts[_inst]\n",
    "            except KeyError:\n",
    "                print(f'\"{_inst}\" not an extracted entity!')\n",
    "                continue\n",
    "            if len(contexts) < 2:\n",
    "                print(f'\"{_inst}\" only have {len(contexts)} context')\n",
    "                continue\n",
    "\n",
    "            _entity_pieces = lm_probe.tokenizer.tokenize(_inst)\n",
    "            if len(_entity_pieces) > max_allowed_ngrams:\n",
    "                print(f'{_entity_pieces} too many word pieces (max {max_allowed_ngrams})')\n",
    "                continue\n",
    "\n",
    "            entity2probs = defaultdict(list)\n",
    "\n",
    "            for _context in contexts[:max_contexts]:\n",
    "                for n_grams in range(1, max_allowed_ngrams+1):\n",
    "                    _ctxt = _context.replace('[MASK]', '[MASK]' + ' [MASK]' * (n_grams-1))\n",
    "                    _ctxt = '[CLS] ' + _ctxt + ' [SEP]'\n",
    "                    _cands = [e_t for e_t in all_ents_tokenized if len(e_t) == n_grams]\n",
    "                    _cand_scores = lm_probe.score_candidates(_ctxt, _cands)\n",
    "\n",
    "                    for _d in _cand_scores:\n",
    "                        _c = ' '.join(_d['cand']).replace(' ##', '')\n",
    "                        _s = _d['score']\n",
    "                        entity2probs[_c].append(_s)\n",
    "\n",
    "        #     print('entity2probs:', len(entity2probs), len(entity2probs[entity]))\n",
    "            for _e, _ss in entity2probs.items():\n",
    "                assert len(_ss) == len(entity2probs[_inst]), \\\n",
    "                    f'entity: {_e} | {lm_probe.tokenizer.tokenize(_e)}\\n\\\n",
    "                    len(_ss) = {len(_ss)}\\n\\\n",
    "                    len(entity2probs[\"{entity}\"]) = {len(entity2probs[entity])}'\n",
    "\n",
    "            _target_ss = entity2probs[_inst]\n",
    "            _target_ss = _target_ss / np.sum(_target_ss)\n",
    "\n",
    "        #     print(_target_ss.shape, _target_ss)\n",
    "\n",
    "            mean_l = [(_e, np.mean(_ss)) for _e, _ss in entity2probs.items()]\n",
    "            mean_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "            kl_l = [(_e, entropy(_target_ss, _ss)) for _e, _ss in entity2probs.items()]\n",
    "            kl_l.sort(key=lambda p : p[-1], reverse=False)\n",
    "            pearson_l = [(_e, pearsonr(_target_ss, _ss)[0]) for _e, _ss in entity2probs.items()]\n",
    "            pearson_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "\n",
    "            entity2ranks = defaultdict(list)\n",
    "            entity2scores = defaultdict(dict)\n",
    "            for i, (_e, _s) in enumerate(mean_l):\n",
    "                entity2ranks[_e].append(i)\n",
    "                entity2scores[_e][\"mean\"] = _s\n",
    "            for i, (_e, _s) in enumerate(kl_l):\n",
    "                entity2ranks[_e].append(i)\n",
    "                entity2scores[_e][\"kl\"] = _s\n",
    "            for i, (_e, _s) in enumerate(pearson_l):\n",
    "                entity2ranks[_e].append(i)\n",
    "                entity2scores[_e][\"pearson\"] = _s\n",
    "            # To simile top-k set intersection, keep the highest rank of _e among each criteria\n",
    "            entity_overall_ranks = [(_e, max(_ranks)) for _e, _ranks in entity2ranks.items()]\n",
    "            entity_overall_ranks.sort(key=lambda p : p[-1])\n",
    "            entity_overall_ranks_dict = dict(entity_overall_ranks)\n",
    "#             # Now, the top-k is for the final selection, not for each criteria\n",
    "            sel_entities = [_e for _e, _ in entity_overall_ranks[:top_k]]\n",
    "\n",
    "#             ints_mean_l = [p for p in mean_l if p[0] in sel_entities]\n",
    "#             ints_kl_l = [p for p in kl_l if p[0] in sel_entities]\n",
    "#             ints_pearson_l = [p for p in pearson_l if p[0] in sel_entities]\n",
    "\n",
    "#             return {\n",
    "#                 \"entity2probs\": entity2probs,\n",
    "#                 \"mean_l\": mean_l,\n",
    "#                 \"kl_l\": kl_l,\n",
    "#                 \"pearson_l\": pearson_l,\n",
    "#                 \"sel_entities\": sel_entities,\n",
    "#                 \"ints_mean_l\": ints_mean_l,\n",
    "#                 \"ints_kl_l\": ints_kl_l,\n",
    "#                 \"ints_pearson_l\": ints_pearson_l,\n",
    "#             }\n",
    "\n",
    "            for _e in sel_entities:\n",
    "                if (_e in _expand_set) or (_e in seed_instances):\n",
    "                    continue\n",
    "                _expand_set.add(_e)\n",
    "                _d = dict(entity2scores[_e])\n",
    "                _d['max_rank'] = entity_overall_ranks_dict[_e]\n",
    "                _expand_records.append((_e, _d))\n",
    "\n",
    "#         for _inst in seed_instances:\n",
    "#             _expand_set.discard(_inst)\n",
    "\n",
    "        for _e, _d in _expand_records:\n",
    "            _out_d = dict(_d)\n",
    "            _out_d['concept'] = a_concept\n",
    "            _out_d['neighbor'] = _e\n",
    "            _out_records.append(_out_d)\n",
    "\n",
    "    return _out_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### full run & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_expansion_out_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_corr_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_expansion_corr(max_contexts=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|                                                    | 0/14 [00:00<?, ?it/s]company :: walmart\n",
      "company :: amazon\n",
      "company :: subway\n",
      "company :: microsoft\n",
      "company :: target\n",
      "  7%|███▏                                        | 1/14 [01:13<16:01, 73.94s/it]dress_code :: business casual\n",
      "dress_code :: uniform\n",
      "dress_code :: hair color\n",
      "dress_code :: tattoos\n",
      "dress_code :: facial hair\n",
      "dress_code :: shoes\n",
      "dress_code :: piercings\n",
      " 14%|██████▎                                     | 2/14 [03:16<17:43, 88.60s/it]job_position :: delivery driver\n",
      "job_position :: store manager\n",
      "job_position :: cashier\n",
      "job_position :: package handler\n",
      "job_position :: sales associate\n",
      "job_position :: barista\n",
      "job_position :: dishwasher\n",
      " 21%|█████████▍                                  | 3/14 [05:17<18:00, 98.21s/it]pay_schedule :: weekly\n",
      "pay_schedule :: biweekly\n",
      "pay_schedule :: friday\n",
      "pay_schedule :: saturday\n",
      " 29%|████████████▌                               | 4/14 [06:27<14:56, 89.66s/it]benefits :: health insurance\n",
      "benefits :: flexible schedule\n",
      "benefits :: 401k\n",
      "benefits :: paid vacation\n",
      "benefits :: sick leave\n",
      "benefits :: vision insurance\n",
      " 36%|███████████████▋                            | 5/14 [08:02<13:42, 91.37s/it]compensation :: base pay\n",
      "compensation :: stock options\n",
      "compensation :: benefits\n",
      "compensation :: overtime pay\n",
      "compensation :: bonus\n",
      " 43%|██████████████████▊                         | 6/14 [09:24<11:49, 88.67s/it]payment_option :: checks\n",
      "payment_option :: direct deposit\n",
      "payment_option :: prepaid card\n",
      " 50%|██████████████████████                      | 7/14 [10:06<08:41, 74.55s/it]background_screening :: drug test\n",
      "background_screening :: criminal background check\n",
      "background_screening :: employment verification\n",
      " 57%|█████████████████████████▏                  | 8/14 [10:44<06:20, 63.48s/it]person :: felons\n",
      "person :: criminals\n",
      "person :: disabled\n",
      "person :: drug addicts\n",
      "person :: high schoolers\n",
      "person :: misdemeanor\n",
      "['mis', '##de', '##me', '##anor'] too many word pieces (max 3)\n",
      "person :: pregnant\n",
      "person :: students\n",
      "person :: seniors\n",
      " 64%|████████████████████████████▎               | 9/14 [12:34<06:27, 77.49s/it]hire_prerequisite :: hiring age\n",
      "hire_prerequisite :: bachelors degree\n",
      "hire_prerequisite :: prior experience\n",
      "hire_prerequisite :: working permit\n",
      "hire_prerequisite :: heavy lifting\n",
      " 71%|██████████████████████████████▋            | 10/14 [13:44<05:01, 75.42s/it]shifts :: night shift\n",
      "shifts :: dinner shift\n",
      "shifts :: early morning shift\n",
      "shifts :: 8 hour shift\n",
      " 79%|█████████████████████████████████▊         | 11/14 [14:28<03:17, 65.96s/it]schedule :: christmas eve\n",
      "schedule :: early morning\n",
      "schedule :: hoilday\n",
      "schedule :: 7 days\n",
      "schedule :: saturday\n",
      "schedule :: sunday\n",
      "schedule :: weekend\n",
      " 86%|████████████████████████████████████▊      | 12/14 [16:11<02:33, 76.86s/it]employee_type :: full time\n",
      "employee_type :: part time\n",
      "employee_type :: seasonal\n",
      " 93%|███████████████████████████████████████▉   | 13/14 [17:01<01:08, 68.90s/it]onboarding_steps :: orientation\n",
      "onboarding_steps :: introduction\n",
      "onboarding_steps :: workstation\n",
      "onboarding_steps :: training\n",
      "onboarding_steps :: team lunch\n",
      "\"team lunch\" only have 1 context\n",
      "100%|███████████████████████████████████████████| 14/14 [17:41<00:00, 75.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use scripts\n",
    "!python compute_EE_corr.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/concept_corr_100.csv \\\n",
    "-ng 3 \\\n",
    "-ct 50 \\\n",
    "-top_k 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5220cc3e4090474b913a67258c0d98e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_entity = 'health insurance'\n",
    "_results = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_results['sel_entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insurance',\n",
       " 'health insurance',\n",
       " 'life insurance',\n",
       " 'property insurance',\n",
       " 'disability insurance',\n",
       " 'health care insurance',\n",
       " 'personal life',\n",
       " 'car insurance',\n",
       " 'offer health insurance',\n",
       " 'vision insurance',\n",
       " 'medical insurance',\n",
       " 'dental insurance',\n",
       " 'social life',\n",
       " 'healthcare',\n",
       " 'vehicle insurance',\n",
       " 'health care',\n",
       " 'social services',\n",
       " 'financial services',\n",
       " 'personal property',\n",
       " 'insurance company']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_results['sel_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42782ed502f8477b8db39b8079ec0903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_entity = 'paid vacation'\n",
    "_results = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " ['paid vacation',\n",
       "  'free food',\n",
       "  'extra hours',\n",
       "  'personal life',\n",
       "  'additional training',\n",
       "  'pay rent',\n",
       "  'extra cash',\n",
       "  'employment',\n",
       "  'extra money',\n",
       "  'regular employee',\n",
       "  'actual training',\n",
       "  'free market',\n",
       "  'home office',\n",
       "  'paid weekly',\n",
       "  'lunch break',\n",
       "  'employment contract',\n",
       "  'paid vacations',\n",
       "  'starting pay',\n",
       "  'training class',\n",
       "  'cash office'])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_results['sel_entities']), _results['sel_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paid vacation', 0.0044874584203954135),\n",
       " ('free food', 0.0030260901631086125),\n",
       " ('employment', 0.0026738146242238693),\n",
       " ('additional training', 0.002321403750532552),\n",
       " ('pay rent', 0.0016830003481619713),\n",
       " ('extra money', 0.0012204012291167322),\n",
       " ('extra hours', 0.0012082061174470255),\n",
       " ('paid vacations', 0.00120581120557009),\n",
       " ('personal life', 0.001053836581509607),\n",
       " ('extra cash', 0.0009903957854880568),\n",
       " ('free market', 0.0007903035967739137),\n",
       " ('employment contract', 0.0007457378170482977),\n",
       " ('regular employee', 0.0007120051084749063),\n",
       " ('actual training', 0.0006806927853699615),\n",
       " ('home office', 0.0006772145559134888),\n",
       " ('paid weekly', 0.0006510896439229592),\n",
       " ('lunch break', 0.0006262294878335945),\n",
       " ('starting pay', 0.0005959591850205348),\n",
       " ('training class', 0.0005751933163302262),\n",
       " ('cash office', 0.0005385432788353982)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_results['ints_mean_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paid vacation', 0.0),\n",
       " ('paid weekly', 0.3553680094673442),\n",
       " ('regular employee', 0.5651236328627899),\n",
       " ('starting pay', 0.6403464447016876),\n",
       " ('home office', 0.702709761379911),\n",
       " ('extra hours', 0.7882322979791239),\n",
       " ('cash office', 0.8216374067668454),\n",
       " ('additional training', 0.8231515801756707),\n",
       " ('free food', 0.8235410993620799),\n",
       " ('extra cash', 0.8406818348940776),\n",
       " ('lunch break', 0.8554870473017729),\n",
       " ('extra money', 0.8671142026312799),\n",
       " ('actual training', 0.8861361628894645),\n",
       " ('free market', 0.8934745945926472),\n",
       " ('personal life', 0.905080634158609),\n",
       " ('pay rent', 0.9191154476332102),\n",
       " ('training class', 0.9618010548607787),\n",
       " ('employment', 1.0064966364964134),\n",
       " ('employment contract', 1.0666759660272174),\n",
       " ('paid vacations', 1.07702367185203)]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_results['ints_kl_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paid vacation', 1.0),\n",
       " ('paid weekly', 0.6898791401226259),\n",
       " ('personal life', 0.6470476793642793),\n",
       " ('home office', 0.6137368598658344),\n",
       " ('employment', 0.5939260343586834),\n",
       " ('regular employee', 0.5934659341843702),\n",
       " ('free food', 0.5814593375358278),\n",
       " ('actual training', 0.5171393046252428),\n",
       " ('extra hours', 0.48931553441132725),\n",
       " ('cash office', 0.4649905535739707),\n",
       " ('training class', 0.45922641771917155),\n",
       " ('additional training', 0.453205530878079),\n",
       " ('starting pay', 0.4452037644119071),\n",
       " ('employment contract', 0.439553353761904),\n",
       " ('pay rent', 0.4366836227238857),\n",
       " ('lunch break', 0.43380180618257874),\n",
       " ('extra cash', 0.4258937516890552),\n",
       " ('extra money', 0.4070871841193142),\n",
       " ('paid vacations', 0.4019298655642553),\n",
       " ('free market', 0.40088368759801624)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_results['ints_pearson_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Both medical and dental insurance is provided as well as [MASK]',\n",
       "  6.578818802360679e-06,\n",
       "  0.00015682175491799882,\n",
       "  0.0018069056141044838),\n",
       " ('No the [MASK] tome will be put on your final pay check',\n",
       "  9.477934070825445e-05,\n",
       "  0.00179112735515401,\n",
       "  0.01783658171282455),\n",
       " (\"A new policy came out apparently saying that you do n't get a week of [MASK] in the first year , if you start after June 1st .\",\n",
       "  0.4888658700418125,\n",
       "  1.0,\n",
       "  0.08162912113546698),\n",
       " ('It is very true that dollar tree do nt pay out your owed [MASK] when you are no longer working for them .',\n",
       "  0.0022030048390930365,\n",
       "  0.0038430425562789427,\n",
       "  0.6893102387382053),\n",
       " ('But they offer no [MASK] and no sick leave .',\n",
       "  0.026742685344147428,\n",
       "  0.05176876375876567,\n",
       "  0.25499081609946683),\n",
       " ('They give [MASK] and sick time , health and dental insurance , 401k , life insurance',\n",
       "  0.9423141194865929,\n",
       "  0.027970293703116284,\n",
       "  0.8023113287226477),\n",
       " ('only assistant managers and general managers received [MASK] pay and sick pay',\n",
       "  0.23182283459346942,\n",
       "  0.07829888924495584,\n",
       "  0.2731482003476367),\n",
       " ('For full time : [MASK] , Sick time , PTO .',\n",
       "  0.24500194640098488,\n",
       "  0.7806978269661807,\n",
       "  0.25867774481661543),\n",
       " ('Once being hired a year [MASK]', 1.4996146523943373e-06, 0.0, 0.0),\n",
       " ('Chase has disability benefits , along with [MASK] ,',\n",
       "  0.0037400833352556565,\n",
       "  0.04770937225247506,\n",
       "  0.10147697923671468),\n",
       " ('health medical , Dental , etc . ; Training ; 401 K , [MASK] .',\n",
       "  0.0030263398273425797,\n",
       "  0.017775233716358415,\n",
       "  0.8941691680646828),\n",
       " ('No [MASK] , no health insurance , nothing !',\n",
       "  0.002597835448280048,\n",
       "  0.03854780193934496,\n",
       "  0.09310450978417306),\n",
       " ('Such as , health care and [MASK] .',\n",
       "  0.0002824426112442476,\n",
       "  0.010915291304438643,\n",
       "  0.019053301564483566),\n",
       " ('I never took any vacations day , I m sure it was nt a [MASK]',\n",
       "  1.976805280428444e-05,\n",
       "  0.0001259792190053521,\n",
       "  0.000134409594121865),\n",
       " ('No [MASK] after a year .',\n",
       "  0.003960501793724179,\n",
       "  0.06561470134708737,\n",
       "  0.08128028100733416),\n",
       " ('Each store is independently owned , so you may have a [MASK] system at your store .',\n",
       "  0.0032324147746924593,\n",
       "  0.014717367664602299,\n",
       "  0.10989044586843134),\n",
       " ('I had to work for a whole year or twelve calendar months before getting a [MASK] time .',\n",
       "  0.30591641551090204,\n",
       "  0.152602106761983,\n",
       "  0.07817021447081042),\n",
       " (\"publix offers [MASK] and sick day but I have n't work long enough to use the benefit .\",\n",
       "  0.23402681471194037,\n",
       "  0.07906629652148292,\n",
       "  0.050667007914498345),\n",
       " ('You receive about a $ 1 . 00 raise , but also you receive [MASK] , sick leave , and guaranteed 2 days off .',\n",
       "  0.3446607765500741,\n",
       "  0.13353111458553363,\n",
       "  0.3233051276691392),\n",
       " ('Vision , Dental , [MASK] , 401 K',\n",
       "  0.0005212524718306747,\n",
       "  0.007993453839044417,\n",
       "  0.017517814788640586),\n",
       " ('After one year and depending on the number of hours you work will depend on how many [MASK] hours / days you will receive .',\n",
       "  0.3262417605927743,\n",
       "  0.1185306531558913,\n",
       "  0.26145063044661676),\n",
       " ('Paid Vacation accumulated over the weeks , non [MASK] was also available',\n",
       "  0.14561309892795496,\n",
       "  0.014946605749923899,\n",
       "  0.20467539264024986),\n",
       " (\"Part time does n't get any [MASK] .\",\n",
       "  0.004818101540371127,\n",
       "  0.014704183796864093,\n",
       "  0.05149127556073687),\n",
       " (\"I did n't qualify for [MASK]\",\n",
       "  0.0,\n",
       "  0.00013833383264332213,\n",
       "  2.200855882550398e-05),\n",
       " ('401k , [MASK] , sick time , medical , dental , vision , bonuses and other incentives',\n",
       "  0.06065868847182519,\n",
       "  0.21872545029662457,\n",
       "  1.0),\n",
       " ('Eligible workers gain access to healthcare coverage , 401 ( k ) retirement plans , sick leave , personal days , and [MASK] , flexible spending accounts , and life insurance options',\n",
       "  0.1725192364944353,\n",
       "  0.007755238396722399,\n",
       "  0.06916860209127944),\n",
       " ('None we do nt recieve [MASK] .',\n",
       "  0.00011854472739062176,\n",
       "  0.0005104552857867912,\n",
       "  0.0010478279669635128),\n",
       " ('Managers receive [MASK] and one free meal a day .',\n",
       "  0.11762298466492851,\n",
       "  0.13096663181722554,\n",
       "  0.39809365947980163),\n",
       " ('401k plan medical and dental [MASK] raise after 90 days',\n",
       "  0.0019179289900465575,\n",
       "  0.041361645716974614,\n",
       "  0.17611902760501727),\n",
       " ('Yes for full time there is a week [MASK]',\n",
       "  6.786200812762701e-05,\n",
       "  0.0003338251452162233,\n",
       "  0.00044098957539795696),\n",
       " ('crew members do not receive [MASK]',\n",
       "  7.044122238550834e-06,\n",
       "  0.0026251276287963398,\n",
       "  0.0008307958414410135),\n",
       " ('You have to work 40 hours to get 1 hour of [MASK] time',\n",
       "  0.16521148326526203,\n",
       "  0.6045480850184173,\n",
       "  0.34156337793211217),\n",
       " ('All the managers and the asst managers got a [MASK]',\n",
       "  1.2137215756066526e-05,\n",
       "  4.405567898891748e-05,\n",
       "  0.000350441742950686),\n",
       " ('No there is not a [MASK]',\n",
       "  4.056053445523595e-06,\n",
       "  2.1407120805241987e-05,\n",
       "  8.023251704585847e-05),\n",
       " (\"U do n't get any [MASK] time are sick time at all\",\n",
       "  0.019711473143794515,\n",
       "  0.006265320269293292,\n",
       "  0.05247547496634478),\n",
       " ('Only managers are full time which means no [MASK]',\n",
       "  3.752162015695963e-05,\n",
       "  0.0035209274956039724,\n",
       "  0.0007831260955182229),\n",
       " ('Unless you are a full time career employee , you do not get any [MASK] time',\n",
       "  1.0,\n",
       "  0.3411526648071449,\n",
       "  0.7082231131298945),\n",
       " (\"If you just went past your 90 day mark then i do n't see why you would n't be able to , but keep in mind , you do not get a [MASK] , and most places will most likely let you go because they ca n't leave a vacant spot for almost two months .\",\n",
       "  0.11149749877991277,\n",
       "  0.017488687437352903,\n",
       "  0.03329519275389829),\n",
       " ('On your 5 year anniversary you will get 500 dollars or a [MASK] .',\n",
       "  0.018360237747319093,\n",
       "  0.0246834791755306,\n",
       "  0.16996853648783594),\n",
       " ('Yes bonuses an [MASK]',\n",
       "  4.2854114280321426e-05,\n",
       "  0.0004991132662695892,\n",
       "  0.0010505137273542167),\n",
       " ('80 hrs of [MASK] per year .',\n",
       "  0.0005614906462792095,\n",
       "  0.0022177594685687013,\n",
       "  0.000172809475151608),\n",
       " ('You do need to be a shift manager for at least a year before you get your [MASK] ( at least in my experience with a franchise location )',\n",
       "  0.012128350336706043,\n",
       "  0.04237491910517959,\n",
       "  0.05330261507094856),\n",
       " ('Store managers   15 + an hour with guaranteed overtime and a week of [MASK] .',\n",
       "  0.6706696047262527,\n",
       "  0.39104137513535925,\n",
       "  0.1529266104320991),\n",
       " ('6 [MASK] days .',\n",
       "  0.0009005486490436924,\n",
       "  0.002073908147796622,\n",
       "  0.005603226966475566),\n",
       " ('menards does not offer maternity leave only [MASK] .',\n",
       "  0.0080900575648695,\n",
       "  0.004675857911426127,\n",
       "  0.012895954396048733),\n",
       " ('How can you get a [MASK] on under 40 hours ? ? ? ?',\n",
       "  0.002360870884724027,\n",
       "  0.07419871925889387,\n",
       "  0.05708052606396038),\n",
       " ('None I barely had hours to get a [MASK]',\n",
       "  3.6816430912121303e-06,\n",
       "  9.8261197820452e-06,\n",
       "  2.154213247477965e-05),\n",
       " ('There is no [MASK] , however they are lenient about your schedule',\n",
       "  0.0018703822220601277,\n",
       "  0.355697917601864,\n",
       "  0.09015526800849852),\n",
       " (\"During my time working there I did n't hear or know about [MASK] .\",\n",
       "  0.0006690955461960481,\n",
       "  0.02424166740629815,\n",
       "  0.022162387860887593),\n",
       " (\"If you do n't have enough hours for [MASK] you can still go on vacation without payment .\",\n",
       "  0.022655908428214726,\n",
       "  0.13233636096964954,\n",
       "  0.02674802956927661)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity2probs = _results['entity2probs']\n",
    "_ser1 = entity2probs['paid vacation']\n",
    "_ser2 = entity2probs['training class']\n",
    "_ser3 = entity2probs['cash office']\n",
    "\n",
    "_ser1 = (_ser1 - min(_ser1)) / (max(_ser1) - min(_ser1))\n",
    "_ser2 = (_ser2 - min(_ser2)) / (max(_ser2) - min(_ser2))\n",
    "_ser3 = (_ser3 - min(_ser3)) / (max(_ser3) - min(_ser3))\n",
    "\n",
    "list(zip(dedup_context['paid vacation'], _ser1, _ser2, _ser3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_entity = 'flexible schedule'\n",
    "_results = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_results['mean_set'] & _results['kl_set'] & _results['pearson_set']), \\\n",
    "_results['mean_set'] & _results['kl_set'] & _results['pearson_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results['ints_mean_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results['ints_pearson_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2probs = _results['entity2probs']\n",
    "_ser1 = entity2probs['flexible schedule']\n",
    "_ser2 = entity2probs['model']\n",
    "_ser3 = entity2probs['low level']\n",
    "\n",
    "_ser1 = (_ser1 - min(_ser1)) / (max(_ser1) - min(_ser1))\n",
    "_ser2 = (_ser2 - min(_ser2)) / (max(_ser2) - min(_ser2))\n",
    "_ser3 = (_ser3 - min(_ser3)) / (max(_ser3) - min(_ser3))\n",
    "\n",
    "list(zip(dedup_context['flexible schedule'], _ser1, _ser2, _ser3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probe.fill_multi_mask(\"[CLS] They have a very [MASK] [MASK] for most departments and if your schedule does n't fit , you 'll more than likely just be moved . [SEP]\", topk=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_entity = 'black jeans'\n",
    "mean_set, kl_set, pearson_set = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(mean_set & kl_set & pearson_set), mean_set & kl_set & pearson_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_entity = 'walmart'\n",
    "mean_set, kl_set, pearson_set = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_set & kl_set & pearson_set), mean_set & kl_set & pearson_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probe_gpt2 = LMProbe_GPT2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_expansion_multiways_GPT2(entity, \n",
    "                                    contexts=None, \n",
    "                                    entities=entities, \n",
    "                                    lm_probe=lm_probe_gpt2, \n",
    "                                    top_k=20):\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe_GPT2()\n",
    "    if contexts is None:\n",
    "        contexts = dedup_context[entity]\n",
    "    \n",
    "    # test: speed up x100\n",
    "    entities = entities[::100]\n",
    "    \n",
    "    entity2probs = defaultdict(list)\n",
    "\n",
    "    for _context in tqdm(contexts[:50]):\n",
    "        _cand_scores = lm_probe.score_candidates(_context, entities)\n",
    "\n",
    "        for _d in _cand_scores:\n",
    "            _c = _d['cand']\n",
    "            _s = _d['score']\n",
    "            entity2probs[_c].append(_s)\n",
    "    \n",
    "#     print('entity2probs:', len(entity2probs), len(entity2probs[entity]))\n",
    "    for _e, _ss in entity2probs.items():\n",
    "        assert len(_ss) == len(entity2probs[entity]), \\\n",
    "            f'entity: {_e} | {lm_probe.tokenizer.tokenize(_e)}; len(_ss): {len(_ss)}'\n",
    "    \n",
    "    _target_ss = entity2probs[entity]\n",
    "    _target_ss = _target_ss / np.sum(_target_ss)\n",
    "    \n",
    "    mean_l = [(_e, np.mean(_ss)) for _e, _ss in entity2probs.items()]\n",
    "    mean_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "    kl_l = [(_e, entropy(_target_ss, _ss)) for _e, _ss in entity2probs.items()]\n",
    "    kl_l.sort(key=lambda p : p[-1], reverse=False)\n",
    "    pearson_l = [(_e, pearsonr(_target_ss, _ss)[0]) for _e, _ss in entity2probs.items()]\n",
    "    pearson_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    entity2ranks = defaultdict(list)\n",
    "    for i, (_e, _s) in enumerate(mean_l):\n",
    "        entity2ranks[_e].append(i)\n",
    "    for i, (_e, _s) in enumerate(kl_l):\n",
    "        entity2ranks[_e].append(i)\n",
    "    for i, (_e, _s) in enumerate(pearson_l):\n",
    "        entity2ranks[_e].append(i)\n",
    "    # To simile top-k set intersection, keep the highest rank of _e among each criteria\n",
    "    entity_overall_ranks = [(_e, max(_ranks)) for _e, _ranks in entity2ranks.items()]\n",
    "    entity_overall_ranks.sort(key=lambda p : p[-1])\n",
    "    # Now, the top-k is for the final selection, not for each criteria\n",
    "    sel_entities = [_e for _e, _ in entity_overall_ranks[:top_k]]\n",
    "    \n",
    "#     mean_set = set([_e for _e, _s in mean_l[:top_k]])\n",
    "#     kl_set = set([_e for _e, _s in kl_l[:top_k]])\n",
    "#     pearson_set = set([_e for _e, _s in pearson_l[:top_k]])\n",
    "    \n",
    "#     sel_entities = mean_set & kl_set & pearson_set\n",
    "    ints_mean_l = [p for p in mean_l if p[0] in sel_entities]\n",
    "    ints_kl_l = [p for p in kl_l if p[0] in sel_entities]\n",
    "    ints_pearson_l = [p for p in pearson_l if p[0] in sel_entities]\n",
    "    \n",
    "    return {\n",
    "        \"entity2probs\": entity2probs,\n",
    "        \"mean_l\": mean_l,\n",
    "        \"kl_l\": kl_l,\n",
    "        \"pearson_l\": pearson_l,\n",
    "#         \"mean_set\": mean_set,\n",
    "#         \"kl_set\": kl_set,\n",
    "#         \"pearson_set\": pearson_set,\n",
    "        \"sel_entities\": sel_entities,\n",
    "        \"ints_mean_l\": ints_mean_l,\n",
    "        \"ints_kl_l\": ints_kl_l,\n",
    "        \"ints_pearson_l\": ints_pearson_l,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_entity = 'health insurance'\n",
    "_results = entity_expansion_multiways_GPT2(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT greedy-filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMProbe_PMI(object):\n",
    "    def __init__(self, model_name='bert-base-uncased', use_gpu=False):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertForMaskedLM.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.mask_token = self.tokenizer.mask_token\n",
    "\n",
    "    def fill_multi_mask(self, input_txt, topk=3):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def score_tail(self, input_txt, tail, head=None, head_len=None, head_first=True):\n",
    "        # input_txt: str, with [HEAD] for head and [TAIL] for tail \n",
    "        # tail: str, the tail entity \n",
    "        # head: str, the head entity \n",
    "        # head_len: int, the length of head entity\n",
    "        # Should only give head or head_len \n",
    "        # head_first: bool, whether the first [MASK] is the head \n",
    "        \n",
    "        assert (head is None) + (head_len is None) == 1, \\\n",
    "            f\"head = {head}, head_len = {head_len}\"\n",
    "        assert input_txt.count(\"[HEAD]\") == input_txt.count(\"[TAIL]\") == 1, \\\n",
    "            f\"Input string must have [HEAD] and [TAIL], got {input_txt}\"\n",
    "        \n",
    "        \n",
    "        tail_toks = self.tokenizer.tokenize(tail)\n",
    "        tail_len = len(tail_toks)\n",
    "        input_txt = input_txt.replace('[TAIL]', '[MASK]' + ' [MASK]' * (tail_len-1))\n",
    "        \n",
    "        if head is not None:\n",
    "            head_toks = self.tokenizer.tokenize(head)\n",
    "            head_len = len(head_toks)\n",
    "            print(head_toks, head_len)\n",
    "            input_txt = input_txt.replace('[HEAD]', head)\n",
    "        else:\n",
    "            input_txt = input_txt.replace('[HEAD]', '[MASK]' + ' [MASK]' * (head_len-1))\n",
    "        \n",
    "        tokenized_txt = self.tokenizer.tokenize(input_txt)\n",
    "        tokenized_txt = ['[CLS]'] + tokenized_txt + ['[SEP]']\n",
    "\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        mask_indices = [i for i, x in enumerate(tokenized_txt) if x == \"[MASK]\"]\n",
    "        if head is not None:\n",
    "            # head is not [MASK] \n",
    "            tail_indices = mask_indices\n",
    "        elif head_first:\n",
    "            # head is [MASK] and first \n",
    "            tail_indices = mask_indices[head_len:]\n",
    "        else:\n",
    "            # head is [MASK] and second \n",
    "            tail_indices = mask_indices[:tail_len]\n",
    "        print(tokenized_txt, tail_indices)\n",
    "        \n",
    "        segment_idx = tokens_tensor * 0\n",
    "        tokens_tensor = tokens_tensor.to(self.device)\n",
    "        segments_tensors = segment_idx.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.softmax(predictions, dim=-1)[0]\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "        \n",
    "        _scores = []\n",
    "        tail_tok_ids = self.tokenizer.convert_tokens_to_ids(tail_toks)\n",
    "        for i, token_id in zip(tail_indices, tail_tok_ids):\n",
    "            _scores.append(probs[i, token_id].item())\n",
    "        score = gmean(_scores)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMProbe_PMI_greedy(object):\n",
    "    def __init__(self, model_name='bert-base-uncased', use_gpu=False):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertForMaskedLM.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.mask_token = self.tokenizer.mask_token\n",
    "\n",
    "    def fill_multi_mask(self, input_txt, topk=3):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def score_tail(self, input_txt, tail, head=None, head_len=None, head_first=True):\n",
    "        # input_txt: str, with [HEAD] for head and [TAIL] for tail \n",
    "        # tail: str, the tail entity \n",
    "        # head: str, the head entity \n",
    "        # head_len: int, the length of head entity\n",
    "        # Should only give head or head_len \n",
    "        # head_first: bool, whether the first [MASK] is the head \n",
    "        \n",
    "        assert (head is None) + (head_len is None) == 1, \\\n",
    "            f\"head = {head}, head_len = {head_len}\"\n",
    "        assert input_txt.count(\"[HEAD]\") == input_txt.count(\"[TAIL]\") == 1, \\\n",
    "            f\"Input string must have [HEAD] and [TAIL], got {input_txt}\"\n",
    "                \n",
    "        tail_toks = self.tokenizer.tokenize(tail)\n",
    "        tail_len = len(tail_toks)\n",
    "        input_txt = input_txt.replace('[TAIL]', '[MASK]' + ' [MASK]' * (tail_len-1))\n",
    "        \n",
    "        if head is not None:\n",
    "            head_toks = self.tokenizer.tokenize(head)\n",
    "            head_len = len(head_toks)\n",
    "            print(head_toks, head_len)\n",
    "            input_txt = input_txt.replace('[HEAD]', head)\n",
    "        else:\n",
    "            input_txt = input_txt.replace('[HEAD]', '[MASK]' + ' [MASK]' * (head_len-1))\n",
    "        \n",
    "        tokenized_txt = self.tokenizer.tokenize(input_txt)\n",
    "        tokenized_txt = ['[CLS]'] + tokenized_txt + ['[SEP]']\n",
    "        mask_indices = [i for i, x in enumerate(tokenized_txt) if x == \"[MASK]\"]\n",
    "\n",
    "        if head is not None:\n",
    "            # head is not [MASK] \n",
    "            tail_indices = mask_indices\n",
    "        elif head_first:\n",
    "            # head is [MASK] and first \n",
    "            tail_indices = mask_indices[head_len:]\n",
    "        else:\n",
    "            # head is [MASK] and second \n",
    "            tail_indices = mask_indices[:tail_len]\n",
    "        \n",
    "        # Greedy filling \n",
    "        unfilled_indices = list(tail_indices)\n",
    "        scores = []\n",
    "        while len(unfilled_indices) > 0:\n",
    "            print(tokenized_txt, unfilled_indices)\n",
    "            \n",
    "            indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
    "            tokens_tensor = torch.tensor([indexed_tokens])\n",
    "            \n",
    "            segment_idx = tokens_tensor * 0\n",
    "            tokens_tensor = tokens_tensor.to(self.device)\n",
    "            segments_tensors = segment_idx.to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "                predictions = outputs[0]\n",
    "\n",
    "            probs = torch.softmax(predictions, dim=-1)[0]\n",
    "            probs = probs.detach().cpu().numpy()\n",
    "\n",
    "            _tok_scores = []\n",
    "            tail_tok_ids = self.tokenizer.convert_tokens_to_ids(tail_toks)\n",
    "            for i, token_id in zip(tail_indices, tail_tok_ids):\n",
    "                if i not in unfilled_indices:\n",
    "                    continue\n",
    "                _score = probs[i, token_id].item()\n",
    "                _tok_scores.append((i, token_id, _score))\n",
    "                \n",
    "            _tok_scores.sort(key=lambda p : p[1], reverse=True)\n",
    "            _fill_idx, _fill_tok, _score = _tok_scores[0]\n",
    "            unfilled_indices.remove(_fill_idx)\n",
    "            scores.append(_score)\n",
    "            tokenized_txt[_fill_idx] = self.tokenizer.convert_ids_to_tokens(_fill_tok)\n",
    "        \n",
    "        return np.prod(scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe_greedy = LMProbe_PMI_greedy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microsoft'] 1\n",
      "['[CLS]', 'microsoft', 'hires', '[MASK]', '[MASK]', '.', '[SEP]'] [3, 4]\n",
      "['[CLS]', 'microsoft', 'hires', '[MASK]', 'engineers', '.', '[SEP]'] [3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0002394940119523417"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sent = '[HEAD] hires [TAIL] .'\n",
    "\n",
    "lm_probe_greedy.score_tail(_sent, tail='software engineers', head='microsoft', head_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target'] 1\n",
      "['[CLS]', 'target', 'hires', '[MASK]', '[MASK]', '.', '[SEP]'] [3, 4]\n",
      "['[CLS]', 'target', 'hires', '[MASK]', 'engineers', '.', '[SEP]'] [3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.490697362450423e-06"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_greedy.score_tail(_sent, tail='software engineers', head='target', head_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '[MASK]', 'hires', '[MASK]', '[MASK]', '.', '[SEP]'] [3, 4]\n",
      "['[CLS]', '[MASK]', 'hires', '[MASK]', 'engineers', '.', '[SEP]'] [3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.044167127037733e-07"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_greedy.score_tail(_sent, tail='software engineers', head_len=1, head_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Extraction Baselines\n",
    "Currently only for single relation. TODO: include all relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null baseline - Cartesian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_Cartesian_RE(seed_concepts_path,\n",
    "                      seed_relations_path,\n",
    "                      concept_knn_path,\n",
    "                      relation,\n",
    "                      topk=None,\n",
    "                      dest=None,\n",
    "                      **kwargs):\n",
    "    \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    seed_relations_df = pd.read_csv(seed_relations_path)\n",
    "    relation_row = seed_relations_df[seed_relations_df['alignedRelationName'] == relation].iloc[0]\n",
    "    concept_knn_results = pd.read_csv(concept_knn_path)\n",
    "    \n",
    "    head_type = relation_row['domain']\n",
    "    tail_type = relation_row['range']\n",
    "    print(head_type, '\\t', tail_type)\n",
    "    seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == head_type]['seedInstances'].item()\n",
    "#     seed_heads = eval(list(seed_heads)[0])\n",
    "    seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == tail_type]['seedInstances'].item()\n",
    "#     seed_tails = eval(list(seed_tails)[0])\n",
    "    print('seed_heads:', seed_heads)\n",
    "    print('seed_tails:', seed_tails)\n",
    "\n",
    "    # Candidate heads / tails from concept knn \n",
    "    cand_heads_df = concept_knn_results[concept_knn_results['concept'] == head_type]\n",
    "    cand_tails_df = concept_knn_results[concept_knn_results['concept'] == tail_type]\n",
    "    cand_heads = [(_h, 1.0) for _h in seed_heads] + \\\n",
    "        list(zip(cand_heads_df['neighbor'].tolist(), cand_heads_df['sim'].tolist()))\n",
    "    cand_tails = [(_t, 1.0) for _t in seed_tails] + \\\n",
    "        list(zip(cand_tails_df['neighbor'].tolist(), cand_tails_df['sim'].tolist()))\n",
    "\n",
    "    if topk is not None:\n",
    "        cand_heads = cand_heads[:topk]\n",
    "        cand_tails = cand_tails[:topk]\n",
    "        \n",
    "    print('cand_heads:', list(zip(*cand_heads))[0])\n",
    "    print('cand_tails:', list(zip(*cand_tails))[0])\n",
    "    \n",
    "    out_rels = []\n",
    "    for _h, _hs in cand_heads:\n",
    "        for _t, _ts in cand_tails:\n",
    "            out_rels.append({\n",
    "                'head': _h, 'relation': relation, 'tail': _t,\n",
    "                'overall_score': _hs * _ts\n",
    "            })\n",
    "    out_rels.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "    \n",
    "    out_rels_df = pd.DataFrame(out_rels)\n",
    "    if dest is not None:\n",
    "        out_rels_df.to_csv(dest, index=False)\n",
    "    return out_rels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "# knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/knn_{cluster_size}.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "\n",
    "relation = 'has_benefits'\n",
    "cartesian_re_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_cartesian-{relation}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company \t benefits\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "cand_heads: ('walmart', 'amazon', 'subway', 'microsoft', 'target', 'wal mart', 'costco', 'publix', 'walgreens', 'kroger', 'home depot', \"sam 's club\", 'dollar general', 'family dollar', 'jcpenney', 'pizza hut', 'starbucks', 'apple', 'kfc', 'dollar tree', 'panera bread', 'safeway', 'hobby lobby', 'cracker barrel', 'spectrum', 'menards', 'chick fil a', 'old navy', 'mcdonalds', 'taco bell', 'marshalls', 'burlington', 'olive garden', 'cvs', 'pepsico', 'sitel', 'burger king', 'petsmart', 'jcp', 'pepsi', \"macy 's\", 'geico', 'whole foods', 'ihop', 'fedex', 'best buy', 'frito lay', 'dunkin donuts', 'chipotle', 'tj maxx', 'verizon', 't mobile', 'g4s', 'usps', 'jc penney', 'at&t', 'planet fitness', 'little caesars', 'company', 'mcdonald')\n",
      "cand_tails: ('health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'insurance', 'healthcare', 'medical insurance', 'health care', 'health', 'medical', 'paid vacations', 'sick days', 'life insurance', 'dental insurance', 'pension', '401k plan', 'holiday pay', 'maternity leave', 'tuition reimbursement', 'discount card', 'vacation days', 'profit sharing', 'employee discounts', 'employee discount', 'retirement plan', 'great benefits', 'health care insurance', 'disability', 'benefits package', 'tuition assistance', 'employee benefits', 'part timers', 'higher pay', 'medicare', 'flexible schedules', 'mandatory', 'pay increase', 'heath', 'education', 'union', 'weekly pay', 'free', 'cobra', 'job security', 'work life balance', 'previous experience', 'cards', 'family', 'child care', 'tax', 'medicaid', 'competitive pay', 'leaves', 'free food', '90 days', 'cigna', 'fair', 'p / t')\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "full_Cartesian_RE(seed_concepts_path=seed_aligned_concepts_path,\n",
    "                  seed_relations_path=seed_aligned_relations_path,\n",
    "                  concept_knn_path=concept_knn_path,\n",
    "                  relation=relation,\n",
    "                  topk=60,\n",
    "                  dest=cartesian_re_path)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company \t benefits\r\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\r\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\r\n",
      "cand_heads: ('walmart', 'amazon', 'subway', 'microsoft', 'target', 'wal mart', 'costco', 'publix', 'walgreens', 'kroger', 'home depot', \"sam 's club\", 'dollar general', 'family dollar', 'jcpenney', 'pizza hut', 'starbucks', 'apple', 'kfc', 'dollar tree', 'panera bread', 'safeway', 'hobby lobby', 'cracker barrel', 'spectrum', 'menards', 'chick fil a', 'old navy', 'mcdonalds', 'taco bell', 'marshalls', 'burlington', 'olive garden', 'cvs', 'pepsico', 'sitel', 'burger king', 'petsmart', 'jcp', 'pepsi', \"macy 's\", 'geico', 'whole foods', 'ihop', 'fedex', 'best buy', 'frito lay', 'dunkin donuts', 'chipotle', 'tj maxx', 'verizon', 't mobile', 'g4s', 'usps', 'jc penney', 'at&t', 'planet fitness', 'little caesars', 'company', 'mcdonald')\r\n",
      "cand_tails: ('health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'insurance', 'healthcare', 'medical insurance', 'health care', 'health', 'medical', 'paid vacations', 'sick days', 'life insurance', 'dental insurance', 'pension', '401k plan', 'holiday pay', 'maternity leave', 'tuition reimbursement', 'discount card', 'vacation days', 'profit sharing', 'employee discounts', 'employee discount', 'retirement plan', 'great benefits', 'health care insurance', 'disability', 'benefits package', 'tuition assistance', 'employee benefits', 'part timers', 'higher pay', 'medicare', 'flexible schedules', 'mandatory', 'pay increase', 'heath', 'education', 'union', 'weekly pay', 'free', 'cobra', 'job security', 'work life balance', 'previous experience', 'cards', 'family', 'child care', 'tax', 'medicaid', 'competitive pay', 'leaves', 'free food', '90 days', 'cigna', 'fair', 'p / t')\r\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_cartesian.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-EE=emb_100-RE=Ct.csv \\\n",
    "-r has_benefits \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_100.csv \\\n",
    "-topk 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction - GPT2 scores (analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation \n",
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt2_score(sentence):\n",
    "    tokenized_input = gpt2_tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        model_outputs = gpt2_model(**tokenized_input, labels=tokenized_input[\"input_ids\"])\n",
    "    score = model_outputs.loss.item()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.463441848754883"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_score('walmart requires dress code dress code dress code.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NLL) X offers Y        \tbenefits\t401k plan\tpaid vacation\tfamily  \n",
      "company                 \t8.153534\t6.109497\t6.707372\t8.615242\n",
      "walmart                 \t9.049321\t6.962499\t8.100282\t8.999038\n",
      "google                  \t8.491952\t6.307848\t7.430027\t9.093484\n",
      "california              \t6.713108\t5.849362\t6.076878\t6.828558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_sent_template = '{0} offers {1}'\n",
    "_heads = ['company', 'walmart', 'google', 'california']\n",
    "_tails = ['benefits', '401k plan', 'paid vacation', 'family']\n",
    "\n",
    "_print_msg = f\"{'(NLL) ' + _sent_template.format('X', 'Y'):24s}\"\n",
    "_print_msg += '\\t' + '\\t'.join([f\"{_t:8s}\" for _t in _tails]) + '\\n'\n",
    "for _h in _heads:\n",
    "    _print_msg += f\"{_h:24s}\"\n",
    "    for _t in _tails:\n",
    "        _sent = _sent_template.format(_h, _t)\n",
    "        _score = gpt2_score(_sent)\n",
    "#         print(f\"(NLL = {_score:.6f}) {_sent}\")\n",
    "        _print_msg += f\"\\t{_score:.6f}\"\n",
    "    _print_msg += \"\\n\"\n",
    "\n",
    "print(_print_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NLL) X allows Y        \tdress code\tjeans   \ttattoos \tdrugs   \n",
      "company                 \t7.646885\t11.025874\t10.445228\t9.259410\n",
      "walmart                 \t8.517221\t10.956227\t10.929914\t10.295705\n",
      "google                  \t8.461215\t12.038675\t12.965143\t10.222376\n",
      "california              \t6.353935\t7.937030\t7.359611\t6.910169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_sent_template = '{0} allows {1}'\n",
    "_heads = ['company', 'walmart', 'google', 'california']\n",
    "_tails = ['dress code', 'jeans', 'tattoos', 'drugs']\n",
    "\n",
    "_print_msg = f\"{'(NLL) ' + _sent_template.format('X', 'Y'):24s}\"\n",
    "_print_msg += '\\t' + '\\t'.join([f\"{_t:8s}\" for _t in _tails]) + '\\n'\n",
    "for _h in _heads:\n",
    "    _print_msg += f\"{_h:24s}\"\n",
    "    for _t in _tails:\n",
    "        _sent = _sent_template.format(_h, _t)\n",
    "        _score = gpt2_score(_sent)\n",
    "#         print(f\"(NLL = {_score:.6f}) {_sent}\")\n",
    "        _print_msg += f\"\\t{_score:.6f}\"\n",
    "    _print_msg += \"\\n\"\n",
    "\n",
    "print(_print_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NLL) X pays Y          \tschedule\tweekly  \tevery friday\tminimum wage\n",
      "company                 \t11.049671\t9.899395\t7.250698\t6.185252\n",
      "walmart                 \t11.554404\t10.105996\t7.789978\t7.334626\n",
      "google                  \t11.968147\t10.422943\t7.292716\t7.170493\n",
      "california              \t8.314291\t7.803281\t6.406629\t5.754911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_sent_template = '{0} pays {1}'\n",
    "_heads = ['company', 'walmart', 'google', 'california']\n",
    "_tails = ['schedule', 'weekly', 'every friday', 'minimum wage']\n",
    "\n",
    "_print_msg = f\"{'(NLL) ' + _sent_template.format('X', 'Y'):24s}\"\n",
    "_print_msg += '\\t' + '\\t'.join([f\"{_t:8s}\" for _t in _tails]) + '\\n'\n",
    "for _h in _heads:\n",
    "    _print_msg += f\"{_h:24s}\"\n",
    "    for _t in _tails:\n",
    "        _sent = _sent_template.format(_h, _t)\n",
    "        _score = gpt2_score(_sent)\n",
    "#         print(f\"(NLL = {_score:.6f}) {_sent}\")\n",
    "        _print_msg += f\"\\t{_score:.6f}\"\n",
    "    _print_msg += \"\\n\"\n",
    "\n",
    "print(_print_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction - scores weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_direct_probing_candidates(templates,\n",
    "                                  lm_probe=None,\n",
    "                                  head_entity=None,\n",
    "                                  tail_entity=None,\n",
    "                                  context=None,\n",
    "                                  topk=10):\n",
    "    '''\n",
    "    Direct probing: let BERT propose possible entities  \n",
    "    :param templates: List[str]: each have 2 slots, {0} for head, {1} for tail \n",
    "    :return: Dict[str, float]: proposed entities and scores \n",
    "    '''\n",
    "    \n",
    "    # ensure given one and propose one \n",
    "    assert (head_entity is None) != (tail_entity is None), f'{head_entity} {tail_entity}'\n",
    "\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    \n",
    "    names_scores = {}\n",
    "    for template in templates:\n",
    "        if head_entity is not None:\n",
    "            # head -> tail \n",
    "            _unigram_template = template.format(head_entity, '[MASK]')\n",
    "            _bigram_template = template.format(head_entity, '[MASK] [MASK]')\n",
    "        else:\n",
    "            # tail -> head \n",
    "            _unigram_template = template.format('[MASK]', tail_entity)\n",
    "            _bigram_template = template.format('[MASK] [MASK]', tail_entity)\n",
    "        \n",
    "        for _template in [_unigram_template, _bigram_template]:\n",
    "            if context:\n",
    "                query = '[CLS] ' + _template + '[SEP]' + context + '[SEP]'\n",
    "            else:\n",
    "                query = '[CLS] ' + _template + '[SEP]'\n",
    "            preds = lm_probe.fill_multi_mask(query, topk=topk)\n",
    "            for pred in preds:\n",
    "                name = ' '.join([p['token_str'] for p in pred])\n",
    "                name = name.replace(' ##', '')\n",
    "                score = np.prod([p['prob'] for p in pred])\n",
    "                scores = names_scores.get(name, [])\n",
    "                scores.append(score)\n",
    "                names_scores[name] = scores\n",
    "                \n",
    "    names_avg_scores = {k: float(sum(v))/ len(v) for k,v in names_scores.items()}\n",
    "    names_avg_scores = {k: v for k, v in sorted(names_avg_scores.items(), reverse=True, key=lambda item: item[1])[:topk]}\n",
    "    return names_avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def direct_probing_RE_v4(seed_concepts_path,\n",
    "                         seed_relations_path,\n",
    "                         emb_path,\n",
    "                         concept_knn_path,\n",
    "                         templates_path,\n",
    "                         relation,\n",
    "                         lm_probe=None,\n",
    "                         embedding_dim=768,\n",
    "                         scores_agg_func=None,\n",
    "                         topk=10,\n",
    "                         dest=None,\n",
    "                         **kwargs):\n",
    "    '''\n",
    "    For each head / tail, rank candidate tails / heads by overall scores. \n",
    "    (v4: Not limited to base -> new; can be new -> new; however, only head->tail, no tail->head)\n",
    "    Current (default) overall score: 0.1 * ht_sim + 10 * concept_sim + 0.1 * log(lm_prob)\n",
    "    '''\n",
    "    \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    seed_relations_df = pd.read_csv(seed_relations_path)\n",
    "    relation_row = seed_relations_df[seed_relations_df['alignedRelationName'] == relation].iloc[0]\n",
    "    entity_embeddings = load_embeddings(emb_path, embedding_dim)\n",
    "    entity_emb_dict = dict(zip(entity_embeddings['entity'].tolist(),\n",
    "                               entity_embeddings['embedding'].tolist()))\n",
    "    concept_knn_results = pd.read_csv(concept_knn_path)\n",
    "    \n",
    "    with open(templates_path, 'r') as f:\n",
    "        all_templates = json.load(f)\n",
    "    templates = all_templates[relation]\n",
    "    templates = templates['positive'] + templates['negative']\n",
    "\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    if scores_agg_func is None:\n",
    "        scores_agg_func = lambda ht_sim, h_sim, t_sim, lm_prob : ht_sim + h_sim + t_sim + np.log10(lm_prob)\n",
    "    \n",
    "    head_type = relation_row['domain']\n",
    "    tail_type = relation_row['range']\n",
    "#     head_type = \"company\"\n",
    "#     tail_type = \"dress_code\"\n",
    "    print(head_type, '\\t', tail_type)\n",
    "    seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == head_type]['seedInstances'].item()\n",
    "#     seed_heads = eval(list(seed_heads)[0])\n",
    "    seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == tail_type]['seedInstances'].item()\n",
    "#     seed_tails = eval(list(seed_tails)[0])\n",
    "    print('seed_heads:', seed_heads)\n",
    "    print('seed_tails:', seed_tails)\n",
    "\n",
    "    # Candidate heads / tails from concept knn \n",
    "    cand_heads_df = concept_knn_results[concept_knn_results['concept'] == head_type]\n",
    "    cand_tails_df = concept_knn_results[concept_knn_results['concept'] == tail_type]\n",
    "    cand_heads_dict = dict(zip(cand_heads_df['neighbor'].tolist(), cand_heads_df['sim'].tolist()))\n",
    "    cand_tails_dict = dict(zip(cand_tails_df['neighbor'].tolist(), cand_tails_df['sim'].tolist()))\n",
    "    for h in seed_heads:\n",
    "        assert h not in cand_heads_dict\n",
    "        cand_heads_dict[h] = 1.0\n",
    "    for t in seed_tails:\n",
    "        assert t not in cand_tails_dict\n",
    "        cand_tails_dict[t] = 1.0\n",
    "        \n",
    "    \n",
    "    all_extraction_results = []\n",
    "    \n",
    "    for c_head in tqdm(cand_heads_dict.keys(), total=len(cand_heads_dict)):\n",
    "        c_head_tokenized = lm_probe.tokenizer.tokenize(c_head)\n",
    "        if len(c_head_tokenized) > 2:\n",
    "            continue\n",
    "\n",
    "        extraction_results = []\n",
    "\n",
    "        ## For each tail, extract concept sim, head sim, lm score, combine and report\n",
    "        \n",
    "        cand_bins = {1: [], 2: []} ## TODO: allow higher grams; switch to GPT-2 for fair probs \n",
    "        for c_tail in cand_tails_dict.keys():\n",
    "            if c_tail == c_head:\n",
    "                continue\n",
    "            c_tail_tokenized = lm_probe.tokenizer.tokenize(c_tail)\n",
    "            if len(c_tail_tokenized) in [1, 2]:\n",
    "                cand_bins[len(c_tail_tokenized)].append(c_tail_tokenized)\n",
    "        \n",
    "        cand_scores_per_template = []\n",
    "        for template in templates:\n",
    "            _unigram_template = '[CLS] ' + template.format(c_head, '[MASK]') + '[SEP]'\n",
    "            _bigram_template = '[CLS] ' + template.format(c_head, '[MASK] [MASK]') + '[SEP]'\n",
    "\n",
    "            _cand_scores_1 = lm_probe.score_candidates(_unigram_template, cand_bins[1])\n",
    "            _cand_scores_2 = lm_probe.score_candidates(_bigram_template, cand_bins[2])\n",
    "            _cand_scores = sorted(_cand_scores_1 + _cand_scores_2, key=lambda d : d[\"cand\"])\n",
    "            # List[Dict[\"cand\", \"score\"]]\n",
    "            cand_scores_per_template.append(_cand_scores)\n",
    "    \n",
    "        cand_scores = []  # List[Dict[\"cand\", \"score\"]], for each \"cand\" the average score \n",
    "        for _cand_score_lst in zip(*cand_scores_per_template):\n",
    "            # _cand_score_lst: List[Dict[\"cand\", \"score\"]], for the same \"cand\" and different template \n",
    "            _cand = _cand_score_lst[0][\"cand\"]\n",
    "            assert all(d[\"cand\"] == _cand for d in _cand_score_lst), _cand_score_lst\n",
    "            _score = np.mean([d[\"score\"] for d in _cand_score_lst])\n",
    "            cand_scores.append({\"cand\": _cand, \"score\": _score})\n",
    "#         cand_scores.sort(key = lambda d : d[\"score\"], reverse=True)\n",
    "\n",
    "        for d in cand_scores:\n",
    "            e_tail = ' '.join(d[\"cand\"]).replace(' ##', '')\n",
    "            if e_tail not in cand_tails_dict:\n",
    "                continue\n",
    "\n",
    "            lm_score = d[\"score\"]\n",
    "            try:\n",
    "                ht_sim_score = 1 - cosine(entity_emb_dict[c_head], entity_emb_dict[e_tail])\n",
    "            except KeyError:\n",
    "                print(f'** embedding of {c_head}: {(c_head in entity_emb_dict)}')\n",
    "                print(f'** embedding of {e_tail}: {(e_tail in entity_emb_dict)}')\n",
    "                ht_sim_score = float(\"nan\")\n",
    "            head_sim_score = cand_heads_dict[c_head]\n",
    "            tail_sim_score = cand_tails_dict[e_tail]\n",
    "            overall_score = scores_agg_func(ht_sim_score, head_sim_score, tail_sim_score, lm_score)\n",
    "\n",
    "            extraction_results.append({'head': c_head, 'relation': relation, 'tail': e_tail,\n",
    "                                       'ht_sim_score': ht_sim_score,\n",
    "                                       'head_sim_score': head_sim_score,\n",
    "                                       'tail_sim_score': tail_sim_score,\n",
    "                                       'lm_score': lm_score,\n",
    "                                       'overall_score': overall_score})\n",
    "        \n",
    "        # extraction_results.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "        all_extraction_results.extend(extraction_results[:topk])\n",
    "\n",
    "    all_extraction_results.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "    all_extraction_results = all_extraction_results[:topk]\n",
    "        \n",
    "    results_df = pd.DataFrame(all_extraction_results)\n",
    "    if dest is not None:\n",
    "        results_df.to_csv(dest, index=None)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company \t benefits\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9307f6c82c94efcae96615f9f922a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>ht_sim_score</th>\n",
       "      <th>head_sim_score</th>\n",
       "      <th>tail_sim_score</th>\n",
       "      <th>lm_score</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>business</td>\n",
       "      <td>0.993406</td>\n",
       "      <td>0.991990</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.415795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home depot</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>car insurance</td>\n",
       "      <td>0.959858</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.973259</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.331895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fulfillment center</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>business</td>\n",
       "      <td>0.983125</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.205897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corporate office</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>business</td>\n",
       "      <td>0.984971</td>\n",
       "      <td>0.988309</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.200351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>store level</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>cards</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.988855</td>\n",
       "      <td>0.975875</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.181516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 head      relation           tail  ht_sim_score  \\\n",
       "0             company  has_benefits       business      0.993406   \n",
       "1          home depot  has_benefits  car insurance      0.959858   \n",
       "2  fulfillment center  has_benefits       business      0.983125   \n",
       "3    corporate office  has_benefits       business      0.984971   \n",
       "4         store level  has_benefits          cards      0.977417   \n",
       "\n",
       "   head_sim_score  tail_sim_score  lm_score  overall_score  \n",
       "0        0.991990        0.972477  0.002870       0.415795  \n",
       "1        0.996124        0.973259  0.002527       0.331895  \n",
       "2        0.987292        0.972477  0.001832       0.205897  \n",
       "3        0.988309        0.972477  0.001797       0.200351  \n",
       "4        0.988855        0.975875  0.001735       0.181516  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "# seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "# knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/knn_{cluster_size}.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_100.csv')\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "\n",
    "templates_path = 'templates_manual.json'\n",
    "\n",
    "extraction_save_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "# extraction_save_path = None\n",
    "\n",
    "extraction_results = direct_probing_RE_v4(seed_concepts_path=seed_aligned_concepts_path,\n",
    "                                          seed_relations_path=seed_aligned_relations_path,\n",
    "                                          emb_path=bert_emb_path,\n",
    "                                          concept_knn_path=concept_knn_path,\n",
    "                                          templates_path=templates_path,\n",
    "                                          relation='has_benefits',\n",
    "                                          lm_probe=lm_probe,\n",
    "                                          topk=10,\n",
    "                                          save_path=extraction_save_path)\n",
    "\n",
    "extraction_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = extraction_results.copy()\n",
    "df[df['head'] == 'walmart'].head(50)\n",
    "# df['overall_score'] = df['ht_sim_score'] * 0.1 + df['concept_sim_score'] * 10 + np.log10(df['lm_score'])\n",
    "# df.sort_values(by='overall_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = extraction_results.copy()\n",
    "df[df['tail'] == 'hair color'].head(50)\n",
    "# df['overall_score'] = df['ht_sim_score'] * 0.1 + df['concept_sim_score'] * 10 + np.log10(df['lm_score'])\n",
    "# df.sort_values(by='overall_score', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "company \t benefits\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "seed_head: walmart\n",
      "seed_head: amazon\n",
      "seed_head: subway\n",
      "seed_head: microsoft\n",
      "seed_head: target\n",
      "seed_tail: health insurance\n",
      "seed_tail: flexible schedule\n",
      "seed_tail: 401k\n",
      "seed_tail: paid vacation\n",
      "seed_tail: sick leave\n",
      "seed_tail: vision insurance\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_avg_scores.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE.csv \\\n",
    "-r has_benefits \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_1000.csv \\\n",
    "-topk 300 \\\n",
    "-dim 768\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction - LM scoring (full run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "company \t benefits\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "100%|█████████████████████████████████████████| 102/102 [47:42<00:00, 28.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_LM.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=LM_bert+seeds.csv \\\n",
    "-r has_benefits \\\n",
    "-ee $base_dir/data/$data_ac/intermediate/concept_knn_100.csv \\\n",
    "-lm bert \\\n",
    "-ex seeds \\\n",
    "-topk 3000 \\\n",
    "-dim 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python relation_extraction_LM.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=LM_pmi.csv \\\n",
    "-r has_benefits \\\n",
    "-ee $base_dir/data/$data_ac/intermediate/concept_knn_100.csv \\\n",
    "-lm pmi \\\n",
    "-topk 300 \\\n",
    "-dim 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Evaluation \n",
    "\n",
    "def load_benchmark(benchmark_full_path,\n",
    "                   seed_concepts_path,\n",
    "                   seed_relations_path):\n",
    "    benchmark = pd.read_csv(benchmark_full_path)\n",
    "    concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    relations_df = load_seed_aligned_relations(seed_relations_path)\n",
    "    \n",
    "    concepts_dict = dict(zip(concepts_df['alignedCategoryName'].tolist(), concepts_df.to_dict('records')))\n",
    "    relations_dict = dict(zip(relations_df['alignedRelationName'].tolist(), relations_df.to_dict('records')))\n",
    "    \n",
    "    # Dict[str(_type), Set[str(_e)]]\n",
    "    all_concepts = defaultdict(set)\n",
    "    # Dict[str(_r), Set[Tuple(_h, _r, _t)]]\n",
    "    all_rel_tuples = defaultdict(set)\n",
    "    \n",
    "    for i, row in benchmark.iterrows():\n",
    "        if row['type'] != 'fact':\n",
    "            continue\n",
    "        \n",
    "        _r = row['relation_name']\n",
    "        _h_type = row['n_head_category']\n",
    "        _t_type = row['n_tail_category']\n",
    "        \n",
    "        if _r not in relations_dict:\n",
    "            continue\n",
    "        _relation_row = relations_dict[_r]\n",
    "        if _relation_row['domain'] != _h_type or _relation_row['range'] != _t_type:\n",
    "            continue\n",
    "        \n",
    "        row_n_head = str(row['n_head']).lower()\n",
    "        row_n_tail = str(row['n_tail']).lower()\n",
    "        \n",
    "        if row_n_head == 'company':\n",
    "            evidence_sents = eval(str(row['sentences']))\n",
    "            head_instances = eval(str(row['Evidence']))\n",
    "            assert len(evidence_sents) == len(head_instances), f'Line {i} length mismatch'\n",
    "\n",
    "            for inst in head_instances:\n",
    "                if len(inst) > 0:\n",
    "                    all_concepts[_h_type].add(inst.lower())\n",
    "                    all_concepts[_t_type].add(row_n_tail)\n",
    "                    all_rel_tuples[_r].add(\n",
    "                        (inst.lower(), _r, row_n_tail)\n",
    "                    )\n",
    "        else:\n",
    "            # treat n_head directly as instance \n",
    "            all_concepts[_h_type].add(row_n_head)\n",
    "            all_concepts[_t_type].add(row_n_tail)\n",
    "            all_rel_tuples[_r].add(\n",
    "                (row_n_head, _r, row_n_tail)\n",
    "            )\n",
    "        \n",
    "    return all_concepts, all_rel_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 14)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "\n",
    "benchmark_concepts, benchmark_relations = load_benchmark(benchmark_full_path=benchmark_path,\n",
    "                                              seed_concepts_path=seed_aligned_concepts_path,\n",
    "                                              seed_relations_path=seed_aligned_relations_path)\n",
    "\n",
    "len(benchmark_concepts), len(benchmark_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "\n",
    "rel_extraction = pd.read_csv(rel_extraction_path)\n",
    "rel_extraction_list = rel_extraction[['head', 'tail']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 3597, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_relations_set = set([tuple(d.values()) for d in benchmark_relations_list])\n",
    "rel_extraction_set = set([tuple(d.values()) for d in rel_extraction_list])\n",
    "\n",
    "intersection = benchmark_relations_set & rel_extraction_set\n",
    "\n",
    "len(benchmark_relations_set), len(rel_extraction_set), len(intersection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=Ct+KV=0.9.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=LM_bert.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 10404\r\n",
      "Intersection: 9\r\n",
      "P = 0.0009, R = 0.1607, F1 = 0.0017\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('burger king', 'has_benefits', 'health')\r\n",
      "('burger king', 'has_benefits', 'sick leave')\r\n",
      "('dollar general', 'has_benefits', 'health insurance')\r\n",
      "('g4s', 'has_benefits', 'sick leave')\r\n",
      "('starbucks', 'has_benefits', 'health')\r\n",
      "('target', 'has_benefits', 'health insurance')\r\n",
      "('walmart', 'has_benefits', '401k')\r\n",
      "('walmart', 'has_benefits', 'life insurance')\r\n",
      "('walmart', 'has_benefits', 'paid vacations')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=Ct.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 3000\r\n",
      "Intersection: 3\r\n",
      "P = 0.0010, R = 0.0536, F1 = 0.0020\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('dollar general', 'has_benefits', 'health insurance')\r\n",
      "('walmart', 'has_benefits', '401k')\r\n",
      "('walmart', 'has_benefits', 'paid vacations')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=LM_pmi_greedy.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_background_screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 207\r\n",
      "Predicted relations: 10302\r\n",
      "Intersection: 42\r\n",
      "P = 0.0041, R = 0.2029, F1 = 0.0080\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('burger king', 'has_background_screening', 'credit history')\r\n",
      "('burger king', 'has_background_screening', 'drug test')\r\n",
      "('burger king', 'has_background_screening', 'random drug tests')\r\n",
      "('cracker barrel', 'has_background_screening', 'credit history')\r\n",
      "('cracker barrel', 'has_background_screening', 'criminal background')\r\n",
      "('cracker barrel', 'has_background_screening', 'criminal background check')\r\n",
      "('dollar general', 'has_background_screening', 'driving record')\r\n",
      "('dollar general', 'has_background_screening', 'social security number')\r\n",
      "('family dollar', 'has_background_screening', 'credit history')\r\n",
      "('family dollar', 'has_background_screening', 'criminal record')\r\n",
      "('fedex', 'has_background_screening', 'random drug test')\r\n",
      "('geico', 'has_background_screening', 'background check')\r\n",
      "('geico', 'has_background_screening', 'drug test')\r\n",
      "('marshalls', 'has_background_screening', 'drug tests')\r\n",
      "('marshalls', 'has_background_screening', 'random drug test')\r\n",
      "('marshalls', 'has_background_screening', 'test')\r\n",
      "('old navy', 'has_background_screening', 'criminal background check')\r\n",
      "('sitel', 'has_background_screening', 'random drug test')\r\n",
      "('subway', 'has_background_screening', 'drug tests')\r\n",
      "('subway', 'has_background_screening', 'test')\r\n",
      "('target', 'has_background_screening', 'background check')\r\n",
      "('target', 'has_background_screening', 'criminal record')\r\n",
      "('target', 'has_background_screening', 'drug test')\r\n",
      "('target', 'has_background_screening', 'drug tests')\r\n",
      "('target', 'has_background_screening', 'drugs')\r\n",
      "('target', 'has_background_screening', 'previous employment')\r\n",
      "('target', 'has_background_screening', 'random drug tests')\r\n",
      "('verizon', 'has_background_screening', 'criminal background')\r\n",
      "('walgreens', 'has_background_screening', 'drug test')\r\n",
      "('walmart', 'has_background_screening', 'background check')\r\n",
      "('walmart', 'has_background_screening', 'credit check')\r\n",
      "('walmart', 'has_background_screening', 'criminal background')\r\n",
      "('walmart', 'has_background_screening', 'criminal background check')\r\n",
      "('walmart', 'has_background_screening', 'criminal history')\r\n",
      "('walmart', 'has_background_screening', 'criminal record')\r\n",
      "('walmart', 'has_background_screening', 'driving record')\r\n",
      "('walmart', 'has_background_screening', 'drug test')\r\n",
      "('walmart', 'has_background_screening', 'drugs')\r\n",
      "('walmart', 'has_background_screening', 'random drug tests')\r\n",
      "('walmart', 'has_background_screening', 'social media')\r\n",
      "('wells fargo', 'has_background_screening', 'credit check')\r\n",
      "('wells fargo', 'has_background_screening', 'dui')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_background_screening-RE=Ct.csv \\\n",
    "-r has_background_screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 207\r\n",
      "Predicted relations: 2196\r\n",
      "Intersection: 41\r\n",
      "P = 0.0187, R = 0.1981, F1 = 0.0341\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('burger king', 'has_background_screening', 'credit history')\r\n",
      "('burger king', 'has_background_screening', 'drug test')\r\n",
      "('burger king', 'has_background_screening', 'random drug tests')\r\n",
      "('cracker barrel', 'has_background_screening', 'credit history')\r\n",
      "('cracker barrel', 'has_background_screening', 'criminal background')\r\n",
      "('cracker barrel', 'has_background_screening', 'criminal background check')\r\n",
      "('dollar general', 'has_background_screening', 'driving record')\r\n",
      "('dollar general', 'has_background_screening', 'social security number')\r\n",
      "('family dollar', 'has_background_screening', 'credit history')\r\n",
      "('family dollar', 'has_background_screening', 'criminal record')\r\n",
      "('fedex', 'has_background_screening', 'random drug test')\r\n",
      "('geico', 'has_background_screening', 'background check')\r\n",
      "('geico', 'has_background_screening', 'drug test')\r\n",
      "('marshalls', 'has_background_screening', 'drug tests')\r\n",
      "('marshalls', 'has_background_screening', 'test')\r\n",
      "('old navy', 'has_background_screening', 'criminal background check')\r\n",
      "('sitel', 'has_background_screening', 'random drug test')\r\n",
      "('subway', 'has_background_screening', 'drug tests')\r\n",
      "('subway', 'has_background_screening', 'test')\r\n",
      "('target', 'has_background_screening', 'background check')\r\n",
      "('target', 'has_background_screening', 'criminal record')\r\n",
      "('target', 'has_background_screening', 'drug test')\r\n",
      "('target', 'has_background_screening', 'drug tests')\r\n",
      "('target', 'has_background_screening', 'drugs')\r\n",
      "('target', 'has_background_screening', 'previous employment')\r\n",
      "('target', 'has_background_screening', 'random drug tests')\r\n",
      "('verizon', 'has_background_screening', 'criminal background')\r\n",
      "('walgreens', 'has_background_screening', 'drug test')\r\n",
      "('walmart', 'has_background_screening', 'background check')\r\n",
      "('walmart', 'has_background_screening', 'credit check')\r\n",
      "('walmart', 'has_background_screening', 'criminal background')\r\n",
      "('walmart', 'has_background_screening', 'criminal background check')\r\n",
      "('walmart', 'has_background_screening', 'criminal history')\r\n",
      "('walmart', 'has_background_screening', 'criminal record')\r\n",
      "('walmart', 'has_background_screening', 'driving record')\r\n",
      "('walmart', 'has_background_screening', 'drug test')\r\n",
      "('walmart', 'has_background_screening', 'drugs')\r\n",
      "('walmart', 'has_background_screening', 'random drug tests')\r\n",
      "('walmart', 'has_background_screening', 'social media')\r\n",
      "('wells fargo', 'has_background_screening', 'credit check')\r\n",
      "('wells fargo', 'has_background_screening', 'dui')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_background_screening-RE=Ct+KV=0.9.csv \\\n",
    "-r has_background_screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMProbe-Joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15496,    11,   616,  3290,   318, 13779]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs = gpt2_tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _outputs = gpt2_model(**_inputs, labels=_inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9901607036590576"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_outputs.loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm_probe.fill_multi_mask(\"[CLS] The payment [MASK] [MASK] is nice. [SEP]\", topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "lm_probe_gpt2 = LMProbe_GPT2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cand': 'good plan', 'score': -4.1346964836120605},\n",
       " {'cand': 'good', 'score': -4.260444641113281},\n",
       " {'cand': 'plan', 'score': -5.5930562019348145}]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_gpt2.score_candidates(\"They have a very [MASK] .\", [\"good\", \"plan\", \"good plan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.47902297973633"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sent = \"Hello ! I would like to have a pizzaaaa\"\n",
    "_inputs = lm_probe_joint.gpt2_tokenizer(_sent, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    _outputs = lm_probe_joint.gpt2_model(**_inputs, labels=_inputs[\"input_ids\"])\n",
    "_outputs.loss.item() * (len(_sent.split(' ')) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [15496, 5145, 314, 561, 588, 284, 423, 257, 14256, 46071], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_joint.gpt2_tokenizer(_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15496,  5145,   314,   561,   588,   284,   423,   257, 14256, 46071]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'Ġ!', 'ĠI', 'Ġwould', 'Ġlike', 'Ġto', 'Ġhave', 'Ġa', 'Ġpizza', 'aaa']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_joint.gpt2_tokenizer.convert_ids_to_tokens([15496,  5145,   314,   561,   588,   284,   423,   257, 14256, 46071])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "code_folding": [
     17
    ]
   },
   "outputs": [],
   "source": [
    "# LMProbe_Joint with bert probs renormalized by gpt2 \n",
    "\n",
    "def _bert_untokenize(pieces):\n",
    "    return ' '.join(pieces).replace(' ##', '')\n",
    "\n",
    "class LMProbe_Joint(object):\n",
    "    def __init__(self,\n",
    "                 bert_model_name='bert-base-uncased',\n",
    "                 gpt2_model_name='gpt2',\n",
    "                 max_n_grams=5,\n",
    "                 use_gpu=False):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.bert_model = BertForMaskedLM.from_pretrained(bert_model_name)\n",
    "        self.bert_model.to(self.device)\n",
    "        self.bert_model.eval()\n",
    "        self.bert_mask_token = self.bert_tokenizer.mask_token\n",
    "        \n",
    "        self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model_name)\n",
    "        self.gpt2_model = GPT2LMHeadModel.from_pretrained(gpt2_model_name, return_dict=True)\n",
    "        self.gpt2_model.to(self.device)\n",
    "        self.gpt2_model.eval()\n",
    "        \n",
    "        self.max_n_grams = max_n_grams\n",
    "        \n",
    "    def joint_score_candidates(self, input_txt, cands, renorm_n=10):\n",
    "        # cands: List[str], list candidates (untokenzied) \n",
    "        \n",
    "        if input_txt.count(\"[MASK]\") != 1:\n",
    "            raise Exception(f'Input string must have exactly one mask token, got {input_txt}')\n",
    "\n",
    "        cand_bins = {i : [] for i in range(1, self.max_n_grams + 1)}\n",
    "        for c in cands:\n",
    "            c_tokenized = self.bert_tokenizer.tokenize(c)\n",
    "            if len(c_tokenized) > self.max_n_grams:\n",
    "                print(f'{c_tokenized}: too many wordpieces')\n",
    "                continue\n",
    "            cand_bins[len(c_tokenized)].append(c_tokenized)\n",
    "        \n",
    "        all_cand_scores = []\n",
    "        for c_len in range(1, self.max_n_grams + 1):\n",
    "            _cands = cand_bins[c_len]\n",
    "            if len(_cands) == 0:\n",
    "                continue\n",
    "            \n",
    "            _input = \"[CLS] \" + input_txt.replace(\"[MASK]\", \"[MASK]\" + \" [MASK]\" * (c_len - 1)) + \" [SEP]\"\n",
    "            _cand_scores = self.bert_score_candidates(_input, _cands)\n",
    "            \n",
    "            _renorm_cand_dicts = _cand_scores[:renorm_n]\n",
    "            _renorm_bert_scores = {_bert_untokenize(d['cand']) : d['score'] for d in _renorm_cand_dicts}\n",
    "            _renorm_cands = list(_renorm_bert_scores.keys())\n",
    "            \n",
    "            _gpt2_cand_scores = self.gpt2_score_candidates(input_txt, _renorm_cands)\n",
    "            _renorm_gpt2_scores = {d['cand'] : d['score'] for d in _gpt2_cand_scores}\n",
    "            \n",
    "#             print('BERT scores:')\n",
    "#             print(json.dumps(_renorm_bert_scores, indent=2))\n",
    "#             print('GPT2 scores:')\n",
    "#             print(json.dumps(_renorm_gpt2_scores, indent=2))\n",
    "#             if len(_renorm_cands) > 2:\n",
    "#                 print('Pearson:')\n",
    "#                 print(pearsonr(\n",
    "#                     np.exp([_renorm_bert_scores[c] for c in _renorm_cands]),\n",
    "#                     np.exp([_renorm_gpt2_scores[c] for c in _renorm_cands])))\n",
    "            \n",
    "            # bert_ll + _renorm_bias -> gpt2_ll\n",
    "            _renorm_bias = np.log(np.sum(np.exp(list(_renorm_gpt2_scores.values())))) \\\n",
    "                - np.log(np.sum(np.exp(list(_renorm_bert_scores.values()))))\n",
    "            \n",
    "            _gpt2_len = len(self.gpt2_tokenizer(input_txt.replace('[MASK]', _renorm_cands[0]))['input_ids'])\n",
    "            \n",
    "            _renormed_cand_scores = [\n",
    "                {'cand': _bert_untokenize(d['cand']),\n",
    "                 'score': (d['score'] + _renorm_bias) / _gpt2_len}\n",
    "                for d in _cand_scores\n",
    "            ]\n",
    "            all_cand_scores.extend(_renormed_cand_scores)\n",
    "        \n",
    "        all_cand_scores.sort(key=lambda d : d['score'], reverse=True)\n",
    "        return all_cand_scores\n",
    "    \n",
    "    \n",
    "    def bert_score_candidates(self, input_txt, cands):\n",
    "        # cands: List[List[str]], list of tokenized candidates \n",
    "        tokenized_txt = self.bert_tokenizer.tokenize(input_txt)\n",
    "        \n",
    "        if tokenized_txt[0] != \"[CLS]\" or tokenized_txt[-1] != \"[SEP]\":\n",
    "            raise Exception(f'Input string must start with [CLS] and end with [SEP], got {input_txt}')\n",
    "        if \"[MASK]\" not in tokenized_txt:\n",
    "            raise Exception(f'Input string must have at least one mask token, got {input_txt}')\n",
    "        \n",
    "        indexed_tokens = self.bert_tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        mask_indices = [i for i, x in enumerate(tokenized_txt) if x == \"[MASK]\"]\n",
    "        segment_idx = tokens_tensor * 0\n",
    "        tokens_tensor = tokens_tensor.to(self.device)\n",
    "        segments_tensors = segment_idx.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert_model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.softmax(predictions, dim=-1)[0]\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "\n",
    "        cand_scores = []\n",
    "        for c in cands:\n",
    "            assert len(c) == len(mask_indices), f'cand {c}; len(mask_indices) = {len(mask_indices)}'\n",
    "\n",
    "            _scores = []\n",
    "            c_token_ids = self.bert_tokenizer.convert_tokens_to_ids(c)\n",
    "            for i, token_id in zip(mask_indices, c_token_ids):\n",
    "                _scores.append(probs[i, token_id].item())\n",
    "            score = np.sum(np.log(_scores))  # sum(log(p))\n",
    "            cand_scores.append({\"cand\": c, \"score\": score})\n",
    "\n",
    "        cand_scores.sort(key=lambda d : d[\"score\"], reverse=True)\n",
    "        return cand_scores\n",
    "    \n",
    "    def gpt2_score_candidates(self, input_txt, cands):\n",
    "        # cands: List[str], list candidates (untokenzied) \n",
    "        \n",
    "        if input_txt.count(\"[MASK]\") != 1:\n",
    "            raise Exception(f'Input string must have exactly one mask token, got {input_txt}')\n",
    "\n",
    "        cand_scores = []\n",
    "        for c in cands:\n",
    "            cand_input_txt = input_txt.replace(\"[MASK]\", c)\n",
    "            tokenized_input = self.gpt2_tokenizer(cand_input_txt, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                model_outputs = self.gpt2_model(**tokenized_input, labels=tokenized_input[\"input_ids\"])\n",
    "                \n",
    "            _input_len = tokenized_input['input_ids'].size(1)\n",
    "            score = -model_outputs.loss.item() * (_input_len - 1)  # (log(p))\n",
    "            cand_scores.append({\"cand\": c, \"score\": score})\n",
    "\n",
    "        cand_scores.sort(key=lambda d : d[\"score\"], reverse=True)\n",
    "        return cand_scores\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe_joint = LMProbe_Joint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT scores:\n",
      "{\n",
      "  \"good\": -3.820184215986424,\n",
      "  \"plan\": -5.464548142423097,\n",
      "  \"nice\": -5.78993798238308\n",
      "}\n",
      "GPT2 scores:\n",
      "{\n",
      "  \"good\": -21.302223205566406,\n",
      "  \"nice\": -23.64457607269287,\n",
      "  \"plan\": -27.965281009674072\n",
      "}\n",
      "Pearson:\n",
      "(0.9899664636147664, 0.09025804686068711)\n",
      "BERT scores:\n",
      "{\n",
      "  \"good plan\": -7.813247270006006\n",
      "}\n",
      "GPT2 scores:\n",
      "{\n",
      "  \"good plan\": -24.808178901672363\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'cand': 'good plan', 'score': -3.544025557381766},\n",
       " {'cand': 'good', 'score': -3.582741819734341},\n",
       " {'cand': 'plan', 'score': -3.856802474140453},\n",
       " {'cand': 'nice', 'score': -3.9110341141337837}]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_joint.joint_score_candidates(\"They have a very [MASK] .\", [\"good\", \"plan\", \"nice\", \"good plan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Verification baseline\n",
    "(finding co-occurrences of head / tail from corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "# # corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences.json')\n",
    "\n",
    "# indeed_dataset_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/question_answers.csv'\n",
    "# company_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/fccid-companyName.csv'\n",
    "\n",
    "# # with open(corpus_path, 'r') as f:\n",
    "# #     sent_dicts = [json.loads(l) for l in tqdm(f.readlines())]\n",
    "\n",
    "# indeed_dataset = pd.read_csv(indeed_dataset_path)\n",
    "# indeed_dataset = indeed_dataset[indeed_dataset['answerContent'].notna()]\n",
    "# company_df = pd.read_csv(company_path)\n",
    "# company_dict = dict(zip(company_df[\"fccompanyId\"].to_list(), company_df[\"companyName\"].to_list()))\n",
    "\n",
    "# indeed_dataset.shape, len(company_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 7)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relations = pd.read_csv(rel_extraction_path)\n",
    "df_relations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1819f0b55e494a85aab302ac773cb8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=413232.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "413232"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(corpus_path, 'r') as f:\n",
    "    sent_dicts = [json.loads(l) for l in tqdm(f.readlines())]\n",
    "\n",
    "len(sent_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['What', 'is', 'the', 'age', 'limit', '.'],\n",
       " 'company': 'Marshalls',\n",
       " 'entities': ['age limit', 'marshalls']}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dicts[1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_ses_dir = os.path.join(yutong_base_dir, \"repos\", \"Roberta_SES\")\n",
    "\n",
    "# 0 = contra, 1 = neutral, 2 = entail\n",
    "entailment_model = Roberta_SES_Entailment(roberta_path='/home/ubuntu/users/yutong/models/roberta-large',\n",
    "        ckpt_path=os.path.join(roberta_ses_dir, 'checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt'),\n",
    "        max_length=512,\n",
    "        device_name='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor([0.9978, 0.0012, 0.0010]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_model.predict(\n",
    "    \"walmart : no you can have tattoo\",\n",
    "    \"walmart allows tattoos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "# KV for (walmart, has_dress_code, uniform)\n",
    "\n",
    "_pos_templates = [\n",
    "    '{0} allows {1}',\n",
    "    '{0} requires {1}',\n",
    "]\n",
    "\n",
    "_neg_templates = [\n",
    "    '{0} doesn\\'t allow {1}',\n",
    "    '{0} doesn\\'t require {1}',\n",
    "]\n",
    "\n",
    "def find_evidences(head, tail, corpus=sent_dicts):\n",
    "    # (s1(evid), s2(tmpl), score)\n",
    "    _pos_evidences = []\n",
    "    _neg_evidences = []\n",
    "\n",
    "    for i, d in enumerate(sent_dicts):\n",
    "        if i > 0 and i % 50000 == 0:\n",
    "            print(f'Progress: {i} / {len(sent_dicts)}')\n",
    "            \n",
    "#         _company_id = row['fccompanyId']\n",
    "#         _company = company_dict[_company_id]\n",
    "\n",
    "#         _answer = row['answerContent']\n",
    "#         _tokens = [str(t) for t in spacy_tokenizer(_answer)]\n",
    "#         _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "        _company = d['company']\n",
    "        _tokens = d['tokens']\n",
    "        _s = f\"{_company.lower()} : {' '.join(_tokens).lower()}\"\n",
    "\n",
    "        if head in d['entities'] and tail in d['entities']:\n",
    "            # Try all pos/neg relation templates, save the best template  \n",
    "            _max_pos_ev = (None, None, 0)\n",
    "            for _tmpl in _pos_templates:\n",
    "                _tmpl_filled = _tmpl.format(head, tail)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_s, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_pos_ev[-1]:\n",
    "                    _max_pos_ev = (_s, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _max_neg_ev = (None, None, 0)\n",
    "            for _tmpl in _neg_templates:\n",
    "                _tmpl_filled = _tmpl.format(head, tail)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_s, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_neg_ev[-1]:\n",
    "                    _max_neg_ev = (_s, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _pos_evidences.append(_max_pos_ev)\n",
    "            _neg_evidences.append(_max_neg_ev)\n",
    "    \n",
    "    _pos_evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    _neg_evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    return _pos_evidences, _neg_evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_pos_evidences, _neg_evidences = find_evidences('walmart', 'black jeans')\n",
    "'POS:', _pos_evidences[:10], 'NEG:', _neg_evidences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def find_evidences_RE(df_relations, corpus=sent_dicts, p_thres=0.7):\n",
    "    ## TODO: to script \n",
    "    \n",
    "    # Dict[Tuple(head, rel, tail): List[Tuple(s1(evid), s2(tmpl), score)]]\n",
    "    pos_evidences = defaultdict(list)\n",
    "    neg_evidences = defaultdict(list)\n",
    "    \n",
    "    # collect all relations \n",
    "    rels = []\n",
    "    head2rels = defaultdict(list)\n",
    "    tail2rels = defaultdict(list)\n",
    "    for i, row in df_relations.iterrows():\n",
    "        _h = row['head']\n",
    "        _t = row['tail']\n",
    "        _r = 'has_dress_code'\n",
    "        rels.append((_h, _r, _t))\n",
    "        if row['base'] == 'HEAD':\n",
    "            head2rels[_h].append((_h, _r, _t))\n",
    "        else:\n",
    "            tail2rels[_t].append((_h, _r, _t))\n",
    "\n",
    "    # collect sents for each entity \n",
    "    entity2sents = defaultdict(set)\n",
    "    for i, d in enumerate(sent_dicts):\n",
    "        _s = f\"{d['company']} : {' '.join(d['tokens'])}\".lower()\n",
    "        for _e in d['entities']:\n",
    "            entity2sents[_e].add(_s)\n",
    "    \n",
    "    for _h, _r, _t in tqdm(rels[200::200]):\n",
    "        # assure key existence\n",
    "        _ = pos_evidences[(_h, _r, _t)]\n",
    "        _ = neg_evidences[(_h, _r, _t)]\n",
    "        \n",
    "        h_sents = entity2sents[_h]\n",
    "        t_sents = entity2sents[_t]\n",
    "        intersect_sents = h_sents & t_sents\n",
    "        \n",
    "        for _s in intersect_sents:\n",
    "            _ss = _s.strip()\n",
    "\n",
    "            # Try all pos/neg relation templates, save the best template  \n",
    "            _max_pos_ev = (None, None, 0)\n",
    "            for _tmpl in _pos_templates:\n",
    "                _tmpl_filled = _tmpl.format(_h, _t)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_pos_ev[-1]:\n",
    "                    _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _max_neg_ev = (None, None, 0)\n",
    "            for _tmpl in _neg_templates:\n",
    "                _tmpl_filled = _tmpl.format(_h, _t)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_neg_ev[-1]:\n",
    "                    _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "            if _max_pos_ev[-1] > p_thres:\n",
    "                pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "            if _max_neg_ev[-1] > p_thres:\n",
    "                neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "    \n",
    "    \n",
    "#     # Head-base\n",
    "#     for _h, _rels in rel_head_index.items():\n",
    "#         # First find sentences with _h\n",
    "#         _h_sents = [] \n",
    "#         for i, d in enumerate(sent_dicts):\n",
    "#             _company = d['company']\n",
    "#             _tokens = d['tokens']\n",
    "#             _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "#             if f' {_h} ' in _s:\n",
    "#                 _h_sents.append(_s)\n",
    "        \n",
    "#         # KV: check for _t only; entail\n",
    "#         for _h, _r, _t in tqdm(_rels):\n",
    "#             for _s in _h_sents:\n",
    "#                 if f' {_t} ' in _s:\n",
    "#                     _ss = _s.strip()\n",
    "                    \n",
    "#                     # Try all pos/neg relation templates, save the best template  \n",
    "#                     _max_pos_ev = (None, None, 0)\n",
    "#                     for _tmpl in _pos_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(_h, _t)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_pos_ev[-1]:\n",
    "#                             _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     _max_neg_ev = (None, None, 0)\n",
    "#                     for _tmpl in _neg_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(_h, _t)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_neg_ev[-1]:\n",
    "#                             _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     if _max_pos_ev[-1] > p_thres:\n",
    "#                         pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "#                     if _max_neg_ev[-1] > p_thres:\n",
    "#                         neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "\n",
    "#     # Tail-base\n",
    "#     for _t, _rels in tqdm(rel_tail_index.items(), total=len(rel_tail_index)):\n",
    "#         # First find sentences with _t\n",
    "#         _t_sents = [] \n",
    "#         for i, d in enumerate(sent_dicts):\n",
    "#             _company = d['company']\n",
    "#             _tokens = d['tokens']\n",
    "#             _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "#             if f' {_t} ' in _s:\n",
    "#                 _t_sents.append(_s)\n",
    "        \n",
    "#         # KV: check for _h only; entail\n",
    "#         for _h, _r, _t in tqdm(_rels):\n",
    "#             if (_h, _r, _t) in pos_evidences or (_h, _r, _t) in neg_evidences:\n",
    "#                 # already computed \n",
    "#                 continue\n",
    "#             for _s in _t_sents:\n",
    "#                 if f' {_h} ' in _s:\n",
    "#                     _ss = _s.strip()\n",
    "                    \n",
    "#                     # Try all pos/neg relation templates, save the best template  \n",
    "#                     _max_pos_ev = (None, None, 0)\n",
    "#                     for _tmpl in _pos_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(head, tail)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_pos_ev[-1]:\n",
    "#                             _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     _max_neg_ev = (None, None, 0)\n",
    "#                     for _tmpl in _neg_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(head, tail)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_neg_ev[-1]:\n",
    "#                             _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     if _max_pos_ev[-1] > p_thres:\n",
    "#                         pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "#                     if _max_neg_ev[-1] > p_thres:\n",
    "#                         neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "\n",
    "    for _rel, _evidences in pos_evidences.items():\n",
    "        _evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    for _rel, _evidences in neg_evidences.items():\n",
    "        _evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    return pos_evidences, neg_evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = find_evidences_RE(df_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use script \n",
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-in $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE.csv \\\n",
    "-o_kv $base_dir/data/$data_ac/intermediate/kv_evidences-has_benefits-RE.json \\\n",
    "-o_re $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE+KV_0.9.csv \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p_kv 0.7 \\\n",
    "-p_re 0.9 \\\n",
    "--fast_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate \n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "\n",
    "benchmark_relations_list = load_benchmark_relations(benchmark_path)\n",
    "len(benchmark_relations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_evidences_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/kv_evidences.json')\n",
    "\n",
    "with open(kv_evidences_path, 'r') as f:\n",
    "    kv_evidences = [json.loads(l) for l in f.readlines()]\n",
    "len(kv_evidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_thres = 0.9\n",
    "\n",
    "kv_filtered_rels = []\n",
    "for d in kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences']\n",
    "    _neg_evs = d['neg_evidences']\n",
    "    if (len(_pos_evs) > 0 and _pos_evs[0][-1] > p_thres):\n",
    "        kv_filtered_rels.append((_h, _t))\n",
    "    elif (len(_neg_evs) > 0 and _neg_evs[0][-1] > p_thres):\n",
    "        kv_filtered_rels.append((_h, _t))\n",
    "\n",
    "len(kv_filtered_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 665, 6)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_relations_set = set([tuple(d.values()) for d in benchmark_relations_list])\n",
    "kv_filtered_rels_set = set(kv_filtered_rels)\n",
    "\n",
    "intersection = benchmark_relations_set & kv_filtered_rels_set\n",
    "\n",
    "len(benchmark_relations_set), len(kv_filtered_rels_set), len(intersection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('best buy', 'uniform'),\n",
       " ('costco', 'hair color'),\n",
       " ('dd', 'facial hair'),\n",
       " ('dollar tree', 'uniform'),\n",
       " ('family dollar', 'facial hair'),\n",
       " ('walmart', 'uniform')}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences']\n",
    "    _neg_evs = d['neg_evidences']\n",
    "    \n",
    "    if (_h, _t) in intersection:\n",
    "        print(_h, _t)\n",
    "        _max = sorted(_pos_evs + _neg_evs, key=lambda p : p[-1], reverse=True)[0]\n",
    "        print(_max)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kv_evidences = list(kv_evidences)\n",
    "\n",
    "for d in test_kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences'][:5]\n",
    "    _neg_evs = d['neg_evidences'][:5]\n",
    "    \n",
    "    _max = sorted(_pos_evs + _neg_evs, key=lambda p : p[-1], reverse=True)[0]\n",
    "    d['pos_evidences'] = _pos_evs\n",
    "    d['neg_evidences'] = _neg_evs\n",
    "    d['max_ev'] = _max\n",
    "\n",
    "sorted(test_kv_evidences, key=lambda d : d['max_ev'][-1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KV analysis: multi-supporting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_ses_dir = os.path.join(yutong_base_dir, \"repos\", \"Roberta_SES\")\n",
    "\n",
    "# 0 = contra, 1 = neutral, 2 = entail\n",
    "entailment_model = Roberta_SES_Entailment(roberta_path='/home/ubuntu/users/yutong/models/roberta-large',\n",
    "        ckpt_path=os.path.join(roberta_ses_dir, 'checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt'),\n",
    "        max_length=512,\n",
    "        device_name='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2), tensor([0.0019, 0.0084, 0.9897]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_model.predict(\n",
    "    'walmart : we have to wear uniform',\n",
    "    'walmart requires uniform'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2), tensor([0.0036, 0.0650, 0.9314]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_model.predict(\n",
    "    'walmart : we have to wear uniform',\n",
    "    'walmart offers uniform'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2), tensor([0.0146, 0.2898, 0.6956]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_model.predict(\n",
    "    'walmart : the uniform is comfortable so we like it',\n",
    "    'walmart requires uniform'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2779,\n",
       " dict_keys(['has_job_position', 'has_benefits', 'has_pay_schedule', 'has_dress_code', 'has_background_screening', 'hires_person']))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/kv_evidences-has_dress_code-RE=Ct.json')\n",
    "templates_path = os.path.join(base_dir, f'src/concept_learning/templates_manual.json')\n",
    "\n",
    "with open(kv_path, 'r') as f:\n",
    "    kv_dicts = [json.loads(l) for l in f]\n",
    "with open(templates_path, 'r') as f:\n",
    "    all_templates = json.load(f)\n",
    "    \n",
    "len(kv_dicts), all_templates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relation': ['walmart', 'has_dress_code', 'business casual'],\n",
       " 'pos_evidences': [['walmart : business casual with a walmart vest',\n",
       "   'walmart requires business casual',\n",
       "   0.9809538125991821],\n",
       "  ['walmart : i was told “ business casual ” ... any colored shirt ( no logo or pictures ) , jeans or pants and close toed shoes .',\n",
       "   'walmart allows business casual',\n",
       "   0.8808652758598328]],\n",
       " 'neg_evidences': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18abeb02ceef40dc8f23eb4d7d2de77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_multi_supporting_evs = []\n",
    "\n",
    "for d in tqdm(kv_dicts[::500]):\n",
    "    head, rel, tail = d['relation']\n",
    "    pos_evs = d['pos_evidences']\n",
    "    neg_evs = d['neg_evidences']\n",
    "    good_evs = [ev for ev in pos_evs + neg_evs if ev[-1] > 0.9]\n",
    "    if len(good_evs) == 0:\n",
    "        continue\n",
    "    \n",
    "    for ev_tuple in good_evs:\n",
    "        ev_sent, ev_hyp, score = ev_tuple\n",
    "        _supports = [(rel, ev_hyp, score)] # what are the relations supported \n",
    "        for _r, (_p_templates, _n_templates) in all_templates.items():\n",
    "            if _r == rel:\n",
    "                continue\n",
    "\n",
    "            _templates = _p_templates + _n_templates\n",
    "            for _tmpl in _templates:\n",
    "                _hyp = _tmpl.format(head, tail)\n",
    "                _score = entailment_model.predict(ev_sent, _hyp)[1][2].item()\n",
    "                if _score > 0.9:\n",
    "                    _supports.append((_r, _hyp, _score))\n",
    "                    break\n",
    "    \n",
    "        if len(_supports) > 1:\n",
    "            _multi_supporting_evs.append((ev_sent, _supports))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_multi_supporting_evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KV feedback to EE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has_dress_code: company / dress_code \n",
    "kv_rels_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction-has_dress_code-RE=Ct+KV=0.9.csv')\n",
    "\n",
    "benchmark_dir = os.path.join(base_dir, f'data/indeed-benchmark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2052, 3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_rels = pd.read_csv(kv_rels_path)\n",
    "kv_rels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 99)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_heads = set(kv_rels['head'].tolist())\n",
    "kv_tails = set(kv_rels['tail'].tolist())\n",
    "\n",
    "len(kv_heads), len(kv_tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv_ee_output_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/entities-KV=0.9.csv')\n",
    "_records = []\n",
    "for e in kv_heads:\n",
    "    _records.append({'concept': 'company', 'neighbor': e})\n",
    "for e in kv_tails:\n",
    "    _records.append({'concept': 'dress_code', 'neighbor': e})\n",
    "pd.DataFrame(_records).to_csv(kv_ee_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_concepts, _all_rel_tuples = load_benchmark(benchmark_full_path=benchmark_path,\n",
    "                                                seed_concepts_path=seed_aligned_concepts_path,\n",
    "                                                seed_relations_path=seed_aligned_relations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 93)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_all_concepts['company']), len(kv_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kv_heads & _all_concepts['company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amazon',\n",
       " 'at&t',\n",
       " 'best buy',\n",
       " 'burger king',\n",
       " 'chipotle',\n",
       " 'costco',\n",
       " 'cracker barrel',\n",
       " 'cvs',\n",
       " 'dd',\n",
       " 'dollar general',\n",
       " 'dollar tree',\n",
       " 'dunkin donuts',\n",
       " 'family dollar',\n",
       " 'fedex',\n",
       " 'frito lay',\n",
       " 'g4s',\n",
       " 'geico',\n",
       " 'hobby lobby',\n",
       " 'home depot',\n",
       " 'ihop',\n",
       " 'jcpenney',\n",
       " 'kfc',\n",
       " 'kroger',\n",
       " 'little caesars',\n",
       " 'marshalls',\n",
       " 'mcdonalds',\n",
       " 'menards',\n",
       " 'old navy',\n",
       " 'olive garden',\n",
       " 'panera bread',\n",
       " 'pepsico',\n",
       " 'petsmart',\n",
       " 'pizza hut',\n",
       " 'planet fitness',\n",
       " 'publix',\n",
       " 'safeway',\n",
       " 'sitel',\n",
       " 'spectrum',\n",
       " 'starbucks',\n",
       " 'subway',\n",
       " 'taco bell',\n",
       " 'target',\n",
       " 'tj maxx',\n",
       " 'training',\n",
       " 'verizon',\n",
       " 'walgreens',\n",
       " 'walmart',\n",
       " 'wells fargo'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_heads & _all_concepts['company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare \n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_100.csv')\n",
    "concept_knn_df = pd.read_csv(concept_knn_path)\n",
    "_knn_entities = set(concept_knn_df[concept_knn_df['concept'] == 'company']['neighbor'].tolist())\n",
    "len(_knn_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amazon', 'microsoft', 'subway', 'target', 'walmart'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "_seed_entities = set(seed_concepts_df[seed_concepts_df['alignedCategoryName'] == 'company']['seedInstances'].item())\n",
    "_seed_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_combine_entities = set(_seed_entities) | _knn_entities\n",
    "len(_combine_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_combine_entities & _all_concepts['company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussions:\n",
    "# coherence clustering / ensemble models?\n",
    "# trying for other relations or entities\n",
    "# using entities in sub-categories\n",
    "# fine-tuning\n",
    "# ambiguous samples (high for pos and neg)\n",
    "# quantitative-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore various techniques\n",
    "# Get prompts \"between\" entities\n",
    "# Get prompts by syntactic parsing\n",
    "# Get prompts by paraphrasing\n",
    "# Get prompts uisng AutoPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit here: /meg-kb/src/analysis/pattern_mining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Amazon []\n",
      "1 is [Amazon, place, .]\n",
      "2 a []\n",
      "3 good []\n",
      "4 place [a, good, for]\n",
      "5 for [working]\n",
      "6 working [as]\n",
      "7 as [time]\n",
      "8 a []\n",
      "9 part []\n",
      "10 - []\n",
      "11 time [a, part, -]\n",
      "12 . []\n"
     ]
    }
   ],
   "source": [
    "_sent = \"Amazon is a good place for working as a part-time.\"\n",
    "_doc = _nlp(_sent)\n",
    "for _t in _doc:\n",
    "    print(_t.i, _t, list(_t.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7fbf27eb0430>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = []\n",
    "for _t in _doc:\n",
    "    for child in _t.children:\n",
    "        edges.append(('{}-{}'.format(_t.lower_,_t.i), '{}-{}'.format(child.lower_,child.i))) \n",
    "\n",
    "graph = nx.Graph(edges)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([('is-1', 'amazon-0'), ('is-1', 'place-4'), ('is-1', '.-12'), ('place-4', 'a-2'), ('place-4', 'good-3'), ('place-4', 'for-5'), ('for-5', 'working-6'), ('working-6', 'as-7'), ('as-7', 'time-11'), ('time-11', 'a-8'), ('time-11', 'part-9'), ('time-11', '--10')])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon-0', 'is-1', 'place-4', 'for-5', 'working-6', 'as-7', 'time-11']\n"
     ]
    }
   ],
   "source": [
    "_src = 'amazon-0'\n",
    "_tgt = 'time-11'\n",
    "if nx.has_path(graph, source=_src, target=_tgt):\n",
    "    path = nx.shortest_path(graph, source=_src, target=_tgt)\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'amazon-0' in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('is-1', 'amazon-0') in graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mine Prompts from seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413232"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(corpus_path, 'r') as f:\n",
    "    corpus = [json.loads(l) for l in f]\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "seed_relations_df = load_seed_aligned_relations(seed_aligned_relations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company dress_code\n"
     ]
    }
   ],
   "source": [
    "_r = 'has_dress_code'\n",
    "\n",
    "_r_row = seed_relations_df[seed_relations_df['alignedRelationName'] == _r].iloc[0]\n",
    "_h_type = _r_row['domain']\n",
    "_t_type = _r_row['range']\n",
    "print(_h_type, _t_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['walmart', 'amazon', 'subway', 'microsoft', 'target'],\n",
       " ['business casual',\n",
       "  'uniform',\n",
       "  'hair color',\n",
       "  'tattoos',\n",
       "  'facial hair',\n",
       "  'shoes',\n",
       "  'piercings'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _h_type]['seedInstances'].item()\n",
    "_seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _t_type]['seedInstances'].item()\n",
    "_seed_heads, _seed_tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_h = 'they'  # proxy for company \n",
    "_t = 'tattoos'\n",
    "\n",
    "_mentions = []\n",
    "for d in corpus:\n",
    "    if _t in d['entities']:\n",
    "        _mentions.append(' '.join(d['tokens']))\n",
    "\n",
    "_res = learn_patterns(_mentions, _h, _t, nlp=_nlp)\n",
    "_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e4632972ae403cbcd2a4f2d7b8b260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('company', 'has_pay_schedule', 'pay_schedule')\n",
      "('company', 'has_dress_code', 'dress_code')\n",
      "('company', 'has_background_screening', 'background_screening')\n",
      "('company', 'has_benefits', 'benefits')\n",
      "('company', 'hires_person', 'person')\n",
      "('company', 'has_compensation', 'compensation')\n",
      "('company', 'has_hire_prerequisite', 'hire_prerequisite')\n",
      "('company', 'operates_on', 'schedule')\n",
      "('company', 'hires_employee_type', 'employee_type')\n",
      "('company', 'has_onboarding_steps', 'onboarding_steps')\n",
      "('company', 'has_shifts', 'shifts')\n",
      "('company', 'has_job_position', 'job_position')\n",
      "('company', 'has_payment_option', 'payment_option')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fully run - all relations, all tail entities \n",
    "\n",
    "all_relation_patterns = dict()\n",
    "\n",
    "for _r_row in tqdm(seed_relations_df.to_records('dict')):\n",
    "    _r = _r_row['alignedRelationName']\n",
    "    _h_type = _r_row['domain']\n",
    "    _t_type = _r_row['range']\n",
    "    \n",
    "    print((_h_type, _r, _t_type))\n",
    "    assert _h_type == 'company'\n",
    "    \n",
    "    # _seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _h_type]['seedInstances'].item()\n",
    "    _seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == _t_type]['seedInstances'].item()\n",
    "    \n",
    "    _r_patterns = dict()\n",
    "    \n",
    "    _h = 'they'\n",
    "    for _t in _seed_tails:\n",
    "        _mentions = []\n",
    "        for d in corpus:\n",
    "            _sent = ' '.join(d['tokens']).lower()\n",
    "            if _h in _sent.split(' ') and _t in d['entities']:\n",
    "                _mentions.append(_sent)\n",
    "\n",
    "        _res = learn_patterns(_mentions, _h, _t, nlp=_nlp)\n",
    "        for _k, _sents in _res:\n",
    "            _r_patterns[_k] = _r_patterns.get(_k, []) + _sents\n",
    "    \n",
    "    all_relation_patterns[_r] = _r_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relation_patterns_sub = dict()\n",
    "for _r, _patterns in all_relation_patterns.items():\n",
    "    _r_patterns = dict()\n",
    "    for _p, _sents in _patterns.items():\n",
    "        _p_dict = {\n",
    "            'count': len(_sents),\n",
    "            'samples': _sents[:20]\n",
    "        }\n",
    "        _r_patterns[_p] = _p_dict\n",
    "    all_relation_patterns_sub[_r] = _r_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<src> offer <tgt> <tgt>': {'count': 15,\n",
       "  'samples': ['no i do nt think it would be because they do nt offer health insurance when you work part time .',\n",
       "   'do they offer health insurance to full time sales associates ?',\n",
       "   \"they do n't offer health insurance\",\n",
       "   'but i hear they offer dental and health insurance .',\n",
       "   'no , they do not offer health insurance or at least the one i work at does not .',\n",
       "   'no they do not offer any health insurance at all',\n",
       "   \"  they also offer health insurance , with different plans , if you 're full time !\",\n",
       "   'they \" offer \" health insurance , but you have to have worked there for 6 + months and then they say they \" ca n\\'t find any paperwork for it \" .',\n",
       "   'they offer health insurance but u have to pick the right one',\n",
       "   'they do offer health insurance but that ’s it .',\n",
       "   'supplemental from 3 months to 13 months and then they offer health insurance that meet obama care guidelines',\n",
       "   'maybe they offer health insurance for there part time workers now i am not sure about that .',\n",
       "   '50 % discount from your meals and they do offer a 401 k and health insurance',\n",
       "   'i believe they do offer health insurance for part time employees',\n",
       "   'they do not offer health insurance']},\n",
       " '<src> provide <tgt> <tgt>': {'count': 5,\n",
       "  'samples': [\"they did n't provide health insurance\",\n",
       "   'they provide health insurance to full and part time help .',\n",
       "   'they do provide health insurance',\n",
       "   'yes they provide health insurance',\n",
       "   'they do not provide health insurance .']},\n",
       " '<src> have <tgt> <tgt>': {'count': 6,\n",
       "  'samples': ['they have health insurance and some 401k plans .',\n",
       "   'yes they have ok health insurance .',\n",
       "   'yes they have health insurance',\n",
       "   'no they do not have health insurance',\n",
       "   'yes , they have flexible schedule , all needed is communication .',\n",
       "   \"they have a very flexible schedule for most departments and if your schedule does n't fit , you 'll more than likely just be moved .\"]},\n",
       " '<src> give <tgt> <tgt>': {'count': 2,\n",
       "  'samples': ['no they do not give health insurance to part - time employees .',\n",
       "   'they do not give part time employees health insurance .']},\n",
       " '<src> get <tgt> <tgt>': {'count': 2,\n",
       "  'samples': ['they do not get health insurance ever',\n",
       "   'they do get health insurance , yes .']},\n",
       " '<src> offer <tgt>': {'count': 12,\n",
       "  'samples': ['no they do not offer 401k',\n",
       "   'yes they do offer 401k for part time and full time .',\n",
       "   'they offer all benefits even 401k .',\n",
       "   'yes they offer 401k .',\n",
       "   'they offer 401k .',\n",
       "   'i know they offer 401k , and will match your contribution up to 6 % of your pay .',\n",
       "   \"they do n't offer 401k\",\n",
       "   'no they offer 401k and stock options',\n",
       "   'i have a interview in a.m do they offer 401k',\n",
       "   'yes , they offer 401k and stock purchase',\n",
       "   'they also offer 401k and stock options after 1 year .',\n",
       "   'yes , they offer 401k']},\n",
       " '<src> provide <tgt>': {'count': 5,\n",
       "  'samples': ['they do provide 401k and other benefits .',\n",
       "   'yes they do provide 401k',\n",
       "   'yes they provide 401k and numerous other perks including health dental and eye insurance and employee discounts .',\n",
       "   'no , they do not provide 401k for supervisors',\n",
       "   'yes , they provide 401k and stock']},\n",
       " '<src> have <tgt>': {'count': 4,\n",
       "  'samples': ['they also have 401k , stock , vacation time , and great insurance plans',\n",
       "   'yes they do have 401k',\n",
       "   'no , they do not have 401k',\n",
       "   'not sure if they have a 401k i was never notified about this .']},\n",
       " '<src> have <tgt> plan': {'count': 3,\n",
       "  'samples': ['they do not have a 401k plan',\n",
       "   'they did not have a 401k plan',\n",
       "   'yes they have a 401k plan']},\n",
       " '<src> offer <tgt> plan': {'count': 2,\n",
       "  'samples': ['they offer 401k plan as well as dental health coverage for you and your spose and vision .',\n",
       "   'they offer the 401k plan and they have company plan where however muck money you put into they company they match and you can cash it in at any given time .']},\n",
       " '<src> provide <tgt> benefits': {'count': 2,\n",
       "  'samples': ['yes they provide 401k benefits',\n",
       "   'yes they do provide 401k benefits']}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_relation_patterns_sub['has_benefits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relation_patterns_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/mined_patterns.json')\n",
    "with open(all_relation_patterns_path, 'w') as f:\n",
    "    json.dump(all_relation_patterns_sub, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_relation_patterns_records = []\n",
    "for _r, _patterns in all_relation_patterns.items():\n",
    "    for _p, _sents in _patterns.items():\n",
    "        _record = {\n",
    "            'relation': _r,\n",
    "            'pattern': _p,\n",
    "            'count': len(_sents),\n",
    "            'samples': _sents[:20]\n",
    "        }\n",
    "        all_relation_patterns_records.append(_record)\n",
    "        \n",
    "all_relation_patterns_df = pd.DataFrame(all_relation_patterns_records)\n",
    "all_relation_patterns_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relation_patterns_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/mined_patterns.csv')\n",
    "all_relation_patterns_df.to_csv(all_relation_patterns_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using prompts to hard-retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _prompt_retrieve(prompt):\n",
    "    ret = []\n",
    "    \n",
    "    for d in corpus:\n",
    "        _entities = d['entities']\n",
    "        _tokens = d['tokens']\n",
    "        if len(_entities) < 2:\n",
    "            continue\n",
    "\n",
    "        _sent = ' '.join(_tokens).lower()\n",
    "        if f' {prompt} ' not in _sent:\n",
    "            continue\n",
    "        \n",
    "        _p_idx = _sent.index(f' {prompt} ') + 1\n",
    "        _e_indices = [_sent.find(e) for e in _entities]\n",
    "        if max(_e_indices) < 0:\n",
    "            continue\n",
    "        _l_indices = [(i, e) for i, e in zip(_e_indices, _entities) if 0 <= i < _p_idx]\n",
    "        _r_indices = [(i, e) for i, e in zip(_e_indices, _entities) if i > _p_idx]\n",
    "        if len(_l_indices) == 0 or len(_r_indices) == 0:\n",
    "            continue\n",
    "        _l_idx, _l_ent = max(_l_indices, key=lambda p: p[0])\n",
    "        _r_idx, _r_ent = min(_r_indices, key=lambda p: p[0])\n",
    "#         _r_idx += len(_r_ent)\n",
    "\n",
    "        ## Extracting dep path \n",
    "        doc = _nlp(_sent)\n",
    "        src_matcher = Matcher(nlp.vocab)\n",
    "        src_pattern = [{\"LOWER\": t} for t in _l_ent.split(' ')]\n",
    "        src_matcher.add(\"src\", [src_pattern])\n",
    "        \n",
    "        prompt_matcher = Matcher(nlp.vocab)\n",
    "        prompt_pattern = [{\"LOWER\": t} for t in prompt.split(' ')]\n",
    "        prompt_matcher.add(\"prompt\", [prompt_pattern])\n",
    "\n",
    "        tgt_matcher = Matcher(nlp.vocab)\n",
    "        tgt_pattern = [{\"LOWER\": t} for t in _r_ent.split(' ')]\n",
    "        tgt_matcher.add(\"tgt\", [tgt_pattern])\n",
    "        \n",
    "        src_matches = src_matcher(doc)\n",
    "        if len(src_matches) == 0:\n",
    "            print('src not matched')\n",
    "            continue\n",
    "        tgt_matches = tgt_matcher(doc)\n",
    "        if len(tgt_matches) == 0:\n",
    "            print('tgt not matched')\n",
    "            continue\n",
    "        prompt_matches = prompt_matcher(doc)\n",
    "        if len(prompt_matches) == 0:\n",
    "            print('prompt not matched')\n",
    "            continue\n",
    "        \n",
    "        src_match = None\n",
    "        src_span = None\n",
    "        for _m in src_matches:\n",
    "            if doc[_m[1]].idx == _l_idx:\n",
    "                src_match = _m[0]\n",
    "                src_span = doc[_m[1]: _m[2]]\n",
    "                break\n",
    "        \n",
    "        prompt_match = None\n",
    "        prompt_span = None\n",
    "        for _m in prompt_matches:\n",
    "            if doc[_m[1]].idx == _p_idx:\n",
    "                prompt_match = _m[0]\n",
    "                prompt_span = doc[_m[1]: _m[2]]\n",
    "                break\n",
    "        \n",
    "        tgt_match = None\n",
    "        tgt_span = None\n",
    "        for _m in tgt_matches:\n",
    "            if doc[_m[1]].idx == _r_idx:\n",
    "                tgt_match = _m[0]\n",
    "                tgt_span = doc[_m[1]: _m[2]]\n",
    "                break\n",
    "        \n",
    "        if None in (src_match, prompt_match, tgt_match):\n",
    "            print('_sent:', _sent)\n",
    "            print(_l_ent, prompt, _r_ent)\n",
    "            print(src_match, prompt_match, tgt_match)\n",
    "            print()\n",
    "            continue\n",
    "        \n",
    "        if len(spacy.util.filter_spans([src_span, prompt_span, tgt_span])) != 3: # distinct_spans\n",
    "            print('overlapping spans')\n",
    "            continue\n",
    "        \n",
    "        src_root = src_span.root\n",
    "        prompt_root = prompt_span.root\n",
    "        tgt_root = tgt_span.root\n",
    "        \n",
    "        edges = []\n",
    "        for token in doc:\n",
    "            for child in token.children:\n",
    "                edges.append(('{}-{}'.format(token.lower_,token.i), '{}-{}'.format(child.lower_,child.i)))\n",
    "#         print(edges)\n",
    "        \n",
    "        graph = nx.Graph(edges)\n",
    "        path = None\n",
    "        source = '{}-{}'.format(src_root.lower_, src_root.i)\n",
    "        middle = '{}-{}'.format(prompt_root.lower_, prompt_root.i)\n",
    "        target = '{}-{}'.format(tgt_root.lower_, tgt_root.i)\n",
    "        if any([n not in graph for n in (source, middle, target)]):\n",
    "            continue\n",
    "        if nx.has_path(graph, source=source, target=middle) and nx.has_path(graph, source=middle, target=target):\n",
    "            path1 = nx.shortest_path(graph, source=source, target=middle)\n",
    "            path2 = nx.shortest_path(graph, source=middle, target=target)\n",
    "            path = path1 + path2[1:]\n",
    "        \n",
    "        if path is not None:\n",
    "            for t in src_span:\n",
    "                n = '{}-{}'.format(t.lower_, t.i)  \n",
    "                if n not in path:\n",
    "                    path.append(n)\n",
    "            for t in prompt_span:\n",
    "                n = '{}-{}'.format(t.lower_, t.i)\n",
    "                if n not in path:\n",
    "                    path.append(n)\n",
    "            for t in tgt_span:\n",
    "                n = '{}-{}'.format(t.lower_, t.i)\n",
    "                if n not in path:\n",
    "                    path.append(n)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        path_nodes = dict()\n",
    "        for p in path:\n",
    "            t, i = p.rsplit('-', 1)\n",
    "            i = int(i)\n",
    "            path_nodes[i] = t\n",
    "        path_nodes = sorted(path_nodes.items(), key=lambda x: x[0])\n",
    "        pattern = ' '.join([p[1] for p in path_nodes])\n",
    "\n",
    "        print('_sent:', _sent)\n",
    "        print(path)\n",
    "        print(pattern, (_l_ent, _r_ent))\n",
    "        print()\n",
    "        ret.append(pattern)\n",
    "        if len(ret) >= 100:\n",
    "            break\n",
    "        \n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: this company has a great lp !\n",
      "['company-1', 'has-2', 'lp-5']\n",
      "company has lp ('company', 'lp')\n",
      "\n",
      "_sent: at&t has many ways to receive higher education .\n",
      "['at&t-0', 'has-1', 'ways-3', 'receive-5', 'education-7', 'higher-6']\n",
      "at&t has ways receive higher education ('at&t', 'higher education')\n",
      "\n",
      "_sent: will at&t hire someone who has a pending felony charge but has not been convicted of it from over three years ago ?\n",
      "['at&t-1', 'hire-2', 'someone-3', 'has-5', 'charge-9', 'pending-7', 'felony-8']\n",
      "at&t hire someone has pending felony charge ('at&t', 'pending felony')\n",
      "\n",
      "_sent: yes , at&t has a generous telecommuting policy .\n",
      "['at&t-2', 'has-3', 'policy-7', 'telecommuting-6']\n",
      "at&t has telecommuting policy ('at&t', 'telecommuting')\n",
      "\n",
      "_sent: management has their own issues because upper management keeps pressure on lower management for unattainable results .\n",
      "['management-0', 'has-1', 'keeps-8', 'management-7', 'upper-6']\n",
      "management has upper management keeps ('management', 'upper')\n",
      "\n",
      "_sent: at&t has all company policy and procedures .\n",
      "['at&t-0', 'has-1', 'policy-4', 'company-3']\n",
      "at&t has company policy ('at&t', 'company')\n",
      "\n",
      "_sent: like all call centers , at&t has a strict attendance policy .\n",
      "['at&t-5', 'has-6', 'policy-10', 'attendance-9']\n",
      "at&t has attendance policy ('at&t', 'attendance policy')\n",
      "\n",
      "_sent: i started right out of high school and had been my only career , but the last three to four years has been the ultimate worst side of our company i have ever seen .\n",
      "['school-6', 'of-4', 'out-3', 'started-1', 'been-22', 'has-21', 'been-22', 'side-26', 'of-27', 'company-29']\n",
      "started out of school has been side of company ('school', 'company')\n",
      "\n",
      "_sent: management has been made to micromanage on the hour , every hour to monitor results , and so much focus on call flow , makes the customers feel like we are n't listening to them when we follow it .\n",
      "['management-0', 'made-3', 'has-1', 'made-3', 'micromanage-5', 'hour-11', 'monitor-13', 'results-14']\n",
      "management has made micromanage hour monitor results ('management', 'results')\n",
      "\n",
      "_sent:   company has put an emphasis in contracting and outsourcing to overseas .\n",
      "['company-1', 'put-3', 'has-2', 'put-3', 'in-6', 'contracting-7', 'outsourcing-9']\n",
      "company has put in contracting outsourcing ('company', 'outsourcing')\n",
      "\n",
      "_sent: my personal experience , yes , at&t , has the right and they exercise that right , to randomly drug test you , any given time of any day , when you arrive at work or during that day of work you can be notified to go get tested , you do so ..... asap\n",
      "['at&t-6', 'experience-2', 'has-8', 'exercise-13', 'randomly-18', 'drug-19', 'test-20']\n",
      "experience at&t has exercise randomly drug test ('at&t', 'randomly drug test')\n",
      "\n",
      "_sent: i would imagine that at&t , like many companies that operate call centers , probably has positions that allow for telecommuting , though i did not work in such a capacity for them .\n",
      "['centers-12', 'operate-10', 'companies-8', 'like-6', 'has-15', 'positions-16', 'allow-18', 'for-19', 'telecommuting-20', 'call-11']\n",
      "like companies operate call centers has positions allow for telecommuting ('call centers', 'telecommuting')\n",
      "\n",
      "_sent: at&t has a very strict code of business conduct and have a zero tolerance attitude towards violating any of the policies .\n",
      "['at&t-0', 'has-1', 'code-5', 'of-6', 'conduct-8', 'business-7']\n",
      "at&t has code of business conduct ('at&t', 'business')\n",
      "\n",
      "_sent: at&t as far as i know has n't ever done a credit check on me or any other employee .\n",
      "['at&t-0', 'far-2', 'done-9', 'has-6', 'done-9', 'check-12', 'credit-11']\n",
      "at&t far has done credit check ('at&t', 'credit check')\n",
      "\n",
      "_sent: no , at&t has a no marijuana policy .\n",
      "['at&t-2', 'has-3', 'policy-7', 'marijuana-6']\n",
      "at&t has marijuana policy ('at&t', 'marijuana')\n",
      "\n",
      "_sent:   the company has very good benefits and will reward you for hard work .\n",
      "['company-2', 'has-3', 'benefits-6']\n",
      "company has benefits ('company', 'benefits')\n",
      "\n",
      "_sent: at&t has slow internal decision processes , have patience .\n",
      "['at&t-0', 'has-1', 'have-7', 'patience-8']\n",
      "at&t has have patience ('at&t', 'patience')\n",
      "\n",
      "_sent: skechers has non slip , they are the most comfortable , durable , work shoes i 've ever bought .\n",
      "['skechers-0', 'has-1', 'slip-3', 'non-2']\n",
      "skechers has non slip ('skechers', 'non slip')\n",
      "\n",
      "_sent: oh we had a guy that fell his background check for  \n",
      "  impostering police and firemen brought it to our manager 's attention it 's on the \n",
      " internet that he 's a liar and a scammer scammer and has done time in prison nothing got done so it really does n't matter about the background check so yeah you got hired congratulations\n",
      "['internet-28', 'on-25', \"'s-24\", \"'s-31\", 'done-40', 'has-39', 'done-40', 'in-42', 'prison-43']\n",
      "'s on internet 's has done in prison ('internet', 'prison')\n",
      "\n",
      "_sent: can go through cb to get oxfords for roughly $ 10 a piece ) \n",
      "\n",
      " apron ( depending upon position can have decorative pins ) \n",
      "\n",
      " pants must reach the ankle and be of either cotton or polyester material in navy blue , black , or khaki ( if it has belt loops a belt has to be worn -- i think brown leather ) .\n",
      "['khaki-46', 'black-43', 'blue-41', 'in-39', 'cotton-35', 'of-33', 'be-32', 'reach-28', 'has-55', 'has-50', 'loops-52', 'belt-51']\n",
      "reach be of cotton in blue black khaki has belt loops has ('khaki', 'belt loops')\n",
      "\n",
      "_sent: cracker barrel has a website where you can order uniforms\n",
      "['barrel-1', 'has-2', 'website-4', 'cracker-0']\n",
      "cracker barrel has website ('cracker barrel', 'website')\n",
      "\n",
      "_sent: their daily volume of guests and the need to step into the age of technology has caused them to update their hiring process .\n",
      "['technology-14', 'of-13', 'age-12', 'into-10', 'step-9', 'need-7', 'volume-2', 'caused-16', 'has-15', 'caused-16', 'update-19', 'process-22', 'hiring-21']\n",
      "volume need step into age of technology has caused update hiring process ('technology', 'hiring process')\n",
      "\n",
      "_sent: raises are given out frequently but it should be known retail has probably the lowest pay scale in the store and they keep adding to the responsibilities .\n",
      "['retail-10', 'has-11', 'scale-16', 'pay-15']\n",
      "retail has pay scale ('retail', 'pay scale')\n",
      "\n",
      "_sent: i believe that cracker barrel should pay for drug tests , especially if the test comes back negative and if that person has no history of drug use .\n",
      "test has history\n",
      "None 10540441779542591554 14930118741968279164\n",
      "\n",
      "_sent: nail polish / acrylic is allowed only if you do not handle food products and it has to be a color that matches your skin tone\n",
      "['products-13', 'handle-11', 'allowed-5', 'has-16', 'be-18', 'color-20', 'matches-22', 'tone-25', 'skin-24']\n",
      "allowed handle products has be color matches skin tone ('products', 'skin')\n",
      "\n",
      "_sent: yes the company has lay offs\n",
      "['company-2', 'lay-4', 'has-3', 'lay-4', 'offs-5']\n",
      "company has lay offs ('company', 'lay offs')\n",
      "\n",
      "_sent: tattoos has to be covered because it is a corporate setting .\n",
      "['tattoos-0', 'has-1', 'covered-4']\n",
      "tattoos has covered ('tattoos', 'covered')\n",
      "\n",
      "_sent: my hiring process was atypical , however , generally once a \" panel \" interview has been completed , the hiring manager makes a decision and either the manager , or possibly the administrative assistant , will make an offer .\n",
      "['process-2', 'was-3', 'completed-17', 'has-15', 'completed-17', 'was-3', 'makes-22', 'manager-21', 'hiring-1', 'hiring-20']\n",
      "hiring process was has completed hiring manager makes ('hiring process', 'hiring manager')\n",
      "\n",
      "_sent: wells fargo has their mortgage officers separately that periodically visit the banks when personal bankers give them leads .\n",
      "['fargo-1', 'has-2', 'officers-5', 'mortgage-4']\n",
      "fargo has mortgage officers ('fargo', 'mortgage')\n",
      "\n",
      "_sent:   wells fargo has a very thorough background check procedure .\n",
      "['fargo-2', 'has-3', 'procedure-9', 'check-8', 'background-7']\n",
      "fargo has background check procedure ('fargo', 'background check')\n",
      "\n",
      "_sent: wells fargo has an on - site cafeteria at most locations .\n",
      "['fargo-1', 'has-2', 'cafeteria-7']\n",
      "fargo has cafeteria ('fargo', 'cafeteria')\n",
      "\n",
      "_sent: yes , retail has trained you in customer service , they will continue your trading to ensure you understand why you are requesting additional documents .\n",
      "['retail-2', 'trained-4', 'has-3', 'trained-4', 'in-6', 'service-8', 'customer-7']\n",
      "retail has trained in customer service ('retail', 'customer service')\n",
      "\n",
      "_sent: i am not sure my job description is not a chasier or has nothing to do with that area\n",
      "['description-6', 'is-7', 'has-12', 'nothing-13', 'do-15', 'with-16', 'area-18', 'job-5']\n",
      "job description is has nothing do with area ('job description', 'area')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: this starting salary is the same as the guy i work with who 's been there for 5 years that has only gotten a dollar raise since he started .\n",
      "['salary-2', 'is-3', 'same-5', 'as-6', 'guy-8', 'work-10', 'with-11', 'been-14', 'for-16', 'years-18', 'gotten-22', 'has-20', 'gotten-22', 'raise-25', 'starting-1', 'dollar-24']\n",
      "starting salary is same as guy work with been for years has gotten dollar raise ('starting salary', 'dollar raise')\n",
      "\n",
      "_sent: yes ,   the company has a mixture of gender and races .\n",
      "['company-4', 'has-5', 'mixture-7', 'of-8', 'gender-9']\n",
      "company has mixture of gender ('company', 'gender')\n",
      "\n",
      "_sent: home depot has there own shipping and receiving dept .\n",
      "['depot-1', 'has-2', 'own-4', 'shipping-5', 'home-0', 'and-6', 'receiving-7']\n",
      "home depot has own shipping and receiving ('home depot', 'shipping and receiving')\n",
      "\n",
      "_sent:   home depot has good training methods , i 've learned a lot , more than i 've ever known & it feels good to be knowledgeable about retail .\n",
      "['depot-2', 'has-3', 'methods-6', 'training-5', 'home-1']\n",
      "home depot has training methods ('home depot', 'training')\n",
      "\n",
      "_sent: home depot has a lack of management .\n",
      "['depot-1', 'has-2', 'lack-4', 'of-5', 'management-6', 'home-0']\n",
      "home depot has lack of management ('home depot', 'management')\n",
      "\n",
      "_sent: management has clearly shown favoritism , and exclusion of employees they do n’t like from company gifts and promotions .\n",
      "['management-0', 'shown-3', 'has-1', 'shown-3', 'exclusion-7', 'do-11', 'like-13', 'from-14', 'gifts-16', 'company-15']\n",
      "management has shown exclusion do like from company gifts ('management', 'company')\n",
      "\n",
      "_sent: fyi - all of the entries below depict a fair assessment of how this conglomerate company has achieved it 's market share .\n",
      "['company-15', 'achieved-17', 'has-16', 'achieved-17', 'of-11', 'assessment-10', 'depict-7', \"'s-19\", 'share-21', 'market-20']\n",
      "depict assessment of company has achieved 's market share ('company', 'market share')\n",
      "\n",
      "_sent: home depot has a team in place for asset protection .\n",
      "['depot-1', 'has-2', 'team-4', 'in-5', 'place-6', 'for-7', 'protection-9', 'home-0', 'asset-8']\n",
      "home depot has team in place for asset protection ('home depot', 'asset protection')\n",
      "\n",
      "_sent: work was without any on the job training whatsoever and the employee has to ask questions in order to perform their duties !\n",
      "['training-7', 'on-4', 'was-1', 'has-12', 'ask-14', 'in-16', 'order-17']\n",
      "was on training has ask in order ('training', 'order')\n",
      "\n",
      "_sent: my home depot experience has been in rock hill , sc and i do not know how many years back this company goes on a background check .\n",
      "['depot-2', 'experience-3', 'been-5', 'has-4', 'been-5', 'in-6', 'hill-8', 'rock-7', 'home-1']\n",
      "home depot experience has been in rock hill ('home depot', 'rock')\n",
      "\n",
      "_sent: the company has many new types of flooring technology and hardware equipment that make our lives easier .\n",
      "['company-1', 'has-2', 'types-5', 'of-6', 'equipment-11', 'technology-8']\n",
      "company has types of technology equipment ('company', 'technology')\n",
      "\n",
      "_sent: you can wear a hat as long as it has a home depot logo on it .\n",
      "['long-6', 'has-9', 'logo-13', 'depot-12', 'home-11']\n",
      "long has home depot logo ('long', 'home depot')\n",
      "\n",
      "_sent: not sure if home depot has 3rd hour night shifts .\n",
      "['depot-4', 'has-5', 'shifts-9', 'home-3', 'night-8']\n",
      "home depot has night shifts ('home depot', 'night shifts')\n",
      "\n",
      "_sent: no my pay rate has not changed from new york to north carolina\n",
      "['rate-3', 'changed-6', 'has-4', 'changed-6', 'from-7', 'york-9', 'pay-2', 'new-8']\n",
      "pay rate has changed from new york ('pay rate', 'new york')\n",
      "\n",
      "_sent: so if you live in a state that has legal weed , they will still turn you down for weed usage- despite having medical use cards and all the such .\n",
      "['state-6', 'has-8', 'weed-10']\n",
      "state has weed ('state', 'weed')\n",
      "\n",
      "_sent: thd has the right to drug test at any time .\n",
      "['thd-0', 'has-1', 'right-3', 'to-4', 'test-6', 'drug-5']\n",
      "thd has right to drug test ('thd', 'drug')\n",
      "\n",
      "_sent: do n't know about washington but california home depot does run a drug test as a part of the application process and the company is & has a no tolerance for drugs & alcohol .\n",
      "['company-23', 'is-24', 'has-26', 'tolerance-29', 'for-30', 'drugs-31']\n",
      "company is has tolerance for drugs ('company', 'drugs')\n",
      "\n",
      "_sent: no the company has a dress code .\n",
      "['company-2', 'has-3', 'code-6', 'dress-5']\n",
      "company has dress code ('company', 'dress code')\n",
      "\n",
      "_sent: yes home depot has a company wide drug testing policy .\n",
      "['depot-2', 'has-3', 'policy-9', 'company-5', 'home-1']\n",
      "home depot has company policy ('home depot', 'company')\n",
      "\n",
      "_sent: the home depot has a policy to test for drugs upon injury .\n",
      "['depot-2', 'has-3', 'policy-5', 'test-7', 'home-1']\n",
      "home depot has policy test ('home depot', 'test')\n",
      "\n",
      "_sent: yes , i 've had purple hair before , two of my coworkers has had pink hair , and a former coworker had blue , purple , and red hair .\n",
      "['hair-7', 'had-5', 'had-15', 'has-14', 'had-15', 'hair-17', 'pink-16']\n",
      "had hair has had pink hair ('hair', 'pink')\n",
      "\n",
      "_sent: home depot has their own loss prevention which works for them\n",
      "['depot-1', 'has-2', 'prevention-6', 'home-0', 'loss-5']\n",
      "home depot has loss prevention ('home depot', 'loss prevention')\n",
      "\n",
      "_sent: the company is huge and has locations all over the united states .\n",
      "['company-1', 'is-2', 'has-5', 'locations-6', 'over-8', 'states-11', 'united-10']\n",
      "company is has locations over united states ('company', 'united states')\n",
      "\n",
      "_sent: no , the home depot has a place for anyone no matter the age .\n",
      "['depot-4', 'has-5', 'matter-11', 'home-3']\n",
      "home depot has matter ('home depot', 'matter')\n",
      "\n",
      "_sent: \n",
      " full time has better coverage with aetna but not very good deductibles .\n",
      "['time-2', 'has-3', 'coverage-5', 'with-6', 'aetna-7', 'full-1']\n",
      "full time has coverage with aetna ('full time', 'aetna')\n",
      "\n",
      "_sent: yes the home depot has healthcare\n",
      "['depot-3', 'has-4', 'healthcare-5', 'home-2']\n",
      "home depot has healthcare ('home depot', 'healthcare')\n",
      "\n",
      "_sent: medical coverage has different tiers , so you can pick one that works within your budget , but is really excellent insurance .\n",
      "['medical-0', 'coverage-1', 'has-2', 'pick-9', 'is-18', 'insurance-21']\n",
      "medical coverage has pick is insurance ('medical', 'insurance')\n",
      "\n",
      "_sent: geico has employees ranging from all ages and walks of life .\n",
      "['geico-0', 'has-1', 'employees-2', 'ranging-3', 'from-4', 'ages-6', 'walks-8']\n",
      "geico has employees ranging from ages walks ('geico', 'walks')\n",
      "\n",
      "_sent: they make you jump through an endless cycle of hoops like almost thousands , you would think that you were interviewing for ceo of a company , not a location that has 10 or 11 pages of nothing but one - star reviews on yelp for their claims being wrongfully denied ( poway , ca ) .\n",
      "['company-25', 'of-23', 'ceo-22', 'location-29', 'has-31', 'pages-35', 'of-36', 'nothing-37', 'but-38', 'reviews-42', 'star-41']\n",
      "ceo of company location has pages of nothing but star reviews ('company', 'star')\n",
      "\n",
      "_sent: they will find a reason to fire someone with a disability because they do n't want to keep someone with the company that has special needs or has to take time off for doctors appointments\n",
      "['company-21', 'has-23', 'needs-25', 'special-24']\n",
      "company has special needs ('company', 'special needs')\n",
      "\n",
      "_sent:   any training that i have had done has been within geico .\n",
      "['training-2', 'been-9', 'has-8', 'been-9', 'within-10', 'geico-11']\n",
      "training has been within geico ('training', 'geico')\n",
      "\n",
      "_sent:   they spend a great deal of time , money and effort on training for the employees to ensure that everyone has the correct information and is comfortable with what they have learned before they need to \" go out into the real world \" to use it .\n",
      "['training-13', 'ensure-18', 'has-21', 'information-24']\n",
      "training ensure has information ('training', 'information')\n",
      "\n",
      "_sent: the company has since changed the hours for certain positions due to different needs in different locations , but sales and customer service are day hours .\n",
      "['company-1', 'changed-4', 'has-2', 'changed-4', 'are-23', 'sales-19', 'service-22', 'customer-21']\n",
      "company has changed sales customer service are ('company', 'customer service')\n",
      "\n",
      "_sent: so i was punished because i was given incorrect information by someone that has no business in that position .\n",
      "['information-9', 'by-10', 'someone-11', 'has-13', 'business-15']\n",
      "information by someone has business ('information', 'business')\n",
      "\n",
      "_sent: i work at a fulfilment center and while each loaction has different ways of operations , everything comes down to are you willing to stand on your feet for extended period of time ?\n",
      "['center-5', 'at-2', 'work-1', 'comes-17', 'has-10', 'comes-17', 'are-20', 'willing-22', 'stand-24', 'for-28', 'period-30']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work at center has comes are willing stand for period ('center', 'period')\n",
      "\n",
      "_sent: amazon has a half million employees worldwide , nobody cares about your work / life balance .\n",
      "['amazon-0', 'has-1', 'cares-9', 'about-10', 'balance-15', 'work-12', '/-13', 'life-14']\n",
      "amazon has cares about work / life balance ('amazon', 'work / life balance')\n",
      "\n",
      "_sent: well as an amazon employee ( waiting for my start date ) and as an amazon prime member and a human who has this very issue of an off balanced work / life balance i just want to focus on learning from my past mistakes and fixing them .\n",
      "['human-20', 'has-22', 'issue-25', 'of-26', 'balance-33', 'work-30', '/-31', 'life-32']\n",
      "human has issue of work / life balance ('human', 'work / life balance')\n",
      "\n",
      "_sent: amazon has a bunch of unqualified am 's and pa 's who do n't know nothing .\n",
      "['amazon-0', 'has-1', 'bunch-3', 'of-4', 'am-6', 'pa-9']\n",
      "amazon has bunch of am pa ('amazon', 'pa')\n",
      "\n",
      "_sent: it ’s disgusting that jeff bezos has become the richest man off the literal blood and sweat of his slaves .\n",
      "['bezos-5', 'become-7', 'has-6', 'become-7', 'man-10', 'off-11', 'blood-14', 'jeff-4']\n",
      "jeff bezos has become man off blood ('jeff bezos', 'blood')\n",
      "\n",
      "_sent: have read at least fifty job requirements and amazon has stated that they are a eeo employer and they use all standards except for disability and age related people .\n",
      "['amazon-8', 'requirements-6', 'stated-10', 'has-9', 'stated-10', 'are-13', 'use-19', 'except-22', 'for-23', 'disability-24']\n",
      "requirements amazon has stated are use except for disability ('amazon', 'disability')\n",
      "\n",
      "_sent:   management has its clicks and base all information on gossip .\n",
      "['management-1', 'has-2', 'base-6', 'information-8']\n",
      "management has base information ('management', 'information')\n",
      "\n",
      "_sent: \n",
      "\n",
      " amazon really has no bias for promoting the company is focused on hiring but never on promotion .\n",
      "['amazon-1', 'has-3', 'bias-5', 'for-6', 'promoting-7', 'company-9']\n",
      "amazon has bias for promoting company ('amazon', 'company')\n",
      "\n",
      "_sent: this company has reached a point where it simply needs warm bodies .\n",
      "['company-1', 'reached-3', 'has-2', 'reached-3', 'point-5', 'needs-9', 'bodies-11', 'warm-10']\n",
      "company has reached point needs warm bodies ('company', 'warm bodies')\n",
      "\n",
      "_sent: it is easier to get a job in a bank , than to be able to finish an applicatiuon on line , nochance to choose shift hours , lack of website information , people from other countries answering to the online chat , amazon has become a s ... hole to even apply to , it might be because they announced $ 15 an hour , and now they are all trying to minimize new hires ? ? ?\n",
      "['amazon-43', 'become-45', 'has-44', 'become-45', 'be-57', 'announced-60', 'trying-71', 'minimize-73', 'hires-75', 'new-74']\n",
      "amazon has become be announced trying minimize new hires ('amazon', 'new hires')\n",
      "\n",
      "_sent: my college education has spread out over the years with moving from state to state , employment , relocations and   family .\n",
      "['education-2', 'spread-4', 'has-3', 'spread-4', 'out-5']\n",
      "education has spread out ('education', 'spread out')\n",
      "\n",
      "_sent: amazon prime now has one of the worst hiring practices that i 've ever experienced .\n",
      "['prime-1', 'has-3', 'one-4', 'of-5', 'practices-9', 'now-2', 'hiring-8']\n",
      "prime now has one of hiring practices ('prime now', 'hiring practices')\n",
      "\n",
      "_sent: 6am-6pm.the company has many different shifts esp during seasonal /holidays .\n",
      "['company-1', 'has-2', 'during-7', 'seasonal-8']\n",
      "company has during seasonal ('company', 'seasonal')\n",
      "\n",
      "_sent: dallas has one inside the city but you will not be able to work at the one i am reviewing .\n",
      "['dallas-0', 'has-1', 'one-2', 'inside-3', 'city-5']\n",
      "dallas has one inside city ('dallas', 'city')\n",
      "\n",
      "_sent: amazon has a lot of great benefits to reward their associates because they know how hard they will work .\n",
      "['amazon-0', 'has-1', 'lot-3', 'of-4', 'benefits-6', 'great-5']\n",
      "amazon has lot of great benefits ('amazon', 'great benefits')\n",
      "\n",
      "_sent: amazon has never requested a urine drug test\n",
      "['amazon-0', 'requested-3', 'has-1', 'requested-3', 'test-7', 'urine-5']\n",
      "amazon has requested urine test ('amazon', 'urine')\n",
      "\n",
      "_sent: every corporation has it problems but , with opening communication and respect for others goes a long way .. i believe in right person for the right sit .\n",
      "['corporation-1', 'has-2', 'goes-14', 'with-7', 'opening-8', 'communication-9']\n",
      "corporation has with opening communication goes ('corporation', 'communication')\n",
      "\n",
      "_sent: they terminated me , and the letter said because i executed a confidentiality and invention assignment agreement , i do not see how that has anything to do with being absent and sick with a doctor 's note ?\n",
      "['invention-14', 'confidentiality-12', 'assignment-15', 'agreement-16', 'executed-10', 'see-21', 'has-24', 'anything-25', 'do-27', 'with-28', 'being-29', 'absent-30', 'sick-32', 'with-33', 'note-37', 'doctor-35', \"'s-36\"]\n",
      "executed confidentiality invention assignment agreement see has anything do with being absent sick with doctor 's note ('invention', \"doctor 's note\")\n",
      "\n",
      "_sent: i work at a brand new sort facility smf5 , my morale has dropped due to earning so little money in the last month .\n",
      "['morale-11', 'dropped-13', 'has-12', 'dropped-13', 'earning-16', 'money-19']\n",
      "morale has dropped earning money ('morale', 'money')\n",
      "\n",
      "_sent: i live in a suburb of cleveland and wondering if amazon has work from home positions .\n",
      "['amazon-10', 'has-11', 'work-12', 'from-13', 'positions-15', 'home-14']\n",
      "amazon has work from home positions ('amazon', 'home positions')\n",
      "\n",
      "_sent:   if an individual was given an invitation to apply for ft position and they have not met their quota by the time amazon fulfills their ft and pt company needs and the individual still has n't   been contacted by hr or a manager , may not have been selected to continue employment and should have received an email or letter in the mail .\n",
      "['company-29', 'needs-30', 'fulfills-24', 'time-22', 'by-20', 'met-17', 'contacted-39', 'has-35', 'contacted-39', 'by-40', 'hr-41', 'manager-44']\n",
      "met by time fulfills company needs has contacted by hr manager ('company', 'manager')\n",
      "\n",
      "_sent: yes , amazon has hired felons .\n",
      "['amazon-2', 'hired-4', 'has-3', 'hired-4', 'felons-5']\n",
      "amazon has hired felons ('amazon', 'felons')\n",
      "\n",
      "_sent: the company has gotten bad press about these measures as many people would like to see a union perhaps with this never happening more than likely because of the effect on wages and safety being paramount as with product .\n",
      "['company-1', 'gotten-3', 'has-2', 'gotten-3', 'like-13', 'see-15', 'union-17']\n",
      "company has gotten like see union ('company', 'union')\n",
      "\n",
      "_sent: for these reasons management has to step up as though people are important just as the bottom line is and , the catharsis lay in the middle without a union which are for far more dangerous professions e.g. aircraft assembly\n",
      "['management-3', 'has-4', 'step-6', 'is-18', 'line-17', 'bottom-16']\n",
      "management has step bottom line is ('management', 'bottom line')\n",
      "\n",
      "_sent: management has to talk with them and also collect all the reasons enclind with the matter and solve with accepting all losical matter .\n",
      "['management-0', 'has-1', 'talk-3']\n",
      "management has talk ('management', 'talk')\n",
      "\n",
      "_sent: never had a problem yet they have been great management has been nice and very helpful ... i am definitely happy with my job ...\n",
      "['management-9', 'been-7', 'had-1', 'been-11', 'has-10', 'been-11', 'nice-12']\n",
      "had been management has been nice ('management', 'nice')\n",
      "\n",
      "_sent: treat people the way the law has order it .\n",
      "['law-5', 'has-6', 'way-3', 'order-7']\n",
      "way law has order ('law', 'order')\n",
      "\n",
      "_sent: for few ( not couple of them ) employees watch video clips on you - tube whole day , \" pa \" enjoying free drinks at bar after work hours by certain employees so they do n't have to work as hard as other employees who has to and are forced to work till last minute while others can stop processing atleast 30 minutes shift ends .\n",
      "['free-23', 'drinks-24', 'enjoying-22', 'have-37', 'work-39', 'hard-41', 'as-42', 'employees-44', 'has-46', 'forced-50', 'work-52', 'till-53']\n",
      "enjoying free drinks have work hard as employees has forced work till ('free', 'till')\n",
      "\n",
      "_sent: as you know , shannon , the president or ceo of this company is a brutal guy and at least for now is keeping his mouth closed in the role he has with trump .\n",
      "['mouth-25', 'keeping-23', 'closed-26', 'in-27', 'role-29', 'has-31', 'role-29', 'in-27', 'closed-26', 'with-32', 'trump-33']\n",
      "keeping mouth closed in role has with trump ('mouth', 'trump')\n",
      "\n",
      "_sent: make sure the products each one receives is awesome and has good reviews and working order before shipping to anybody makes a lasting customer relationship\n",
      "['products-3', 'is-7', 'has-10', 'reviews-12', 'order-15']\n",
      "products is has reviews order ('products', 'order')\n",
      "\n",
      "_sent: i was shocked to be terminated suddenly by an email stating that “ as everyone has heard that the packages were coming in later ” and “ we did communicate during our all - hands meeting that we needed volunteers from our associates to switch their schedules to nit sorts ” .\n",
      "['email-9', 'stating-10', 'that-11', '“-12', 'heard-16', 'has-15', 'heard-16', 'communicate-29', 'during-30', 'meeting-35', 'needed-38', 'switch-44', 'to-47', 'sorts-49', 'nit-48']\n",
      "email stating that “ has heard communicate during meeting needed switch to nit sorts ('email', 'nit')\n",
      "\n",
      "_sent: i live about 40 minutes away and my route has a lot of construction which can cause me to have to leave the house an hour to an hour and a half early in the morning to make sure i get to work on time .\n",
      "['live-1', 'has-9', 'lot-11', 'of-12', 'construction-13']\n",
      "live has lot of construction ('live', 'construction')\n",
      "\n",
      "_sent: amazon provides a livable wage and has been at the forefront of global innovation in retail .\n",
      "['wage-4', 'provides-1', 'been-7', 'has-6', 'been-7', 'at-8', 'forefront-10', 'of-11', 'innovation-13', 'livable-3']\n",
      "provides livable wage has been at forefront of innovation ('livable wage', 'innovation')\n",
      "\n",
      "_sent: \n",
      "\n",
      " it is so disheartening that such a great company has such a poor organization .\n",
      "['company-9', 'has-10', 'organization-14']\n",
      "company has organization ('company', 'organization')\n",
      "\n",
      "company has lp\n",
      "at&t has ways receive higher education\n",
      "at&t hire someone has pending felony charge\n",
      "at&t has telecommuting policy\n",
      "management has upper management keeps\n",
      "at&t has company policy\n",
      "at&t has attendance policy\n",
      "started out of school has been side of company\n",
      "management has made micromanage hour monitor results\n",
      "company has put in contracting outsourcing\n",
      "experience at&t has exercise randomly drug test\n",
      "like companies operate call centers has positions allow for telecommuting\n",
      "at&t has code of business conduct\n",
      "at&t far has done credit check\n",
      "at&t has marijuana policy\n",
      "company has benefits\n",
      "at&t has have patience\n",
      "skechers has non slip\n",
      "'s on internet 's has done in prison\n",
      "reach be of cotton in blue black khaki has belt loops has\n",
      "cracker barrel has website\n",
      "volume need step into age of technology has caused update hiring process\n",
      "retail has pay scale\n",
      "allowed handle products has be color matches skin tone\n",
      "company has lay offs\n",
      "tattoos has covered\n",
      "hiring process was has completed hiring manager makes\n",
      "fargo has mortgage officers\n",
      "fargo has background check procedure\n",
      "fargo has cafeteria\n",
      "retail has trained in customer service\n",
      "job description is has nothing do with area\n",
      "starting salary is same as guy work with been for years has gotten dollar raise\n",
      "company has mixture of gender\n",
      "home depot has own shipping and receiving\n",
      "home depot has training methods\n",
      "home depot has lack of management\n",
      "management has shown exclusion do like from company gifts\n",
      "depict assessment of company has achieved 's market share\n",
      "home depot has team in place for asset protection\n",
      "was on training has ask in order\n",
      "home depot experience has been in rock hill\n",
      "company has types of technology equipment\n",
      "long has home depot logo\n",
      "home depot has night shifts\n",
      "pay rate has changed from new york\n",
      "state has weed\n",
      "thd has right to drug test\n",
      "company is has tolerance for drugs\n",
      "company has dress code\n",
      "home depot has company policy\n",
      "home depot has policy test\n",
      "had hair has had pink hair\n",
      "home depot has loss prevention\n",
      "company is has locations over united states\n",
      "home depot has matter\n",
      "full time has coverage with aetna\n",
      "home depot has healthcare\n",
      "medical coverage has pick is insurance\n",
      "geico has employees ranging from ages walks\n",
      "ceo of company location has pages of nothing but star reviews\n",
      "company has special needs\n",
      "training has been within geico\n",
      "training ensure has information\n",
      "company has changed sales customer service are\n",
      "information by someone has business\n",
      "work at center has comes are willing stand for period\n",
      "amazon has cares about work / life balance\n",
      "human has issue of work / life balance\n",
      "amazon has bunch of am pa\n",
      "jeff bezos has become man off blood\n",
      "requirements amazon has stated are use except for disability\n",
      "management has base information\n",
      "amazon has bias for promoting company\n",
      "company has reached point needs warm bodies\n",
      "amazon has become be announced trying minimize new hires\n",
      "education has spread out\n",
      "prime now has one of hiring practices\n",
      "company has during seasonal\n",
      "dallas has one inside city\n",
      "amazon has lot of great benefits\n",
      "amazon has requested urine test\n",
      "corporation has with opening communication goes\n",
      "executed confidentiality invention assignment agreement see has anything do with being absent sick with doctor 's note\n",
      "morale has dropped earning money\n",
      "amazon has work from home positions\n",
      "met by time fulfills company needs has contacted by hr manager\n",
      "amazon has hired felons\n",
      "company has gotten like see union\n",
      "management has step bottom line is\n",
      "management has talk\n",
      "had been management has been nice\n",
      "way law has order\n",
      "enjoying free drinks have work hard as employees has forced work till\n",
      "keeping mouth closed in role has with trump\n",
      "products is has reviews order\n",
      "email stating that “ has heard communicate during meeting needed switch to nit sorts\n",
      "live has lot of construction\n",
      "provides livable wage has been at forefront of innovation\n",
      "company has organization\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(_prompt_retrieve('has')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: \n",
      " and the company does n't hire your if you do n't have a tam card ..\n",
      "['company-3', 'hire-6', 'have-12', 'do-10', 'have-12', 'card-15']\n",
      "company hire do have card ('company', 'card')\n",
      "\n",
      "_sent: yes that s what i lke about rhis company is that you can be yourself they do nt judge or makes you wear clothes or shoes do nt like\n",
      "['company-8', 'about-6', 'lke-5', 's-2', 'is-9', 'be-13', 'yourself-14', 'judge-18', 'do-16', 'judge-18']\n",
      "s lke about company is be yourself do judge ('company', 'judge')\n",
      "\n",
      "_sent: no marshalls does not do any drug test .\n",
      "['marshalls-1', 'do-4', 'test-7', 'drug-6']\n",
      "marshalls do drug test ('marshalls', 'drug')\n",
      "\n",
      "_sent: how much is the pay in durham nc and do they pay every week or bi weekly\n",
      "['nc-7', 'in-5', 'pay-4', 'is-2', 'pay-11', 'do-9', 'pay-11', 'week-13', 'bi-15', 'weekly-16']\n",
      "is pay in nc do pay week bi weekly ('nc', 'bi weekly')\n",
      "\n",
      "_sent: marshalls do not allow leggings to be worn at any time .\n",
      "['marshalls-0', 'allow-3', 'do-1', 'allow-3', 'worn-7', 'leggings-4']\n",
      "marshalls do allow leggings worn ('marshalls', 'leggings')\n",
      "\n",
      "_sent: the drug test they would do is urine .\n",
      "['test-2', 'do-5', 'test-2', 'is-6', 'urine-7']\n",
      "test do is urine ('test', 'urine')\n",
      "\n",
      "_sent: i did n't mind it at first for a part time job to have me do something while i was in community college , but now that i left i 'd say that this is a great first job if you 're wanting to experience what retail is like .\n",
      "['time-10', 'job-11', 'have-13', 'do-15', 'was-19', 'in-20', 'college-22', 'community-21', 'part-9']\n",
      "part time job have do was in community college ('part time', 'community')\n",
      "\n",
      "_sent: the company will do drug testing and will ask for background checks .\n",
      "['company-1', 'do-3', 'testing-5', 'drug-4']\n",
      "company do drug testing ('company', 'drug')\n",
      "\n",
      "_sent: they allow you to dress freely as long as you do n't wear big logos or ripped jeans .\n",
      "['long-7', 'wear-12', 'do-10', 'wear-12', 'logos-14']\n",
      "long do wear logos ('long', 'logos')\n",
      "\n",
      "_sent: depending on when do you apply to a position , and for how long that position would be posted , it could take a minimum of 3 weeks ( for existing employees ) to 5 weeks for new hired employees .\n",
      "['depending-0', 'apply-5', 'do-3', 'apply-5', 'take-22', 'for-11', 'posted-18', 'long-13', 'on-1']\n",
      "depending on do apply for long posted take ('depending on', 'long')\n",
      "\n",
      "_sent: i sent my application may 11th 2019 on may 13th they sent me an email to do the video interview .\n",
      "['email-14', 'do-16', 'interview-19', 'video-18']\n",
      "email do video interview ('email', 'video')\n",
      "\n",
      "_sent: at&t do take drug test .\n",
      "['at&t-0', 'take-2', 'do-1', 'take-2', 'test-4', 'drug-3']\n",
      "at&t do take drug test ('at&t', 'drug')\n",
      "\n",
      "_sent:   i would think with those working in non - management positions such as outside plant and installers , they probably do have drug testing .\n",
      "['plant-15', 'as-13', 'positions-11', 'in-7', 'working-6', 'those-5', 'with-4', 'think-3', 'have-22', 'do-21', 'have-22', 'testing-24', 'drug-23']\n",
      "think with those working in positions as plant do have drug testing ('plant', 'drug')\n",
      "\n",
      "_sent: how much knowledge do you have regarding new cell phones , accessories and tablets .\n",
      "['knowledge-2', 'have-5', 'do-3', 'have-5', 'regarding-6', 'phones-9', 'cell-8']\n",
      "knowledge do have regarding cell phones ('knowledge', 'cell phones')\n",
      "\n",
      "_sent: like working for hitler they do not care about employees as long as they can make themselves look good .\n",
      "['hitler-3', 'for-2', 'working-1', 'like-0', 'care-7', 'do-5', 'care-7', 'long-11']\n",
      "like working for hitler do care long ('hitler', 'long')\n",
      "\n",
      "_sent: your life is over and they do not care about you or your family .\n",
      "['life-1', 'is-2', 'care-8', 'do-6', 'care-8', 'about-9', 'you-10', 'family-13']\n",
      "life is do care about you family ('life', 'family')\n",
      "\n",
      "_sent: i went to college , they do not work with school\n",
      "['college-3', 'to-2', 'went-1', 'work-8', 'do-6', 'work-8', 'with-9', 'school-10']\n",
      "went to college do work with school ('college', 'school')\n",
      "\n",
      "_sent: management thinks you should sleep with them , and if you do nt your life will be misery , and good luck reporting it , i tried that route and was told oh i 'm so sorry and nothing was even done about it or even looked at even though i had concrete proof and other agents had reported the same manager harassing them as well .\n",
      "['sleep-4', 'thinks-1', 'be-16', 'do-11', 'be-16', 'life-14']\n",
      "thinks sleep do life be ('sleep', 'life')\n",
      "\n",
      "_sent: so far major lipservice is all you have managed to do in this area .\n",
      "['major-2', 'lipservice-3', 'is-4', 'all-5', 'managed-8', 'do-10', 'in-11', 'area-13']\n",
      "major lipservice is all managed do in area ('major', 'area')\n",
      "\n",
      "_sent: lack of support from management and the fact that i do n't count .\n",
      "['management-4', 'from-3', 'support-2', 'of-1', 'lack-0', 'fact-7', 'count-12', 'do-10', 'count-12']\n",
      "lack of support from management fact do count ('management', 'count')\n",
      "\n",
      "_sent: i had weekends off most of my career with at&t and there were lots of employees you could do a shift trade with .\n",
      "['at&t-9', 'with-8', 'weekends-2', 'had-1', 'do-18', 'trade-21']\n",
      "had weekends with at&t do trade ('at&t', 'trade')\n",
      "\n",
      "_sent: yes , there are flexible schedules that do allow for training etc .\n",
      "['schedules-5', 'allow-8', 'do-7', 'allow-8', 'for-9', 'etc-11', 'training-10', 'flexible-4']\n",
      "flexible schedules do allow for training etc ('flexible schedules', 'training')\n",
      "\n",
      "_sent:   i am a retiree and would love to do something on contract with at&t.   i started in the call center and from there promoted up to 1st and then 2nd level in 12 years .\n",
      "['love-7', 'do-9', 'something-10', 'on-11', 'contract-12']\n",
      "love do something on contract ('love', 'contract')\n",
      "\n",
      "_sent: how long do you work there until the health insurance kicks in\n",
      "['long-1', 'work-4', 'do-2', 'work-4', 'until-6', 'kicks-10', 'insurance-9', 'health-8']\n",
      "long do work until health insurance kicks ('long', 'health')\n",
      "\n",
      "_sent: i have no idea as my position with at&t had nothing to do with hiring decisions .\n",
      "['at&t-8', 'with-7', 'position-6', 'had-9', 'nothing-10', 'do-12', 'with-13', 'hiring-14', 'decisions-15']\n",
      "position with at&t had nothing do with hiring decisions ('at&t', 'hiring decisions')\n",
      "\n",
      "_sent: i 'm sure if you 're going to be working in a retail environment with at&t they do a pretty extensive background check .\n",
      "['at&t-16', 'with-15', 'working-10', 'going-7', 'do-18', 'check-23', 'extensive-21', 'background-22']\n",
      "going working with at&t do extensive background check ('at&t', 'extensive background check')\n",
      "\n",
      "_sent: nothing in particular as management employees do not get top notch \" paid benefits \"\n",
      "['management-4', 'employees-5', 'get-8', 'do-6', 'get-8', 'benefits-13']\n",
      "management employees do get benefits ('management', 'benefits')\n",
      "\n",
      "_sent: make sure there is a contact number or email in order to do a follow up .\n",
      "['order-10', 'do-12', 'follow-14', 'up-15']\n",
      "order do follow up ('order', 'follow up')\n",
      "\n",
      "_sent: what is your ambition in life and where do you see yourself in 5 years with at&t ?\n",
      "['life-5', 'in-4', 'ambition-3', 'is-1', 'see-10', 'do-8', 'see-10', 'with-15', 'at&t-16']\n",
      "is ambition in life do see with at&t ('life', 'at&t')\n",
      "\n",
      "_sent: no if your part time they do not extend benefits and the union acts like your invisible\n",
      "['time-4', 'extend-8', 'do-6', 'extend-8', 'benefits-9', 'part-3']\n",
      "part time do extend benefits ('part time', 'benefits')\n",
      "\n",
      "_sent:  \n",
      "\n",
      " answer : it cost less to maintain at&t system in texas rather than in california , do to personnel and the needs of the business .\n",
      "['california-15', 'in-14', 'maintain-7', 'cost-4', 'do-17', 'to-18', 'personnel-19', 'needs-22', 'of-23', 'business-25']\n",
      "cost maintain in california do to personnel needs of business ('california', 'business')\n",
      "\n",
      "_sent: not long at all , you will do a few days of training and you will start making phone calls after a few training sessions via online .\n",
      "['long-1', 'all-3', 'do-7', 'days-10', 'of-11', 'training-12']\n",
      "long all do days of training ('long', 'training')\n",
      "\n",
      "_sent: i was not associated or involved in the hr department and do not know at&t pay rates .\n",
      "['department-9', 'in-6', 'involved-5', 'associated-3', 'know-13', 'do-11', 'know-13', 'rates-16', 'at&t-14']\n",
      "associated involved in department do know at&t rates ('department', 'at&t')\n",
      "\n",
      "_sent: i was not associated or involved in the hr department and do not know at&t hiring / substance use policies .\n",
      "['department-9', 'in-6', 'involved-5', 'associated-3', 'know-13', 'do-11', 'know-13', 'use-18', 'substance-17', 'at&t-14']\n",
      "associated involved in department do know at&t substance use ('department', 'at&t')\n",
      "\n",
      "_sent: drugs are a non factor , there is so much to do with such short time frames , those that use drugs do so far from the job and to their own detriment .\n",
      "['drugs-0', 'are-1', 'is-7', 'much-9', 'do-11', 'with-12', 'frames-16', 'time-15', 'short-14']\n",
      "drugs are is much do with short time frames ('drugs', 'short')\n",
      "\n",
      "_sent: since hostess shifts are generally 6 hours long with no one to cover , i do not get time to have an employee meal .\n",
      "['cover-12', 'one-10', 'with-8', 'are-3', 'get-17', 'do-15', 'get-17', 'time-18', 'have-20', 'meal-23', 'employee-22']\n",
      "are with one cover do get time have employee meal ('cover', 'employee meal')\n",
      "\n",
      "_sent: does cracker barrel do direct deposit\n",
      "['barrel-2', 'do-3', 'deposit-5', 'cracker-1', 'direct-4']\n",
      "cracker barrel do direct deposit ('cracker barrel', 'direct deposit')\n",
      "\n",
      "_sent: what web site do i go under to check the cracker barrel background check .\n",
      "['site-2', 'go-5', 'do-3', 'go-5', 'check-8', 'check-13', 'barrel-11', 'web-1', 'cracker-10']\n",
      "web site do go check cracker barrel check ('web site', 'cracker barrel')\n",
      "\n",
      "_sent: how long do it take for a background check to come back\n",
      "['long-1', 'take-4', 'do-2', 'take-4', 'for-5', 'check-8', 'background-7']\n",
      "long do take for background check ('long', 'background check')\n",
      "\n",
      "_sent: the only one suffering is the guest ; get in the business of retaining   ( you are exhausting yourself ) when all you do is train .\n",
      "['business-11', 'in-9', 'get-8', 'exhausting-18', 'is-25', 'all-22', 'do-24', 'all-22', 'is-25', 'train-26']\n",
      "get in business exhausting all do is train ('business', 'train')\n",
      "\n",
      "_sent: i am not very familiar with the hiring process of the company , but i know they do a background check .\n",
      "['company-11', 'of-9', 'process-8', 'with-5', 'familiar-4', 'am-1', 'know-15', 'do-17', 'check-20', 'background-19']\n",
      "am familiar with process of company know do background check ('company', 'background check')\n",
      "\n",
      "_sent: but in my store the district manager and store manager do not mind very small nose piercings\n",
      "['manager-9', 'mind-12', 'do-10', 'mind-12', 'piercings-16', 'store-8', 'nose-15']\n",
      "store manager do mind nose piercings ('store manager', 'nose piercings')\n",
      "\n",
      "_sent: i got to watch a video and do paper work then they made me come back and do an online course which took at 3 hours .\n",
      "['video-5', 'watch-3', 'do-7', 'work-9', 'paper-8']\n",
      "watch video do paper work ('video', 'paper')\n",
      "\n",
      "_sent: usually they only want natural hair colors however they do n't always make a big deal about it .\n",
      "['hair-5', 'colors-6', 'want-3', 'make-12', 'do-9', 'make-12', 'deal-15', 'big-14']\n",
      "want hair colors do make big deal ('hair', 'big deal')\n",
      "\n",
      "_sent: yea they will hire you as long as you do n't have violent crime\n",
      "['long-6', 'have-11', 'do-9', 'have-11', 'crime-13', 'violent-12']\n",
      "long do have violent crime ('long', 'violent crime')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: ask if they can undergo high stress environment with extreme heat some can do one or the other but doing both is a big deal while working at cracker barrel\n",
      "['heat-10', 'with-8', 'undergo-4', 'do-13', 'is-21', 'deal-24', 'big-23']\n",
      "undergo with heat do is big deal ('heat', 'big deal')\n",
      "\n",
      "_sent: does cracker barrel do direct deposit\n",
      "['barrel-2', 'do-3', 'deposit-5', 'cracker-1', 'direct-4']\n",
      "cracker barrel do direct deposit ('cracker barrel', 'direct deposit')\n",
      "\n",
      "_sent: nail polish / acrylic is allowed only if you do not handle food products and it has to be a color that matches your skin tone\n",
      "['polish-1', 'acrylic-3', 'allowed-5', 'handle-11', 'do-9', 'handle-11', 'products-13', 'food-12']\n",
      "polish acrylic allowed do handle food products ('polish', 'food')\n",
      "\n",
      "src not matched\n",
      "_sent: classes normally ran from 8:00 am - 4:30 pm , however , i would normally be an hour early and stay at least a half hour late to do all of my daily emails and voice messages .\n",
      "['hour-25', 'late-26', 'stay-20', 'do-28', 'all-29', 'of-30', 'emails-33', 'daily-32', 'half-24']\n",
      "stay half hour late do all of daily emails ('half hour', 'daily')\n",
      "\n",
      "_sent: some jobs at the bank do not require dealing with counting large amounts of money and much is done electronically .\n",
      "['bank-4', 'at-2', 'jobs-1', 'require-7', 'do-5', 'require-7', 'dealing-8', 'with-9', 'counting-10', 'amounts-12', 'of-13', 'money-14']\n",
      "jobs at bank do require dealing with counting amounts of money ('bank', 'money')\n",
      "\n",
      "_sent: yes , as most banks do require a credit check , backround check - fingerprinting .\n",
      "['banks-4', 'require-6', 'do-5', 'require-6', 'check-9', 'credit-8']\n",
      "banks do require credit check ('banks', 'credit check')\n",
      "\n",
      "_sent: during my 2nd interview i was asked if i could do a third interview with the hiring manager so i had my 3rd interview in the same day .\n",
      "['interview-3', 'during-0', 'asked-6', 'do-10', 'interview-13', 'with-14', 'manager-17', '2nd-2', 'hiring-16']\n",
      "during 2nd interview asked do interview with hiring manager ('2nd interview', 'hiring manager')\n",
      "\n",
      "_sent: i think wells fargo needs to do a mental health screening on all their current managers .\n",
      "['fargo-3', 'needs-4', 'do-6', 'screening-10', 'mental-8', 'health-9']\n",
      "fargo needs do mental health screening ('fargo', 'mental health')\n",
      "\n",
      "_sent: in our department we did not do credit checks , but they may have done so at different departments .\n",
      "['department-2', 'in-0', 'do-6', 'checks-8', 'credit-7']\n",
      "in department do credit checks ('department', 'credit checks')\n",
      "\n",
      "_sent: it was really quick , i got a phone call to do a one on one after the group interview about three or four hours after the end of the group interview .\n",
      "['call-9', 'do-11', 'interview-19', 'phone-8', 'group-18']\n",
      "phone call do group interview ('phone call', 'group interview')\n",
      "\n",
      "_sent: yes , part timers do get benefits just the same as a full timer .\n",
      "['timers-3', 'get-5', 'do-4', 'get-5', 'benefits-6', 'part-2']\n",
      "part timers do get benefits ('part timers', 'benefits')\n",
      "\n",
      "_sent: just a general do not reply email to confirm my 2nd interview appointment .\n",
      "['general-2', 'reply-5', 'do-3', 'reply-5', 'email-6']\n",
      "general do reply email ('general', 'email')\n",
      "\n",
      "_sent: teller does not that the same password and does not have to do as much as lead .\n",
      "['password-6', 'does-1', 'have-10', 'do-12', 'much-14', 'as-15', 'lead-16']\n",
      "does password have do much as lead ('password', 'lead')\n",
      "\n",
      "_sent: working remotely out of the san antonio area , but i do believe when i first started with world savings there was random drug testing involved during the hiring process .\n",
      "['area-7', 'of-3', 'out-2', 'working-0', 'believe-12', 'do-11', 'believe-12', 'was-21', 'testing-24', 'random-22', 'drug-23']\n",
      "working out of area do believe was random drug testing ('area', 'random drug testing')\n",
      "\n",
      "_sent: yes take finger prints and do drug test .\n",
      "['prints-3', 'take-1', 'do-5', 'test-7', 'drug-6', 'finger-2']\n",
      "take finger prints do drug test ('finger prints', 'drug')\n",
      "\n",
      "_sent: wells fargo does do a background check before you are eligible to start work there .\n",
      "['fargo-1', 'do-3', 'check-6', 'background-5']\n",
      "fargo do background check ('fargo', 'background check')\n",
      "\n",
      "_sent: yes all job with this company do drug test\n",
      "['company-5', 'with-3', 'job-2', 'do-6', 'test-8', 'drug-7']\n",
      "job with company do drug test ('company', 'drug')\n",
      "\n",
      "_sent: i am not sure what a phone banker is , nor do i know roanoke va .\n",
      "['banker-7', 'is-8', 'sure-3', 'am-1', 'know-13', 'do-11', 'know-13', 'va-15', 'roanoke-14', 'phone-6']\n",
      "am sure phone banker is do know roanoke va ('phone banker', 'roanoke')\n",
      "\n",
      "_sent: criminal history , i believe they do a credit check too\n",
      "['history-1', 'believe-4', 'do-6', 'check-9', 'credit-8']\n",
      "history believe do credit check ('history', 'credit check')\n",
      "\n",
      "_sent: does anybody know if wells fargo background check have alot to do with education ?\n",
      "['check-7', 'have-8', 'alot-9', 'do-11', 'with-12', 'education-13', 'background-6']\n",
      "background check have alot do with education ('background check', 'education')\n",
      "\n",
      "_sent: have to take a phone interview and then come in to do a group interview\n",
      "['interview-5', 'take-2', 'come-8', 'do-11', 'interview-14', 'phone-4', 'group-13']\n",
      "take phone interview come do group interview ('phone interview', 'group interview')\n",
      "\n",
      "_sent:   they will fingerprint you but do not administer any drug tests .\n",
      "['fingerprint-3', 'administer-8', 'do-6', 'administer-8', 'tests-11', 'drug-10']\n",
      "fingerprint do administer drug tests ('fingerprint', 'drug')\n",
      "\n",
      "_sent: part time employees do not receive benefits that i am aware of .\n",
      "['time-1', 'receive-5', 'do-3', 'receive-5', 'benefits-6', 'part-0']\n",
      "part time do receive benefits ('part time', 'benefits')\n",
      "\n",
      "_sent: yes the management of home depot do not discriminate in any way towards those with a criminal record , it anything they are always willing to help people get back on their feet .\n",
      "['depot-5', 'of-3', 'management-2', 'discriminate-8', 'do-6', 'discriminate-8', 'in-9', 'way-11', 'towards-12', 'those-13', 'with-14', 'record-17', 'home-4', 'criminal-16']\n",
      "management of home depot do discriminate in way towards those with criminal record ('home depot', 'criminal record')\n",
      "\n",
      "_sent: i did a drug screening for employment at home depot how do i give list of prescription drugs i 'm on ? ?\n",
      "['depot-9', 'at-7', 'did-1', 'give-13', 'do-11', 'give-13', 'list-14', 'of-15', 'drugs-17', 'home-8', 'prescription-16']\n",
      "did at home depot do give list of prescription drugs ('home depot', 'prescription drugs')\n",
      "\n",
      "_sent: the home depot on thompson lane in nashville tn does drug test and they do mouth swab\n",
      "['test-11', 'does-9', 'do-14', 'swab-16', 'mouth-15']\n",
      "does test do mouth swab ('test', 'mouth')\n",
      "\n",
      "_sent: how does home depot   do the pre drug test is it swab or urine\n",
      "['depot-3', 'do-5', 'is-10', 'test-9', 'drug-8', 'home-2']\n",
      "home depot do drug test is ('home depot', 'drug')\n",
      "\n",
      "_sent: for asheville nc   home depot how do they do the test swab or urine\n",
      "['depot-5', 'do-9', 'do-7', 'do-9', 'swab-12', 'test-11', 'home-4']\n",
      "home depot do do test swab ('home depot', 'test')\n",
      "\n",
      "_sent: part time workers do not get benefits besides some vacation days and sick days .\n",
      "['time-1', 'workers-2', 'get-5', 'do-3', 'get-5', 'benefits-6', 'part-0']\n",
      "part time workers do get benefits ('part time', 'benefits')\n",
      "\n",
      "_sent: i am not sure my job description is not a chasier or has nothing to do with that area\n",
      "['description-6', 'is-7', 'has-12', 'nothing-13', 'do-15', 'with-16', 'area-18', 'job-5']\n",
      "job description is has nothing do with area ('job description', 'area')\n",
      "\n",
      "_sent: department managers do not work set schedules\n",
      "['department-0', 'managers-1', 'work-4', 'do-2', 'work-4', 'set-5', 'schedules-6']\n",
      "department managers do work set schedules ('department', 'set schedules')\n",
      "\n",
      "_sent: are you a friendly outgoing person do you like working with the public how are your customer service skills\n",
      "['friendly-3', 'outgoing-4', 'person-5', 'are-0', 'like-8', 'do-6', 'like-8', 'working-9', 'with-10', 'public-12']\n",
      "are friendly outgoing person do like working with public ('friendly', 'public')\n",
      "\n",
      "_sent: no the home depot do not hire felons\n",
      "['depot-3', 'hire-6', 'do-4', 'hire-6', 'home-2', 'felons-7']\n",
      "home depot do hire felons ('home depot', 'hire felons')\n",
      "\n",
      "_sent: management only cares about the numbers and if you do n't get a customer to apply for a credit card you will receive a note in the system and then terminated .\n",
      "['management-0', 'cares-2', 'get-11', 'do-9', 'get-11', 'apply-15', 'for-16', 'card-19', 'credit-18']\n",
      "management cares do get apply for credit card ('management', 'credit card')\n",
      "\n",
      "_sent: department heads are rude and do n't know how to talk to their workers , then they expect you to do they work while they take credit for it unless it is done incorrectly .\n",
      "['department-0', 'heads-1', 'are-2', 'know-7', 'do-5', 'know-7', 'talk-10']\n",
      "department heads are do know talk ('department', 'talk')\n",
      "\n",
      "_sent: company hires some of the most incompetent managers , which is your corporate district people , they absolutely do not   have a good work life balance ,   do n't plan on making it a career because if you work your way up to a decent wage and your in your 40 ' s   you can be assured they will shove you around till you leave , home depot is famous for getting rid of older people making good money , but very careful how they do it ,   look up history on a law suite in co. any good people they suck dry ,   the negetives you read are true\n",
      "['district-13', 'people-14', 'is-10', 'managers-7', 'of-3', 'some-2', 'hires-1', 'have-21', 'do-18', 'have-21', 'balance-26', 'work-24', 'life-25']\n",
      "hires some of managers is district people do have work life balance ('district', 'work life balance')\n",
      "\n",
      "_sent: new district manager who spent thousands of dollars to make things pretty , removed anti - fatigue mats , self - checkout registers do n't work , bad working conditions , threaten to take away your breaks and lunches because no coverage .\n",
      "['anti-14', '--15', 'fatigue-16', 'mats-17', 'manager-2', 'work-25', 'do-23', 'work-25', 'conditions-29', 'working-28']\n",
      "manager anti - fatigue mats do work working conditions ('anti', 'working conditions')\n",
      "\n",
      "_sent: butt off get all your funky reeards you hand out and do e fluzy thier only 1year get promoted to full time .\n",
      "e do full time\n",
      "None 10540441779542591554 14930118741968279164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: management has clearly shown favoritism , and exclusion of employees they do n’t like from company gifts and promotions .\n",
      "['management-0', 'shown-3', 'exclusion-7', 'do-11', 'like-13', 'from-14', 'gifts-16', 'company-15']\n",
      "management shown exclusion do like from company gifts ('management', 'company')\n",
      "\n",
      "_sent: if part time you do n't get a weekend off , ever , unless you request it .\n",
      "['time-2', 'get-6', 'do-4', 'get-6', 'weekend-8', 'part-1', 'off-9']\n",
      "part time do get weekend off ('part time', 'weekend off')\n",
      "\n",
      "_sent: what products home depot sells , what 's my work experience like , anything to do with customer relations .\n",
      "['depot-3', 'sells-4', \"'s-7\", 'anything-13', 'do-15', 'with-16', 'relations-18', 'home-2', 'customer-17']\n",
      "home depot sells 's anything do with customer relations ('home depot', 'customer relations')\n",
      "\n",
      "_sent: as long as you wear a collared shirt or polo and do not show any rude logos they do not care .\n",
      "['polo-9', 'shirt-7', 'wear-4', 'show-13', 'do-11', 'show-13', 'logos-16']\n",
      "wear shirt polo do show logos ('polo', 'logos')\n",
      "\n",
      "_sent: \n",
      " how long do you think you would stay @ home depot ?\n",
      "['long-2', 'think-5', 'do-3', 'think-5', 'stay-8', '@-9', 'depot-11', 'home-10']\n",
      "long do think stay @ home depot ('long', 'home depot')\n",
      "\n",
      "_sent: urine , i do n't do drugs so not really a concern .\n",
      "['urine-0', 'do-5', 'do-3', 'do-5', 'drugs-6']\n",
      "urine do do drugs ('urine', 'drugs')\n",
      "\n",
      "_sent: not sure , but as long as you do n't operate heavy machinery , i think you 'll be fine .\n",
      "['long-5', 'operate-10', 'do-8', 'operate-10', 'machinery-12', 'heavy-11']\n",
      "long do operate heavy machinery ('long', 'heavy machinery')\n",
      "\n",
      "_sent: worst company ever if your in houston texas jake   mcord is a lying weasel and snake , promise to pay but never do , worthless excuse of a marine\n",
      "['snake-16', 'weasel-14', 'is-11', 'promise-18', 'pay-20', 'do-23', 'excuse-26', 'of-27', 'marine-29']\n",
      "is weasel snake promise pay do excuse of marine ('snake', 'marine')\n",
      "\n",
      "_sent: home depot will do their best to work with you through your disability .\n",
      "['depot-1', 'do-3', 'work-7', 'through-10', 'disability-12', 'home-0']\n",
      "home depot do work through disability ('home depot', 'disability')\n",
      "\n",
      "_sent: i started with the company 16 years ago and i do not recall if there was   a background check .\n",
      "['company-4', 'with-2', 'started-1', 'recall-12', 'do-10', 'recall-12', 'was-15', 'check-19', 'background-18']\n",
      "started with company do recall was background check ('company', 'background check')\n",
      "\n",
      "_sent: easy to pass , as long as you do n't do anything for 24 - 72 hours before your test !\n",
      "['long-5', 'do-10', 'do-8', 'do-10', 'before-17', 'test-19']\n",
      "long do do before test ('long', 'test')\n",
      "\n",
      "_sent: i did n't work in this location , but all home depot stores do individual criminal background checks i believe , but not sure .\n",
      "['depot-11', 'stores-12', 'do-13', 'checks-17', 'background-16', 'home-10', 'criminal-15']\n",
      "home depot stores do criminal background checks ('home depot', 'criminal background')\n",
      "\n",
      "src not matched\n",
      "_sent: no idea is this location does drug testing or not i do n't know why they chose wind him connecticut because i worked at a home depot in mount pleasant texas\n",
      "['drug-6', 'testing-7', 'does-5', 'know-13', 'do-11', 'know-13', 'chose-16', 'wind-17']\n",
      "does drug testing do know chose wind ('drug', 'wind')\n",
      "\n",
      "_sent: as long as you do n't have a felony you should be ok .\n",
      "['long-1', 'have-6', 'do-4', 'have-6', 'felony-8']\n",
      "long do have felony ('long', 'felony')\n",
      "\n",
      "_sent: these associates are considered home depot associates and do receive home depot benefits\n",
      "['depot-5', 'associates-6', 'considered-3', 'receive-9', 'do-8', 'receive-9', 'benefits-12', 'home-4']\n",
      "considered home depot associates do receive benefits ('home depot', 'benefits')\n",
      "\n",
      "_sent: in orlando , florida , i was required to do the saliva swab drug test .\n",
      "['florida-3', 'orlando-1', 'in-0', 'required-7', 'do-9', 'test-14', 'saliva-11']\n",
      "in orlando florida required do saliva test ('florida', 'saliva')\n",
      "\n",
      "_sent: if you are offered a position with the home depot you do have a drug test administered on - site .\n",
      "['depot-9', 'have-12', 'do-11', 'have-12', 'test-15', 'drug-14', 'home-8']\n",
      "home depot do have drug test ('home depot', 'drug')\n",
      "\n",
      "_sent: i never whent to hawaii to do the drug screening i did it in new jersey\n",
      "['hawaii-4', 'do-6', 'screening-9', 'drug-8']\n",
      "hawaii do drug screening ('hawaii', 'drug')\n",
      "\n",
      "company hire do have card\n",
      "s lke about company is be yourself do judge\n",
      "marshalls do drug test\n",
      "is pay in nc do pay week bi weekly\n",
      "marshalls do allow leggings worn\n",
      "test do is urine\n",
      "part time job have do was in community college\n",
      "company do drug testing\n",
      "long do wear logos\n",
      "depending on do apply for long posted take\n",
      "email do video interview\n",
      "at&t do take drug test\n",
      "think with those working in positions as plant do have drug testing\n",
      "knowledge do have regarding cell phones\n",
      "like working for hitler do care long\n",
      "life is do care about you family\n",
      "went to college do work with school\n",
      "thinks sleep do life be\n",
      "major lipservice is all managed do in area\n",
      "lack of support from management fact do count\n",
      "had weekends with at&t do trade\n",
      "flexible schedules do allow for training etc\n",
      "love do something on contract\n",
      "long do work until health insurance kicks\n",
      "position with at&t had nothing do with hiring decisions\n",
      "going working with at&t do extensive background check\n",
      "management employees do get benefits\n",
      "order do follow up\n",
      "is ambition in life do see with at&t\n",
      "part time do extend benefits\n",
      "cost maintain in california do to personnel needs of business\n",
      "long all do days of training\n",
      "associated involved in department do know at&t rates\n",
      "associated involved in department do know at&t substance use\n",
      "drugs are is much do with short time frames\n",
      "are with one cover do get time have employee meal\n",
      "cracker barrel do direct deposit\n",
      "web site do go check cracker barrel check\n",
      "long do take for background check\n",
      "get in business exhausting all do is train\n",
      "am familiar with process of company know do background check\n",
      "store manager do mind nose piercings\n",
      "watch video do paper work\n",
      "want hair colors do make big deal\n",
      "long do have violent crime\n",
      "undergo with heat do is big deal\n",
      "cracker barrel do direct deposit\n",
      "polish acrylic allowed do handle food products\n",
      "stay half hour late do all of daily emails\n",
      "jobs at bank do require dealing with counting amounts of money\n",
      "banks do require credit check\n",
      "during 2nd interview asked do interview with hiring manager\n",
      "fargo needs do mental health screening\n",
      "in department do credit checks\n",
      "phone call do group interview\n",
      "part timers do get benefits\n",
      "general do reply email\n",
      "does password have do much as lead\n",
      "working out of area do believe was random drug testing\n",
      "take finger prints do drug test\n",
      "fargo do background check\n",
      "job with company do drug test\n",
      "am sure phone banker is do know roanoke va\n",
      "history believe do credit check\n",
      "background check have alot do with education\n",
      "take phone interview come do group interview\n",
      "fingerprint do administer drug tests\n",
      "part time do receive benefits\n",
      "management of home depot do discriminate in way towards those with criminal record\n",
      "did at home depot do give list of prescription drugs\n",
      "does test do mouth swab\n",
      "home depot do drug test is\n",
      "home depot do do test swab\n",
      "part time workers do get benefits\n",
      "job description is has nothing do with area\n",
      "department managers do work set schedules\n",
      "are friendly outgoing person do like working with public\n",
      "home depot do hire felons\n",
      "management cares do get apply for credit card\n",
      "department heads are do know talk\n",
      "hires some of managers is district people do have work life balance\n",
      "manager anti - fatigue mats do work working conditions\n",
      "management shown exclusion do like from company gifts\n",
      "part time do get weekend off\n",
      "home depot sells 's anything do with customer relations\n",
      "wear shirt polo do show logos\n",
      "long do think stay @ home depot\n",
      "urine do do drugs\n",
      "long do operate heavy machinery\n",
      "is weasel snake promise pay do excuse of marine\n",
      "home depot do work through disability\n",
      "started with company do recall was background check\n",
      "long do do before test\n",
      "home depot stores do criminal background checks\n",
      "does drug testing do know chose wind\n",
      "long do have felony\n",
      "considered home depot associates do receive benefits\n",
      "in orlando florida required do saliva test\n",
      "home depot do have drug test\n",
      "hawaii do drug screening\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(_prompt_retrieve('do')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: marshalls pays employees every other week , or biweekly .\n",
      "['marshalls-0', 'pays-1', 'biweekly-8']\n",
      "marshalls pays biweekly ('marshalls', 'biweekly')\n",
      "\n",
      "_sent: marshalls pays weekly\n",
      "['marshalls-0', 'pays-1', 'weekly-2']\n",
      "marshalls pays weekly ('marshalls', 'weekly')\n",
      "\n",
      "_sent: marshalls pays weekly , i myself have never had any problems with my paycheck while working here .\n",
      "['marshalls-0', 'pays-1', 'weekly-2']\n",
      "marshalls pays weekly ('marshalls', 'weekly')\n",
      "\n",
      "_sent: the marshall 's division pays associates on a weekly basis .\n",
      "['division-3', 'pays-4', 'on-6', 'basis-9', 'weekly-8']\n",
      "division pays on weekly basis ('division', 'weekly basis')\n",
      "\n",
      "_sent: the company pays weekly\n",
      "['company-1', 'pays-2', 'weekly-3']\n",
      "company pays weekly ('company', 'weekly')\n",
      "\n",
      "_sent: wells fargo pays biweekly pay periods for base pay and monthly for commission .\n",
      "['fargo-1', 'pays-2', 'pay-4', 'biweekly-3']\n",
      "fargo pays biweekly pay ('fargo', 'biweekly')\n",
      "\n",
      "_sent: i stayed with wells fargo because they are the only bank where i live that pays enough to support a family .\n",
      "['live-13', 'bank-10', 'pays-15', 'support-18', 'family-20']\n",
      "bank live pays support family ('live', 'family')\n",
      "\n",
      "_sent: yes i would be able to work with college courses as well , i could take morning or night classes , whatever fits in with my work schedule , i want a job that pays decent money so i can afford my funds at school along with extra money for stuff i need\n",
      "['college-8', 'courses-9', 'with-7', 'work-6', 'able-4', 'be-3', 'take-15', 'want-30', 'job-32', 'pays-34', 'money-36', 'decent-35']\n",
      "be able work with college courses take want job pays decent money ('college', 'decent money')\n",
      "\n",
      "_sent: home depot pays biweekly .\n",
      "['depot-1', 'pays-2', 'biweekly-3', 'home-0']\n",
      "home depot pays biweekly ('home depot', 'biweekly')\n",
      "\n",
      "_sent: home depot pays you biweekly\n",
      "['depot-1', 'pays-2', 'biweekly-4', 'home-0']\n",
      "home depot pays biweekly ('home depot', 'biweekly')\n",
      "\n",
      "_sent: a full time associate roughly pays $ 200 for medical insurance .\n",
      "['time-2', 'associate-3', 'pays-5', '200-7', 'for-8', 'insurance-10', 'medical-9', 'full-1']\n",
      "full time associate pays 200 for medical insurance ('full time', 'medical')\n",
      "\n",
      "_sent: home depot pays bi - weekly\n",
      "['depot-1', 'pays-2', 'weekly-5', 'home-0']\n",
      "home depot pays weekly ('home depot', 'weekly')\n",
      "\n",
      "_sent: home depot pays biweekly\n",
      "['depot-1', 'pays-2', 'biweekly-3', 'home-0']\n",
      "home depot pays biweekly ('home depot', 'biweekly')\n",
      "\n",
      "_sent: i m currently still working my full time job monday through friday , that pays the bills .\n",
      "['friday-11', 'through-10', 'working-4', 'pays-14', 'bills-16']\n",
      "working through friday pays bills ('friday', 'bills')\n",
      "\n",
      "_sent: amazon pays weekly\n",
      "['amazon-0', 'pays-1', 'weekly-2']\n",
      "amazon pays weekly ('amazon', 'weekly')\n",
      "\n",
      "_sent: 20 - 30 full time pays better but night shift make more lmoney lesson .\n",
      "['time-4', 'pays-5', 'make-10', 'shift-9', 'full-3', 'night-8']\n",
      "full time pays night shift make ('full time', 'night shift')\n",
      "\n",
      "_sent: dollar tree warehouse pays their employees more thn amazon and that s sad ! !\n",
      "['warehouse-2', 'pays-3', 'amazon-8']\n",
      "warehouse pays amazon ('warehouse', 'amazon')\n",
      "\n",
      "_sent: would mainly be because everywhere else has a pay increase or pays much more for less the stress of worrying about being terminated because you could nt make rate due to amazon system .\n",
      "['increase-9', 'has-6', 'pays-11', 'make-27', 'due-29', 'to-30', 'system-32', 'amazon-31', 'pay-8']\n",
      "has pay increase pays make due to amazon system ('pay increase', 'amazon')\n",
      "\n",
      "_sent: favoritism ... straight from the top , managers are instructed not to disipline the people from neopaul or any person from a foreign country ... these people are why amazon pays no taxes,,they make their production rate @460 items processed , then stop working .\n",
      "['amazon-29', 'pays-30', 'make-33', 'rate-36', 'production-35']\n",
      "amazon pays make production rate ('amazon', 'production')\n",
      "\n",
      "_sent: tampa pays seasonal $ 10.50 , full time starts at $ 11.00\n",
      "['tampa-0', 'pays-1', 'seasonal-2']\n",
      "tampa pays seasonal ('tampa', 'seasonal')\n",
      "\n",
      "_sent: tjmaxx distribuition center pays 1.25 as shift differential .\n",
      "['center-2', 'pays-3', 'as-5', 'differential-7', 'shift-6']\n",
      "center pays as shift differential ('center', 'shift differential')\n",
      "\n",
      "_sent: hope that answered your question but always ask because i know they only have that shift in columbus and all pays jump state to state and country to etc .\n",
      "['columbus-17', 'in-16', 'shift-15', 'have-13', 'pays-20', 'state-22']\n",
      "have shift in columbus pays state ('columbus', 'state')\n",
      "\n",
      "_sent: amazon pays bi weekly\n",
      "['amazon-0', 'pays-1', 'bi-2', 'weekly-3']\n",
      "amazon pays bi weekly ('amazon', 'bi weekly')\n",
      "\n",
      "_sent: from personal experience amazon pays bi - weekly .\n",
      "['amazon-3', 'from-0', 'pays-4', 'weekly-7']\n",
      "from amazon pays weekly ('amazon', 'weekly')\n",
      "\n",
      "_sent: amazon pays on a by weekly fashion\n",
      "['amazon-0', 'pays-1', 'by-4', 'fashion-6', 'weekly-5']\n",
      "amazon pays by weekly fashion ('amazon', 'weekly')\n",
      "\n",
      "_sent: amazon pays weekly for the roll i was hired for .\n",
      "['amazon-0', 'pays-1', 'weekly-2']\n",
      "amazon pays weekly ('amazon', 'weekly')\n",
      "\n",
      "_sent: no , subway pays bi - weekly so every 2 weeks .\n",
      "['subway-2', 'pays-3', 'weekly-6']\n",
      "subway pays weekly ('subway', 'weekly')\n",
      "\n",
      "src not matched\n",
      "_sent: most people give you \" that look \" when you say you work in fast food , but it pays the bills and it 's a great work environment .\n",
      "['food-15', 'in-13', 'work-12', 'say-10', 'look-6', 'give-2', 'pays-19', 'bills-21']\n",
      "give look say work in food pays bills ('food', 'bills')\n",
      "\n",
      "_sent: working night ( 3 - 9 average ) is just the same as working morning , it pays minimum wage and is n't worth it .\n",
      "['average-6', 'night-1', 'is-8', 'pays-17', 'wage-19', 'minimum-18']\n",
      "night average is pays minimum wage ('average', 'minimum wage')\n",
      "\n",
      "_sent: subway pays biweekly\n",
      "['subway-0', 'pays-1', 'biweekly-2']\n",
      "subway pays biweekly ('subway', 'biweekly')\n",
      "\n",
      "_sent: subway pays biweekly\n",
      "['subway-0', 'pays-1', 'biweekly-2']\n",
      "subway pays biweekly ('subway', 'biweekly')\n",
      "\n",
      "_sent: subway pays weekly\n",
      "['subway-0', 'pays-1', 'weekly-2']\n",
      "subway pays weekly ('subway', 'weekly')\n",
      "\n",
      "_sent: subway pays bi weekly on wednesday\n",
      "['subway-0', 'pays-1', 'bi-2', 'weekly-3']\n",
      "subway pays bi weekly ('subway', 'bi weekly')\n",
      "\n",
      "_sent: rural retreat subway pays bi weekly .\n",
      "['subway-2', 'pays-3', 'bi-4', 'weekly-5']\n",
      "subway pays bi weekly ('subway', 'bi weekly')\n",
      "\n",
      "_sent: if subway pays on friday , where does salary start counting hours ; what day , to where it caps ; ditto ?\n",
      "['subway-1', 'pays-2', 'on-3', 'friday-4']\n",
      "subway pays on friday ('subway', 'friday')\n",
      "\n",
      "_sent: subway pays the employees bi - weekly plus the occasional small tips .\n",
      "['subway-0', 'pays-1', 'weekly-6']\n",
      "subway pays weekly ('subway', 'weekly')\n",
      "\n",
      "_sent: subway pays biweekly\n",
      "['subway-0', 'pays-1', 'biweekly-2']\n",
      "subway pays biweekly ('subway', 'biweekly')\n",
      "\n",
      "_sent: fedex home delivery pays on a weekly basis .\n",
      "['fedex-0', 'delivery-2', 'pays-3', 'on-4', 'basis-7', 'weekly-6']\n",
      "fedex delivery pays on weekly basis ('fedex', 'weekly basis')\n",
      "\n",
      "_sent: weekly it pays every friday\n",
      "['weekly-0', 'pays-2', 'friday-4']\n",
      "weekly pays friday ('weekly', 'friday')\n",
      "\n",
      "_sent: fedex pays for the costs of the drug test .\n",
      "['fedex-0', 'pays-1', 'for-2', 'costs-4', 'of-5', 'test-8', 'drug-7']\n",
      "fedex pays for costs of drug test ('fedex', 'drug')\n",
      "\n",
      "_sent: fedex pays weekly\n",
      "['fedex-0', 'pays-1', 'weekly-2']\n",
      "fedex pays weekly ('fedex', 'weekly')\n",
      "\n",
      "_sent: yes , fedex pays for orientation and training .\n",
      "['fedex-2', 'pays-3', 'for-4', 'orientation-5']\n",
      "fedex pays for orientation ('fedex', 'orientation')\n",
      "\n",
      "_sent: yes , the management pays special attention to the new hires\n",
      "['management-3', 'pays-4', 'to-7', 'hires-10', 'new-9']\n",
      "management pays to new hires ('management', 'new hires')\n",
      "\n",
      "_sent: starbucks pays retail employees bi weekly .\n",
      "['starbucks-0', 'pays-1', 'employees-3', 'retail-2']\n",
      "starbucks pays retail employees ('starbucks', 'retail')\n",
      "\n",
      "_sent: starbucks pays bi - weekly .\n",
      "['starbucks-0', 'pays-1', 'weekly-4']\n",
      "starbucks pays weekly ('starbucks', 'weekly')\n",
      "\n",
      "_sent: starbucks pays bi - weekly\n",
      "['starbucks-0', 'pays-1', 'weekly-4']\n",
      "starbucks pays weekly ('starbucks', 'weekly')\n",
      "\n",
      "_sent: starbucks pays you bi - weekly .\n",
      "['starbucks-0', 'pays-1', 'weekly-5']\n",
      "starbucks pays weekly ('starbucks', 'weekly')\n",
      "\n",
      "_sent: starbucks pays biweekly\n",
      "['starbucks-0', 'pays-1', 'biweekly-2']\n",
      "starbucks pays biweekly ('starbucks', 'biweekly')\n",
      "\n",
      "_sent: starbucks pays biweekly with no stipend however you do get tips once a week .\n",
      "['starbucks-0', 'pays-1', 'biweekly-2']\n",
      "starbucks pays biweekly ('starbucks', 'biweekly')\n",
      "\n",
      "_sent: starbucks pays biweekly .\n",
      "['starbucks-0', 'pays-1', 'biweekly-2']\n",
      "starbucks pays biweekly ('starbucks', 'biweekly')\n",
      "\n",
      "_sent: starbucks pays their employees biweekly\n",
      "['starbucks-0', 'pays-1', 'biweekly-4']\n",
      "starbucks pays biweekly ('starbucks', 'biweekly')\n",
      "\n",
      "_sent: starbucks pays biweekly\n",
      "['starbucks-0', 'pays-1', 'biweekly-2']\n",
      "starbucks pays biweekly ('starbucks', 'biweekly')\n",
      "\n",
      "_sent: starbucks pays by weekly\n",
      "['starbucks-0', 'pays-1', 'by-2', 'weekly-3']\n",
      "starbucks pays by weekly ('starbucks', 'weekly')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: starbucks pays weekly\n",
      "['starbucks-0', 'pays-1', 'weekly-2']\n",
      "starbucks pays weekly ('starbucks', 'weekly')\n",
      "\n",
      "_sent: all of harmans kfc pays weekly which is great !\n",
      "['kfc-3', 'of-1', 'all-0', 'pays-4', 'weekly-5']\n",
      "all of kfc pays weekly ('kfc', 'weekly')\n",
      "\n",
      "_sent: kfc pays biweekly .\n",
      "['kfc-0', 'pays-1', 'biweekly-2']\n",
      "kfc pays biweekly ('kfc', 'biweekly')\n",
      "\n",
      "_sent: i think mcdonalds pays more and chock - fill - a gives more benefits like for example shcolarships\n",
      "['mcdonalds-2', 'pays-3', 'think-1', 'gives-11', 'benefits-13']\n",
      "think mcdonalds pays gives benefits ('mcdonalds', 'benefits')\n",
      "\n",
      "_sent: macy 's pays weekly + commission\n",
      "['macy-0', 'pays-2', 'weekly-3', \"'s-1\"]\n",
      "macy 's pays weekly (\"macy 's\", 'weekly')\n",
      "\n",
      "_sent: in florida and idaho macy 's pays weekly .\n",
      "['macy-4', 'florida-1', 'in-0', 'weekly-7', 'pays-6', 'weekly-7', \"'s-5\"]\n",
      "in florida macy 's pays weekly (\"macy 's\", 'weekly')\n",
      "\n",
      "_sent: chipotle mexican grill pays bi weekly .\n",
      "['mexican-1', 'grill-2', 'pays-3', 'bi-4', 'weekly-5']\n",
      "mexican grill pays bi weekly ('mexican', 'bi weekly')\n",
      "\n",
      "_sent: chipotle pays biweekly .\n",
      "['chipotle-0', 'pays-1', 'biweekly-2']\n",
      "chipotle pays biweekly ('chipotle', 'biweekly')\n",
      "\n",
      "_sent: chipotle pays bi - weekly .\n",
      "['chipotle-0', 'pays-1', 'weekly-4']\n",
      "chipotle pays weekly ('chipotle', 'weekly')\n",
      "\n",
      "_sent: chipotle pays bi - weekly\n",
      "['chipotle-0', 'pays-1', 'weekly-4']\n",
      "chipotle pays weekly ('chipotle', 'weekly')\n",
      "\n",
      "_sent: i am a college student , and no one pays my bills for me .\n",
      "['student-4', 'am-1', 'pays-9', 'bills-11']\n",
      "am student pays bills ('student', 'bills')\n",
      "\n",
      "_sent: it will be three weeks since panera bread pays bi - weekly .\n",
      "['bread-7', 'pays-8', 'weekly-11']\n",
      "bread pays weekly ('bread', 'weekly')\n",
      "\n",
      "_sent: jcpenney pays on a biweekly basis .\n",
      "['jcpenney-0', 'pays-1', 'on-2', 'basis-5', 'biweekly-4']\n",
      "jcpenney pays on biweekly basis ('jcpenney', 'biweekly')\n",
      "\n",
      "_sent: jcpenney pays biweekly .\n",
      "['jcpenney-0', 'pays-1', 'biweekly-2']\n",
      "jcpenney pays biweekly ('jcpenney', 'biweekly')\n",
      "\n",
      "_sent: jcpenney pays bi - weekly\n",
      "['jcpenney-0', 'pays-1', 'weekly-4']\n",
      "jcpenney pays weekly ('jcpenney', 'weekly')\n",
      "\n",
      "_sent: target pays weekly\n",
      "['target-0', 'pays-1', 'weekly-2']\n",
      "target pays weekly ('target', 'weekly')\n",
      "\n",
      "_sent: target pays bi - weekly\n",
      "['target-0', 'pays-1', 'weekly-4']\n",
      "target pays weekly ('target', 'weekly')\n",
      "\n",
      "_sent: target pays on a biweekly rate\n",
      "['target-0', 'pays-1', 'on-2', 'rate-5', 'biweekly-4']\n",
      "target pays on biweekly rate ('target', 'biweekly')\n",
      "\n",
      "_sent: target pays biweekly .\n",
      "['target-0', 'pays-1', 'biweekly-2']\n",
      "target pays biweekly ('target', 'biweekly')\n",
      "\n",
      "_sent: target pays biweekly .\n",
      "['target-0', 'pays-1', 'biweekly-2']\n",
      "target pays biweekly ('target', 'biweekly')\n",
      "\n",
      "_sent: yes target pays while you are in orientation .\n",
      "['target-1', 'pays-2', 'are-5', 'in-6', 'orientation-7']\n",
      "target pays are in orientation ('target', 'orientation')\n",
      "\n",
      "_sent: this company pays weekly\n",
      "['company-1', 'pays-2', 'weekly-3']\n",
      "company pays weekly ('company', 'weekly')\n",
      "\n",
      "_sent: target pays biweekly .\n",
      "['target-0', 'pays-1', 'biweekly-2']\n",
      "target pays biweekly ('target', 'biweekly')\n",
      "\n",
      "_sent: target pays its workers bi - weekly\n",
      "['target-0', 'pays-1', 'weekly-6']\n",
      "target pays weekly ('target', 'weekly')\n",
      "\n",
      "_sent: target pays biweekly\n",
      "['target-0', 'pays-1', 'biweekly-2']\n",
      "target pays biweekly ('target', 'biweekly')\n",
      "\n",
      "_sent: target pays bi weekly\n",
      "['target-0', 'pays-1', 'bi-2', 'weekly-3']\n",
      "target pays bi weekly ('target', 'bi weekly')\n",
      "\n",
      "_sent: target pays biweekly\n",
      "['target-0', 'pays-1', 'biweekly-2']\n",
      "target pays biweekly ('target', 'biweekly')\n",
      "\n",
      "_sent: target pays weekly\n",
      "['target-0', 'pays-1', 'weekly-2']\n",
      "target pays weekly ('target', 'weekly')\n",
      "\n",
      "_sent: olive garden pays bi - weekly\n",
      "['garden-1', 'pays-2', 'weekly-5']\n",
      "garden pays weekly ('garden', 'weekly')\n",
      "\n",
      "_sent: olive garden pays weekly\n",
      "['garden-1', 'pays-2', 'weekly-3']\n",
      "garden pays weekly ('garden', 'weekly')\n",
      "\n",
      "_sent: olive garden pays weekly\n",
      "['garden-1', 'pays-2', 'weekly-3']\n",
      "garden pays weekly ('garden', 'weekly')\n",
      "\n",
      "_sent: olive garden pays every friday\n",
      "['garden-1', 'pays-2', 'friday-4']\n",
      "garden pays friday ('garden', 'friday')\n",
      "\n",
      "_sent: olive garden pays bi - weekly\n",
      "['garden-1', 'pays-2', 'weekly-5']\n",
      "garden pays weekly ('garden', 'weekly')\n",
      "\n",
      "_sent: taken off wiki of goodwill mission statement , really when they should be eliminating ... \n",
      "\n",
      " they underpay people , underappreciate people , undervalue people , they want to find others to rule with an iron fist alongside them and most of all they do n't care for you ... literally if you do n't meet the production quota ( why do we have quotas when this company states and claims they want to eliminate barriers in the work force yet they then go around in the shadow and say if you do n't get these numbers you 're fired ... literally in the employee handbook ( idgaf about disposing confidential information they 're putting you on a leash until you get fired then silence you with threats as always ) \n",
      "\n",
      " mcdonalds pays better and at least have a more professional management ... \n",
      "\n",
      " now if you 'll excuse me i got a month left until i leave this horrid place and then hopefully my manager gets fired or found out about how abusive she freak'n is .\n",
      "['mcdonalds-132', 'pays-133', 'have-138', 'management-142', 'professional-141']\n",
      "mcdonalds pays have professional management ('mcdonalds', 'professional')\n",
      "\n",
      "_sent: this company pays biweekly .\n",
      "['company-1', 'pays-2', 'biweekly-3']\n",
      "company pays biweekly ('company', 'biweekly')\n",
      "\n",
      "_sent: burger king pays weekly .\n",
      "['king-1', 'pays-2', 'weekly-3']\n",
      "king pays weekly ('king', 'weekly')\n",
      "\n",
      "src not matched\n",
      "_sent: burger king pays biweekly\n",
      "['king-1', 'pays-2', 'biweekly-3']\n",
      "king pays biweekly ('king', 'biweekly')\n",
      "\n",
      "_sent: michigan burger king pays weekly ... what about terre haute indiana\n",
      "['king-2', 'pays-3', 'weekly-4']\n",
      "king pays weekly ('king', 'weekly')\n",
      "\n",
      "_sent: burger king in my experience pays bi - weekly(every 2 weeks ) and paydays usually fall on a friday .\n",
      "['king-1', 'pays-5', 'fall-15', 'on-16', 'friday-18']\n",
      "king pays fall on friday ('king', 'friday')\n",
      "\n",
      "_sent: i do n't know how burger king pays in baltimore but in scott city , mo , we got paid twice a month , once on the 7th of the month and once on the 22nd of the month .\n",
      "['king-6', 'pays-7', 'in-8', 'baltimore-9']\n",
      "king pays in baltimore ('king', 'baltimore')\n",
      "\n",
      "_sent: yes , burger king pays employees before thanksgiving .\n",
      "['king-3', 'pays-4', 'before-6', 'thanksgiving-7']\n",
      "king pays before thanksgiving ('king', 'thanksgiving')\n",
      "\n",
      "_sent: no , burger king pays bi - weekly .\n",
      "['king-3', 'pays-4', 'weekly-7']\n",
      "king pays weekly ('king', 'weekly')\n",
      "\n",
      "_sent: mburger king pays bi weekly\n",
      "['king-1', 'pays-2', 'bi-3', 'weekly-4']\n",
      "king pays bi weekly ('king', 'bi weekly')\n",
      "\n",
      "_sent: yes burger king pays you for jury duty\n",
      "['king-2', 'pays-3', 'for-5', 'duty-7', 'jury-6']\n",
      "king pays for jury duty ('king', 'jury duty')\n",
      "\n",
      "_sent: t - mobile pays bi - weekly .\n",
      "['mobile-2', 'pays-3', 'weekly-6']\n",
      "mobile pays weekly ('mobile', 'weekly')\n",
      "\n",
      "_sent: chili 's pays bi - weekly .\n",
      "['chili-0', 'pays-2', 'chili-0', 'weekly-5']\n",
      "chili pays weekly ('chili', 'weekly')\n",
      "\n",
      "_sent: chilis pays biweekly\n",
      "['chilis-0', 'pays-1', 'biweekly-2']\n",
      "chilis pays biweekly ('chilis', 'biweekly')\n",
      "\n",
      "marshalls pays biweekly\n",
      "marshalls pays weekly\n",
      "marshalls pays weekly\n",
      "division pays on weekly basis\n",
      "company pays weekly\n",
      "fargo pays biweekly pay\n",
      "bank live pays support family\n",
      "be able work with college courses take want job pays decent money\n",
      "home depot pays biweekly\n",
      "home depot pays biweekly\n",
      "full time associate pays 200 for medical insurance\n",
      "home depot pays weekly\n",
      "home depot pays biweekly\n",
      "working through friday pays bills\n",
      "amazon pays weekly\n",
      "full time pays night shift make\n",
      "warehouse pays amazon\n",
      "has pay increase pays make due to amazon system\n",
      "amazon pays make production rate\n",
      "tampa pays seasonal\n",
      "center pays as shift differential\n",
      "have shift in columbus pays state\n",
      "amazon pays bi weekly\n",
      "from amazon pays weekly\n",
      "amazon pays by weekly fashion\n",
      "amazon pays weekly\n",
      "subway pays weekly\n",
      "give look say work in food pays bills\n",
      "night average is pays minimum wage\n",
      "subway pays biweekly\n",
      "subway pays biweekly\n",
      "subway pays weekly\n",
      "subway pays bi weekly\n",
      "subway pays bi weekly\n",
      "subway pays on friday\n",
      "subway pays weekly\n",
      "subway pays biweekly\n",
      "fedex delivery pays on weekly basis\n",
      "weekly pays friday\n",
      "fedex pays for costs of drug test\n",
      "fedex pays weekly\n",
      "fedex pays for orientation\n",
      "management pays to new hires\n",
      "starbucks pays retail employees\n",
      "starbucks pays weekly\n",
      "starbucks pays weekly\n",
      "starbucks pays weekly\n",
      "starbucks pays biweekly\n",
      "starbucks pays biweekly\n",
      "starbucks pays biweekly\n",
      "starbucks pays biweekly\n",
      "starbucks pays biweekly\n",
      "starbucks pays by weekly\n",
      "starbucks pays weekly\n",
      "all of kfc pays weekly\n",
      "kfc pays biweekly\n",
      "think mcdonalds pays gives benefits\n",
      "macy 's pays weekly\n",
      "in florida macy 's pays weekly\n",
      "mexican grill pays bi weekly\n",
      "chipotle pays biweekly\n",
      "chipotle pays weekly\n",
      "chipotle pays weekly\n",
      "am student pays bills\n",
      "bread pays weekly\n",
      "jcpenney pays on biweekly basis\n",
      "jcpenney pays biweekly\n",
      "jcpenney pays weekly\n",
      "target pays weekly\n",
      "target pays weekly\n",
      "target pays on biweekly rate\n",
      "target pays biweekly\n",
      "target pays biweekly\n",
      "target pays are in orientation\n",
      "company pays weekly\n",
      "target pays biweekly\n",
      "target pays weekly\n",
      "target pays biweekly\n",
      "target pays bi weekly\n",
      "target pays biweekly\n",
      "target pays weekly\n",
      "garden pays weekly\n",
      "garden pays weekly\n",
      "garden pays weekly\n",
      "garden pays friday\n",
      "garden pays weekly\n",
      "mcdonalds pays have professional management\n",
      "company pays biweekly\n",
      "king pays weekly\n",
      "king pays biweekly\n",
      "king pays weekly\n",
      "king pays fall on friday\n",
      "king pays in baltimore\n",
      "king pays before thanksgiving\n",
      "king pays weekly\n",
      "king pays bi weekly\n",
      "king pays for jury duty\n",
      "mobile pays weekly\n",
      "chili pays weekly\n",
      "chilis pays biweekly\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(_prompt_retrieve('pays')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: with the unemployment rate being so low ( and you ’re not the only company that receives all of these complaints it ’s the way our whole system / economy is set up ) all of you corporations better be careful because people are clearly getting fed up being treated like americanized sweat shop workers .\n",
      "['company-14', 'receives-16', 'company-14', '’re-10', 'way-24', 'set-31', 'economy-29']\n",
      "’re company receives way economy set ('company', 'economy')\n",
      "\n",
      "_sent: make sure the products each one receives is awesome and has good reviews and working order before shipping to anybody makes a lasting customer relationship\n",
      "['products-3', 'receives-6', 'products-3', 'is-7', 'has-10', 'reviews-12', 'order-15']\n",
      "products receives is has reviews order ('products', 'order')\n",
      "\n",
      "_sent: once the candidate receives the drug screen email from infomart , containing a link to the drug screen then there , the canada is responsible for selecting a testing facility / collection site , printing the e - passport provided and bringing the e - passport and proper identification to drug screen collection site within 2 business days not including weekends and holidays , of receipt of the drug screen email from infomart .\n",
      "e receives drug\n",
      "None 10540441779542591554 14930118741968279164\n",
      "\n",
      "_sent: you qualify for certain ones as part time , full time receives all benefits .\n",
      "['time-10', 'receives-11', 'benefits-13', 'full-9']\n",
      "full time receives benefits ('full time', 'benefits')\n",
      "\n",
      "_sent: but for all i know so far , the students who do work here receives good benefits from target .\n",
      "['students-9', 'receives-14', 'benefits-16']\n",
      "students receives benefits ('students', 'benefits')\n",
      "\n",
      "_sent: after the organization receives the background check , they may decide to do their own investigating to determine whether or not a potential candidate can be hired .\n",
      "['organization-2', 'receives-3', 'check-6', 'background-5']\n",
      "organization receives background check ('organization', 'background check')\n",
      "\n",
      "_sent: you receive a drug test form and take it to a hospital and then petsmart receives the results .\n",
      "['petsmart-14', 'receives-15', 'results-17']\n",
      "petsmart receives results ('petsmart', 'results')\n",
      "\n",
      "_sent: no we do not only management receives sick days\n",
      "['management-5', 'receives-6', 'days-8', 'sick-7']\n",
      "management receives sick days ('management', 'sick days')\n",
      "\n",
      "_sent: yes , once the management receives the results , you should be informed within a week of taking the test\n",
      "['management-4', 'receives-5', 'results-7']\n",
      "management receives results ('management', 'results')\n",
      "\n",
      "_sent: yes everyoone   that works for walmart receives health insurance\n",
      "['walmart-6', 'for-5', 'works-4', 'receives-7', 'insurance-9', 'health-8']\n",
      "works for walmart receives health insurance ('walmart', 'health')\n",
      "\n",
      "_sent: 40 hours a week unless its around the holidays then they may ask you stay and collect overtime.usually everyone with open availability receives no less than 32 hrs .\n",
      "['availability-21', 'with-19', 'everyone-18', 'receives-22', 'hrs-27', 'open-20', '32-26']\n",
      "everyone with open availability receives 32 hrs ('open availability', '32 hrs')\n",
      "\n",
      "_sent: mobile department of best buy receives 30 % bonus on sales at the end of the month .\n",
      "['buy-4', 'of-2', 'department-1', 'receives-5', 'bonus-8', 'best-3']\n",
      "department of best buy receives bonus ('best buy', 'bonus')\n",
      "\n",
      "_sent: full time receives dental , vision , medical .\n",
      "['time-1', 'receives-2', 'dental-3', 'vision-5', 'medical-7', 'full-0']\n",
      "full time receives dental vision medical ('full time', 'medical')\n",
      "\n",
      "_sent: \n",
      " for sick leave , a part time employee receives no pay ; you must have a doctor 's note to explain these days off as well .\n",
      "['time-7', 'employee-8', 'receives-9', 'have-15', 'note-19', 'part-6', 'doctor-17', \"'s-18\"]\n",
      "part time employee receives have doctor 's note ('part time', \"doctor 's note\")\n",
      "\n",
      "_sent: none for part - time and i 'm unaware if full time receives any benefits as its never been offer to me or anyof my co - workers that i know of .\n",
      "['time-12', 'receives-13', 'benefits-15', 'full-11']\n",
      "full time receives benefits ('full time', 'benefits')\n",
      "\n",
      "_sent: management also receives quarterly bonuses .\n",
      "['management-0', 'receives-2', 'bonuses-4', 'quarterly-3']\n",
      "management receives quarterly bonuses ('management', 'quarterly bonuses')\n",
      "\n",
      "_sent: the company will send you an email as soon as the store that you applied for receives your assessment test .\n",
      "['email-6', 'send-3', 'soon-8', 'as-9', 'store-11', 'applied-14', 'for-15', 'receives-16', 'test-19', 'assessment-18']\n",
      "send email soon as store applied for receives assessment test ('email', 'assessment test')\n",
      "\n",
      "_sent: only management receives benefits if they opt in .\n",
      "['management-1', 'receives-2', 'benefits-3']\n",
      "management receives benefits ('management', 'benefits')\n",
      "\n",
      "_sent:   but management receives no support from corporate , forcing them to try to find quick fixes to problems with no real thought given to the long term effect .\n",
      "['management-2', 'receives-3', 'forcing-9', 'try-12', 'find-14', 'to-17', 'problems-18', 'with-19', 'thought-22', 'given-23', 'to-24', 'effect-28', 'term-27', 'long-26']\n",
      "management receives forcing try find to problems with thought given to long term effect ('management', 'long')\n",
      "\n",
      "’re company receives way economy set\n",
      "products receives is has reviews order\n",
      "full time receives benefits\n",
      "students receives benefits\n",
      "organization receives background check\n",
      "petsmart receives results\n",
      "management receives sick days\n",
      "management receives results\n",
      "works for walmart receives health insurance\n",
      "everyone with open availability receives 32 hrs\n",
      "department of best buy receives bonus\n",
      "full time receives dental vision medical\n",
      "part time employee receives have doctor 's note\n",
      "full time receives benefits\n",
      "management receives quarterly bonuses\n",
      "send email soon as store applied for receives assessment test\n",
      "management receives benefits\n",
      "management receives forcing try find to problems with thought given to long term effect\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(_prompt_retrieve('receives')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sent: they use mostly dress shoes or at least shoes that a professional would wear which does n't allow sandals , sneakers , or sports shoes of any kind .\n",
      "['professional-11', 'wear-13', 'allow-17', 'sandals-18', 'sneakers-20', 'shoes-24', 'sports-23', 'does-15', \"n't-16\"]\n",
      "professional wear does n't allow sandals sneakers sports shoes ('professional', 'sports')\n",
      "\n",
      "_sent: only if you 're a full time employee , which target does n't allow team members to come close to 40 hours .\n",
      "['target-10', 'allow-13', 'come-17', 'members-15', 'does-11', \"n't-12\", 'team-14']\n",
      "target does n't allow team members come ('target', 'team members')\n",
      "\n",
      "_sent: union does n't allow employees to be drug tested unless you have an accident .\n",
      "['union-0', 'allow-3', 'be-6', 'drug-7', 'does-1', \"n't-2\"]\n",
      "union does n't allow be drug ('union', 'drug')\n",
      "\n",
      "_sent: it might be the opposite because i do know that the company does n't allow hourly associates to have overtime but i 'm not sure how that works at a dc .\n",
      "['company-11', 'allow-14', 'have-18', 'associates-16', 'does-12', \"n't-13\", 'hourly-15']\n",
      "company does n't allow hourly associates have ('company', 'hourly associates')\n",
      "\n",
      "_sent: union does n't allow employees to be screened after the pre employment screening .\n",
      "['union-0', 'allow-3', 'screened-7', 'after-8', 'screening-12', 'employment-11', 'does-1', \"n't-2\", 'pre-10']\n",
      "union does n't allow screened after pre employment screening ('union', 'pre employment')\n",
      "\n",
      "_sent: stand ... management does n't allow seats unless you have an injury and doctor note for reasonable accommodation and they still give you a hard time about that .. you have to fight for decent human rights\n",
      "['management-2', 'allow-5', 'have-9', 'note-14', 'for-15', 'accommodation-17', 'does-3', \"n't-4\", 'reasonable-16']\n",
      "management does n't allow have note for reasonable accommodation ('management', 'reasonable accommodation')\n",
      "\n",
      "professional wear does n't allow sandals sneakers sports shoes\n",
      "target does n't allow team members come\n",
      "union does n't allow be drug\n",
      "company does n't allow hourly associates have\n",
      "union does n't allow screened after pre employment screening\n",
      "management does n't allow have note for reasonable accommodation\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(_prompt_retrieve('does n\\'t allow')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Prompt Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit here: /meg-kb/src/analysis/lm_probing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggest Quality Prompts"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_transformers_nikita)",
   "language": "python",
   "name": "conda_transformers_nikita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
