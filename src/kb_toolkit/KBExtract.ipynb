{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"/mnt/efs/shared/meg_shared_scripts/meg-kb\"\n",
    "data_ac=\"indeeda-meg-ac\"\n",
    "data_pt=\"indeeda-meg-pt\"\n",
    "yutong_base_dir=\"/home/ubuntu/users/yutong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, entropy, gmean\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import logging\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from annoy import AnnoyIndex\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "\n",
    "from compute_concept_clusters import knn\n",
    "from compute_keyphrase_embeddings import ensure_tensor_on_device, mean_pooling\n",
    "\n",
    "from utils import LMProbe, LMProbe_GPT2\n",
    "from utils import load_embeddings, load_seed_aligned_concepts, load_seed_aligned_relations, load_benchmark\n",
    "from utils import get_masked_contexts\n",
    "\n",
    "from roberta_ses.interface import Roberta_SES_Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: text corpus\n",
    "# step 1: extract key phrases (autophrase)\n",
    "# step 2: generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Key Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/keyword_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n"
     ]
    }
   ],
   "source": [
    "#change to keyword extractor directory\n",
    "%cd $base_dir/src/keyword_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./corpusProcess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dataset and thread no\n",
    "data_ac = 'indeeda-meg-ac'\n",
    "data_pt = 'indeeda-meg-pt'\n",
    "thread = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n",
      "\u001b[32m===Corpus Name: sample-indeeda-meg-ac===\u001b[m\n",
      "\u001b[32m===Current Path: /mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction===\u001b[m\n",
      "\u001b[32m===Cleaning input corpus===\u001b[m\n",
      "\u001b[32m===Running AutoPhrase===\u001b[m\n",
      "make: Nothing to be done for 'all'.\n",
      "\u001b[32m===RAW_TRAIN: ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt===\u001b[m\n",
      "auto_phrase.sh parameters: sample-indeeda-meg-ac ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt 10 data/EN/wiki_quality.txt 8\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m0.702s\n",
      "user\t0m1.668s\n",
      "sys\t0m0.100s\n",
      "Detected Language: EN\u001b[0K\n",
      "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
      "No provided expert labels.\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===AutoPhrasing===\u001b[m\n",
      "=== Current Settings ===\n",
      "Iterations = 2\n",
      "Minimum Support Threshold = 10\n",
      "Maximum Length Threshold = 6\n",
      "POS-Tagging Mode Disabled\n",
      "Discard Ratio = 0.050000\n",
      "Number of threads = 8\n",
      "Labeling Method = DPDN\n",
      "\tAuto labels from knowledge bases\n",
      "\tMax Positive Samples = -1\n",
      "=======\n",
      "Loading data...\n",
      "# of total tokens = 6553\n",
      "max word token id = 1450\n",
      "# of documents = 500\n",
      "# of distinct POS tags = 0\n",
      "Mining frequent phrases...\n",
      "selected MAGIC = 1451\n",
      "# of frequent phrases = 1483\n",
      "Extracting features...\n",
      "Constructing label pools...\n",
      "\tThe size of the positive pool = 192\n",
      "\tThe size of the negative pool = 1282\n",
      "# truth patterns = 1202\n",
      "Estimating Phrase Quality...\n",
      "0 32\n",
      "[ERROR] not enough training data found!\n",
      "Segmenting...\n",
      "Rectifying features...\n",
      "Estimating Phrase Quality...\n",
      "0 32\n",
      "[ERROR] not enough training data found!\n",
      "Segmenting...\n",
      "Dumping results...\n",
      "Done.\n",
      "\n",
      "real\t0m1.922s\n",
      "user\t0m2.496s\n",
      "sys\t0m0.016s\n",
      "\u001b[32m===Saving Model and Results===\u001b[m\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "phrasal_segmentation.sh parameters: sample-indeeda-meg-ac ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt 0.5 0.9 8\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m0.568s\n",
      "user\t0m1.396s\n",
      "sys\t0m0.108s\n",
      "Detected Language: EN\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===Phrasal Segmentation===\u001b[m\n",
      "=== Current Settings ===\n",
      "Segmentation Model Path = models/sample-indeeda-meg-ac/segmentation.model\n",
      "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
      "\tQ(multi-word phrases) >= 0.500000\n",
      "\tQ(single-word phrases) >= 0.900000\n",
      "=======\n",
      "Length penalty model loaded.\n",
      "\tpenalty = 199.805\n",
      "# of loaded patterns = 136\n",
      "# of loaded truth patterns = 1394\n",
      "Phrasal segmentation finished.\n",
      "   # of total highlighted quality phrases = 715\n",
      "   # of total processed sentences = 828\n",
      "   avg highlights per sentence = 0.863527\n",
      "\n",
      "real\t0m0.050s\n",
      "user\t0m0.016s\n",
      "sys\t0m0.000s\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "\u001b[32m===Generating Phrase Text===\u001b[m\n",
      "process_segmentation.py parameters: ../../../data/sample-indeeda-meg-ac/intermediate/ 0.5 0.9\n",
      "11.152\n",
      "\u001b[32m===Running NLP Feature Extraction===\u001b[m\n",
      "100%|███████████████████████████████████████████| 51/51 [00:00<00:00, 66.53it/s]\n",
      " 71%|██████████████████████████████▌            | 47/66 [00:00<00:00, 58.53it/s]Finish NLP processing, using time 0.8209497928619385 (second)\n",
      "100%|███████████████████████████████████████████| 57/57 [00:00<00:00, 65.72it/s]\n",
      " 80%|██████████████████████████████████▌        | 53/66 [00:00<00:00, 57.33it/s]Finish NLP processing, using time 0.9230477809906006 (second)\n",
      "100%|███████████████████████████████████████████| 62/62 [00:00<00:00, 70.06it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:00<00:00, 57.63it/s]\n",
      "Finish NLP processing, using time 0.9408359527587891 (second)\n",
      " 95%|████████████████████████████████████████▉  | 60/63 [00:00<00:00, 74.56it/s]Finish NLP processing, using time 0.8718316555023193 (second)\n",
      "100%|███████████████████████████████████████████| 66/66 [00:01<00:00, 62.34it/s]\n",
      "100%|███████████████████████████████████████████| 63/63 [00:00<00:00, 68.87it/s]\n",
      "Finish NLP processing, using time 1.1157433986663818 (second)\n",
      "100%|███████████████████████████████████████████| 76/76 [00:00<00:00, 80.52it/s]\n",
      "Finish NLP processing, using time 0.9821081161499023 (second)\n",
      "Finish NLP processing, using time 1.003368854522705 (second)\n",
      "100%|███████████████████████████████████████████| 79/79 [00:01<00:00, 76.95it/s]\n",
      "Finish NLP processing, using time 1.0861637592315674 (second)\n",
      "\u001b[32m===Clean unnecessary files===\u001b[m\n",
      "\u001b[32m===Key Term Extraction===\u001b[m\n",
      "Extract Key Terms from Corpus: 100%|███████| 694/694 [00:00<00:00, 24407.16it/s]\n",
      "\u001b[32m===Sentence-wise Entity Segmentation===\u001b[m\n",
      "loading corpus for word2vec training: 100%|█| 694/694 [00:00<00:00, 288117.09it/\n",
      "100%|███████████████████████████████████████| 94/94 [00:00<00:00, 431834.15it/s]\n",
      "100%|█████████████████████████████████████| 122/122 [00:00<00:00, 423947.88it/s]\n",
      "100%|█████████████████████████████████████| 118/118 [00:00<00:00, 377519.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# process corpus and generate key prhases\n",
    "!./corpusProcess.sh $data_ac $thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy these results to sample-meg-pt\n",
    "!cp -r ../../data/$data_ac ../../data/$data_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus with company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/question_answers.csv'\n",
    "company_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/fccid-companyName.csv'\n",
    "entity_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "out_corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8053"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(entity_emb_num_path, 'r') as f:\n",
    "    entities = [l.strip().rsplit(' ', 1)[0] for l in f.readlines()]\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv(dataset_path) \n",
    "df_dataset = df_dataset[df_dataset['answerContent'].notna()]\n",
    "df_company = pd.read_csv(company_path)\n",
    "\n",
    "df_merged_dataset = df_dataset.merge(df_company, how='inner', on='fccompanyId')\n",
    "df_merged_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307122, 11)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I, applied, online, and, submitted, all, attachments, that, I, could, .]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df_merged_dataset.iloc[1]\n",
    "_d = nlp(row[\"answerContent\"])\n",
    "list(_d.sents)\n",
    "list(list(_d.sents)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_corpus = []\n",
    "\n",
    "for i, row in df_merged_dataset.iterrows():\n",
    "    if i > 0 and i % 5000 == 0:\n",
    "        print(f'Progress: {i} / {df_merged_dataset.shape[0]}')\n",
    "    \n",
    "    company = row[\"companyName\"]\n",
    "    ans = row[\"answerContent\"]\n",
    "    ans_nlp = nlp(ans)\n",
    "    for sent in ans_nlp.sents:\n",
    "        sent_tok_list = [str(t) for t in sent]\n",
    "        _s = f' {company} : {\" \".join(sent_tok_list)} '.lower()\n",
    "        _ents = []\n",
    "        for _e in entities:\n",
    "            if f' {_e} ' in _s:\n",
    "                _ents.append(_e)\n",
    "        out_corpus.append({\n",
    "            \"tokens\": sent_tok_list,\n",
    "            \"company\": company,\n",
    "            \"entities\": _ents,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out_corpus), out_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_corpus_path, 'w') as f:\n",
    "    for d in out_corpus:\n",
    "        f.write(json.dumps(d) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lines: 100%|████████████████| 307122/307122 [11:51<00:00, 431.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "!python build_corpus_with_companies.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-rd /home/ubuntu/users/nikita/data/indeed/indeedQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "#change to concept learning directory\n",
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|█████████████████████| 694/694 [00:00<00:00, 194471.34it/s]\n",
      "computing entity-wise embedding: 100%|████████| 177/177 [00:03<00:00, 50.59it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!python compute_keyphrase_embeddings.py -m bert-base-uncased -et ac -d ../../data/$data_ac/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenated Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|█████████████████████| 694/694 [00:00<00:00, 191566.11it/s]\n",
      "computing entity-wise embedding: 100%|████████| 177/177 [00:03<00:00, 53.88it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!python compute_keyphrase_embeddings.py -m bert-base-uncased -et pt -d ../../data/$data_pt/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/tools/AutoPhrase\n"
     ]
    }
   ],
   "source": [
    "# change directory to autophrase\n",
    "%cd $base_dir/src/tools/AutoPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corel = 'sample-indeeda-corel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2021-06-18 00:36:18,384 : INFO : loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2021-06-18 00:36:18,776 : INFO : loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ubuntu/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2021-06-18 00:36:18,777 : INFO : Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2021-06-18 00:36:19,108 : INFO : loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/ubuntu/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "Traceback (most recent call last):\n",
      "  File \"extractBertEmbedding.py\", line 86, in <module>\n",
      "    with open(inputFilePath, \"r\") as fin:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../../../data/sample-indeeda-corel/intermediate//sent_segmentation.txt'\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python extractBertEmbedding.py ../../../data/$data_corel/intermediate/ $thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add embeddings for seed instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_masked_contexts_for_entities(entities, input_file):\n",
    "    \"\"\"Return a (list of) sentence(s) with entity replaced with MASK.\"\"\"\n",
    "    \"\"\"YS: input should be sentences.json\"\"\"\n",
    "    \n",
    "    ent_freq = {ent : 0 for ent in entities}\n",
    "    ent_context = {ent : [] for ent in entities}\n",
    "    \n",
    "    with open(input_file, \"r\") as fin:\n",
    "        lines = fin.readlines()\n",
    "        for line in tqdm(lines, total=len(lines), desc=\"loading corpus\"):\n",
    "            json_dict = json.loads(line)\n",
    "            sent = ' ' + ' '.join(json_dict['tokens']).lower() + ' '\n",
    "            #entities = [match.group(1) for match in re.finditer(pat, line)]\n",
    "            \n",
    "            for entity in entities:\n",
    "                pat = f' {entity} '\n",
    "                if pat not in sent:\n",
    "                    continue\n",
    "\n",
    "                context = sent.replace(pat, ' [MASK] ').strip()\n",
    "                c = context.split('[MASK]')\n",
    "                if len(c) != 2:  # sanity to not have too many repeating phrases in the context\n",
    "                    continue\n",
    "\n",
    "                # ignore too short contexts\n",
    "                if len(context) < 15:\n",
    "                    continue\n",
    "\n",
    "                # print(entity)\n",
    "                # print(context)\n",
    "                \n",
    "                _freq = ent_freq.get(entity, 0)\n",
    "                ent_freq[entity] = _freq + 1\n",
    "\n",
    "                context_lst = ent_context.get(entity, [])\n",
    "                context_lst.append(context)\n",
    "                ent_context[entity] = context_lst\n",
    "\n",
    "    dedup_context = {}\n",
    "    for e, v in ent_context.items():\n",
    "        dedup_context[e] = list(set(v))\n",
    "    return ent_freq, dedup_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_avg_context_embedding_for_entities(entities, model_path, input_file, max_context_ct):\n",
    "    '''\n",
    "    mean pooling from sentence-transformers\n",
    "    :param entity: List[str], the entities to compute embeddings for\n",
    "    :param model_path:\n",
    "    :param input_file:\n",
    "    :return:\n",
    "    '''\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "    ent_freq, ent_context = get_masked_contexts_for_entities(entities, input_file)\n",
    "    \n",
    "    entity_embeddings = {}\n",
    "    for entity, en_context_lst in tqdm(ent_context.items(), total=len(ent_context), desc=\"computing entity-wise embedding\"):\n",
    "#     for entity, en_context_lst in ent_context.items():\n",
    "        print(entity)\n",
    "        en_context_lst = random.sample(en_context_lst, min(len(en_context_lst), max_context_ct))\n",
    "        chunks = [en_context_lst[i:i + 100] for i in range(0, len(en_context_lst), 100)]\n",
    "        # print(entity)\n",
    "        # print(len(en_context_lst))\n",
    "        all_context_embeddings = []\n",
    "        for chunk in chunks:\n",
    "            encoded_input = tokenizer.batch_encode_plus(chunk, return_token_type_ids=True, add_special_tokens=True, max_length=128, return_tensors='pt', padding=True, pad_to_max_length=True, truncation=True)\n",
    "            mask = encoded_input['input_ids'] != mask_token_id\n",
    "            with torch.no_grad():\n",
    "                encoded_input = ensure_tensor_on_device(device, **encoded_input)\n",
    "                model_output = model(**encoded_input)  # Compute token embeddings\n",
    "            context_embeddings = mean_pooling(model_output, mask)  # mean pooling\n",
    "            all_context_embeddings.append(context_embeddings)\n",
    "            \n",
    "        assert len(all_context_embeddings) > 0\n",
    "            \n",
    "        entity_embedding = torch.mean(torch.cat(all_context_embeddings, dim=0), dim=0).cpu().detach().numpy().tolist()\n",
    "        entity_embeddings[entity] = entity_embedding\n",
    "    \n",
    "    return entity_embeddings, ent_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences.json')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "\n",
    "orig_bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed.txt')\n",
    "orig_bert_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum.txt')\n",
    "\n",
    "new_bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "new_bert_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "\n",
    "orig_emb_df = load_embeddings(bert_emb_path, 768)\n",
    "emb_dict = dict(zip(orig_emb_df['entity'].to_list(), orig_emb_df['embedding'].to_list()))\n",
    "\n",
    "with open(orig_bert_emb_num_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    emb_freq_dict = dict([l.strip().rsplit(' ', 1) for l in lines])\n",
    "\n",
    "concepts_df = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "seed_instances_list = [inst for _, (_a_con, _u_con, _gnrl, _seed_instances) in concepts_df.iterrows()\n",
    "                           for inst in _seed_instances]\n",
    "\n",
    "## debug\n",
    "seed_instances_list = seed_instances_list[::10]\n",
    "\n",
    "print(seed_instances_list)\n",
    "\n",
    "entity_embeddings, ent_freq = \\\n",
    "    get_avg_context_embedding_for_entities(entities=seed_instances_list, \n",
    "                                           model_path='bert-base-uncased',\n",
    "                                           input_file=corpus_path,\n",
    "                                           max_context_ct=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "for inst in seed_instances_list:\n",
    "    emb = entity_embeddings[inst]\n",
    "    freq = ent_freq[inst]\n",
    "    if inst in emb_dict:\n",
    "        print(f'Already exists: {inst}')\n",
    "#         assert np.allclose(emb_dict[inst], emb)\n",
    "#         assert emb_freq_dict[inst] == freq, f'{inst}: orig {emb_freq_dict[inst]} != new {freq}'\n",
    "#         print(f'Check passed: {inst}')\n",
    "    else:\n",
    "        emb_dict[inst] = emb\n",
    "        emb_freq_dict[inst] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "entity_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "with open(new_bert_emb_path, 'w') as f, open(new_bert_emb_num_path, 'w') as f2:\n",
    "    for inst in seed_instances_list:\n",
    "        emb = emb_dict[inst]\n",
    "        freq = ent_freq[inst]\n",
    "        f.write(\"{} {}\\n\".format(inst, ' '.join([str(x) for x in emb])))\n",
    "        f2.write(\"{} {}\\n\".format(inst, freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed instances: ['walmart', 'amazon', 'subway', 'microsoft', 'target', 'business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings', 'delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher', 'weekly', 'biweekly', 'friday', 'saturday', 'health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'base pay', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'direct deposit', 'prepaid card', 'drug test', 'criminal background check', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors', 'hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting', 'night shift', 'dinner shift', 'early morning shift', '8 hour shift', 'christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "New instances: ['uniform', 'hair color', 'tattoos', 'shoes', 'cashier', 'weekly', 'biweekly', 'friday', 'saturday', '401k', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'pregnant', 'students', 'seniors', '8 hour shift', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'training', 'team lunch']\n",
      "loading corpus: 100%|████████████████| 465226/465226 [00:09<00:00, 47556.15it/s]\n",
      "computing entity-wise embedding: 100%|██████████| 36/36 [00:41<00:00,  1.14s/it]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "# Using script\n",
    "\n",
    "!python add_seed_instances_embeddings.py -m bert-base-uncased -et ac -d $base_dir/data/$data_ac/intermediate -b $base_dir/data/indeed-benchmark -c 750\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub_dir = data_ac\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/BERTembed+seeds.txt')\n",
    "\n",
    "embeddings = load_embeddings(bert_emb_path, 768)\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>biweekly</td>\n",
       "      <td>[0.06975648552179337, -0.06970633566379547, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity                                          embedding\n",
       "8023  biweekly  [0.06975648552179337, -0.06970633566379547, 0...."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[embeddings['entity'] == 'biweekly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (X) Other ways of embeddings / clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|██████████| 458/458 [00:00<00:00, 73813.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(175, 175)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/sent_segmentation.txt')\n",
    "ent_freq, dedup_context = get_masked_contexts(input_file_path)\n",
    "len(ent_freq), len(dedup_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [\"we dropped by in hopes of finding atkinson 's peanut_butter bars ( we first tried them from honey salt 's [MASK] bowl ) and after searching a few minutes , we found it .\",\n",
       "  \"if you 're searching for a [MASK] or soda_pop you grew up with and can no longer find , there 's a good chance you 'll find it here .\"])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_freq['candy'], dedup_context['candy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_all_context_embeddings(model_path, input_file, max_context_ct):\n",
    "    '''\n",
    "    Adapted from get_avg_context_embeddings()\n",
    "    keep all context embeddings, using max similarity for knn\n",
    "    :param model_path:\n",
    "    :param input_file:\n",
    "    :return:\n",
    "    '''\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "    ent_freq, ent_context = get_masked_contexts(input_file)\n",
    "    entity_embeddings = {}\n",
    "    for entity, en_context_lst in tqdm(ent_context.items(), total=len(ent_context), desc=\"computing entity-wise embedding\"):\n",
    "        en_context_lst = random.sample(en_context_lst, min(len(en_context_lst), max_context_ct))\n",
    "        chunks = [en_context_lst[i:i + 100] for i in range(0, len(en_context_lst), 100)]\n",
    "        # print(entity)\n",
    "        # print(len(en_context_lst))\n",
    "        all_context_embeddings = []\n",
    "        for chunk in chunks:\n",
    "            encoded_input = tokenizer.batch_encode_plus(chunk, return_token_type_ids=True, add_special_tokens=True, max_length=128, return_tensors='pt', padding=True, pad_to_max_length=True, truncation=True)\n",
    "            mask = encoded_input['input_ids'] != mask_token_id\n",
    "            with torch.no_grad():\n",
    "                encoded_input = ensure_tensor_on_device(device, **encoded_input)\n",
    "                model_output = model(**encoded_input)  # Compute token embeddings\n",
    "            context_embeddings = mean_pooling(model_output, mask)  # mean pooling\n",
    "            # print(context_embeddings.size())\n",
    "            all_context_embeddings.append(context_embeddings)\n",
    "            \n",
    "        # entity_embedding = torch.mean(torch.cat(all_context_embeddings, dim=0), dim=0).cpu().detach().numpy().tolist()\n",
    "        # entity_embeddings[entity] = entity_embedding\n",
    "        entity_embeddings[entity] = torch.cat(all_context_embeddings, dim=0).cpu().detach().numpy().tolist()\n",
    "        \n",
    "    return entity_embeddings, ent_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|██████████| 458/458 [00:00<00:00, 150194.78it/s]\n",
      "computing entity-wise embedding: 100%|██████████| 175/175 [00:04<00:00, 41.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(175, 175)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'bert-base-uncased'\n",
    "input_file_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/sent_segmentation.txt')\n",
    "max_context_ct = 10\n",
    "\n",
    "entity_embeddings, ent_freq = get_all_context_embeddings(model_path, input_file_path, max_context_ct)\n",
    "len(entity_embeddings), len(ent_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_embeddings['candy'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _knn(entity_embeddings, embedding_dim, cluster_size, thread_ct=None, cluster_dest=None, **kwargs):\n",
    "    # entity_embeddings = load_embeddings(embed_src, embedding_dim)\n",
    "    \n",
    "    t = AnnoyIndex(embedding_dim, 'angular')\n",
    "    # entities = entity_embeddings['entity'].tolist()\n",
    "    entities = [f'{entity}-{_i}' for entity, embs in entity_embeddings.items() for _i in range(len(embs))]\n",
    "    # print(entities)\n",
    "    # for i, row in tqdm(entity_embeddings.iterrows(), total=entity_embeddings.shape[0], desc=\"building entity index\"):\n",
    "    #     t.add_item(i, row['embedding'])\n",
    "    i = 0\n",
    "    for entity, embs in tqdm(entity_embeddings.items(), total=len(entity_embeddings)):\n",
    "        for emb in embs:\n",
    "            t.add_item(i, emb)\n",
    "            i += 1\n",
    "    assert i == len(entities)\n",
    "    \n",
    "    t.build(100)\n",
    "    \n",
    "    neighbors = []\n",
    "    for i, entity in enumerate(tqdm(entities, desc=\"finding nearest neighbors by entity\")):\n",
    "        # print(i, entity)\n",
    "        nns, dists = t.get_nns_by_item(i, cluster_size + 1, include_distances=True)\n",
    "        cos_sim_scores = [(2 - d ** 2) / 2 for d in dists]  # convert angular distance to cosine similarity\n",
    "        zipped = list(zip(nns, cos_sim_scores))\n",
    "        sorted_nns = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "        if len(sorted_nns) > 0:\n",
    "            for nn_idx, d in sorted_nns:\n",
    "                neighbor_entity = entities[nn_idx]\n",
    "                if neighbor_entity == entity:\n",
    "                    continue\n",
    "                neighbors.append({\"entity\": entity, \"neighbor\": neighbor_entity, \"sim\": d})\n",
    "    c_df = pd.DataFrame(neighbors)\n",
    "    return c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 24854.50it/s]\n",
      "finding nearest neighbors by entity: 100%|██████████| 269/269 [00:00<00:00, 6006.44it/s]\n"
     ]
    }
   ],
   "source": [
    "knn_results = _knn(entity_embeddings, 768, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = 'meat'\n",
    "\n",
    "df = knn_results\n",
    "\n",
    "n_embs = len(entity_embeddings[query])\n",
    "sub_frames = []\n",
    "for _i in range(n_embs):\n",
    "    ent_name = f'{query}-{_i}'\n",
    "    sub_frames.append(df[df['entity'] == ent_name])\n",
    "\n",
    "pd.concat(sub_frames).sort_values('sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original avg context knn \n",
    "knn_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/knn_100.csv')\n",
    "\n",
    "knn_results = pd.read_csv(knn_path)\n",
    "df = knn_results\n",
    "\n",
    "query = 'walmart'\n",
    "sub_frame = df[df['entity'] == query]\n",
    "sub_frame.sort_values('sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Seed Entities (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "#change to concept learning directory\n",
    "%cd ../../concept_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn sentence-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 100\n",
    "output = '../../data/'+data_ac+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|████████████████| 177/177 [00:00<00:00, 5435.26it/s]\n",
      "finding nearest neighbors by entity: 100%|██| 177/177 [00:00<00:00, 2001.57it/s]\n"
     ]
    }
   ],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_ac/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn token concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 20\n",
    "output = '../../data/'+data_pt+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|████████████████| 177/177 [00:00<00:00, 3661.18it/s]\n",
      "finding nearest neighbors by entity: 100%|██| 177/177 [00:00<00:00, 4052.00it/s]\n"
     ]
    }
   ],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_pt/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 20\n",
    "output = '../../data/'+data_pt+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_corel/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed instances clustering\n",
    "(using all seed instances of a concept to find neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "# seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_concept_knn(embed_src, embedding_dim, seed_aligned_concept_src, cluster_size, thread_ct, cluster_dest, **kwargs):\n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concept_src)\n",
    "    \n",
    "    entity_embeddings = load_embeddings(embed_src, embedding_dim)\n",
    "    t = AnnoyIndex(embedding_dim, 'angular')\n",
    "    entities = entity_embeddings['entity'].tolist()\n",
    "    for i, row in tqdm(entity_embeddings.iterrows(), total=entity_embeddings.shape[0], desc=\"building entity index\"):\n",
    "        t.add_item(i, row['embedding'])\n",
    "    t.build(100)\n",
    "    \n",
    "    entity_emb_dict = dict(zip(entities, entity_embeddings['embedding'].tolist()))\n",
    "\n",
    "    neighbors = []\n",
    "    for i, (a_concept, u_concept, gnrl, seed_instances) in tqdm(seed_concepts_df.iterrows(), desc=\"finding nearest neighbors by concept\"):\n",
    "        embs = []\n",
    "        for inst in seed_instances:\n",
    "            try:\n",
    "                embs.append(entity_emb_dict[inst])\n",
    "            except KeyError:\n",
    "                print(f\"{inst} not found in entity_emb_dict??\")\n",
    "                continue\n",
    "        if len(embs) == 0:\n",
    "            continue\n",
    "        concept_emb = np.mean(embs, axis=0)\n",
    "        \n",
    "        nns, dists = t.get_nns_by_vector(concept_emb, cluster_size + 1, include_distances=True)\n",
    "        cos_sim_scores = [(2 - d ** 2) / 2 for d in dists]  # convert angular distance to cosine similarity\n",
    "        zipped = list(zip(nns, cos_sim_scores))\n",
    "        sorted_nns = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "        if len(sorted_nns) > 0:\n",
    "            for nn_idx, d in sorted_nns:\n",
    "                neighbor_entity = entities[nn_idx]\n",
    "                if neighbor_entity in seed_instances:\n",
    "                    continue\n",
    "                neighbors.append({\"concept\": a_concept, \"neighbor\": neighbor_entity, \"sim\": d})\n",
    "    c_df = pd.DataFrame(neighbors)\n",
    "    c_df.to_csv(cluster_dest, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "cluster_size = 1000\n",
    "\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_{cluster_size}.csv')\n",
    "\n",
    "get_concept_knn(embed_src=bert_emb_path,\n",
    "            embedding_dim=768,\n",
    "            seed_aligned_concept_src=seed_aligned_concepts_path,\n",
    "            cluster_size=1000,\n",
    "            thread_ct=1,\n",
    "            cluster_dest=concept_knn_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|██████████████| 8053/8053 [00:01<00:00, 6521.18it/s]\n",
      "finding nearest neighbors by concept: 14it [00:00, 433.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "cluster_size = 100\n",
    "!python compute_concept_seeds_knn.py -d $base_dir/data/$data_ac/intermediate -b $base_dir/data/indeed-benchmark -s 100 -o $base_dir/data/$data_ac/intermediate/concept_knn_100.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check results \n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_{cluster_size}.csv')\n",
    "\n",
    "df = pd.read_csv(concept_knn_path)\n",
    "df[df['concept'] == 'company'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(concept_knn_path)\n",
    "df[df['concept'] == 'pay_schedule'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit here: /meg_shared_scripts/meg-kb/src/analysis/concept_learning-test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')\n",
    "\n",
    "concept_knn_path = concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_embeddings = load_embeddings(bert_emb_path, 768)\n",
    "entity_emb_dict = dict(zip(entity_embeddings['entity'].tolist(), entity_embeddings['embedding'].tolist()))\n",
    "\n",
    "seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "\n",
    "concepts_knn_df = pd.read_csv(concept_knn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_records = []\n",
    "# record item: List[\n",
    "#     (con_name, con_emb),\n",
    "#     List[(seed_name, seed_emb)],\n",
    "#     List[(inst_name, inst_emb)],\n",
    "# ]\n",
    "\n",
    "for i, (a_concept, u_concept, gnrl, _seed_instances) in seed_concepts_df.iterrows():\n",
    "    _seed_embs = []\n",
    "    for inst in _seed_instances:\n",
    "        try:\n",
    "            _emb = entity_emb_dict[inst]\n",
    "            _seed_embs.append(_emb)\n",
    "        except KeyError:\n",
    "            print(f\"{inst} not found in entity_emb_dict??\")\n",
    "            continue\n",
    "    if len(_seed_embs) == 0:\n",
    "        continue\n",
    "    _concept_emb = np.mean(_seed_embs, axis=0)\n",
    "    \n",
    "    _concept_knns = concepts_knn_df[concepts_knn_df['concept'] == a_concept]['neighbor'].tolist()\n",
    "    _concept_knn_embs = [entity_emb_dict[inst] for inst in _concept_knns]\n",
    "    \n",
    "    _record = [(a_concept, _concept_emb),\n",
    "       list(zip(seed_instances, _seed_embs)),\n",
    "       list(zip(_concept_knns, _concept_knn_embs))\n",
    "    ]\n",
    "    \n",
    "    vis_records.append(_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "_label_list = []\n",
    "_raw_emb_list = []\n",
    "_size_list = []   # knn = 1, seed = 2, concept = 3 \n",
    "_color_id_list = []\n",
    "\n",
    "_CONCEPT_SIZE = 100\n",
    "_SEED_SIZE = 30\n",
    "_CAND_SIZE = 1\n",
    "\n",
    "for c_id, ((_con, _con_emb), _seeds, _knns) in enumerate(vis_records):\n",
    "    _label_list.append(_con)\n",
    "    _raw_emb_list.append(_con_emb)\n",
    "    _size_list.append(_CONCEPT_SIZE)\n",
    "    _color_id_list.append(c_id)\n",
    "    for _seed, _seed_emb in _seeds:\n",
    "        _label_list.append(_seed)\n",
    "        _raw_emb_list.append(_seed_emb)\n",
    "        _size_list.append(_SEED_SIZE)\n",
    "        _color_id_list.append(c_id)\n",
    "    for _inst, _inst_emb in _knns:\n",
    "        _label_list.append(_inst)\n",
    "        _raw_emb_list.append(_inst_emb)\n",
    "        _size_list.append(_CAND_SIZE)\n",
    "        _color_id_list.append(c_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_raw_emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "_tsne_emb_list = tsne.fit_transform(_raw_emb_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_tsne_x, _tsne_y = list(zip(*_tsne_emb_list))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.gca()\n",
    "\n",
    "# _scatter = ax.scatter(_tsne_x, _tsne_y, s=_size_list, c=_color_id_list)\n",
    "\n",
    "cmap = plt.get_cmap(name='viridis')\n",
    "\n",
    "for c_id, _record in enumerate(vis_records[:10]):\n",
    "    _data_ids = [i for i, c in enumerate(_color_id_list) if c == c_id]\n",
    "    _x = [_tsne_x[i] for i in _data_ids]\n",
    "    _y = [_tsne_y[i] for i in _data_ids]\n",
    "    _s = [_size_list[i] for i in _data_ids]\n",
    "#     _c = [c_id for i in _data_ids]\n",
    "#     _c = matplotlib.colors.rgb2hex(cmap(1.0 * c_id / len(vis_records)))\n",
    "    ax.scatter(_x, _y, s=_s, label=_record[0][0])\n",
    "\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend1 = ax.legend(*_scatter.legend_elements(), title=\"Classes\")\n",
    "# # ax.add_artist(legend1)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.colors.rgb2hex(cmap(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity expansion evaluation\n",
    "Now using benchmark entities, mean reciprocal rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['company', 'dress_code', 'job_position', 'pay_schedule', 'benefits', 'compensation', 'payment_option', 'background_screening', 'person', 'hire_prerequisite', 'shifts', 'schedule', 'employee_type', 'onboarding_steps']\n",
      "['has_pay_schedule', 'has_pay_schedule', 'has_dress_code', 'has_dress_code', 'has_background_screening', 'has_benefits', 'has_benefits', 'hires_person', 'has_compensation', 'has_compensation', 'has_hire_prerequisite', 'operates_on', 'hires_employee_type', 'has_onboarding_steps', 'has_shifts', 'has_shifts', 'has_job_position', 'has_hiring_policy', 'has_payment_option']\n",
      "{'onboarding_steps', 'pay_schedule', 'shifts', 'schedule', 'company', 'job_position', 'hire_prerequisite', 'payment_option', 'benefits', 'background_screening', 'person', 'employee_type', 'dress_code', 'compensation'}\n",
      "(706, 17)\n"
     ]
    }
   ],
   "source": [
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')\n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "\n",
    "seed_aligned_concepts = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "seed_aligned_relations = load_seed_aligned_relations(seed_aligned_relations_path)\n",
    "benchmark = pd.read_csv(benchmark_path)\n",
    "concept_knn = pd.read_csv(concept_knn_path)\n",
    "\n",
    "print(seed_aligned_concepts['alignedCategoryName'].tolist())\n",
    "print(seed_aligned_relations['alignedRelationName'].tolist())\n",
    "print(set(concept_knn['concept'].tolist()))\n",
    "print(benchmark.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_EE(predictions_path,\n",
    "                seed_concepts_path,\n",
    "                seed_relations_path,\n",
    "                benchmark_path):\n",
    "    '''Format of prediction file: CSV, with column \"concept\" and \"neighbor\"(entity) '''\n",
    "    preds_df = pd.read_csv(predictions_path)\n",
    "    \n",
    "    all_benchmark_instances, _ = load_benchmark(benchmark_path, seed_concepts_path, seed_relations_path)\n",
    "    seed_aligned_concepts = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    \n",
    "    mrr_dict = dict()\n",
    "    for i, d in seed_aligned_concepts.iterrows():\n",
    "        a_concept = d[\"alignedCategoryName\"]\n",
    "        u_concept = d[\"unalignedCategoryName\"]\n",
    "        seed_instances = d[\"seedInstances\"]\n",
    "\n",
    "#         concept_knn_instances = concept_knn[concept_knn[\"concept\"] == a_concept][\"neighbor\"].to_list()\n",
    "        pred_instances = preds_df[preds_df[\"concept\"] == a_concept][\"neighbor\"].to_list()\n",
    "\n",
    "#         _b_head_instances = benchmark[benchmark[\"n_head_category\"] == a_concept][\"n_head\"].to_list()\n",
    "#         _b_tail_instances = benchmark[benchmark[\"n_tail_category\"] == a_concept][\"n_tail\"].to_list()\n",
    "#         benchmark_instances = list(set(_b_head_instances + _b_tail_instances))\n",
    "        benchmark_instances = all_benchmark_instances[a_concept]\n",
    "\n",
    "        print(f'Concept: {a_concept} / {u_concept}')\n",
    "        print(f'seeds: {seed_instances}')\n",
    "        b_inst_ranks = dict()\n",
    "        recip_ranks = []\n",
    "        for _inst in benchmark_instances:\n",
    "            if _inst in seed_instances:\n",
    "                b_inst_ranks[_inst] = -1\n",
    "            elif _inst in pred_instances:\n",
    "                _rank = pred_instances.index(_inst) + 1\n",
    "                b_inst_ranks[_inst] = _rank\n",
    "                recip_ranks.append(1.0 / _rank)\n",
    "            else:\n",
    "                b_inst_ranks[_inst] = float('nan')\n",
    "                recip_ranks.append(0.0)\n",
    "                \n",
    "        mrr = np.mean(recip_ranks) if len(recip_ranks) > 0 else 0.0\n",
    "        mrr_dict[a_concept] = mrr\n",
    "        print(json.dumps(b_inst_ranks, indent=4))\n",
    "        print('MRR:', mrr)\n",
    "        print()\n",
    "\n",
    "    print('--- Summary ---')\n",
    "    print(json.dumps(mrr_dict, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "\n",
    "evaluate_EE(predictions_path=concept_knn_path,\n",
    "            seed_concepts_path=seed_aligned_concepts_path,\n",
    "            seed_relations_path=seed_aligned_relations_path,\n",
    "            benchmark_path=benchmark_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: company / company\r\n",
      "seeds: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\r\n",
      "{\r\n",
      "    \"frito\": NaN,\r\n",
      "    \"verizon\": NaN,\r\n",
      "    \"olive garden\": NaN,\r\n",
      "    \"lowe's\": NaN,\r\n",
      "    \"family dollar\": NaN,\r\n",
      "    \"wells fargo\": NaN,\r\n",
      "    \"panera\": NaN,\r\n",
      "    \"instacart\": NaN,\r\n",
      "    \"t-mobile\": NaN,\r\n",
      "    \"chipotle\": NaN,\r\n",
      "    \"training\": NaN,\r\n",
      "    \"barnes & noble\": NaN,\r\n",
      "    \"american eagle outfitters\": NaN,\r\n",
      "    \"concentrix\": NaN,\r\n",
      "    \"domino's\": NaN,\r\n",
      "    \"mcdonald's\": NaN,\r\n",
      "    \"foot locker\": NaN,\r\n",
      "    \"ihop\": NaN,\r\n",
      "    \"panera bread\": NaN,\r\n",
      "    \"dunkin donuts\": NaN,\r\n",
      "    \"frito lay\": NaN,\r\n",
      "    \"fedex ground\": NaN,\r\n",
      "    \"electric\": NaN,\r\n",
      "    \"marshalls\": 272,\r\n",
      "    \"victoria's secret\": NaN,\r\n",
      "    \"g4s\": NaN,\r\n",
      "    \"chilis\": NaN,\r\n",
      "    \"cvs\": 426,\r\n",
      "    \"pepsi\": NaN,\r\n",
      "    \"dollar general\": 251,\r\n",
      "    \"sonic drive-in\": NaN,\r\n",
      "    \"costco\": NaN,\r\n",
      "    \"allied universal security services, systems and solutions\": NaN,\r\n",
      "    \"wendys\": NaN,\r\n",
      "    \"pizza hut\": NaN,\r\n",
      "    \"geico\": NaN,\r\n",
      "    \"spectrum\": NaN,\r\n",
      "    \"chipotle mexican grill\": NaN,\r\n",
      "    \"whataburger\": NaN,\r\n",
      "    \"lowes\": NaN,\r\n",
      "    \"cracker barrel\": NaN,\r\n",
      "    \"subway\": -1,\r\n",
      "    \"united states postal service\": NaN,\r\n",
      "    \"goodwill industries\": NaN,\r\n",
      "    \"taco bell\": NaN,\r\n",
      "    \"starbucks\": 34,\r\n",
      "    \"old navy\": NaN,\r\n",
      "    \"teleperformance\": NaN,\r\n",
      "    \"quiktrip\": NaN,\r\n",
      "    \"frito-lay\": NaN,\r\n",
      "    \"tj maxx\": NaN,\r\n",
      "    \"target\": -1,\r\n",
      "    \"planet fitness\": NaN,\r\n",
      "    \"mcdonalds\": 295,\r\n",
      "    \"marriott international, inc.\": NaN,\r\n",
      "    \"ulta\": NaN,\r\n",
      "    \"whole foods market\": NaN,\r\n",
      "    \"publix\": NaN,\r\n",
      "    \"dd\": NaN,\r\n",
      "    \"kroger stores\": NaN,\r\n",
      "    \"little caesars\": NaN,\r\n",
      "    \"doordash\": NaN,\r\n",
      "    \"macy's\": NaN,\r\n",
      "    \"petsmart\": NaN,\r\n",
      "    \"t.j. maxx\": NaN,\r\n",
      "    \"heb\": NaN,\r\n",
      "    \"mcdonald\": NaN,\r\n",
      "    \"best buy\": NaN,\r\n",
      "    \"amazon\": -1,\r\n",
      "    \"fedex\": NaN,\r\n",
      "    \"subways\": NaN,\r\n",
      "    \"chili's\": NaN,\r\n",
      "    \"ross dress for less\": NaN,\r\n",
      "    \"sam's club\": NaN,\r\n",
      "    \"walmart\": -1,\r\n",
      "    \"dollar tree\": NaN,\r\n",
      "    \"amazon.com\": NaN,\r\n",
      "    \"costco wholesale\": NaN,\r\n",
      "    \"chick-fil-a\": NaN,\r\n",
      "    \"the wendy's company\": NaN,\r\n",
      "    \"the home depot\": NaN,\r\n",
      "    \"alorica\": NaN,\r\n",
      "    \"at&t\": NaN,\r\n",
      "    \"walgreens\": NaN,\r\n",
      "    \"primark\": NaN,\r\n",
      "    \"applebee's\": NaN,\r\n",
      "    \"hobby lobby\": NaN,\r\n",
      "    \"burger king\": NaN,\r\n",
      "    \"kfc\": NaN,\r\n",
      "    \"enterprise holdings\": NaN,\r\n",
      "    \"dick's sporting goods\": NaN,\r\n",
      "    \"cvs health\": 375,\r\n",
      "    \"menards\": NaN,\r\n",
      "    \"kroger\": NaN,\r\n",
      "    \"burlington stores\": NaN,\r\n",
      "    \"jcpenney\": NaN,\r\n",
      "    \"ups\": NaN,\r\n",
      "    \"safeway\": NaN,\r\n",
      "    \"dunkin' donuts\": NaN,\r\n",
      "    \"sitel\": 428,\r\n",
      "    \"pepsico\": NaN,\r\n",
      "    \"home depot\": 228,\r\n",
      "    \"kohl's\": NaN,\r\n",
      "    \"aldi\": NaN,\r\n",
      "    \"tim hortons\": NaN\r\n",
      "}\r\n",
      "MRR: 0.0005168180947036233\r\n",
      "\r\n",
      "Concept: dress_code / dress code\r\n",
      "seeds: ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\r\n",
      "{\r\n",
      "    \"facial piercings\": 3,\r\n",
      "    \"black jeans\": 413,\r\n",
      "    \"jeans\": NaN,\r\n",
      "    \"resistant shoes\": 76,\r\n",
      "    \"strict dress code\": 252,\r\n",
      "    \"color hair\": 36,\r\n",
      "    \"unnatural hair colors\": NaN,\r\n",
      "    \"hat\": NaN,\r\n",
      "    \"attire\": NaN,\r\n",
      "    \"blue collar\": 37,\r\n",
      "    \"wear fake nails\": NaN,\r\n",
      "    \"hairnets\": NaN,\r\n",
      "    \"professional\": 16,\r\n",
      "    \"wear jeans\": 198,\r\n",
      "    \"dress pants\": 27,\r\n",
      "    \"uniform\": -1,\r\n",
      "    \"ponytail\": NaN,\r\n",
      "    \"uniform shirts\": 44,\r\n",
      "    \"shoes\": -1,\r\n",
      "    \"uniform policy\": 144,\r\n",
      "    \"dress shirts\": 46,\r\n",
      "    \"black slacks\": NaN,\r\n",
      "    \"fake nails\": 429,\r\n",
      "    \"skirts\": NaN,\r\n",
      "    \"uniforms\": NaN,\r\n",
      "    \"non slip shoes\": NaN,\r\n",
      "    \"red shirts\": NaN,\r\n",
      "    \"brown pants\": 264,\r\n",
      "    \"mustaches\": NaN,\r\n",
      "    \"shorts\": NaN,\r\n",
      "    \"hats\": NaN,\r\n",
      "    \"unnatural colored hair\": 142,\r\n",
      "    \"wear shorts\": NaN,\r\n",
      "    \"polo shirts\": NaN,\r\n",
      "    \"shirt\": NaN,\r\n",
      "    \"natural colored hair\": 47,\r\n",
      "    \"scrubs\": 123,\r\n",
      "    \"hair color\": -1,\r\n",
      "    \"casual dress code\": 82,\r\n",
      "    \"casual\": NaN,\r\n",
      "    \"colorful hair\": 417,\r\n",
      "    \"nose rings\": 55,\r\n",
      "    \"pants\": NaN,\r\n",
      "    \"shirts\": NaN,\r\n",
      "    \"piercings\": -1,\r\n",
      "    \"face tattoos\": 4,\r\n",
      "    \"hair colors\": NaN,\r\n",
      "    \"facial hair\": -1,\r\n",
      "    \"hair net\": NaN,\r\n",
      "    \"jewelry\": NaN,\r\n",
      "    \"natural colors\": 407,\r\n",
      "    \"black pants\": 283,\r\n",
      "    \"unnatural hair color\": NaN,\r\n",
      "    \"business casual\": -1,\r\n",
      "    \"lab coats\": NaN\r\n",
      "}\r\n",
      "MRR: 0.01826566099506606\r\n",
      "\r\n",
      "Concept: job_position / job position\r\n",
      "seeds: ['delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher']\r\n",
      "{\r\n",
      "    \"server\": NaN,\r\n",
      "    \"truck drivers\": NaN,\r\n",
      "    \"servers\": NaN,\r\n",
      "    \"shift leader\": 207,\r\n",
      "    \"cashier\": -1\r\n",
      "}\r\n",
      "MRR: 0.0012077294685990338\r\n",
      "\r\n",
      "Concept: pay_schedule / pay period\r\n",
      "seeds: ['weekly', 'biweekly', 'friday', 'saturday']\r\n",
      "{\r\n",
      "    \"weekly\": -1,\r\n",
      "    \"paid bi weekly\": 21,\r\n",
      "    \"paid weekly\": 8,\r\n",
      "    \"biweekly\": -1,\r\n",
      "    \"bi weekly\": 2,\r\n",
      "    \"friday\": -1,\r\n",
      "    \"tuesday\": NaN,\r\n",
      "    \"tuesdays\": NaN,\r\n",
      "    \"week\": NaN,\r\n",
      "    \"weeks\": NaN,\r\n",
      "    \"paid biweekly\": NaN,\r\n",
      "    \"fridays\": NaN\r\n",
      "}\r\n",
      "MRR: 0.07473544973544974\r\n",
      "\r\n",
      "Concept: benefits / benefits\r\n",
      "seeds: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\r\n",
      "{\r\n",
      "    \"sick leave\": -1,\r\n",
      "    \"schooling\": NaN,\r\n",
      "    \"pto\": NaN,\r\n",
      "    \"prescription drugs\": NaN,\r\n",
      "    \"health\": 133,\r\n",
      "    \"healthcare\": 63,\r\n",
      "    \"pension\": NaN,\r\n",
      "    \"tuition assistance\": 93,\r\n",
      "    \"discounts\": NaN,\r\n",
      "    \"retirement plan\": 105,\r\n",
      "    \"health plans\": NaN,\r\n",
      "    \"relocation\": NaN,\r\n",
      "    \"discount\": NaN,\r\n",
      "    \"health benefits\": 72,\r\n",
      "    \"health care\": 37,\r\n",
      "    \"paid vacations\": 54,\r\n",
      "    \"relocate\": NaN,\r\n",
      "    \"free lunch\": NaN,\r\n",
      "    \"vacations\": NaN,\r\n",
      "    \"retirement\": NaN,\r\n",
      "    \"sick days\": 22,\r\n",
      "    \"health coverage\": NaN,\r\n",
      "    \"401k\": -1,\r\n",
      "    \"401 k\": NaN,\r\n",
      "    \"health insurance\": -1,\r\n",
      "    \"401k plan\": NaN,\r\n",
      "    \"monthly bonus\": NaN,\r\n",
      "    \"breakfast\": NaN,\r\n",
      "    \"life insurance\": 8,\r\n",
      "    \"vacation\": NaN\r\n",
      "}\r\n",
      "MRR: 0.010131751498160353\r\n",
      "\r\n",
      "Concept: compensation / compensation\r\n",
      "seeds: ['base pay', 'stock options', 'benefits', 'overtime pay', 'bonus']\r\n",
      "{\r\n",
      "    \"benefits\": -1,\r\n",
      "    \"benfits\": NaN,\r\n",
      "    \"compensation\": NaN\r\n",
      "}\r\n",
      "MRR: 0.0\r\n",
      "\r\n",
      "Concept: payment_option / nan\r\n",
      "seeds: ['checks', 'direct deposit', 'prepaid card']\r\n",
      "{\r\n",
      "    \"direct deposits\": 19,\r\n",
      "    \"checks\": -1,\r\n",
      "    \"prepaid card\": -1,\r\n",
      "    \"paycheck\": NaN,\r\n",
      "    \"direct deposit\": -1,\r\n",
      "    \"paper checks\": NaN\r\n",
      "}\r\n",
      "MRR: 0.017543859649122806\r\n",
      "\r\n",
      "Concept: background_screening / background screening\r\n",
      "seeds: ['drug test', 'criminal background check', 'employment verification']\r\n",
      "{\r\n",
      "    \"credit checks\": 182,\r\n",
      "    \"random drug test\": 9,\r\n",
      "    \"saliva drug test\": 27,\r\n",
      "    \"follicle test\": NaN,\r\n",
      "    \"urine tests\": 71,\r\n",
      "    \"previous employment\": 78,\r\n",
      "    \"testing\": NaN,\r\n",
      "    \"mouth swab\": NaN,\r\n",
      "    \"criminal background checks\": NaN,\r\n",
      "    \"criminal record\": 50,\r\n",
      "    \"mouth swap\": NaN,\r\n",
      "    \"background checks\": 146,\r\n",
      "    \"cannabis\": NaN,\r\n",
      "    \"cheek swab\": NaN,\r\n",
      "    \"urine\": NaN,\r\n",
      "    \"blood test\": 3,\r\n",
      "    \"backround check\": NaN,\r\n",
      "    \"criminal background check\": -1,\r\n",
      "    \"swab test\": NaN,\r\n",
      "    \"saliva test\": 23,\r\n",
      "    \"test\": 48,\r\n",
      "    \"credit history\": 105,\r\n",
      "    \"hair follicle test\": NaN,\r\n",
      "    \"mouth swabs\": NaN,\r\n",
      "    \"drug screened\": NaN,\r\n",
      "    \"social security number\": 61,\r\n",
      "    \"drug tested\": NaN,\r\n",
      "    \"urine drug test\": 18,\r\n",
      "    \"urine test\": 6,\r\n",
      "    \"urine testing\": NaN,\r\n",
      "    \"criminal background\": 100,\r\n",
      "    \"saliva\": NaN,\r\n",
      "    \"dui\": NaN,\r\n",
      "    \"urine sample\": NaN,\r\n",
      "    \"hair sample\": NaN,\r\n",
      "    \"previous employer\": NaN,\r\n",
      "    \"credit score\": 195,\r\n",
      "    \"urine drug screen\": NaN,\r\n",
      "    \"random tests\": 177,\r\n",
      "    \"background check\": 36,\r\n",
      "    \"background report\": 119,\r\n",
      "    \"drug\": NaN,\r\n",
      "    \"drug screen\": NaN,\r\n",
      "    \"drug tests\": 14,\r\n",
      "    \"previous employers\": NaN,\r\n",
      "    \"criminal records\": 99,\r\n",
      "    \"drugs\": NaN,\r\n",
      "    \"previous jobs\": NaN,\r\n",
      "    \"credit report\": 40,\r\n",
      "    \"random drug testing\": 106,\r\n",
      "    \"alcohol\": NaN,\r\n",
      "    \"drug test\": -1,\r\n",
      "    \"screen\": NaN,\r\n",
      "    \"criminal backgrounds\": NaN,\r\n",
      "    \"criminal history\": 218,\r\n",
      "    \"drugged tested\": NaN,\r\n",
      "    \"backround\": NaN,\r\n",
      "    \"drug text\": NaN,\r\n",
      "    \"credit check\": 35,\r\n",
      "    \"backround checks\": NaN,\r\n",
      "    \"drug testing\": 44,\r\n",
      "    \"drug screens\": NaN,\r\n",
      "    \"previously worked\": NaN,\r\n",
      "    \"screening process\": NaN,\r\n",
      "    \"social security\": NaN,\r\n",
      "    \"driving record\": 94,\r\n",
      "    \"backgrounds\": NaN,\r\n",
      "    \"random drug tests\": 57,\r\n",
      "    \"screening\": NaN,\r\n",
      "    \"drug screening\": 134,\r\n",
      "    \"social media\": NaN,\r\n",
      "    \"mouth\": NaN,\r\n",
      "    \"pre employment drug screening\": NaN\r\n",
      "}\r\n",
      "MRR: 0.015741333766030093\r\n",
      "\r\n",
      "Concept: person / nan\r\n",
      "seeds: ['felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors']\r\n",
      "{\r\n",
      "    \"pregnant\": -1,\r\n",
      "    \"felony\": NaN,\r\n",
      "    \"seniors\": -1,\r\n",
      "    \"high school students\": NaN,\r\n",
      "    \"high schoolers\": -1,\r\n",
      "    \"disabled\": -1,\r\n",
      "    \"felony record\": NaN,\r\n",
      "    \"felonys\": NaN,\r\n",
      "    \"school students\": NaN,\r\n",
      "    \"disabilities\": NaN,\r\n",
      "    \"misdemeanor charges\": NaN,\r\n",
      "    \"ex felons\": NaN,\r\n",
      "    \"high school graduate\": NaN,\r\n",
      "    \"high school\": NaN,\r\n",
      "    \"pregnant women\": 361,\r\n",
      "    \"schoolers\": NaN,\r\n",
      "    \"seniority\": NaN,\r\n",
      "    \"misdemeanor theft\": NaN,\r\n",
      "    \"sex offenders\": 6,\r\n",
      "    \"felonies\": NaN,\r\n",
      "    \"felons\": -1,\r\n",
      "    \"senior citizens\": 30,\r\n",
      "    \"misdemeanor\": -1,\r\n",
      "    \"criminals\": -1,\r\n",
      "    \"convicted felons\": NaN\r\n",
      "}\r\n",
      "MRR: 0.01126500461680517\r\n",
      "\r\n",
      "Concept: hire_prerequisite / qualification\r\n",
      "seeds: ['hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting']\r\n",
      "{\r\n",
      "    \"gpa\": NaN,\r\n",
      "    \"college degree\": 14,\r\n",
      "    \"ged\": NaN,\r\n",
      "    \"workers permit\": 179,\r\n",
      "    \"working permit\": -1,\r\n",
      "    \"diploma\": 205,\r\n",
      "    \"high school diploma\": 30,\r\n",
      "    \"hs diploma\": 243,\r\n",
      "    \"degrees\": NaN,\r\n",
      "    \"birth certificate\": 192,\r\n",
      "    \"high school education\": 77,\r\n",
      "    \"bachelor degree\": 6\r\n",
      "}\r\n",
      "MRR: 0.02765488954960228\r\n",
      "\r\n",
      "Concept: shifts / work shift\r\n",
      "seeds: ['night shift', 'dinner shift', 'early morning shift', '8 hour shift']\r\n",
      "{\r\n",
      "    \"3rd shift\": 31,\r\n",
      "    \"12 hour shifts\": 50,\r\n",
      "    \"night shifts\": 4,\r\n",
      "    \"open 24 hours\": NaN,\r\n",
      "    \"weekend shift\": 2\r\n",
      "}\r\n",
      "MRR: 0.1604516129032258\r\n",
      "\r\n",
      "Concept: schedule / nan\r\n",
      "seeds: ['christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend']\r\n",
      "{\r\n",
      "    \"saturday\": -1,\r\n",
      "    \"saturdays\": NaN,\r\n",
      "    \"federal holidays\": NaN,\r\n",
      "    \"early morning\": -1,\r\n",
      "    \"open 7 days\": NaN,\r\n",
      "    \"christmas eve\": -1,\r\n",
      "    \"weekend\": -1,\r\n",
      "    \"sunday\": -1,\r\n",
      "    \"weekends\": NaN,\r\n",
      "    \"hoildays\": NaN\r\n",
      "}\r\n",
      "MRR: 0.0\r\n",
      "\r\n",
      "Concept: employee_type / nan\r\n",
      "seeds: ['full time', 'part time', 'seasonal']\r\n",
      "{\r\n",
      "    \"seasonal positions\": NaN,\r\n",
      "    \"ft\": NaN,\r\n",
      "    \"season\": NaN,\r\n",
      "    \"seasonal workers\": NaN,\r\n",
      "    \"seasons\": NaN,\r\n",
      "    \"seasonal employees\": 183,\r\n",
      "    \"fulltime\": NaN,\r\n",
      "    \"seasonal\": -1,\r\n",
      "    \"seasonals\": NaN\r\n",
      "}\r\n",
      "MRR: 0.0006830601092896175\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: onboarding_steps / onboarding process steps\r\n",
      "seeds: ['orientation', 'introduction', 'workstation', 'training', 'team lunch']\r\n",
      "{\r\n",
      "    \"training classes\": 179,\r\n",
      "    \"training program\": 54,\r\n",
      "    \"training\": -1,\r\n",
      "    \"orientation\": -1\r\n",
      "}\r\n",
      "MRR: 0.012052555348644734\r\n",
      "\r\n",
      "--- Summary ---\r\n",
      "{\r\n",
      "  \"company\": 0.0005168180947036233,\r\n",
      "  \"dress_code\": 0.01826566099506606,\r\n",
      "  \"job_position\": 0.0012077294685990338,\r\n",
      "  \"pay_schedule\": 0.07473544973544974,\r\n",
      "  \"benefits\": 0.010131751498160353,\r\n",
      "  \"compensation\": 0.0,\r\n",
      "  \"payment_option\": 0.017543859649122806,\r\n",
      "  \"background_screening\": 0.015741333766030093,\r\n",
      "  \"person\": 0.01126500461680517,\r\n",
      "  \"hire_prerequisite\": 0.02765488954960228,\r\n",
      "  \"shifts\": 0.1604516129032258,\r\n",
      "  \"schedule\": 0.0,\r\n",
      "  \"employee_type\": 0.0006830601092896175,\r\n",
      "  \"onboarding_steps\": 0.012052555348644734\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "!python eval_entities.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/concept_corr_100.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: company / company\n",
      "seeds: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "{\n",
      "    \"geico\": 30,\n",
      "    \"goodwill industries\": NaN,\n",
      "    \"dunkin' donuts\": NaN,\n",
      "    \"wells fargo\": 50,\n",
      "    \"sonic drive-in\": NaN,\n",
      "    \"domino's\": NaN,\n",
      "    \"pizza hut\": 9,\n",
      "    \"frito-lay\": NaN,\n",
      "    \"marshalls\": 35,\n",
      "    \"fedex ground\": NaN,\n",
      "    \"whole foods market\": NaN,\n",
      "    \"burger king\": 32,\n",
      "    \"target\": -1,\n",
      "    \"tim hortons\": NaN,\n",
      "    \"t.j. maxx\": NaN,\n",
      "    \"cracker barrel\": 20,\n",
      "    \"subways\": NaN,\n",
      "    \"ulta\": NaN,\n",
      "    \"olive garden\": 12,\n",
      "    \"kroger\": 7,\n",
      "    \"spectrum\": 18,\n",
      "    \"verizon\": 38,\n",
      "    \"united states postal service\": NaN,\n",
      "    \"frito\": NaN,\n",
      "    \"taco bell\": 37,\n",
      "    \"mcdonald\": NaN,\n",
      "    \"dick's sporting goods\": NaN,\n",
      "    \"training\": 92,\n",
      "    \"ups\": NaN,\n",
      "    \"panera bread\": 11,\n",
      "    \"lowe's\": NaN,\n",
      "    \"walgreens\": 6,\n",
      "    \"primark\": NaN,\n",
      "    \"mcdonalds\": 14,\n",
      "    \"foot locker\": NaN,\n",
      "    \"applebee's\": NaN,\n",
      "    \"chipotle\": 34,\n",
      "    \"dollar tree\": 17,\n",
      "    \"t-mobile\": NaN,\n",
      "    \"costco wholesale\": NaN,\n",
      "    \"cvs\": 25,\n",
      "    \"little caesars\": 74,\n",
      "    \"best buy\": 13,\n",
      "    \"kohl's\": NaN,\n",
      "    \"allied universal security services, systems and solutions\": NaN,\n",
      "    \"marriott international, inc.\": NaN,\n",
      "    \"chilis\": NaN,\n",
      "    \"cvs health\": NaN,\n",
      "    \"costco\": 2,\n",
      "    \"tj maxx\": 49,\n",
      "    \"enterprise holdings\": NaN,\n",
      "    \"at&t\": 41,\n",
      "    \"electric\": NaN,\n",
      "    \"fedex\": 36,\n",
      "    \"whataburger\": NaN,\n",
      "    \"mcdonald's\": NaN,\n",
      "    \"the wendy's company\": NaN,\n",
      "    \"panera\": NaN,\n",
      "    \"planet fitness\": 65,\n",
      "    \"sam's club\": NaN,\n",
      "    \"menards\": 24,\n",
      "    \"walmart\": -1,\n",
      "    \"teleperformance\": NaN,\n",
      "    \"alorica\": NaN,\n",
      "    \"amazon\": -1,\n",
      "    \"macy's\": NaN,\n",
      "    \"kfc\": 19,\n",
      "    \"kroger stores\": NaN,\n",
      "    \"publix\": 8,\n",
      "    \"american eagle outfitters\": NaN,\n",
      "    \"starbucks\": 10,\n",
      "    \"burlington stores\": NaN,\n",
      "    \"subway\": -1,\n",
      "    \"sitel\": 42,\n",
      "    \"home depot\": 5,\n",
      "    \"ross dress for less\": NaN,\n",
      "    \"hobby lobby\": 73,\n",
      "    \"aldi\": NaN,\n",
      "    \"concentrix\": NaN,\n",
      "    \"chipotle mexican grill\": NaN,\n",
      "    \"lowes\": NaN,\n",
      "    \"instacart\": NaN,\n",
      "    \"old navy\": 16,\n",
      "    \"dunkin donuts\": 43,\n",
      "    \"petsmart\": 40,\n",
      "    \"safeway\": 22,\n",
      "    \"the home depot\": NaN,\n",
      "    \"quiktrip\": NaN,\n",
      "    \"doordash\": NaN,\n",
      "    \"wendys\": NaN,\n",
      "    \"chick-fil-a\": NaN,\n",
      "    \"pepsi\": 39,\n",
      "    \"chili's\": NaN,\n",
      "    \"victoria's secret\": NaN,\n",
      "    \"dollar general\": 3,\n",
      "    \"family dollar\": 15,\n",
      "    \"pepsico\": 53,\n",
      "    \"barnes & noble\": NaN,\n",
      "    \"jcpenney\": 21,\n",
      "    \"g4s\": 44,\n",
      "    \"heb\": NaN,\n",
      "    \"amazon.com\": NaN,\n",
      "    \"ihop\": 26,\n",
      "    \"frito lay\": 33,\n",
      "    \"dd\": 84\n",
      "}\n",
      "MRR: 0.030340620401210584\n",
      "\n",
      "Concept: dress_code / dress code\n",
      "seeds: ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\n",
      "{\n",
      "    \"hats\": NaN,\n",
      "    \"red shirts\": NaN,\n",
      "    \"unnatural hair colors\": NaN,\n",
      "    \"wear jeans\": NaN,\n",
      "    \"ponytail\": NaN,\n",
      "    \"shirts\": NaN,\n",
      "    \"unnatural colored hair\": NaN,\n",
      "    \"uniform policy\": 23,\n",
      "    \"face tattoos\": NaN,\n",
      "    \"shorts\": NaN,\n",
      "    \"shirt\": NaN,\n",
      "    \"black slacks\": NaN,\n",
      "    \"hair color\": -1,\n",
      "    \"mustaches\": NaN,\n",
      "    \"black jeans\": NaN,\n",
      "    \"jewelry\": NaN,\n",
      "    \"hair net\": NaN,\n",
      "    \"wear fake nails\": NaN,\n",
      "    \"dress shirts\": NaN,\n",
      "    \"hairnets\": NaN,\n",
      "    \"nose rings\": 9,\n",
      "    \"business casual\": -1,\n",
      "    \"attire\": NaN,\n",
      "    \"uniform shirts\": NaN,\n",
      "    \"non slip shoes\": NaN,\n",
      "    \"professional\": 21,\n",
      "    \"hair colors\": NaN,\n",
      "    \"strict dress code\": 48,\n",
      "    \"dress pants\": NaN,\n",
      "    \"uniforms\": NaN,\n",
      "    \"scrubs\": 58,\n",
      "    \"facial piercings\": 3,\n",
      "    \"lab coats\": NaN,\n",
      "    \"casual dress code\": NaN,\n",
      "    \"hat\": NaN,\n",
      "    \"brown pants\": NaN,\n",
      "    \"pants\": NaN,\n",
      "    \"jeans\": NaN,\n",
      "    \"natural colored hair\": NaN,\n",
      "    \"piercings\": -1,\n",
      "    \"shoes\": -1,\n",
      "    \"color hair\": 35,\n",
      "    \"fake nails\": 8,\n",
      "    \"colorful hair\": 62,\n",
      "    \"unnatural hair color\": NaN,\n",
      "    \"uniform\": -1,\n",
      "    \"blue collar\": NaN,\n",
      "    \"wear shorts\": NaN,\n",
      "    \"polo shirts\": NaN,\n",
      "    \"facial hair\": -1,\n",
      "    \"casual\": NaN,\n",
      "    \"natural colors\": 78,\n",
      "    \"skirts\": NaN,\n",
      "    \"resistant shoes\": NaN,\n",
      "    \"black pants\": NaN\n",
      "}\n",
      "MRR: 0.015431376310749822\n",
      "\n",
      "Concept: job_position / job position\n",
      "seeds: ['delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher']\n",
      "{\n",
      "    \"cashier\": -1,\n",
      "    \"servers\": NaN,\n",
      "    \"shift leader\": 10,\n",
      "    \"truck drivers\": NaN,\n",
      "    \"server\": NaN\n",
      "}\n",
      "MRR: 0.025\n",
      "\n",
      "Concept: pay_schedule / pay period\n",
      "seeds: ['weekly', 'biweekly', 'friday', 'saturday']\n",
      "{\n",
      "    \"tuesdays\": NaN,\n",
      "    \"week\": NaN,\n",
      "    \"paid biweekly\": NaN,\n",
      "    \"bi weekly\": 3,\n",
      "    \"tuesday\": NaN,\n",
      "    \"paid weekly\": NaN,\n",
      "    \"weeks\": NaN,\n",
      "    \"friday\": -1,\n",
      "    \"paid bi weekly\": NaN,\n",
      "    \"fridays\": NaN,\n",
      "    \"biweekly\": -1,\n",
      "    \"weekly\": -1\n",
      "}\n",
      "MRR: 0.037037037037037035\n",
      "\n",
      "Concept: benefits / benefits\n",
      "seeds: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "{\n",
      "    \"health insurance\": -1,\n",
      "    \"tuition assistance\": NaN,\n",
      "    \"health care\": 2,\n",
      "    \"health\": 7,\n",
      "    \"retirement\": NaN,\n",
      "    \"health coverage\": NaN,\n",
      "    \"retirement plan\": 74,\n",
      "    \"relocation\": NaN,\n",
      "    \"sick days\": 10,\n",
      "    \"monthly bonus\": NaN,\n",
      "    \"paid vacations\": 65,\n",
      "    \"vacation\": NaN,\n",
      "    \"401k\": -1,\n",
      "    \"life insurance\": 8,\n",
      "    \"relocate\": NaN,\n",
      "    \"schooling\": NaN,\n",
      "    \"pto\": NaN,\n",
      "    \"health benefits\": NaN,\n",
      "    \"breakfast\": NaN,\n",
      "    \"pension\": 63,\n",
      "    \"401 k\": NaN,\n",
      "    \"free lunch\": NaN,\n",
      "    \"sick leave\": -1,\n",
      "    \"prescription drugs\": NaN,\n",
      "    \"discounts\": NaN,\n",
      "    \"discount\": NaN,\n",
      "    \"vacations\": NaN,\n",
      "    \"healthcare\": 1,\n",
      "    \"401k plan\": NaN,\n",
      "    \"health plans\": NaN\n",
      "}\n",
      "MRR: 0.0708380847269736\n",
      "\n",
      "Concept: compensation / compensation\n",
      "seeds: ['base pay', 'stock options', 'benefits', 'overtime pay', 'bonus']\n",
      "{\n",
      "    \"benfits\": NaN,\n",
      "    \"benefits\": -1,\n",
      "    \"compensation\": NaN\n",
      "}\n",
      "MRR: 0.0\n",
      "\n",
      "Concept: payment_option / nan\n",
      "seeds: ['checks', 'direct deposit', 'prepaid card']\n",
      "{\n",
      "    \"prepaid card\": -1,\n",
      "    \"direct deposits\": 13,\n",
      "    \"checks\": -1,\n",
      "    \"paycheck\": 14,\n",
      "    \"direct deposit\": -1,\n",
      "    \"paper checks\": NaN\n",
      "}\n",
      "MRR: 0.04945054945054945\n",
      "\n",
      "Concept: background_screening / background screening\n",
      "seeds: ['drug test', 'criminal background check', 'employment verification']\n",
      "{\n",
      "    \"drug tests\": 82,\n",
      "    \"mouth swap\": NaN,\n",
      "    \"hair sample\": NaN,\n",
      "    \"criminal background\": 8,\n",
      "    \"criminal backgrounds\": NaN,\n",
      "    \"random drug testing\": NaN,\n",
      "    \"credit check\": 18,\n",
      "    \"backround checks\": NaN,\n",
      "    \"cheek swab\": NaN,\n",
      "    \"background checks\": NaN,\n",
      "    \"credit score\": NaN,\n",
      "    \"hair follicle test\": NaN,\n",
      "    \"saliva\": NaN,\n",
      "    \"saliva drug test\": NaN,\n",
      "    \"saliva test\": NaN,\n",
      "    \"social media\": 54,\n",
      "    \"social security number\": 50,\n",
      "    \"drug screening\": NaN,\n",
      "    \"drug screens\": NaN,\n",
      "    \"swab test\": NaN,\n",
      "    \"urine drug screen\": NaN,\n",
      "    \"credit history\": 89,\n",
      "    \"criminal records\": NaN,\n",
      "    \"urine drug test\": NaN,\n",
      "    \"drugs\": 40,\n",
      "    \"drug screen\": NaN,\n",
      "    \"previous employer\": NaN,\n",
      "    \"previous employment\": 34,\n",
      "    \"screening\": NaN,\n",
      "    \"drug text\": NaN,\n",
      "    \"drug test\": -1,\n",
      "    \"mouth swab\": NaN,\n",
      "    \"blood test\": NaN,\n",
      "    \"background report\": NaN,\n",
      "    \"urine\": NaN,\n",
      "    \"previous employers\": NaN,\n",
      "    \"credit report\": 63,\n",
      "    \"backround check\": NaN,\n",
      "    \"mouth\": NaN,\n",
      "    \"dui\": 29,\n",
      "    \"previously worked\": NaN,\n",
      "    \"urine sample\": NaN,\n",
      "    \"background check\": 14,\n",
      "    \"screen\": NaN,\n",
      "    \"test\": 11,\n",
      "    \"drug tested\": NaN,\n",
      "    \"follicle test\": NaN,\n",
      "    \"urine tests\": NaN,\n",
      "    \"alcohol\": NaN,\n",
      "    \"mouth swabs\": NaN,\n",
      "    \"social security\": NaN,\n",
      "    \"urine testing\": NaN,\n",
      "    \"criminal record\": 10,\n",
      "    \"previous jobs\": NaN,\n",
      "    \"drugged tested\": NaN,\n",
      "    \"criminal background checks\": NaN,\n",
      "    \"testing\": NaN,\n",
      "    \"screening process\": NaN,\n",
      "    \"urine test\": NaN,\n",
      "    \"credit checks\": NaN,\n",
      "    \"drug testing\": NaN,\n",
      "    \"random drug tests\": 75,\n",
      "    \"cannabis\": NaN,\n",
      "    \"drug screened\": NaN,\n",
      "    \"criminal history\": 1,\n",
      "    \"random tests\": NaN,\n",
      "    \"criminal background check\": -1,\n",
      "    \"driving record\": 6,\n",
      "    \"random drug test\": 80,\n",
      "    \"pre employment drug screening\": NaN,\n",
      "    \"drug\": 77,\n",
      "    \"backgrounds\": NaN,\n",
      "    \"backround\": NaN\n",
      "}\n",
      "MRR: 0.025564751628249813\n",
      "\n",
      "Concept: person / nan\n",
      "seeds: ['felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors']\n",
      "{\n",
      "    \"disabilities\": NaN,\n",
      "    \"high schoolers\": -1,\n",
      "    \"felony record\": NaN,\n",
      "    \"high school\": 55,\n",
      "    \"felonies\": 44,\n",
      "    \"pregnant women\": 25,\n",
      "    \"seniors\": -1,\n",
      "    \"disabled\": -1,\n",
      "    \"misdemeanor theft\": NaN,\n",
      "    \"pregnant\": -1,\n",
      "    \"sex offenders\": NaN,\n",
      "    \"convicted felons\": NaN,\n",
      "    \"felonys\": NaN,\n",
      "    \"high school graduate\": NaN,\n",
      "    \"schoolers\": NaN,\n",
      "    \"seniority\": NaN,\n",
      "    \"misdemeanor\": -1,\n",
      "    \"felons\": -1,\n",
      "    \"criminals\": -1,\n",
      "    \"felony\": NaN,\n",
      "    \"high school students\": NaN,\n",
      "    \"senior citizens\": 57,\n",
      "    \"misdemeanor charges\": NaN,\n",
      "    \"ex felons\": 50,\n",
      "    \"school students\": NaN\n",
      "}\n",
      "MRR: 0.006580719475456317\n",
      "\n",
      "Concept: hire_prerequisite / qualification\n",
      "seeds: ['hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting']\n",
      "{\n",
      "    \"birth certificate\": NaN,\n",
      "    \"working permit\": -1,\n",
      "    \"high school diploma\": NaN,\n",
      "    \"gpa\": NaN,\n",
      "    \"bachelor degree\": NaN,\n",
      "    \"degrees\": NaN,\n",
      "    \"diploma\": 76,\n",
      "    \"high school education\": NaN,\n",
      "    \"college degree\": 97,\n",
      "    \"hs diploma\": NaN,\n",
      "    \"workers permit\": NaN,\n",
      "    \"ged\": NaN\n",
      "}\n",
      "MRR: 0.0021333793715779606\n",
      "\n",
      "Concept: shifts / work shift\n",
      "seeds: ['night shift', 'dinner shift', 'early morning shift', '8 hour shift']\n",
      "{\n",
      "    \"weekend shift\": 12,\n",
      "    \"12 hour shifts\": 17,\n",
      "    \"3rd shift\": 37,\n",
      "    \"night shifts\": 10,\n",
      "    \"open 24 hours\": NaN\n",
      "}\n",
      "MRR: 0.05383677795442501\n",
      "\n",
      "Concept: schedule / nan\n",
      "seeds: ['christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend']\n",
      "{\n",
      "    \"open 7 days\": NaN,\n",
      "    \"early morning\": -1,\n",
      "    \"hoildays\": NaN,\n",
      "    \"saturday\": -1,\n",
      "    \"christmas eve\": -1,\n",
      "    \"saturdays\": NaN,\n",
      "    \"sunday\": -1,\n",
      "    \"federal holidays\": NaN,\n",
      "    \"weekends\": NaN,\n",
      "    \"weekend\": -1\n",
      "}\n",
      "MRR: 0.0\n",
      "\n",
      "Concept: employee_type / nan\n",
      "seeds: ['full time', 'part time', 'seasonal']\n",
      "{\n",
      "    \"seasonal\": -1,\n",
      "    \"seasons\": NaN,\n",
      "    \"seasonals\": NaN,\n",
      "    \"seasonal employees\": 10,\n",
      "    \"ft\": NaN,\n",
      "    \"fulltime\": NaN,\n",
      "    \"season\": NaN,\n",
      "    \"seasonal workers\": 64,\n",
      "    \"seasonal positions\": NaN\n",
      "}\n",
      "MRR: 0.014453125\n",
      "\n",
      "Concept: onboarding_steps / onboarding process steps\n",
      "seeds: ['orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "{\n",
      "    \"training\": -1,\n",
      "    \"training classes\": 38,\n",
      "    \"orientation\": -1,\n",
      "    \"training program\": NaN\n",
      "}\n",
      "MRR: 0.013157894736842105\n",
      "\n",
      "--- Summary ---\n",
      "{\n",
      "  \"company\": 0.030340620401210584,\n",
      "  \"dress_code\": 0.015431376310749822,\n",
      "  \"job_position\": 0.025,\n",
      "  \"pay_schedule\": 0.037037037037037035,\n",
      "  \"benefits\": 0.0708380847269736,\n",
      "  \"compensation\": 0.0,\n",
      "  \"payment_option\": 0.04945054945054945,\n",
      "  \"background_screening\": 0.025564751628249813,\n",
      "  \"person\": 0.006580719475456317,\n",
      "  \"hire_prerequisite\": 0.0021333793715779606,\n",
      "  \"shifts\": 0.05383677795442501,\n",
      "  \"schedule\": 0.0,\n",
      "  \"employee_type\": 0.014453125,\n",
      "  \"onboarding_steps\": 0.013157894736842105\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "!python eval_entities.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/concept_knn_100.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LM probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM correlation-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')\n",
    "\n",
    "# with open(corpus_path, 'r') as f:\n",
    "#     sent_dicts = [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_file_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sent_segmentation.txt')\n",
    "# ent_freq, dedup_context = get_masked_contexts(input_file_path)\n",
    "\n",
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')\n",
    "embed_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "\n",
    "entities, dedup_context = get_masked_contexts(corpus_path, embed_num_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8064, 8064, 7921)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities), len(set(entities)), len(dedup_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2372, 4132, 1144, 314, 55]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ents_tokenized = [tuple(lm_probe.tokenizer.tokenize(e)) for e in entities]\n",
    "all_ents_tokenized = list(set(all_ents_tokenized))\n",
    "[sum([len(e_t) == _l for e_t in all_ents_tokenized]) for _l in (1,2,3,4,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: keep rank in output\n",
    "\n",
    "def entity_expansion_corr(seed_concepts_path=seed_aligned_concepts_path,\n",
    "                          all_contexts=dedup_context, \n",
    "                          all_ents_tokenized=all_ents_tokenized, \n",
    "                          lm_probe=lm_probe,\n",
    "                          max_allowed_ngrams=3,\n",
    "                          max_contexts=50,\n",
    "                          top_k=100):\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "        \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    \n",
    "#     if contexts is None:\n",
    "#         try:\n",
    "#             contexts = dedup_context[entity]\n",
    "#         except KeyError:\n",
    "#             print(f'\"{entity}\" not an extracted entity!')\n",
    "#             return None\n",
    "\n",
    "    _out_records = []\n",
    "\n",
    "    for i, (a_concept, u_concept, gnrl, seed_instances) in tqdm(seed_concepts_df.iterrows(), total=seed_concepts_df.shape[0]):\n",
    "        _expand_set = set()\n",
    "        _expand_records = []\n",
    "        \n",
    "        for _inst in seed_instances:\n",
    "            print(f'{a_concept} :: {_inst}')\n",
    "            try:\n",
    "                contexts = all_contexts[_inst]\n",
    "            except KeyError:\n",
    "                print(f'\"{_inst}\" not an extracted entity!')\n",
    "                continue\n",
    "            if len(contexts) < 2:\n",
    "                print(f'\"{_inst}\" only have {len(contexts)} context')\n",
    "                continue\n",
    "\n",
    "            _entity_pieces = lm_probe.tokenizer.tokenize(_inst)\n",
    "            if len(_entity_pieces) > max_allowed_ngrams:\n",
    "                print(f'{_entity_pieces} too many word pieces (max {max_allowed_ngrams})')\n",
    "                continue\n",
    "\n",
    "            entity2probs = defaultdict(list)\n",
    "\n",
    "            for _context in contexts[:max_contexts]:\n",
    "                for n_grams in range(1, max_allowed_ngrams+1):\n",
    "                    _ctxt = _context.replace('[MASK]', '[MASK]' + ' [MASK]' * (n_grams-1))\n",
    "                    _ctxt = '[CLS] ' + _ctxt + ' [SEP]'\n",
    "                    _cands = [e_t for e_t in all_ents_tokenized if len(e_t) == n_grams]\n",
    "                    _cand_scores = lm_probe.score_candidates(_ctxt, _cands)\n",
    "\n",
    "                    for _d in _cand_scores:\n",
    "                        _c = ' '.join(_d['cand']).replace(' ##', '')\n",
    "                        _s = _d['score']\n",
    "                        entity2probs[_c].append(_s)\n",
    "\n",
    "        #     print('entity2probs:', len(entity2probs), len(entity2probs[entity]))\n",
    "            for _e, _ss in entity2probs.items():\n",
    "                assert len(_ss) == len(entity2probs[_inst]), \\\n",
    "                    f'entity: {_e} | {lm_probe.tokenizer.tokenize(_e)}\\n\\\n",
    "                    len(_ss) = {len(_ss)}\\n\\\n",
    "                    len(entity2probs[\"{entity}\"]) = {len(entity2probs[entity])}'\n",
    "\n",
    "            _target_ss = entity2probs[_inst]\n",
    "            _target_ss = _target_ss / np.sum(_target_ss)\n",
    "\n",
    "        #     print(_target_ss.shape, _target_ss)\n",
    "\n",
    "            mean_l = [(_e, np.mean(_ss)) for _e, _ss in entity2probs.items()]\n",
    "            mean_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "            kl_l = [(_e, entropy(_target_ss, _ss)) for _e, _ss in entity2probs.items()]\n",
    "            kl_l.sort(key=lambda p : p[-1], reverse=False)\n",
    "            pearson_l = [(_e, pearsonr(_target_ss, _ss)[0]) for _e, _ss in entity2probs.items()]\n",
    "            pearson_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "\n",
    "            entity2ranks = defaultdict(list)\n",
    "            entity2scores = defaultdict(dict)\n",
    "            for i, (_e, _s) in enumerate(mean_l):\n",
    "                entity2ranks[_e].append(i)\n",
    "                entity2scores[_e][\"mean\"] = _s\n",
    "            for i, (_e, _s) in enumerate(kl_l):\n",
    "                entity2ranks[_e].append(i)\n",
    "                entity2scores[_e][\"kl\"] = _s\n",
    "            for i, (_e, _s) in enumerate(pearson_l):\n",
    "                entity2ranks[_e].append(i)\n",
    "                entity2scores[_e][\"pearson\"] = _s\n",
    "            # To simile top-k set intersection, keep the highest rank of _e among each criteria\n",
    "            entity_overall_ranks = [(_e, max(_ranks)) for _e, _ranks in entity2ranks.items()]\n",
    "            entity_overall_ranks.sort(key=lambda p : p[-1])\n",
    "            entity_overall_ranks_dict = dict(entity_overall_ranks)\n",
    "#             # Now, the top-k is for the final selection, not for each criteria\n",
    "            sel_entities = [_e for _e, _ in entity_overall_ranks[:top_k]]\n",
    "\n",
    "#             ints_mean_l = [p for p in mean_l if p[0] in sel_entities]\n",
    "#             ints_kl_l = [p for p in kl_l if p[0] in sel_entities]\n",
    "#             ints_pearson_l = [p for p in pearson_l if p[0] in sel_entities]\n",
    "\n",
    "#             return {\n",
    "#                 \"entity2probs\": entity2probs,\n",
    "#                 \"mean_l\": mean_l,\n",
    "#                 \"kl_l\": kl_l,\n",
    "#                 \"pearson_l\": pearson_l,\n",
    "#                 \"sel_entities\": sel_entities,\n",
    "#                 \"ints_mean_l\": ints_mean_l,\n",
    "#                 \"ints_kl_l\": ints_kl_l,\n",
    "#                 \"ints_pearson_l\": ints_pearson_l,\n",
    "#             }\n",
    "\n",
    "            for _e in sel_entities:\n",
    "                if (_e in _expand_set) or (_e in seed_instances):\n",
    "                    continue\n",
    "                _expand_set.add(_e)\n",
    "                _d = dict(entity2scores[_e])\n",
    "                _d['max_rank'] = entity_overall_ranks_dict[_e]\n",
    "                _expand_records.append((_e, _d))\n",
    "\n",
    "#         for _inst in seed_instances:\n",
    "#             _expand_set.discard(_inst)\n",
    "\n",
    "        for _e, _d in _expand_records:\n",
    "            _out_d = dict(_d)\n",
    "            _out_d['concept'] = a_concept\n",
    "            _out_d['neighbor'] = _e\n",
    "            _out_records.append(_out_d)\n",
    "\n",
    "    return _out_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### full run & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_expansion_out_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_corr_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_expansion_corr(max_contexts=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|                                                    | 0/14 [00:00<?, ?it/s]company :: walmart\n",
      "company :: amazon\n",
      "company :: subway\n",
      "company :: microsoft\n",
      "company :: target\n",
      "  7%|███▏                                        | 1/14 [01:13<16:01, 73.94s/it]dress_code :: business casual\n",
      "dress_code :: uniform\n",
      "dress_code :: hair color\n",
      "dress_code :: tattoos\n",
      "dress_code :: facial hair\n",
      "dress_code :: shoes\n",
      "dress_code :: piercings\n",
      " 14%|██████▎                                     | 2/14 [03:16<17:43, 88.60s/it]job_position :: delivery driver\n",
      "job_position :: store manager\n",
      "job_position :: cashier\n",
      "job_position :: package handler\n",
      "job_position :: sales associate\n",
      "job_position :: barista\n",
      "job_position :: dishwasher\n",
      " 21%|█████████▍                                  | 3/14 [05:17<18:00, 98.21s/it]pay_schedule :: weekly\n",
      "pay_schedule :: biweekly\n",
      "pay_schedule :: friday\n",
      "pay_schedule :: saturday\n",
      " 29%|████████████▌                               | 4/14 [06:27<14:56, 89.66s/it]benefits :: health insurance\n",
      "benefits :: flexible schedule\n",
      "benefits :: 401k\n",
      "benefits :: paid vacation\n",
      "benefits :: sick leave\n",
      "benefits :: vision insurance\n",
      " 36%|███████████████▋                            | 5/14 [08:02<13:42, 91.37s/it]compensation :: base pay\n",
      "compensation :: stock options\n",
      "compensation :: benefits\n",
      "compensation :: overtime pay\n",
      "compensation :: bonus\n",
      " 43%|██████████████████▊                         | 6/14 [09:24<11:49, 88.67s/it]payment_option :: checks\n",
      "payment_option :: direct deposit\n",
      "payment_option :: prepaid card\n",
      " 50%|██████████████████████                      | 7/14 [10:06<08:41, 74.55s/it]background_screening :: drug test\n",
      "background_screening :: criminal background check\n",
      "background_screening :: employment verification\n",
      " 57%|█████████████████████████▏                  | 8/14 [10:44<06:20, 63.48s/it]person :: felons\n",
      "person :: criminals\n",
      "person :: disabled\n",
      "person :: drug addicts\n",
      "person :: high schoolers\n",
      "person :: misdemeanor\n",
      "['mis', '##de', '##me', '##anor'] too many word pieces (max 3)\n",
      "person :: pregnant\n",
      "person :: students\n",
      "person :: seniors\n",
      " 64%|████████████████████████████▎               | 9/14 [12:34<06:27, 77.49s/it]hire_prerequisite :: hiring age\n",
      "hire_prerequisite :: bachelors degree\n",
      "hire_prerequisite :: prior experience\n",
      "hire_prerequisite :: working permit\n",
      "hire_prerequisite :: heavy lifting\n",
      " 71%|██████████████████████████████▋            | 10/14 [13:44<05:01, 75.42s/it]shifts :: night shift\n",
      "shifts :: dinner shift\n",
      "shifts :: early morning shift\n",
      "shifts :: 8 hour shift\n",
      " 79%|█████████████████████████████████▊         | 11/14 [14:28<03:17, 65.96s/it]schedule :: christmas eve\n",
      "schedule :: early morning\n",
      "schedule :: hoilday\n",
      "schedule :: 7 days\n",
      "schedule :: saturday\n",
      "schedule :: sunday\n",
      "schedule :: weekend\n",
      " 86%|████████████████████████████████████▊      | 12/14 [16:11<02:33, 76.86s/it]employee_type :: full time\n",
      "employee_type :: part time\n",
      "employee_type :: seasonal\n",
      " 93%|███████████████████████████████████████▉   | 13/14 [17:01<01:08, 68.90s/it]onboarding_steps :: orientation\n",
      "onboarding_steps :: introduction\n",
      "onboarding_steps :: workstation\n",
      "onboarding_steps :: training\n",
      "onboarding_steps :: team lunch\n",
      "\"team lunch\" only have 1 context\n",
      "100%|███████████████████████████████████████████| 14/14 [17:41<00:00, 75.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use scripts\n",
    "!python compute_EE_corr.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/concept_corr_100.csv \\\n",
    "-ng 3 \\\n",
    "-ct 50 \\\n",
    "-top_k 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5220cc3e4090474b913a67258c0d98e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_entity = 'health insurance'\n",
    "_results = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_results['sel_entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insurance',\n",
       " 'health insurance',\n",
       " 'life insurance',\n",
       " 'property insurance',\n",
       " 'disability insurance',\n",
       " 'health care insurance',\n",
       " 'personal life',\n",
       " 'car insurance',\n",
       " 'offer health insurance',\n",
       " 'vision insurance',\n",
       " 'medical insurance',\n",
       " 'dental insurance',\n",
       " 'social life',\n",
       " 'healthcare',\n",
       " 'vehicle insurance',\n",
       " 'health care',\n",
       " 'social services',\n",
       " 'financial services',\n",
       " 'personal property',\n",
       " 'insurance company']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_results['sel_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42782ed502f8477b8db39b8079ec0903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_entity = 'paid vacation'\n",
    "_results = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " ['paid vacation',\n",
       "  'free food',\n",
       "  'extra hours',\n",
       "  'personal life',\n",
       "  'additional training',\n",
       "  'pay rent',\n",
       "  'extra cash',\n",
       "  'employment',\n",
       "  'extra money',\n",
       "  'regular employee',\n",
       "  'actual training',\n",
       "  'free market',\n",
       "  'home office',\n",
       "  'paid weekly',\n",
       "  'lunch break',\n",
       "  'employment contract',\n",
       "  'paid vacations',\n",
       "  'starting pay',\n",
       "  'training class',\n",
       "  'cash office'])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_results['sel_entities']), _results['sel_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paid vacation', 0.0044874584203954135),\n",
       " ('free food', 0.0030260901631086125),\n",
       " ('employment', 0.0026738146242238693),\n",
       " ('additional training', 0.002321403750532552),\n",
       " ('pay rent', 0.0016830003481619713),\n",
       " ('extra money', 0.0012204012291167322),\n",
       " ('extra hours', 0.0012082061174470255),\n",
       " ('paid vacations', 0.00120581120557009),\n",
       " ('personal life', 0.001053836581509607),\n",
       " ('extra cash', 0.0009903957854880568),\n",
       " ('free market', 0.0007903035967739137),\n",
       " ('employment contract', 0.0007457378170482977),\n",
       " ('regular employee', 0.0007120051084749063),\n",
       " ('actual training', 0.0006806927853699615),\n",
       " ('home office', 0.0006772145559134888),\n",
       " ('paid weekly', 0.0006510896439229592),\n",
       " ('lunch break', 0.0006262294878335945),\n",
       " ('starting pay', 0.0005959591850205348),\n",
       " ('training class', 0.0005751933163302262),\n",
       " ('cash office', 0.0005385432788353982)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_results['ints_mean_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paid vacation', 0.0),\n",
       " ('paid weekly', 0.3553680094673442),\n",
       " ('regular employee', 0.5651236328627899),\n",
       " ('starting pay', 0.6403464447016876),\n",
       " ('home office', 0.702709761379911),\n",
       " ('extra hours', 0.7882322979791239),\n",
       " ('cash office', 0.8216374067668454),\n",
       " ('additional training', 0.8231515801756707),\n",
       " ('free food', 0.8235410993620799),\n",
       " ('extra cash', 0.8406818348940776),\n",
       " ('lunch break', 0.8554870473017729),\n",
       " ('extra money', 0.8671142026312799),\n",
       " ('actual training', 0.8861361628894645),\n",
       " ('free market', 0.8934745945926472),\n",
       " ('personal life', 0.905080634158609),\n",
       " ('pay rent', 0.9191154476332102),\n",
       " ('training class', 0.9618010548607787),\n",
       " ('employment', 1.0064966364964134),\n",
       " ('employment contract', 1.0666759660272174),\n",
       " ('paid vacations', 1.07702367185203)]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_results['ints_kl_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paid vacation', 1.0),\n",
       " ('paid weekly', 0.6898791401226259),\n",
       " ('personal life', 0.6470476793642793),\n",
       " ('home office', 0.6137368598658344),\n",
       " ('employment', 0.5939260343586834),\n",
       " ('regular employee', 0.5934659341843702),\n",
       " ('free food', 0.5814593375358278),\n",
       " ('actual training', 0.5171393046252428),\n",
       " ('extra hours', 0.48931553441132725),\n",
       " ('cash office', 0.4649905535739707),\n",
       " ('training class', 0.45922641771917155),\n",
       " ('additional training', 0.453205530878079),\n",
       " ('starting pay', 0.4452037644119071),\n",
       " ('employment contract', 0.439553353761904),\n",
       " ('pay rent', 0.4366836227238857),\n",
       " ('lunch break', 0.43380180618257874),\n",
       " ('extra cash', 0.4258937516890552),\n",
       " ('extra money', 0.4070871841193142),\n",
       " ('paid vacations', 0.4019298655642553),\n",
       " ('free market', 0.40088368759801624)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_results['ints_pearson_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Both medical and dental insurance is provided as well as [MASK]',\n",
       "  6.578818802360679e-06,\n",
       "  0.00015682175491799882,\n",
       "  0.0018069056141044838),\n",
       " ('No the [MASK] tome will be put on your final pay check',\n",
       "  9.477934070825445e-05,\n",
       "  0.00179112735515401,\n",
       "  0.01783658171282455),\n",
       " (\"A new policy came out apparently saying that you do n't get a week of [MASK] in the first year , if you start after June 1st .\",\n",
       "  0.4888658700418125,\n",
       "  1.0,\n",
       "  0.08162912113546698),\n",
       " ('It is very true that dollar tree do nt pay out your owed [MASK] when you are no longer working for them .',\n",
       "  0.0022030048390930365,\n",
       "  0.0038430425562789427,\n",
       "  0.6893102387382053),\n",
       " ('But they offer no [MASK] and no sick leave .',\n",
       "  0.026742685344147428,\n",
       "  0.05176876375876567,\n",
       "  0.25499081609946683),\n",
       " ('They give [MASK] and sick time , health and dental insurance , 401k , life insurance',\n",
       "  0.9423141194865929,\n",
       "  0.027970293703116284,\n",
       "  0.8023113287226477),\n",
       " ('only assistant managers and general managers received [MASK] pay and sick pay',\n",
       "  0.23182283459346942,\n",
       "  0.07829888924495584,\n",
       "  0.2731482003476367),\n",
       " ('For full time : [MASK] , Sick time , PTO .',\n",
       "  0.24500194640098488,\n",
       "  0.7806978269661807,\n",
       "  0.25867774481661543),\n",
       " ('Once being hired a year [MASK]', 1.4996146523943373e-06, 0.0, 0.0),\n",
       " ('Chase has disability benefits , along with [MASK] ,',\n",
       "  0.0037400833352556565,\n",
       "  0.04770937225247506,\n",
       "  0.10147697923671468),\n",
       " ('health medical , Dental , etc . ; Training ; 401 K , [MASK] .',\n",
       "  0.0030263398273425797,\n",
       "  0.017775233716358415,\n",
       "  0.8941691680646828),\n",
       " ('No [MASK] , no health insurance , nothing !',\n",
       "  0.002597835448280048,\n",
       "  0.03854780193934496,\n",
       "  0.09310450978417306),\n",
       " ('Such as , health care and [MASK] .',\n",
       "  0.0002824426112442476,\n",
       "  0.010915291304438643,\n",
       "  0.019053301564483566),\n",
       " ('I never took any vacations day , I m sure it was nt a [MASK]',\n",
       "  1.976805280428444e-05,\n",
       "  0.0001259792190053521,\n",
       "  0.000134409594121865),\n",
       " ('No [MASK] after a year .',\n",
       "  0.003960501793724179,\n",
       "  0.06561470134708737,\n",
       "  0.08128028100733416),\n",
       " ('Each store is independently owned , so you may have a [MASK] system at your store .',\n",
       "  0.0032324147746924593,\n",
       "  0.014717367664602299,\n",
       "  0.10989044586843134),\n",
       " ('I had to work for a whole year or twelve calendar months before getting a [MASK] time .',\n",
       "  0.30591641551090204,\n",
       "  0.152602106761983,\n",
       "  0.07817021447081042),\n",
       " (\"publix offers [MASK] and sick day but I have n't work long enough to use the benefit .\",\n",
       "  0.23402681471194037,\n",
       "  0.07906629652148292,\n",
       "  0.050667007914498345),\n",
       " ('You receive about a $ 1 . 00 raise , but also you receive [MASK] , sick leave , and guaranteed 2 days off .',\n",
       "  0.3446607765500741,\n",
       "  0.13353111458553363,\n",
       "  0.3233051276691392),\n",
       " ('Vision , Dental , [MASK] , 401 K',\n",
       "  0.0005212524718306747,\n",
       "  0.007993453839044417,\n",
       "  0.017517814788640586),\n",
       " ('After one year and depending on the number of hours you work will depend on how many [MASK] hours / days you will receive .',\n",
       "  0.3262417605927743,\n",
       "  0.1185306531558913,\n",
       "  0.26145063044661676),\n",
       " ('Paid Vacation accumulated over the weeks , non [MASK] was also available',\n",
       "  0.14561309892795496,\n",
       "  0.014946605749923899,\n",
       "  0.20467539264024986),\n",
       " (\"Part time does n't get any [MASK] .\",\n",
       "  0.004818101540371127,\n",
       "  0.014704183796864093,\n",
       "  0.05149127556073687),\n",
       " (\"I did n't qualify for [MASK]\",\n",
       "  0.0,\n",
       "  0.00013833383264332213,\n",
       "  2.200855882550398e-05),\n",
       " ('401k , [MASK] , sick time , medical , dental , vision , bonuses and other incentives',\n",
       "  0.06065868847182519,\n",
       "  0.21872545029662457,\n",
       "  1.0),\n",
       " ('Eligible workers gain access to healthcare coverage , 401 ( k ) retirement plans , sick leave , personal days , and [MASK] , flexible spending accounts , and life insurance options',\n",
       "  0.1725192364944353,\n",
       "  0.007755238396722399,\n",
       "  0.06916860209127944),\n",
       " ('None we do nt recieve [MASK] .',\n",
       "  0.00011854472739062176,\n",
       "  0.0005104552857867912,\n",
       "  0.0010478279669635128),\n",
       " ('Managers receive [MASK] and one free meal a day .',\n",
       "  0.11762298466492851,\n",
       "  0.13096663181722554,\n",
       "  0.39809365947980163),\n",
       " ('401k plan medical and dental [MASK] raise after 90 days',\n",
       "  0.0019179289900465575,\n",
       "  0.041361645716974614,\n",
       "  0.17611902760501727),\n",
       " ('Yes for full time there is a week [MASK]',\n",
       "  6.786200812762701e-05,\n",
       "  0.0003338251452162233,\n",
       "  0.00044098957539795696),\n",
       " ('crew members do not receive [MASK]',\n",
       "  7.044122238550834e-06,\n",
       "  0.0026251276287963398,\n",
       "  0.0008307958414410135),\n",
       " ('You have to work 40 hours to get 1 hour of [MASK] time',\n",
       "  0.16521148326526203,\n",
       "  0.6045480850184173,\n",
       "  0.34156337793211217),\n",
       " ('All the managers and the asst managers got a [MASK]',\n",
       "  1.2137215756066526e-05,\n",
       "  4.405567898891748e-05,\n",
       "  0.000350441742950686),\n",
       " ('No there is not a [MASK]',\n",
       "  4.056053445523595e-06,\n",
       "  2.1407120805241987e-05,\n",
       "  8.023251704585847e-05),\n",
       " (\"U do n't get any [MASK] time are sick time at all\",\n",
       "  0.019711473143794515,\n",
       "  0.006265320269293292,\n",
       "  0.05247547496634478),\n",
       " ('Only managers are full time which means no [MASK]',\n",
       "  3.752162015695963e-05,\n",
       "  0.0035209274956039724,\n",
       "  0.0007831260955182229),\n",
       " ('Unless you are a full time career employee , you do not get any [MASK] time',\n",
       "  1.0,\n",
       "  0.3411526648071449,\n",
       "  0.7082231131298945),\n",
       " (\"If you just went past your 90 day mark then i do n't see why you would n't be able to , but keep in mind , you do not get a [MASK] , and most places will most likely let you go because they ca n't leave a vacant spot for almost two months .\",\n",
       "  0.11149749877991277,\n",
       "  0.017488687437352903,\n",
       "  0.03329519275389829),\n",
       " ('On your 5 year anniversary you will get 500 dollars or a [MASK] .',\n",
       "  0.018360237747319093,\n",
       "  0.0246834791755306,\n",
       "  0.16996853648783594),\n",
       " ('Yes bonuses an [MASK]',\n",
       "  4.2854114280321426e-05,\n",
       "  0.0004991132662695892,\n",
       "  0.0010505137273542167),\n",
       " ('80 hrs of [MASK] per year .',\n",
       "  0.0005614906462792095,\n",
       "  0.0022177594685687013,\n",
       "  0.000172809475151608),\n",
       " ('You do need to be a shift manager for at least a year before you get your [MASK] ( at least in my experience with a franchise location )',\n",
       "  0.012128350336706043,\n",
       "  0.04237491910517959,\n",
       "  0.05330261507094856),\n",
       " ('Store managers   15 + an hour with guaranteed overtime and a week of [MASK] .',\n",
       "  0.6706696047262527,\n",
       "  0.39104137513535925,\n",
       "  0.1529266104320991),\n",
       " ('6 [MASK] days .',\n",
       "  0.0009005486490436924,\n",
       "  0.002073908147796622,\n",
       "  0.005603226966475566),\n",
       " ('menards does not offer maternity leave only [MASK] .',\n",
       "  0.0080900575648695,\n",
       "  0.004675857911426127,\n",
       "  0.012895954396048733),\n",
       " ('How can you get a [MASK] on under 40 hours ? ? ? ?',\n",
       "  0.002360870884724027,\n",
       "  0.07419871925889387,\n",
       "  0.05708052606396038),\n",
       " ('None I barely had hours to get a [MASK]',\n",
       "  3.6816430912121303e-06,\n",
       "  9.8261197820452e-06,\n",
       "  2.154213247477965e-05),\n",
       " ('There is no [MASK] , however they are lenient about your schedule',\n",
       "  0.0018703822220601277,\n",
       "  0.355697917601864,\n",
       "  0.09015526800849852),\n",
       " (\"During my time working there I did n't hear or know about [MASK] .\",\n",
       "  0.0006690955461960481,\n",
       "  0.02424166740629815,\n",
       "  0.022162387860887593),\n",
       " (\"If you do n't have enough hours for [MASK] you can still go on vacation without payment .\",\n",
       "  0.022655908428214726,\n",
       "  0.13233636096964954,\n",
       "  0.02674802956927661)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity2probs = _results['entity2probs']\n",
    "_ser1 = entity2probs['paid vacation']\n",
    "_ser2 = entity2probs['training class']\n",
    "_ser3 = entity2probs['cash office']\n",
    "\n",
    "_ser1 = (_ser1 - min(_ser1)) / (max(_ser1) - min(_ser1))\n",
    "_ser2 = (_ser2 - min(_ser2)) / (max(_ser2) - min(_ser2))\n",
    "_ser3 = (_ser3 - min(_ser3)) / (max(_ser3) - min(_ser3))\n",
    "\n",
    "list(zip(dedup_context['paid vacation'], _ser1, _ser2, _ser3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_entity = 'flexible schedule'\n",
    "_results = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_results['mean_set'] & _results['kl_set'] & _results['pearson_set']), \\\n",
    "_results['mean_set'] & _results['kl_set'] & _results['pearson_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results['ints_mean_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results['ints_pearson_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2probs = _results['entity2probs']\n",
    "_ser1 = entity2probs['flexible schedule']\n",
    "_ser2 = entity2probs['model']\n",
    "_ser3 = entity2probs['low level']\n",
    "\n",
    "_ser1 = (_ser1 - min(_ser1)) / (max(_ser1) - min(_ser1))\n",
    "_ser2 = (_ser2 - min(_ser2)) / (max(_ser2) - min(_ser2))\n",
    "_ser3 = (_ser3 - min(_ser3)) / (max(_ser3) - min(_ser3))\n",
    "\n",
    "list(zip(dedup_context['flexible schedule'], _ser1, _ser2, _ser3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probe.fill_multi_mask(\"[CLS] They have a very [MASK] [MASK] for most departments and if your schedule does n't fit , you 'll more than likely just be moved . [SEP]\", topk=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_entity = 'black jeans'\n",
    "mean_set, kl_set, pearson_set = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(mean_set & kl_set & pearson_set), mean_set & kl_set & pearson_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_entity = 'walmart'\n",
    "mean_set, kl_set, pearson_set = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_set & kl_set & pearson_set), mean_set & kl_set & pearson_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probe_gpt2 = LMProbe_GPT2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_expansion_multiways_GPT2(entity, \n",
    "                                    contexts=None, \n",
    "                                    entities=entities, \n",
    "                                    lm_probe=lm_probe_gpt2, \n",
    "                                    top_k=20):\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe_GPT2()\n",
    "    if contexts is None:\n",
    "        contexts = dedup_context[entity]\n",
    "    \n",
    "    # test: speed up x100\n",
    "    entities = entities[::100]\n",
    "    \n",
    "    entity2probs = defaultdict(list)\n",
    "\n",
    "    for _context in tqdm(contexts[:50]):\n",
    "        _cand_scores = lm_probe.score_candidates(_context, entities)\n",
    "\n",
    "        for _d in _cand_scores:\n",
    "            _c = _d['cand']\n",
    "            _s = _d['score']\n",
    "            entity2probs[_c].append(_s)\n",
    "    \n",
    "#     print('entity2probs:', len(entity2probs), len(entity2probs[entity]))\n",
    "    for _e, _ss in entity2probs.items():\n",
    "        assert len(_ss) == len(entity2probs[entity]), \\\n",
    "            f'entity: {_e} | {lm_probe.tokenizer.tokenize(_e)}; len(_ss): {len(_ss)}'\n",
    "    \n",
    "    _target_ss = entity2probs[entity]\n",
    "    _target_ss = _target_ss / np.sum(_target_ss)\n",
    "    \n",
    "    mean_l = [(_e, np.mean(_ss)) for _e, _ss in entity2probs.items()]\n",
    "    mean_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "    kl_l = [(_e, entropy(_target_ss, _ss)) for _e, _ss in entity2probs.items()]\n",
    "    kl_l.sort(key=lambda p : p[-1], reverse=False)\n",
    "    pearson_l = [(_e, pearsonr(_target_ss, _ss)[0]) for _e, _ss in entity2probs.items()]\n",
    "    pearson_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    entity2ranks = defaultdict(list)\n",
    "    for i, (_e, _s) in enumerate(mean_l):\n",
    "        entity2ranks[_e].append(i)\n",
    "    for i, (_e, _s) in enumerate(kl_l):\n",
    "        entity2ranks[_e].append(i)\n",
    "    for i, (_e, _s) in enumerate(pearson_l):\n",
    "        entity2ranks[_e].append(i)\n",
    "    # To simile top-k set intersection, keep the highest rank of _e among each criteria\n",
    "    entity_overall_ranks = [(_e, max(_ranks)) for _e, _ranks in entity2ranks.items()]\n",
    "    entity_overall_ranks.sort(key=lambda p : p[-1])\n",
    "    # Now, the top-k is for the final selection, not for each criteria\n",
    "    sel_entities = [_e for _e, _ in entity_overall_ranks[:top_k]]\n",
    "    \n",
    "#     mean_set = set([_e for _e, _s in mean_l[:top_k]])\n",
    "#     kl_set = set([_e for _e, _s in kl_l[:top_k]])\n",
    "#     pearson_set = set([_e for _e, _s in pearson_l[:top_k]])\n",
    "    \n",
    "#     sel_entities = mean_set & kl_set & pearson_set\n",
    "    ints_mean_l = [p for p in mean_l if p[0] in sel_entities]\n",
    "    ints_kl_l = [p for p in kl_l if p[0] in sel_entities]\n",
    "    ints_pearson_l = [p for p in pearson_l if p[0] in sel_entities]\n",
    "    \n",
    "    return {\n",
    "        \"entity2probs\": entity2probs,\n",
    "        \"mean_l\": mean_l,\n",
    "        \"kl_l\": kl_l,\n",
    "        \"pearson_l\": pearson_l,\n",
    "#         \"mean_set\": mean_set,\n",
    "#         \"kl_set\": kl_set,\n",
    "#         \"pearson_set\": pearson_set,\n",
    "        \"sel_entities\": sel_entities,\n",
    "        \"ints_mean_l\": ints_mean_l,\n",
    "        \"ints_kl_l\": ints_kl_l,\n",
    "        \"ints_pearson_l\": ints_pearson_l,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_entity = 'health insurance'\n",
    "_results = entity_expansion_multiways_GPT2(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT greedy-filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMProbe_PMI_greedy(object):\n",
    "    def __init__(self, model_name='bert-base-uncased', use_gpu=False):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertForMaskedLM.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.mask_token = self.tokenizer.mask_token\n",
    "\n",
    "    def fill_multi_mask(self, input_txt, topk=3):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def score_tail(self, input_txt, tail, head=None, head_len=None, head_first=True):\n",
    "        # input_txt: str, with [HEAD] for head and [TAIL] for tail \n",
    "        # tail: str, the tail entity \n",
    "        # head: str, the head entity \n",
    "        # head_len: int, the length of head entity\n",
    "        # Should only give head or head_len \n",
    "        # head_first: bool, whether the first [MASK] is the head \n",
    "        \n",
    "        assert (head is None) + (head_len is None) == 1, \\\n",
    "            f\"head = {head}, head_len = {head_len}\"\n",
    "        assert input_txt.count(\"[HEAD]\") == input_txt.count(\"[TAIL]\") == 1, \\\n",
    "            f\"Input string must have [HEAD] and [TAIL], got {input_txt}\"\n",
    "        \n",
    "        \n",
    "        tail_toks = self.tokenizer.tokenize(tail)\n",
    "        tail_len = len(tail_toks)\n",
    "        input_txt = input_txt.replace('[TAIL]', '[MASK]' + ' [MASK]' * (tail_len-1))\n",
    "        \n",
    "        if head is not None:\n",
    "            head_toks = self.tokenizer.tokenize(head)\n",
    "            head_len = len(head_toks)\n",
    "            print(head_toks, head_len)\n",
    "            input_txt = input_txt.replace('[HEAD]', head)\n",
    "        else:\n",
    "            input_txt = input_txt.replace('[HEAD]', '[MASK]' + ' [MASK]' * (head_len-1))\n",
    "        \n",
    "        tokenized_txt = self.tokenizer.tokenize(input_txt)\n",
    "        tokenized_txt = ['[CLS]'] + tokenized_txt + ['[SEP]']\n",
    "\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        mask_indices = [i for i, x in enumerate(tokenized_txt) if x == \"[MASK]\"]\n",
    "        if head is not None:\n",
    "            # head is not [MASK] \n",
    "            tail_indices = mask_indices\n",
    "        elif head_first:\n",
    "            # head is [MASK] and first \n",
    "            tail_indices = mask_indices[head_len:]\n",
    "        else:\n",
    "            # head is [MASK] and second \n",
    "            tail_indices = mask_indices[:tail_len]\n",
    "        print(tokenized_txt, tail_indices)\n",
    "        \n",
    "        segment_idx = tokens_tensor * 0\n",
    "        tokens_tensor = tokens_tensor.to(self.device)\n",
    "        segments_tensors = segment_idx.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.softmax(predictions, dim=-1)[0]\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "        \n",
    "        _scores = []\n",
    "        tail_tok_ids = self.tokenizer.convert_tokens_to_ids(tail_toks)\n",
    "        for i, token_id in zip(tail_indices, tail_tok_ids):\n",
    "            _scores.append(probs[i, token_id].item())\n",
    "        score = gmean(_scores)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe_greedy = LMProbe_PMI_greedy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microsoft'] 1\n",
      "['[CLS]', 'microsoft', 'hires', '[MASK]', '[MASK]', '[SEP]'] [3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.249095345026383e-07"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sent = '[HEAD] hires [TAIL]'\n",
    "\n",
    "lm_probe_greedy.score_tail(_sent, tail='software engineer', head='microsoft', head_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '[MASK]', 'hires', '[MASK]', '[MASK]', '[SEP]'] [3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0638130627670454e-07"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_greedy.score_tail(_sent, tail='software engineer', head_len=1, head_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Extraction Baselines\n",
    "Currently only for single relation. TODO: include all relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null baseline - Cartesian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_Cartesian_RE(seed_concepts_path,\n",
    "                      seed_relations_path,\n",
    "                      concept_knn_path,\n",
    "                      relation,\n",
    "                      topk=None,\n",
    "                      dest=None,\n",
    "                      **kwargs):\n",
    "    \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    seed_relations_df = pd.read_csv(seed_relations_path)\n",
    "    relation_row = seed_relations_df[seed_relations_df['alignedRelationName'] == relation].iloc[0]\n",
    "    concept_knn_results = pd.read_csv(concept_knn_path)\n",
    "    \n",
    "    head_type = relation_row['domain']\n",
    "    tail_type = relation_row['range']\n",
    "    print(head_type, '\\t', tail_type)\n",
    "    seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == head_type]['seedInstances'].item()\n",
    "#     seed_heads = eval(list(seed_heads)[0])\n",
    "    seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == tail_type]['seedInstances'].item()\n",
    "#     seed_tails = eval(list(seed_tails)[0])\n",
    "    print('seed_heads:', seed_heads)\n",
    "    print('seed_tails:', seed_tails)\n",
    "\n",
    "    # Candidate heads / tails from concept knn \n",
    "    cand_heads_df = concept_knn_results[concept_knn_results['concept'] == head_type]\n",
    "    cand_tails_df = concept_knn_results[concept_knn_results['concept'] == tail_type]\n",
    "    cand_heads = [(_h, 1.0) for _h in seed_heads] + \\\n",
    "        list(zip(cand_heads_df['neighbor'].tolist(), cand_heads_df['sim'].tolist()))\n",
    "    cand_tails = [(_t, 1.0) for _t in seed_tails] + \\\n",
    "        list(zip(cand_tails_df['neighbor'].tolist(), cand_tails_df['sim'].tolist()))\n",
    "\n",
    "    if topk is not None:\n",
    "        cand_heads = cand_heads[:topk]\n",
    "        cand_tails = cand_tails[:topk]\n",
    "        \n",
    "    print('cand_heads:', list(zip(*cand_heads))[0])\n",
    "    print('cand_tails:', list(zip(*cand_tails))[0])\n",
    "    \n",
    "    out_rels = []\n",
    "    for _h, _hs in cand_heads:\n",
    "        for _t, _ts in cand_tails:\n",
    "            out_rels.append({\n",
    "                'head': _h, 'relation': relation, 'tail': _t,\n",
    "                'overall_score': _hs * _ts\n",
    "            })\n",
    "    out_rels.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "    \n",
    "    out_rels_df = pd.DataFrame(out_rels)\n",
    "    if dest is not None:\n",
    "        out_rels_df.to_csv(dest, index=False)\n",
    "    return out_rels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "# knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/knn_{cluster_size}.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "\n",
    "relation = 'has_benefits'\n",
    "cartesian_re_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_cartesian-{relation}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company \t benefits\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "cand_heads: ('walmart', 'amazon', 'subway', 'microsoft', 'target', 'wal mart', 'costco', 'publix', 'walgreens', 'kroger', 'home depot', \"sam 's club\", 'dollar general', 'family dollar', 'jcpenney', 'pizza hut', 'starbucks', 'apple', 'kfc', 'dollar tree', 'panera bread', 'safeway', 'hobby lobby', 'cracker barrel', 'spectrum', 'menards', 'chick fil a', 'old navy', 'mcdonalds', 'taco bell', 'marshalls', 'burlington', 'olive garden', 'cvs', 'pepsico', 'sitel', 'burger king', 'petsmart', 'jcp', 'pepsi', \"macy 's\", 'geico', 'whole foods', 'ihop', 'fedex', 'best buy', 'frito lay', 'dunkin donuts', 'chipotle', 'tj maxx', 'verizon', 't mobile', 'g4s', 'usps', 'jc penney', 'at&t', 'planet fitness', 'little caesars', 'company', 'mcdonald')\n",
      "cand_tails: ('health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'insurance', 'healthcare', 'medical insurance', 'health care', 'health', 'medical', 'paid vacations', 'sick days', 'life insurance', 'dental insurance', 'pension', '401k plan', 'holiday pay', 'maternity leave', 'tuition reimbursement', 'discount card', 'vacation days', 'profit sharing', 'employee discounts', 'employee discount', 'retirement plan', 'great benefits', 'health care insurance', 'disability', 'benefits package', 'tuition assistance', 'employee benefits', 'part timers', 'higher pay', 'medicare', 'flexible schedules', 'mandatory', 'pay increase', 'heath', 'education', 'union', 'weekly pay', 'free', 'cobra', 'job security', 'work life balance', 'previous experience', 'cards', 'family', 'child care', 'tax', 'medicaid', 'competitive pay', 'leaves', 'free food', '90 days', 'cigna', 'fair', 'p / t')\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "full_Cartesian_RE(seed_concepts_path=seed_aligned_concepts_path,\n",
    "                  seed_relations_path=seed_aligned_relations_path,\n",
    "                  concept_knn_path=concept_knn_path,\n",
    "                  relation=relation,\n",
    "                  topk=60,\n",
    "                  dest=cartesian_re_path)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company \t benefits\r\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\r\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\r\n",
      "cand_heads: ('walmart', 'amazon', 'subway', 'microsoft', 'target', 'wal mart', 'costco', 'publix', 'walgreens', 'kroger', 'home depot', \"sam 's club\", 'dollar general', 'family dollar', 'jcpenney', 'pizza hut', 'starbucks', 'apple', 'kfc', 'dollar tree', 'panera bread', 'safeway', 'hobby lobby', 'cracker barrel', 'spectrum', 'menards', 'chick fil a', 'old navy', 'mcdonalds', 'taco bell', 'marshalls', 'burlington', 'olive garden', 'cvs', 'pepsico', 'sitel', 'burger king', 'petsmart', 'jcp', 'pepsi', \"macy 's\", 'geico', 'whole foods', 'ihop', 'fedex', 'best buy', 'frito lay', 'dunkin donuts', 'chipotle', 'tj maxx', 'verizon', 't mobile', 'g4s', 'usps', 'jc penney', 'at&t', 'planet fitness', 'little caesars', 'company', 'mcdonald')\r\n",
      "cand_tails: ('health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'insurance', 'healthcare', 'medical insurance', 'health care', 'health', 'medical', 'paid vacations', 'sick days', 'life insurance', 'dental insurance', 'pension', '401k plan', 'holiday pay', 'maternity leave', 'tuition reimbursement', 'discount card', 'vacation days', 'profit sharing', 'employee discounts', 'employee discount', 'retirement plan', 'great benefits', 'health care insurance', 'disability', 'benefits package', 'tuition assistance', 'employee benefits', 'part timers', 'higher pay', 'medicare', 'flexible schedules', 'mandatory', 'pay increase', 'heath', 'education', 'union', 'weekly pay', 'free', 'cobra', 'job security', 'work life balance', 'previous experience', 'cards', 'family', 'child care', 'tax', 'medicaid', 'competitive pay', 'leaves', 'free food', '90 days', 'cigna', 'fair', 'p / t')\r\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_cartesian.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=Ct.csv \\\n",
    "-r has_benefits \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_1000.csv \\\n",
    "-topk 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction - GPT2 scores (analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation \n",
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt2_score(sentence):\n",
    "    tokenized_input = gpt2_tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        model_outputs = gpt2_model(**tokenized_input, labels=tokenized_input[\"input_ids\"])\n",
    "    score = model_outputs.loss.item()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NLL) X offers Y        \tbenefits\t401k plan\tpaid vacation\tfamily  \n",
      "company                 \t8.153534\t6.109497\t6.707372\t8.615242\n",
      "walmart                 \t9.049321\t6.962499\t8.100282\t8.999038\n",
      "google                  \t8.491952\t6.307848\t7.430027\t9.093484\n",
      "california              \t6.713108\t5.849362\t6.076878\t6.828558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_sent_template = '{0} offers {1}'\n",
    "_heads = ['company', 'walmart', 'google', 'california']\n",
    "_tails = ['benefits', '401k plan', 'paid vacation', 'family']\n",
    "\n",
    "_print_msg = f\"{'(NLL) ' + _sent_template.format('X', 'Y'):24s}\"\n",
    "_print_msg += '\\t' + '\\t'.join([f\"{_t:8s}\" for _t in _tails]) + '\\n'\n",
    "for _h in _heads:\n",
    "    _print_msg += f\"{_h:24s}\"\n",
    "    for _t in _tails:\n",
    "        _sent = _sent_template.format(_h, _t)\n",
    "        _score = gpt2_score(_sent)\n",
    "#         print(f\"(NLL = {_score:.6f}) {_sent}\")\n",
    "        _print_msg += f\"\\t{_score:.6f}\"\n",
    "    _print_msg += \"\\n\"\n",
    "\n",
    "print(_print_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NLL) X allows Y        \tdress code\tjeans   \ttattoos \tdrugs   \n",
      "company                 \t7.646885\t11.025874\t10.445228\t9.259410\n",
      "walmart                 \t8.517221\t10.956227\t10.929914\t10.295705\n",
      "google                  \t8.461215\t12.038675\t12.965143\t10.222376\n",
      "california              \t6.353935\t7.937030\t7.359611\t6.910169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_sent_template = '{0} allows {1}'\n",
    "_heads = ['company', 'walmart', 'google', 'california']\n",
    "_tails = ['dress code', 'jeans', 'tattoos', 'drugs']\n",
    "\n",
    "_print_msg = f\"{'(NLL) ' + _sent_template.format('X', 'Y'):24s}\"\n",
    "_print_msg += '\\t' + '\\t'.join([f\"{_t:8s}\" for _t in _tails]) + '\\n'\n",
    "for _h in _heads:\n",
    "    _print_msg += f\"{_h:24s}\"\n",
    "    for _t in _tails:\n",
    "        _sent = _sent_template.format(_h, _t)\n",
    "        _score = gpt2_score(_sent)\n",
    "#         print(f\"(NLL = {_score:.6f}) {_sent}\")\n",
    "        _print_msg += f\"\\t{_score:.6f}\"\n",
    "    _print_msg += \"\\n\"\n",
    "\n",
    "print(_print_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NLL) X pays Y          \tschedule\tweekly  \tevery friday\tminimum wage\n",
      "company                 \t11.049671\t9.899395\t7.250698\t6.185252\n",
      "walmart                 \t11.554404\t10.105996\t7.789978\t7.334626\n",
      "google                  \t11.968147\t10.422943\t7.292716\t7.170493\n",
      "california              \t8.314291\t7.803281\t6.406629\t5.754911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_sent_template = '{0} pays {1}'\n",
    "_heads = ['company', 'walmart', 'google', 'california']\n",
    "_tails = ['schedule', 'weekly', 'every friday', 'minimum wage']\n",
    "\n",
    "_print_msg = f\"{'(NLL) ' + _sent_template.format('X', 'Y'):24s}\"\n",
    "_print_msg += '\\t' + '\\t'.join([f\"{_t:8s}\" for _t in _tails]) + '\\n'\n",
    "for _h in _heads:\n",
    "    _print_msg += f\"{_h:24s}\"\n",
    "    for _t in _tails:\n",
    "        _sent = _sent_template.format(_h, _t)\n",
    "        _score = gpt2_score(_sent)\n",
    "#         print(f\"(NLL = {_score:.6f}) {_sent}\")\n",
    "        _print_msg += f\"\\t{_score:.6f}\"\n",
    "    _print_msg += \"\\n\"\n",
    "\n",
    "print(_print_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction - scores weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_direct_probing_candidates(templates,\n",
    "                                  lm_probe=None,\n",
    "                                  head_entity=None,\n",
    "                                  tail_entity=None,\n",
    "                                  context=None,\n",
    "                                  topk=10):\n",
    "    '''\n",
    "    Direct probing: let BERT propose possible entities  \n",
    "    :param templates: List[str]: each have 2 slots, {0} for head, {1} for tail \n",
    "    :return: Dict[str, float]: proposed entities and scores \n",
    "    '''\n",
    "    \n",
    "    # ensure given one and propose one \n",
    "    assert (head_entity is None) != (tail_entity is None), f'{head_entity} {tail_entity}'\n",
    "\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    \n",
    "    names_scores = {}\n",
    "    for template in templates:\n",
    "        if head_entity is not None:\n",
    "            # head -> tail \n",
    "            _unigram_template = template.format(head_entity, '[MASK]')\n",
    "            _bigram_template = template.format(head_entity, '[MASK] [MASK]')\n",
    "        else:\n",
    "            # tail -> head \n",
    "            _unigram_template = template.format('[MASK]', tail_entity)\n",
    "            _bigram_template = template.format('[MASK] [MASK]', tail_entity)\n",
    "        \n",
    "        for _template in [_unigram_template, _bigram_template]:\n",
    "            if context:\n",
    "                query = '[CLS] ' + _template + '[SEP]' + context + '[SEP]'\n",
    "            else:\n",
    "                query = '[CLS] ' + _template + '[SEP]'\n",
    "            preds = lm_probe.fill_multi_mask(query, topk=topk)\n",
    "            for pred in preds:\n",
    "                name = ' '.join([p['token_str'] for p in pred])\n",
    "                name = name.replace(' ##', '')\n",
    "                score = np.prod([p['prob'] for p in pred])\n",
    "                scores = names_scores.get(name, [])\n",
    "                scores.append(score)\n",
    "                names_scores[name] = scores\n",
    "                \n",
    "    names_avg_scores = {k: float(sum(v))/ len(v) for k,v in names_scores.items()}\n",
    "    names_avg_scores = {k: v for k, v in sorted(names_avg_scores.items(), reverse=True, key=lambda item: item[1])[:topk]}\n",
    "    return names_avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def direct_probing_RE_v4(seed_concepts_path,\n",
    "                         seed_relations_path,\n",
    "                         emb_path,\n",
    "                         concept_knn_path,\n",
    "                         templates_path,\n",
    "                         relation,\n",
    "                         lm_probe=None,\n",
    "                         embedding_dim=768,\n",
    "                         scores_agg_func=None,\n",
    "                         topk=10,\n",
    "                         dest=None,\n",
    "                         **kwargs):\n",
    "    '''\n",
    "    For each head / tail, rank candidate tails / heads by overall scores. \n",
    "    (v4: Not limited to base -> new; can be new -> new; however, only head->tail, no tail->head)\n",
    "    Current (default) overall score: 0.1 * ht_sim + 10 * concept_sim + 0.1 * log(lm_prob)\n",
    "    '''\n",
    "    \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    seed_relations_df = pd.read_csv(seed_relations_path)\n",
    "    relation_row = seed_relations_df[seed_relations_df['alignedRelationName'] == relation].iloc[0]\n",
    "    entity_embeddings = load_embeddings(emb_path, embedding_dim)\n",
    "    entity_emb_dict = dict(zip(entity_embeddings['entity'].tolist(),\n",
    "                               entity_embeddings['embedding'].tolist()))\n",
    "    concept_knn_results = pd.read_csv(concept_knn_path)\n",
    "    \n",
    "    with open(templates_path, 'r') as f:\n",
    "        all_templates = json.load(f)\n",
    "    templates = all_templates[relation]\n",
    "    templates = templates['positive'] + templates['negative']\n",
    "\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    if scores_agg_func is None:\n",
    "        scores_agg_func = lambda ht_sim, h_sim, t_sim, lm_prob : ht_sim + h_sim + t_sim + np.log10(lm_prob)\n",
    "    \n",
    "    head_type = relation_row['domain']\n",
    "    tail_type = relation_row['range']\n",
    "#     head_type = \"company\"\n",
    "#     tail_type = \"dress_code\"\n",
    "    print(head_type, '\\t', tail_type)\n",
    "    seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == head_type]['seedInstances'].item()\n",
    "#     seed_heads = eval(list(seed_heads)[0])\n",
    "    seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == tail_type]['seedInstances'].item()\n",
    "#     seed_tails = eval(list(seed_tails)[0])\n",
    "    print('seed_heads:', seed_heads)\n",
    "    print('seed_tails:', seed_tails)\n",
    "\n",
    "    # Candidate heads / tails from concept knn \n",
    "    cand_heads_df = concept_knn_results[concept_knn_results['concept'] == head_type]\n",
    "    cand_tails_df = concept_knn_results[concept_knn_results['concept'] == tail_type]\n",
    "    cand_heads_dict = dict(zip(cand_heads_df['neighbor'].tolist(), cand_heads_df['sim'].tolist()))\n",
    "    cand_tails_dict = dict(zip(cand_tails_df['neighbor'].tolist(), cand_tails_df['sim'].tolist()))\n",
    "    for h in seed_heads:\n",
    "        assert h not in cand_heads_dict\n",
    "        cand_heads_dict[h] = 1.0\n",
    "    for t in seed_tails:\n",
    "        assert t not in cand_tails_dict\n",
    "        cand_tails_dict[t] = 1.0\n",
    "        \n",
    "    \n",
    "    all_extraction_results = []\n",
    "    \n",
    "    for c_head in tqdm(cand_heads_dict.keys(), total=len(cand_heads_dict)):\n",
    "        c_head_tokenized = lm_probe.tokenizer.tokenize(c_head)\n",
    "        if len(c_head_tokenized) > 2:\n",
    "            continue\n",
    "\n",
    "        extraction_results = []\n",
    "\n",
    "        ## For each tail, extract concept sim, head sim, lm score, combine and report\n",
    "        \n",
    "        cand_bins = {1: [], 2: []} ## TODO: allow higher grams; switch to GPT-2 for fair probs \n",
    "        for c_tail in cand_tails_dict.keys():\n",
    "            if c_tail == c_head:\n",
    "                continue\n",
    "            c_tail_tokenized = lm_probe.tokenizer.tokenize(c_tail)\n",
    "            if len(c_tail_tokenized) in [1, 2]:\n",
    "                cand_bins[len(c_tail_tokenized)].append(c_tail_tokenized)\n",
    "        \n",
    "        cand_scores_per_template = []\n",
    "        for template in templates:\n",
    "            _unigram_template = '[CLS] ' + template.format(c_head, '[MASK]') + '[SEP]'\n",
    "            _bigram_template = '[CLS] ' + template.format(c_head, '[MASK] [MASK]') + '[SEP]'\n",
    "\n",
    "            _cand_scores_1 = lm_probe.score_candidates(_unigram_template, cand_bins[1])\n",
    "            _cand_scores_2 = lm_probe.score_candidates(_bigram_template, cand_bins[2])\n",
    "            _cand_scores = sorted(_cand_scores_1 + _cand_scores_2, key=lambda d : d[\"cand\"])\n",
    "            # List[Dict[\"cand\", \"score\"]]\n",
    "            cand_scores_per_template.append(_cand_scores)\n",
    "    \n",
    "        cand_scores = []  # List[Dict[\"cand\", \"score\"]], for each \"cand\" the average score \n",
    "        for _cand_score_lst in zip(*cand_scores_per_template):\n",
    "            # _cand_score_lst: List[Dict[\"cand\", \"score\"]], for the same \"cand\" and different template \n",
    "            _cand = _cand_score_lst[0][\"cand\"]\n",
    "            assert all(d[\"cand\"] == _cand for d in _cand_score_lst), _cand_score_lst\n",
    "            _score = np.mean([d[\"score\"] for d in _cand_score_lst])\n",
    "            cand_scores.append({\"cand\": _cand, \"score\": _score})\n",
    "#         cand_scores.sort(key = lambda d : d[\"score\"], reverse=True)\n",
    "\n",
    "        for d in cand_scores:\n",
    "            e_tail = ' '.join(d[\"cand\"]).replace(' ##', '')\n",
    "            if e_tail not in cand_tails_dict:\n",
    "                continue\n",
    "\n",
    "            lm_score = d[\"score\"]\n",
    "            try:\n",
    "                ht_sim_score = 1 - cosine(entity_emb_dict[c_head], entity_emb_dict[e_tail])\n",
    "            except KeyError:\n",
    "                print(f'** embedding of {c_head}: {(c_head in entity_emb_dict)}')\n",
    "                print(f'** embedding of {e_tail}: {(e_tail in entity_emb_dict)}')\n",
    "                ht_sim_score = float(\"nan\")\n",
    "            head_sim_score = cand_heads_dict[c_head]\n",
    "            tail_sim_score = cand_tails_dict[e_tail]\n",
    "            overall_score = scores_agg_func(ht_sim_score, head_sim_score, tail_sim_score, lm_score)\n",
    "\n",
    "            extraction_results.append({'head': c_head, 'relation': relation, 'tail': e_tail,\n",
    "                                       'ht_sim_score': ht_sim_score,\n",
    "                                       'head_sim_score': head_sim_score,\n",
    "                                       'tail_sim_score': tail_sim_score,\n",
    "                                       'lm_score': lm_score,\n",
    "                                       'overall_score': overall_score})\n",
    "        \n",
    "        # extraction_results.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "        all_extraction_results.extend(extraction_results[:topk])\n",
    "\n",
    "    all_extraction_results.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "    all_extraction_results = all_extraction_results[:topk]\n",
    "        \n",
    "    results_df = pd.DataFrame(all_extraction_results)\n",
    "    if dest is not None:\n",
    "        results_df.to_csv(dest, index=None)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company \t benefits\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9307f6c82c94efcae96615f9f922a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>ht_sim_score</th>\n",
       "      <th>head_sim_score</th>\n",
       "      <th>tail_sim_score</th>\n",
       "      <th>lm_score</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>business</td>\n",
       "      <td>0.993406</td>\n",
       "      <td>0.991990</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.415795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home depot</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>car insurance</td>\n",
       "      <td>0.959858</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.973259</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.331895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fulfillment center</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>business</td>\n",
       "      <td>0.983125</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.205897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corporate office</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>business</td>\n",
       "      <td>0.984971</td>\n",
       "      <td>0.988309</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.200351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>store level</td>\n",
       "      <td>has_benefits</td>\n",
       "      <td>cards</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.988855</td>\n",
       "      <td>0.975875</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.181516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 head      relation           tail  ht_sim_score  \\\n",
       "0             company  has_benefits       business      0.993406   \n",
       "1          home depot  has_benefits  car insurance      0.959858   \n",
       "2  fulfillment center  has_benefits       business      0.983125   \n",
       "3    corporate office  has_benefits       business      0.984971   \n",
       "4         store level  has_benefits          cards      0.977417   \n",
       "\n",
       "   head_sim_score  tail_sim_score  lm_score  overall_score  \n",
       "0        0.991990        0.972477  0.002870       0.415795  \n",
       "1        0.996124        0.973259  0.002527       0.331895  \n",
       "2        0.987292        0.972477  0.001832       0.205897  \n",
       "3        0.988309        0.972477  0.001797       0.200351  \n",
       "4        0.988855        0.975875  0.001735       0.181516  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "# seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "# knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/knn_{cluster_size}.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_100.csv')\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "\n",
    "templates_path = 'templates_manual.json'\n",
    "\n",
    "extraction_save_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "# extraction_save_path = None\n",
    "\n",
    "extraction_results = direct_probing_RE_v4(seed_concepts_path=seed_aligned_concepts_path,\n",
    "                                          seed_relations_path=seed_aligned_relations_path,\n",
    "                                          emb_path=bert_emb_path,\n",
    "                                          concept_knn_path=concept_knn_path,\n",
    "                                          templates_path=templates_path,\n",
    "                                          relation='has_benefits',\n",
    "                                          lm_probe=lm_probe,\n",
    "                                          topk=10,\n",
    "                                          save_path=extraction_save_path)\n",
    "\n",
    "extraction_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = extraction_results.copy()\n",
    "df[df['head'] == 'walmart'].head(50)\n",
    "# df['overall_score'] = df['ht_sim_score'] * 0.1 + df['concept_sim_score'] * 10 + np.log10(df['lm_score'])\n",
    "# df.sort_values(by='overall_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = extraction_results.copy()\n",
    "df[df['tail'] == 'hair color'].head(50)\n",
    "# df['overall_score'] = df['ht_sim_score'] * 0.1 + df['concept_sim_score'] * 10 + np.log10(df['lm_score'])\n",
    "# df.sort_values(by='overall_score', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "company \t benefits\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "seed_head: walmart\n",
      "seed_head: amazon\n",
      "seed_head: subway\n",
      "seed_head: microsoft\n",
      "seed_head: target\n",
      "seed_tail: health insurance\n",
      "seed_tail: flexible schedule\n",
      "seed_tail: 401k\n",
      "seed_tail: paid vacation\n",
      "seed_tail: sick leave\n",
      "seed_tail: vision insurance\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_avg_scores.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE.csv \\\n",
    "-r has_benefits \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_1000.csv \\\n",
    "-topk 300 \\\n",
    "-dim 768\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Evaluation \n",
    "\n",
    "def load_benchmark(benchmark_full_path,\n",
    "                   seed_concepts_path,\n",
    "                   seed_relations_path):\n",
    "    benchmark = pd.read_csv(benchmark_full_path)\n",
    "    concepts_df = load_seed_aligned_concepts(seed_concepts_path)\n",
    "    relations_df = load_seed_aligned_relations(seed_relations_path)\n",
    "    \n",
    "    concepts_dict = dict(zip(concepts_df['alignedCategoryName'].tolist(), concepts_df.to_dict('records')))\n",
    "    relations_dict = dict(zip(relations_df['alignedRelationName'].tolist(), relations_df.to_dict('records')))\n",
    "    \n",
    "    # Dict[str(_type), Set[str(_e)]]\n",
    "    all_concepts = defaultdict(set)\n",
    "    # Dict[str(_r), Set[Tuple(_h, _r, _t)]]\n",
    "    all_rel_tuples = defaultdict(set)\n",
    "    \n",
    "    for i, row in benchmark.iterrows():\n",
    "        if row['type'] != 'fact':\n",
    "            continue\n",
    "        \n",
    "        _r = row['relation_name']\n",
    "        _h_type = row['n_head_category']\n",
    "        _t_type = row['n_tail_category']\n",
    "        \n",
    "        if _r not in relations_dict:\n",
    "            continue\n",
    "        _relation_row = relations_dict[_r]\n",
    "        if _relation_row['domain'] != _h_type or _relation_row['range'] != _t_type:\n",
    "            continue\n",
    "        \n",
    "        row_n_head = str(row['n_head']).lower()\n",
    "        row_n_tail = str(row['n_tail']).lower()\n",
    "        \n",
    "        if row_n_head == 'company':\n",
    "            evidence_sents = eval(str(row['sentences']))\n",
    "            head_instances = eval(str(row['Evidence']))\n",
    "            assert len(evidence_sents) == len(head_instances), f'Line {i} length mismatch'\n",
    "\n",
    "            for inst in head_instances:\n",
    "                if len(inst) > 0:\n",
    "                    all_concepts[_h_type].add(inst.lower())\n",
    "                    all_concepts[_t_type].add(row_n_tail)\n",
    "                    all_rel_tuples[_r].add(\n",
    "                        (inst.lower(), _r, row_n_tail)\n",
    "                    )\n",
    "        else:\n",
    "            # treat n_head directly as instance \n",
    "            all_concepts[_h_type].add(row_n_head)\n",
    "            all_concepts[_t_type].add(row_n_tail)\n",
    "            all_rel_tuples[_r].add(\n",
    "                (row_n_head, _r, row_n_tail)\n",
    "            )\n",
    "        \n",
    "    return all_concepts, all_rel_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 14)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations_nodup.csv')\n",
    "\n",
    "benchmark_concepts, benchmark_relations = load_benchmark(benchmark_full_path=benchmark_path,\n",
    "                                              seed_concepts_path=seed_aligned_concepts_path,\n",
    "                                              seed_relations_path=seed_aligned_relations_path)\n",
    "\n",
    "len(benchmark_concepts), len(benchmark_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "\n",
    "rel_extraction = pd.read_csv(rel_extraction_path)\n",
    "rel_extraction_list = rel_extraction[['head', 'tail']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 3597, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_relations_set = set([tuple(d.values()) for d in benchmark_relations_list])\n",
    "rel_extraction_set = set([tuple(d.values()) for d in rel_extraction_list])\n",
    "\n",
    "intersection = benchmark_relations_set & rel_extraction_set\n",
    "\n",
    "len(benchmark_relations_set), len(rel_extraction_set), len(intersection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 107\r\n",
      "Predicted relations: 3600\r\n",
      "Intersection: 15\r\n",
      "P = 0.0042, R = 0.1402, F1 = 0.0081\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('jcpenney', 'has_dress_code', 'uniform policy')\r\n",
      "('olive garden', 'has_dress_code', 'facial hair')\r\n",
      "('walgreens', 'has_dress_code', 'hair color')\r\n",
      "('marshalls', 'has_dress_code', 'color hair')\r\n",
      "('at&t', 'has_dress_code', 'uniform')\r\n",
      "('costco', 'has_dress_code', 'hair color')\r\n",
      "('walmart', 'has_dress_code', 'uniform')\r\n",
      "('taco bell', 'has_dress_code', 'nose rings')\r\n",
      "('walmart', 'has_dress_code', 'face tattoos')\r\n",
      "('dollar general', 'has_dress_code', 'strict dress code')\r\n",
      "('best buy', 'has_dress_code', 'uniform')\r\n",
      "('family dollar', 'has_dress_code', 'facial hair')\r\n",
      "('subway', 'has_dress_code', 'piercings')\r\n",
      "('dollar tree', 'has_dress_code', 'uniform')\r\n",
      "('dollar tree', 'has_dress_code', 'professional')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_cartesian-has_dress_code.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 107\r\n",
      "Predicted relations: 1018\r\n",
      "Intersection: 13\r\n",
      "P = 0.0128, R = 0.1215, F1 = 0.0231\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('taco bell', 'has_dress_code', 'nose rings')\r\n",
      "('olive garden', 'has_dress_code', 'facial hair')\r\n",
      "('costco', 'has_dress_code', 'hair color')\r\n",
      "('jcpenney', 'has_dress_code', 'uniform policy')\r\n",
      "('dollar tree', 'has_dress_code', 'uniform')\r\n",
      "('best buy', 'has_dress_code', 'uniform')\r\n",
      "('marshalls', 'has_dress_code', 'color hair')\r\n",
      "('walmart', 'has_dress_code', 'uniform')\r\n",
      "('subway', 'has_dress_code', 'piercings')\r\n",
      "('dollar tree', 'has_dress_code', 'professional')\r\n",
      "('walgreens', 'has_dress_code', 'hair color')\r\n",
      "('at&t', 'has_dress_code', 'uniform')\r\n",
      "('family dollar', 'has_dress_code', 'facial hair')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE=Ct+KV=0.9.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 107\r\n",
      "Predicted relations: 3593\r\n",
      "Intersection: 8\r\n",
      "P = 0.0022, R = 0.0748, F1 = 0.0043\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('walmart', 'has_dress_code', 'uniform')\r\n",
      "('costco', 'has_dress_code', 'hair color')\r\n",
      "('dollar tree', 'has_dress_code', 'uniform')\r\n",
      "('walmart', 'has_dress_code', 'face tattoos')\r\n",
      "('subway', 'has_dress_code', 'piercings')\r\n",
      "('family dollar', 'has_dress_code', 'facial hair')\r\n",
      "('dd', 'has_dress_code', 'facial hair')\r\n",
      "('best buy', 'has_dress_code', 'uniform')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 107\r\n",
      "Predicted relations: 613\r\n",
      "Intersection: 7\r\n",
      "P = 0.0114, R = 0.0654, F1 = 0.0194\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('costco', 'has_dress_code', 'hair color')\r\n",
      "('subway', 'has_dress_code', 'piercings')\r\n",
      "('dd', 'has_dress_code', 'facial hair')\r\n",
      "('walmart', 'has_dress_code', 'uniform')\r\n",
      "('family dollar', 'has_dress_code', 'facial hair')\r\n",
      "('best buy', 'has_dress_code', 'uniform')\r\n",
      "('dollar tree', 'has_dress_code', 'uniform')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_dress_code-RE+KV_0.9.csv \\\n",
    "-r has_dress_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 3600\r\n",
      "Intersection: 11\r\n",
      "P = 0.0031, R = 0.1964, F1 = 0.0060\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('burger king', 'has_benefits', 'health')\r\n",
      "('burger king', 'has_benefits', 'sick leave')\r\n",
      "('walmart', 'has_benefits', '401k')\r\n",
      "('walmart', 'has_benefits', '401k plan')\r\n",
      "('olive garden', 'has_benefits', '401k plan')\r\n",
      "('g4s', 'has_benefits', 'sick leave')\r\n",
      "('walmart', 'has_benefits', 'life insurance')\r\n",
      "('target', 'has_benefits', 'health insurance')\r\n",
      "('walmart', 'has_benefits', 'paid vacations')\r\n",
      "('starbucks', 'has_benefits', 'health')\r\n",
      "('dollar general', 'has_benefits', 'health insurance')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_cartesian-has_benefits.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 1312\r\n",
      "Intersection: 11\r\n",
      "P = 0.0084, R = 0.1964, F1 = 0.0161\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('starbucks', 'has_benefits', 'health')\r\n",
      "('dollar general', 'has_benefits', 'health insurance')\r\n",
      "('walmart', 'has_benefits', '401k plan')\r\n",
      "('walmart', 'has_benefits', 'life insurance')\r\n",
      "('target', 'has_benefits', 'health insurance')\r\n",
      "('burger king', 'has_benefits', 'health')\r\n",
      "('walmart', 'has_benefits', 'paid vacations')\r\n",
      "('burger king', 'has_benefits', 'sick leave')\r\n",
      "('g4s', 'has_benefits', 'sick leave')\r\n",
      "('walmart', 'has_benefits', '401k')\r\n",
      "('olive garden', 'has_benefits', '401k plan')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE=Ct+KV=0.9.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 3294\r\n",
      "Intersection: 5\r\n",
      "P = 0.0015, R = 0.0893, F1 = 0.0030\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('dollar general', 'has_benefits', 'health insurance')\r\n",
      "('burger king', 'has_benefits', 'sick leave')\r\n",
      "('target', 'has_benefits', 'health insurance')\r\n",
      "('walmart', 'has_benefits', '401k')\r\n",
      "('walmart', 'has_benefits', 'life insurance')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RE Results ---\r\n",
      "Benchmark relations: 56\r\n",
      "Predicted relations: 713\r\n",
      "Intersection: 5\r\n",
      "P = 0.0070, R = 0.0893, F1 = 0.0130\r\n",
      "\r\n",
      "Intersection:\r\n",
      "('target', 'has_benefits', 'health insurance')\r\n",
      "('walmart', 'has_benefits', '401k')\r\n",
      "('burger king', 'has_benefits', 'sick leave')\r\n",
      "('walmart', 'has_benefits', 'life insurance')\r\n",
      "('dollar general', 'has_benefits', 'health insurance')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval_relations.py \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-pred $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE+KV_0.9.csv \\\n",
    "-r has_benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMProbe-Joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15496,    11,   616,  3290,   318, 13779]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs = gpt2_tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _outputs = gpt2_model(**_inputs, labels=_inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9901607036590576"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_outputs.loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm_probe.fill_multi_mask(\"[CLS] The payment [MASK] [MASK] is nice. [SEP]\", topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "lm_probe_gpt2 = LMProbe_GPT2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cand': 'good plan', 'score': -4.1346964836120605},\n",
       " {'cand': 'good', 'score': -4.260444641113281},\n",
       " {'cand': 'plan', 'score': -5.5930562019348145}]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_gpt2.score_candidates(\"They have a very [MASK] .\", [\"good\", \"plan\", \"good plan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.47902297973633"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sent = \"Hello ! I would like to have a pizzaaaa\"\n",
    "_inputs = lm_probe_joint.gpt2_tokenizer(_sent, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    _outputs = lm_probe_joint.gpt2_model(**_inputs, labels=_inputs[\"input_ids\"])\n",
    "_outputs.loss.item() * (len(_sent.split(' ')) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [15496, 5145, 314, 561, 588, 284, 423, 257, 14256, 46071], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_joint.gpt2_tokenizer(_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15496,  5145,   314,   561,   588,   284,   423,   257, 14256, 46071]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'Ġ!', 'ĠI', 'Ġwould', 'Ġlike', 'Ġto', 'Ġhave', 'Ġa', 'Ġpizza', 'aaa']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_joint.gpt2_tokenizer.convert_ids_to_tokens([15496,  5145,   314,   561,   588,   284,   423,   257, 14256, 46071])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "code_folding": [
     17
    ]
   },
   "outputs": [],
   "source": [
    "# LMProbe_Joint with bert probs renormalized by gpt2 \n",
    "\n",
    "def _bert_untokenize(pieces):\n",
    "    return ' '.join(pieces).replace(' ##', '')\n",
    "\n",
    "class LMProbe_Joint(object):\n",
    "    def __init__(self,\n",
    "                 bert_model_name='bert-base-uncased',\n",
    "                 gpt2_model_name='gpt2',\n",
    "                 max_n_grams=5,\n",
    "                 use_gpu=False):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.bert_model = BertForMaskedLM.from_pretrained(bert_model_name)\n",
    "        self.bert_model.to(self.device)\n",
    "        self.bert_model.eval()\n",
    "        self.bert_mask_token = self.bert_tokenizer.mask_token\n",
    "        \n",
    "        self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model_name)\n",
    "        self.gpt2_model = GPT2LMHeadModel.from_pretrained(gpt2_model_name, return_dict=True)\n",
    "        self.gpt2_model.to(self.device)\n",
    "        self.gpt2_model.eval()\n",
    "        \n",
    "        self.max_n_grams = max_n_grams\n",
    "        \n",
    "    def joint_score_candidates(self, input_txt, cands, renorm_n=10):\n",
    "        # cands: List[str], list candidates (untokenzied) \n",
    "        \n",
    "        if input_txt.count(\"[MASK]\") != 1:\n",
    "            raise Exception(f'Input string must have exactly one mask token, got {input_txt}')\n",
    "\n",
    "        cand_bins = {i : [] for i in range(1, self.max_n_grams + 1)}\n",
    "        for c in cands:\n",
    "            c_tokenized = self.bert_tokenizer.tokenize(c)\n",
    "            if len(c_tokenized) > self.max_n_grams:\n",
    "                print(f'{c_tokenized}: too many wordpieces')\n",
    "                continue\n",
    "            cand_bins[len(c_tokenized)].append(c_tokenized)\n",
    "        \n",
    "        all_cand_scores = []\n",
    "        for c_len in range(1, self.max_n_grams + 1):\n",
    "            _cands = cand_bins[c_len]\n",
    "            if len(_cands) == 0:\n",
    "                continue\n",
    "            \n",
    "            _input = \"[CLS] \" + input_txt.replace(\"[MASK]\", \"[MASK]\" + \" [MASK]\" * (c_len - 1)) + \" [SEP]\"\n",
    "            _cand_scores = self.bert_score_candidates(_input, _cands)\n",
    "            \n",
    "            _renorm_cand_dicts = _cand_scores[:renorm_n]\n",
    "            _renorm_bert_scores = {_bert_untokenize(d['cand']) : d['score'] for d in _renorm_cand_dicts}\n",
    "            _renorm_cands = list(_renorm_bert_scores.keys())\n",
    "            \n",
    "            _gpt2_cand_scores = self.gpt2_score_candidates(input_txt, _renorm_cands)\n",
    "            _renorm_gpt2_scores = {d['cand'] : d['score'] for d in _gpt2_cand_scores}\n",
    "            \n",
    "#             print('BERT scores:')\n",
    "#             print(json.dumps(_renorm_bert_scores, indent=2))\n",
    "#             print('GPT2 scores:')\n",
    "#             print(json.dumps(_renorm_gpt2_scores, indent=2))\n",
    "#             if len(_renorm_cands) > 2:\n",
    "#                 print('Pearson:')\n",
    "#                 print(pearsonr(\n",
    "#                     np.exp([_renorm_bert_scores[c] for c in _renorm_cands]),\n",
    "#                     np.exp([_renorm_gpt2_scores[c] for c in _renorm_cands])))\n",
    "            \n",
    "            # bert_ll + _renorm_bias -> gpt2_ll\n",
    "            _renorm_bias = np.log(np.sum(np.exp(list(_renorm_gpt2_scores.values())))) \\\n",
    "                - np.log(np.sum(np.exp(list(_renorm_bert_scores.values()))))\n",
    "            \n",
    "            _gpt2_len = len(self.gpt2_tokenizer(input_txt.replace('[MASK]', _renorm_cands[0]))['input_ids'])\n",
    "            \n",
    "            _renormed_cand_scores = [\n",
    "                {'cand': _bert_untokenize(d['cand']),\n",
    "                 'score': (d['score'] + _renorm_bias) / _gpt2_len}\n",
    "                for d in _cand_scores\n",
    "            ]\n",
    "            all_cand_scores.extend(_renormed_cand_scores)\n",
    "        \n",
    "        all_cand_scores.sort(key=lambda d : d['score'], reverse=True)\n",
    "        return all_cand_scores\n",
    "    \n",
    "    \n",
    "    def bert_score_candidates(self, input_txt, cands):\n",
    "        # cands: List[List[str]], list of tokenized candidates \n",
    "        tokenized_txt = self.bert_tokenizer.tokenize(input_txt)\n",
    "        \n",
    "        if tokenized_txt[0] != \"[CLS]\" or tokenized_txt[-1] != \"[SEP]\":\n",
    "            raise Exception(f'Input string must start with [CLS] and end with [SEP], got {input_txt}')\n",
    "        if \"[MASK]\" not in tokenized_txt:\n",
    "            raise Exception(f'Input string must have at least one mask token, got {input_txt}')\n",
    "        \n",
    "        indexed_tokens = self.bert_tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        mask_indices = [i for i, x in enumerate(tokenized_txt) if x == \"[MASK]\"]\n",
    "        segment_idx = tokens_tensor * 0\n",
    "        tokens_tensor = tokens_tensor.to(self.device)\n",
    "        segments_tensors = segment_idx.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert_model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.softmax(predictions, dim=-1)[0]\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "\n",
    "        cand_scores = []\n",
    "        for c in cands:\n",
    "            assert len(c) == len(mask_indices), f'cand {c}; len(mask_indices) = {len(mask_indices)}'\n",
    "\n",
    "            _scores = []\n",
    "            c_token_ids = self.bert_tokenizer.convert_tokens_to_ids(c)\n",
    "            for i, token_id in zip(mask_indices, c_token_ids):\n",
    "                _scores.append(probs[i, token_id].item())\n",
    "            score = np.sum(np.log(_scores))  # sum(log(p))\n",
    "            cand_scores.append({\"cand\": c, \"score\": score})\n",
    "\n",
    "        cand_scores.sort(key=lambda d : d[\"score\"], reverse=True)\n",
    "        return cand_scores\n",
    "    \n",
    "    def gpt2_score_candidates(self, input_txt, cands):\n",
    "        # cands: List[str], list candidates (untokenzied) \n",
    "        \n",
    "        if input_txt.count(\"[MASK]\") != 1:\n",
    "            raise Exception(f'Input string must have exactly one mask token, got {input_txt}')\n",
    "\n",
    "        cand_scores = []\n",
    "        for c in cands:\n",
    "            cand_input_txt = input_txt.replace(\"[MASK]\", c)\n",
    "            tokenized_input = self.gpt2_tokenizer(cand_input_txt, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                model_outputs = self.gpt2_model(**tokenized_input, labels=tokenized_input[\"input_ids\"])\n",
    "                \n",
    "            _input_len = tokenized_input['input_ids'].size(1)\n",
    "            score = -model_outputs.loss.item() * (_input_len - 1)  # (log(p))\n",
    "            cand_scores.append({\"cand\": c, \"score\": score})\n",
    "\n",
    "        cand_scores.sort(key=lambda d : d[\"score\"], reverse=True)\n",
    "        return cand_scores\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe_joint = LMProbe_Joint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT scores:\n",
      "{\n",
      "  \"good\": -3.820184215986424,\n",
      "  \"plan\": -5.464548142423097,\n",
      "  \"nice\": -5.78993798238308\n",
      "}\n",
      "GPT2 scores:\n",
      "{\n",
      "  \"good\": -21.302223205566406,\n",
      "  \"nice\": -23.64457607269287,\n",
      "  \"plan\": -27.965281009674072\n",
      "}\n",
      "Pearson:\n",
      "(0.9899664636147664, 0.09025804686068711)\n",
      "BERT scores:\n",
      "{\n",
      "  \"good plan\": -7.813247270006006\n",
      "}\n",
      "GPT2 scores:\n",
      "{\n",
      "  \"good plan\": -24.808178901672363\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'cand': 'good plan', 'score': -3.544025557381766},\n",
       " {'cand': 'good', 'score': -3.582741819734341},\n",
       " {'cand': 'plan', 'score': -3.856802474140453},\n",
       " {'cand': 'nice', 'score': -3.9110341141337837}]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe_joint.joint_score_candidates(\"They have a very [MASK] .\", [\"good\", \"plan\", \"nice\", \"good plan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Verification baseline\n",
    "(finding co-occurrences of head / tail from corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "# # corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences.json')\n",
    "\n",
    "# indeed_dataset_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/question_answers.csv'\n",
    "# company_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/fccid-companyName.csv'\n",
    "\n",
    "# # with open(corpus_path, 'r') as f:\n",
    "# #     sent_dicts = [json.loads(l) for l in tqdm(f.readlines())]\n",
    "\n",
    "# indeed_dataset = pd.read_csv(indeed_dataset_path)\n",
    "# indeed_dataset = indeed_dataset[indeed_dataset['answerContent'].notna()]\n",
    "# company_df = pd.read_csv(company_path)\n",
    "# company_dict = dict(zip(company_df[\"fccompanyId\"].to_list(), company_df[\"companyName\"].to_list()))\n",
    "\n",
    "# indeed_dataset.shape, len(company_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 7)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relations = pd.read_csv(rel_extraction_path)\n",
    "df_relations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1819f0b55e494a85aab302ac773cb8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=413232.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "413232"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(corpus_path, 'r') as f:\n",
    "    sent_dicts = [json.loads(l) for l in tqdm(f.readlines())]\n",
    "\n",
    "len(sent_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['What', 'is', 'the', 'age', 'limit', '.'],\n",
       " 'company': 'Marshalls',\n",
       " 'entities': ['age limit', 'marshalls']}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dicts[1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entailment model \n",
    "yutong_base_dir = \"/home/ubuntu/users/yutong\"\n",
    "roberta_ses_dir = os.path.join(yutong_base_dir, \"repos\", \"Roberta_SES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = contra, 1 = neutral, 2 = entail\n",
    "entailment_model = Roberta_SES_Entailment(roberta_path='/home/ubuntu/users/yutong/models/roberta-large',\n",
    "        ckpt_path=os.path.join(roberta_ses_dir, 'checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt'),\n",
    "        max_length=512,\n",
    "        device_name='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor([0.9978, 0.0012, 0.0010]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_model.predict(\n",
    "    \"walmart : no you can have tattoo\",\n",
    "    \"walmart allows tattoos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "# KV for (walmart, has_dress_code, uniform)\n",
    "\n",
    "_pos_templates = [\n",
    "    '{0} allows {1}',\n",
    "    '{0} requires {1}',\n",
    "]\n",
    "\n",
    "_neg_templates = [\n",
    "    '{0} doesn\\'t allow {1}',\n",
    "    '{0} doesn\\'t require {1}',\n",
    "]\n",
    "\n",
    "def find_evidences(head, tail, corpus=sent_dicts):\n",
    "    # (s1(evid), s2(tmpl), score)\n",
    "    _pos_evidences = []\n",
    "    _neg_evidences = []\n",
    "\n",
    "    for i, d in enumerate(sent_dicts):\n",
    "        if i > 0 and i % 50000 == 0:\n",
    "            print(f'Progress: {i} / {len(sent_dicts)}')\n",
    "            \n",
    "#         _company_id = row['fccompanyId']\n",
    "#         _company = company_dict[_company_id]\n",
    "\n",
    "#         _answer = row['answerContent']\n",
    "#         _tokens = [str(t) for t in spacy_tokenizer(_answer)]\n",
    "#         _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "        _company = d['company']\n",
    "        _tokens = d['tokens']\n",
    "        _s = f\"{_company.lower()} : {' '.join(_tokens).lower()}\"\n",
    "\n",
    "        if head in d['entities'] and tail in d['entities']:\n",
    "            # Try all pos/neg relation templates, save the best template  \n",
    "            _max_pos_ev = (None, None, 0)\n",
    "            for _tmpl in _pos_templates:\n",
    "                _tmpl_filled = _tmpl.format(head, tail)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_s, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_pos_ev[-1]:\n",
    "                    _max_pos_ev = (_s, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _max_neg_ev = (None, None, 0)\n",
    "            for _tmpl in _neg_templates:\n",
    "                _tmpl_filled = _tmpl.format(head, tail)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_s, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_neg_ev[-1]:\n",
    "                    _max_neg_ev = (_s, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _pos_evidences.append(_max_pos_ev)\n",
    "            _neg_evidences.append(_max_neg_ev)\n",
    "    \n",
    "    _pos_evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    _neg_evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    return _pos_evidences, _neg_evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_pos_evidences, _neg_evidences = find_evidences('walmart', 'black jeans')\n",
    "'POS:', _pos_evidences[:10], 'NEG:', _neg_evidences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def find_evidences_RE(df_relations, corpus=sent_dicts, p_thres=0.7):\n",
    "    ## TODO: to script \n",
    "    \n",
    "    # Dict[Tuple(head, rel, tail): List[Tuple(s1(evid), s2(tmpl), score)]]\n",
    "    pos_evidences = defaultdict(list)\n",
    "    neg_evidences = defaultdict(list)\n",
    "    \n",
    "    # collect all relations \n",
    "    rels = []\n",
    "    head2rels = defaultdict(list)\n",
    "    tail2rels = defaultdict(list)\n",
    "    for i, row in df_relations.iterrows():\n",
    "        _h = row['head']\n",
    "        _t = row['tail']\n",
    "        _r = 'has_dress_code'\n",
    "        rels.append((_h, _r, _t))\n",
    "        if row['base'] == 'HEAD':\n",
    "            head2rels[_h].append((_h, _r, _t))\n",
    "        else:\n",
    "            tail2rels[_t].append((_h, _r, _t))\n",
    "\n",
    "    # collect sents for each entity \n",
    "    entity2sents = defaultdict(set)\n",
    "    for i, d in enumerate(sent_dicts):\n",
    "        _s = f\"{d['company']} : {' '.join(d['tokens'])}\".lower()\n",
    "        for _e in d['entities']:\n",
    "            entity2sents[_e].add(_s)\n",
    "    \n",
    "    for _h, _r, _t in tqdm(rels[200::200]):\n",
    "        # assure key existence\n",
    "        _ = pos_evidences[(_h, _r, _t)]\n",
    "        _ = neg_evidences[(_h, _r, _t)]\n",
    "        \n",
    "        h_sents = entity2sents[_h]\n",
    "        t_sents = entity2sents[_t]\n",
    "        intersect_sents = h_sents & t_sents\n",
    "        \n",
    "        for _s in intersect_sents:\n",
    "            _ss = _s.strip()\n",
    "\n",
    "            # Try all pos/neg relation templates, save the best template  \n",
    "            _max_pos_ev = (None, None, 0)\n",
    "            for _tmpl in _pos_templates:\n",
    "                _tmpl_filled = _tmpl.format(_h, _t)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_pos_ev[-1]:\n",
    "                    _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _max_neg_ev = (None, None, 0)\n",
    "            for _tmpl in _neg_templates:\n",
    "                _tmpl_filled = _tmpl.format(_h, _t)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_neg_ev[-1]:\n",
    "                    _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "            if _max_pos_ev[-1] > p_thres:\n",
    "                pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "            if _max_neg_ev[-1] > p_thres:\n",
    "                neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "    \n",
    "    \n",
    "#     # Head-base\n",
    "#     for _h, _rels in rel_head_index.items():\n",
    "#         # First find sentences with _h\n",
    "#         _h_sents = [] \n",
    "#         for i, d in enumerate(sent_dicts):\n",
    "#             _company = d['company']\n",
    "#             _tokens = d['tokens']\n",
    "#             _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "#             if f' {_h} ' in _s:\n",
    "#                 _h_sents.append(_s)\n",
    "        \n",
    "#         # KV: check for _t only; entail\n",
    "#         for _h, _r, _t in tqdm(_rels):\n",
    "#             for _s in _h_sents:\n",
    "#                 if f' {_t} ' in _s:\n",
    "#                     _ss = _s.strip()\n",
    "                    \n",
    "#                     # Try all pos/neg relation templates, save the best template  \n",
    "#                     _max_pos_ev = (None, None, 0)\n",
    "#                     for _tmpl in _pos_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(_h, _t)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_pos_ev[-1]:\n",
    "#                             _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     _max_neg_ev = (None, None, 0)\n",
    "#                     for _tmpl in _neg_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(_h, _t)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_neg_ev[-1]:\n",
    "#                             _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     if _max_pos_ev[-1] > p_thres:\n",
    "#                         pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "#                     if _max_neg_ev[-1] > p_thres:\n",
    "#                         neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "\n",
    "#     # Tail-base\n",
    "#     for _t, _rels in tqdm(rel_tail_index.items(), total=len(rel_tail_index)):\n",
    "#         # First find sentences with _t\n",
    "#         _t_sents = [] \n",
    "#         for i, d in enumerate(sent_dicts):\n",
    "#             _company = d['company']\n",
    "#             _tokens = d['tokens']\n",
    "#             _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "#             if f' {_t} ' in _s:\n",
    "#                 _t_sents.append(_s)\n",
    "        \n",
    "#         # KV: check for _h only; entail\n",
    "#         for _h, _r, _t in tqdm(_rels):\n",
    "#             if (_h, _r, _t) in pos_evidences or (_h, _r, _t) in neg_evidences:\n",
    "#                 # already computed \n",
    "#                 continue\n",
    "#             for _s in _t_sents:\n",
    "#                 if f' {_h} ' in _s:\n",
    "#                     _ss = _s.strip()\n",
    "                    \n",
    "#                     # Try all pos/neg relation templates, save the best template  \n",
    "#                     _max_pos_ev = (None, None, 0)\n",
    "#                     for _tmpl in _pos_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(head, tail)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_pos_ev[-1]:\n",
    "#                             _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     _max_neg_ev = (None, None, 0)\n",
    "#                     for _tmpl in _neg_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(head, tail)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_neg_ev[-1]:\n",
    "#                             _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     if _max_pos_ev[-1] > p_thres:\n",
    "#                         pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "#                     if _max_neg_ev[-1] > p_thres:\n",
    "#                         neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "\n",
    "    for _rel, _evidences in pos_evidences.items():\n",
    "        _evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    for _rel, _evidences in neg_evidences.items():\n",
    "        _evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    return pos_evidences, neg_evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = find_evidences_RE(df_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use script \n",
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-in $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE.csv \\\n",
    "-o_kv $base_dir/data/$data_ac/intermediate/kv_evidences-has_benefits-RE.json \\\n",
    "-o_re $base_dir/data/$data_ac/intermediate/rel_extraction-has_benefits-RE+KV_0.9.csv \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p_kv 0.7 \\\n",
    "-p_re 0.9 \\\n",
    "--fast_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate \n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "\n",
    "benchmark_relations_list = load_benchmark_relations(benchmark_path)\n",
    "len(benchmark_relations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_evidences_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/kv_evidences.json')\n",
    "\n",
    "with open(kv_evidences_path, 'r') as f:\n",
    "    kv_evidences = [json.loads(l) for l in f.readlines()]\n",
    "len(kv_evidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_thres = 0.9\n",
    "\n",
    "kv_filtered_rels = []\n",
    "for d in kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences']\n",
    "    _neg_evs = d['neg_evidences']\n",
    "    if (len(_pos_evs) > 0 and _pos_evs[0][-1] > p_thres):\n",
    "        kv_filtered_rels.append((_h, _t))\n",
    "    elif (len(_neg_evs) > 0 and _neg_evs[0][-1] > p_thres):\n",
    "        kv_filtered_rels.append((_h, _t))\n",
    "\n",
    "len(kv_filtered_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 665, 6)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_relations_set = set([tuple(d.values()) for d in benchmark_relations_list])\n",
    "kv_filtered_rels_set = set(kv_filtered_rels)\n",
    "\n",
    "intersection = benchmark_relations_set & kv_filtered_rels_set\n",
    "\n",
    "len(benchmark_relations_set), len(kv_filtered_rels_set), len(intersection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('best buy', 'uniform'),\n",
       " ('costco', 'hair color'),\n",
       " ('dd', 'facial hair'),\n",
       " ('dollar tree', 'uniform'),\n",
       " ('family dollar', 'facial hair'),\n",
       " ('walmart', 'uniform')}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences']\n",
    "    _neg_evs = d['neg_evidences']\n",
    "    \n",
    "    if (_h, _t) in intersection:\n",
    "        print(_h, _t)\n",
    "        _max = sorted(_pos_evs + _neg_evs, key=lambda p : p[-1], reverse=True)[0]\n",
    "        print(_max)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kv_evidences = list(kv_evidences)\n",
    "\n",
    "for d in test_kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences'][:5]\n",
    "    _neg_evs = d['neg_evidences'][:5]\n",
    "    \n",
    "    _max = sorted(_pos_evs + _neg_evs, key=lambda p : p[-1], reverse=True)[0]\n",
    "    d['pos_evidences'] = _pos_evs\n",
    "    d['neg_evidences'] = _neg_evs\n",
    "    d['max_ev'] = _max\n",
    "\n",
    "sorted(test_kv_evidences, key=lambda d : d['max_ev'][-1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussions:\n",
    "# coherence clustering / ensemble models?\n",
    "# trying for other relations or entities\n",
    "# using entities in sub-categories\n",
    "# fine-tuning\n",
    "# ambiguous samples (high for pos and neg)\n",
    "# quantitative-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore various techniques\n",
    "# Get prompts \"between\" entities\n",
    "# Get prompts by syntactic parsing\n",
    "# Get prompts by paraphrasing\n",
    "# Get prompts uisng AutoPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit here: /meg-kb/src/analysis/pattern_mining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Amazon []\n",
      "1 is [Amazon, place, .]\n",
      "2 a []\n",
      "3 good []\n",
      "4 place [a, good, for]\n",
      "5 for [working]\n",
      "6 working [as]\n",
      "7 as [time]\n",
      "8 a []\n",
      "9 part []\n",
      "10 - []\n",
      "11 time [a, part, -]\n",
      "12 . []\n"
     ]
    }
   ],
   "source": [
    "_sent = \"Amazon is a good place for working as a part-time.\"\n",
    "_doc = _nlp(_sent)\n",
    "for _t in _doc:\n",
    "    print(_t.i, _t, list(_t.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7f9cb8795670>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = []\n",
    "for _t in _doc:\n",
    "    for child in _t.children:\n",
    "        edges.append(('{}-{}'.format(_t.lower_,_t.i), '{}-{}'.format(child.lower_,child.i))) \n",
    "\n",
    "graph = nx.Graph(edges)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([('is-1', 'amazon-0'), ('is-1', 'place-4'), ('is-1', '.-12'), ('place-4', 'a-2'), ('place-4', 'good-3'), ('place-4', 'for-5'), ('for-5', 'working-6'), ('working-6', 'as-7'), ('as-7', 'time-11'), ('time-11', 'a-8'), ('time-11', 'part-9'), ('time-11', '--10')])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon-0', 'is-1', 'place-4', 'for-5', 'working-6', 'as-7', 'time-11']\n"
     ]
    }
   ],
   "source": [
    "_src = 'amazon-0'\n",
    "_tgt = 'time-11'\n",
    "if nx.has_path(graph, source=_src, target=_tgt):\n",
    "    path = nx.shortest_path(graph, source=_src, target=_tgt)\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Prompt Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit here: /meg-kb/src/analysis/lm_probing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggest Quality Prompts"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_transformers_nikita)",
   "language": "python",
   "name": "conda_transformers_nikita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
