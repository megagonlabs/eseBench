{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/mnt/efs/shared/meg_shared_scripts/meg-kb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr, entropy\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import logging\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "\n",
    "from compute_concept_clusters import load_embeddings, knn\n",
    "from compute_keyphrase_embeddings import get_masked_contexts, ensure_tensor_on_device, mean_pooling\n",
    "from relation_extraction_avg_scores import LMProbe\n",
    "\n",
    "from roberta_ses.interface import Roberta_SES_Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: text corpus\n",
    "# step 1: extract key phrases (autophrase)\n",
    "# step 2: generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Key Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/keyword_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n"
     ]
    }
   ],
   "source": [
    "#change to keyword extractor directory\n",
    "%cd $base_dir/src/keyword_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./corpusProcess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dataset and thread no\n",
    "data_ac = 'indeeda-meg-ac'\n",
    "data_pt = 'indeeda-meg-pt'\n",
    "thread = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction\n",
      "\u001b[32m===Corpus Name: sample-indeeda-meg-ac===\u001b[m\n",
      "\u001b[32m===Current Path: /mnt/efs/shared/meg_shared_scripts/meg-kb/src/keyword_extraction===\u001b[m\n",
      "\u001b[32m===Cleaning input corpus===\u001b[m\n",
      "\u001b[32m===Running AutoPhrase===\u001b[m\n",
      "make: Nothing to be done for 'all'.\n",
      "\u001b[32m===RAW_TRAIN: ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt===\u001b[m\n",
      "auto_phrase.sh parameters: sample-indeeda-meg-ac ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt 10 data/EN/wiki_quality.txt 8\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m0.702s\n",
      "user\t0m1.668s\n",
      "sys\t0m0.100s\n",
      "Detected Language: EN\u001b[0K\n",
      "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
      "No provided expert labels.\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===AutoPhrasing===\u001b[m\n",
      "=== Current Settings ===\n",
      "Iterations = 2\n",
      "Minimum Support Threshold = 10\n",
      "Maximum Length Threshold = 6\n",
      "POS-Tagging Mode Disabled\n",
      "Discard Ratio = 0.050000\n",
      "Number of threads = 8\n",
      "Labeling Method = DPDN\n",
      "\tAuto labels from knowledge bases\n",
      "\tMax Positive Samples = -1\n",
      "=======\n",
      "Loading data...\n",
      "# of total tokens = 6553\n",
      "max word token id = 1450\n",
      "# of documents = 500\n",
      "# of distinct POS tags = 0\n",
      "Mining frequent phrases...\n",
      "selected MAGIC = 1451\n",
      "# of frequent phrases = 1483\n",
      "Extracting features...\n",
      "Constructing label pools...\n",
      "\tThe size of the positive pool = 192\n",
      "\tThe size of the negative pool = 1282\n",
      "# truth patterns = 1202\n",
      "Estimating Phrase Quality...\n",
      "0 32\n",
      "[ERROR] not enough training data found!\n",
      "Segmenting...\n",
      "Rectifying features...\n",
      "Estimating Phrase Quality...\n",
      "0 32\n",
      "[ERROR] not enough training data found!\n",
      "Segmenting...\n",
      "Dumping results...\n",
      "Done.\n",
      "\n",
      "real\t0m1.922s\n",
      "user\t0m2.496s\n",
      "sys\t0m0.016s\n",
      "\u001b[32m===Saving Model and Results===\u001b[m\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "phrasal_segmentation.sh parameters: sample-indeeda-meg-ac ../../../data/sample-indeeda-meg-ac/source/corpus.clean.txt 0.5 0.9 8\n",
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m0.568s\n",
      "user\t0m1.396s\n",
      "sys\t0m0.108s\n",
      "Detected Language: EN\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "\u001b[32m===Phrasal Segmentation===\u001b[m\n",
      "=== Current Settings ===\n",
      "Segmentation Model Path = models/sample-indeeda-meg-ac/segmentation.model\n",
      "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
      "\tQ(multi-word phrases) >= 0.500000\n",
      "\tQ(single-word phrases) >= 0.900000\n",
      "=======\n",
      "Length penalty model loaded.\n",
      "\tpenalty = 199.805\n",
      "# of loaded patterns = 136\n",
      "# of loaded truth patterns = 1394\n",
      "Phrasal segmentation finished.\n",
      "   # of total highlighted quality phrases = 715\n",
      "   # of total processed sentences = 828\n",
      "   avg highlights per sentence = 0.863527\n",
      "\n",
      "real\t0m0.050s\n",
      "user\t0m0.016s\n",
      "sys\t0m0.000s\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "\u001b[32m===Generating Phrase Text===\u001b[m\n",
      "process_segmentation.py parameters: ../../../data/sample-indeeda-meg-ac/intermediate/ 0.5 0.9\n",
      "11.152\n",
      "\u001b[32m===Running NLP Feature Extraction===\u001b[m\n",
      "100%|███████████████████████████████████████████| 51/51 [00:00<00:00, 66.53it/s]\n",
      " 71%|██████████████████████████████▌            | 47/66 [00:00<00:00, 58.53it/s]Finish NLP processing, using time 0.8209497928619385 (second)\n",
      "100%|███████████████████████████████████████████| 57/57 [00:00<00:00, 65.72it/s]\n",
      " 80%|██████████████████████████████████▌        | 53/66 [00:00<00:00, 57.33it/s]Finish NLP processing, using time 0.9230477809906006 (second)\n",
      "100%|███████████████████████████████████████████| 62/62 [00:00<00:00, 70.06it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:00<00:00, 57.63it/s]\n",
      "Finish NLP processing, using time 0.9408359527587891 (second)\n",
      " 95%|████████████████████████████████████████▉  | 60/63 [00:00<00:00, 74.56it/s]Finish NLP processing, using time 0.8718316555023193 (second)\n",
      "100%|███████████████████████████████████████████| 66/66 [00:01<00:00, 62.34it/s]\n",
      "100%|███████████████████████████████████████████| 63/63 [00:00<00:00, 68.87it/s]\n",
      "Finish NLP processing, using time 1.1157433986663818 (second)\n",
      "100%|███████████████████████████████████████████| 76/76 [00:00<00:00, 80.52it/s]\n",
      "Finish NLP processing, using time 0.9821081161499023 (second)\n",
      "Finish NLP processing, using time 1.003368854522705 (second)\n",
      "100%|███████████████████████████████████████████| 79/79 [00:01<00:00, 76.95it/s]\n",
      "Finish NLP processing, using time 1.0861637592315674 (second)\n",
      "\u001b[32m===Clean unnecessary files===\u001b[m\n",
      "\u001b[32m===Key Term Extraction===\u001b[m\n",
      "Extract Key Terms from Corpus: 100%|███████| 694/694 [00:00<00:00, 24407.16it/s]\n",
      "\u001b[32m===Sentence-wise Entity Segmentation===\u001b[m\n",
      "loading corpus for word2vec training: 100%|█| 694/694 [00:00<00:00, 288117.09it/\n",
      "100%|███████████████████████████████████████| 94/94 [00:00<00:00, 431834.15it/s]\n",
      "100%|█████████████████████████████████████| 122/122 [00:00<00:00, 423947.88it/s]\n",
      "100%|█████████████████████████████████████| 118/118 [00:00<00:00, 377519.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# process corpus and generate key prhases\n",
    "!./corpusProcess.sh $data_ac $thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy these results to sample-meg-pt\n",
    "!cp -r ../../data/$data_ac ../../data/$data_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus with company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/question_answers.csv'\n",
    "company_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/fccid-companyName.csv'\n",
    "entity_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "out_corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8053"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(entity_emb_num_path, 'r') as f:\n",
    "    entities = [l.strip().rsplit(' ', 1)[0] for l in f.readlines()]\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionId</th>\n",
       "      <th>fccompanyId</th>\n",
       "      <th>questionCode</th>\n",
       "      <th>topics</th>\n",
       "      <th>questionContent</th>\n",
       "      <th>answerId</th>\n",
       "      <th>DateAnswered</th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>jobLocation</th>\n",
       "      <th>answerContent</th>\n",
       "      <th>companyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>2016-06-16T02:15:39.931Z</td>\n",
       "      <td>Retail associate, floor maintenance</td>\n",
       "      <td>Lake Placid, NY</td>\n",
       "      <td>I went to the open interview sessions they had...</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1amcsjj6oakaid9l</td>\n",
       "      <td>2016-06-29T01:33:07.160Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I applied online and submitted all attachments...</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1aonur8nlas2r8di</td>\n",
       "      <td>2016-07-28T05:15:18.133Z</td>\n",
       "      <td>Sales Associate</td>\n",
       "      <td>San Marcos, TX</td>\n",
       "      <td>He said he liked me and saw nothing that he di...</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1ap63mfneaqi1drb</td>\n",
       "      <td>2016-08-02T17:09:26.382Z</td>\n",
       "      <td>Equipment Operator</td>\n",
       "      <td>Decatur, GA</td>\n",
       "      <td>It was good</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1apm7cii7aka0csa</td>\n",
       "      <td>2016-08-08T23:21:46.823Z</td>\n",
       "      <td>Sales Associate</td>\n",
       "      <td>Stone Mountain, GA</td>\n",
       "      <td>Applied for the job.</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1aq859am1ak569l9</td>\n",
       "      <td>2016-08-15T22:31:23.073Z</td>\n",
       "      <td>Sales Associate</td>\n",
       "      <td>Redlands, CA</td>\n",
       "      <td>I got my first interview with Marshalls by goi...</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1au922hjvaqh08g7</td>\n",
       "      <td>2016-10-04T23:57:16.799Z</td>\n",
       "      <td>Customer Service Associate</td>\n",
       "      <td>Fort Worth, TX 76119</td>\n",
       "      <td>After putting in my application at my nearest ...</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1b55n7nr00kbr607</td>\n",
       "      <td>2016-12-29T16:40:02.144Z</td>\n",
       "      <td>Sales Associate, Cashier</td>\n",
       "      <td>Aventura, FL</td>\n",
       "      <td>I walk in and ask to apply</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1b5b6bkk10kbr2nj</td>\n",
       "      <td>2016-12-31T19:40:30.721Z</td>\n",
       "      <td>Cashier/Fitting Room Attendant</td>\n",
       "      <td>Miller Place, NY</td>\n",
       "      <td>I received my first interview after a friend r...</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1albfs54rak5j9ff</td>\n",
       "      <td>403</td>\n",
       "      <td>FIRST_INTERVIEW</td>\n",
       "      <td>INTERVIEW</td>\n",
       "      <td>How did you get your first interview at Marsha...</td>\n",
       "      <td>1b5tkjj5gb85ae4v</td>\n",
       "      <td>2017-01-07T23:35:51.216Z</td>\n",
       "      <td>Inventory Specialist/Sales Associate</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>I see the hiring sign and apply at marshall</td>\n",
       "      <td>Marshalls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         questionId  fccompanyId     questionCode     topics  \\\n",
       "0  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "1  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "2  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "3  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "4  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "5  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "6  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "7  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "8  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "9  1albfs54rak5j9ff          403  FIRST_INTERVIEW  INTERVIEW   \n",
       "\n",
       "                                     questionContent          answerId  \\\n",
       "0  How did you get your first interview at Marsha...  1albfs54rak5j9ff   \n",
       "1  How did you get your first interview at Marsha...  1amcsjj6oakaid9l   \n",
       "2  How did you get your first interview at Marsha...  1aonur8nlas2r8di   \n",
       "3  How did you get your first interview at Marsha...  1ap63mfneaqi1drb   \n",
       "4  How did you get your first interview at Marsha...  1apm7cii7aka0csa   \n",
       "5  How did you get your first interview at Marsha...  1aq859am1ak569l9   \n",
       "6  How did you get your first interview at Marsha...  1au922hjvaqh08g7   \n",
       "7  How did you get your first interview at Marsha...  1b55n7nr00kbr607   \n",
       "8  How did you get your first interview at Marsha...  1b5b6bkk10kbr2nj   \n",
       "9  How did you get your first interview at Marsha...  1b5tkjj5gb85ae4v   \n",
       "\n",
       "               DateAnswered                              jobTitle  \\\n",
       "0  2016-06-16T02:15:39.931Z   Retail associate, floor maintenance   \n",
       "1  2016-06-29T01:33:07.160Z                                   NaN   \n",
       "2  2016-07-28T05:15:18.133Z                       Sales Associate   \n",
       "3  2016-08-02T17:09:26.382Z                    Equipment Operator   \n",
       "4  2016-08-08T23:21:46.823Z                       Sales Associate   \n",
       "5  2016-08-15T22:31:23.073Z                       Sales Associate   \n",
       "6  2016-10-04T23:57:16.799Z            Customer Service Associate   \n",
       "7  2016-12-29T16:40:02.144Z              Sales Associate, Cashier   \n",
       "8  2016-12-31T19:40:30.721Z        Cashier/Fitting Room Attendant   \n",
       "9  2017-01-07T23:35:51.216Z  Inventory Specialist/Sales Associate   \n",
       "\n",
       "            jobLocation                                      answerContent  \\\n",
       "0       Lake Placid, NY  I went to the open interview sessions they had...   \n",
       "1                   NaN  I applied online and submitted all attachments...   \n",
       "2        San Marcos, TX  He said he liked me and saw nothing that he di...   \n",
       "3           Decatur, GA                                        It was good   \n",
       "4    Stone Mountain, GA                               Applied for the job.   \n",
       "5          Redlands, CA  I got my first interview with Marshalls by goi...   \n",
       "6  Fort Worth, TX 76119  After putting in my application at my nearest ...   \n",
       "7          Aventura, FL                         I walk in and ask to apply   \n",
       "8      Miller Place, NY  I received my first interview after a friend r...   \n",
       "9           Redmond, WA        I see the hiring sign and apply at marshall   \n",
       "\n",
       "  companyName  \n",
       "0   Marshalls  \n",
       "1   Marshalls  \n",
       "2   Marshalls  \n",
       "3   Marshalls  \n",
       "4   Marshalls  \n",
       "5   Marshalls  \n",
       "6   Marshalls  \n",
       "7   Marshalls  \n",
       "8   Marshalls  \n",
       "9   Marshalls  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset = pd.read_csv(dataset_path) \n",
    "df_dataset = df_dataset[df_dataset['answerContent'].notna()]\n",
    "df_company = pd.read_csv(company_path)\n",
    "\n",
    "df_merged_dataset = df_dataset.merge(df_company, how='inner', on='fccompanyId')\n",
    "df_merged_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307122, 11)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I, applied, online, and, submitted, all, attachments, that, I, could, .]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df_merged_dataset.iloc[1]\n",
    "_d = nlp(row[\"answerContent\"])\n",
    "list(_d.sents)\n",
    "list(list(_d.sents)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 5000 / 307122\n",
      "Progress: 10000 / 307122\n",
      "Progress: 15000 / 307122\n",
      "Progress: 20000 / 307122\n",
      "Progress: 25000 / 307122\n",
      "Progress: 30000 / 307122\n",
      "Progress: 35000 / 307122\n",
      "Progress: 40000 / 307122\n",
      "Progress: 45000 / 307122\n",
      "Progress: 50000 / 307122\n",
      "Progress: 55000 / 307122\n",
      "Progress: 60000 / 307122\n",
      "Progress: 65000 / 307122\n",
      "Progress: 70000 / 307122\n",
      "Progress: 75000 / 307122\n",
      "Progress: 80000 / 307122\n",
      "Progress: 85000 / 307122\n",
      "Progress: 90000 / 307122\n",
      "Progress: 95000 / 307122\n",
      "Progress: 100000 / 307122\n",
      "Progress: 105000 / 307122\n",
      "Progress: 110000 / 307122\n",
      "Progress: 115000 / 307122\n",
      "Progress: 120000 / 307122\n",
      "Progress: 125000 / 307122\n",
      "Progress: 130000 / 307122\n",
      "Progress: 135000 / 307122\n",
      "Progress: 140000 / 307122\n",
      "Progress: 145000 / 307122\n",
      "Progress: 150000 / 307122\n",
      "Progress: 155000 / 307122\n",
      "Progress: 160000 / 307122\n",
      "Progress: 165000 / 307122\n",
      "Progress: 170000 / 307122\n",
      "Progress: 175000 / 307122\n",
      "Progress: 180000 / 307122\n",
      "Progress: 185000 / 307122\n",
      "Progress: 190000 / 307122\n",
      "Progress: 195000 / 307122\n",
      "Progress: 200000 / 307122\n",
      "Progress: 205000 / 307122\n",
      "Progress: 210000 / 307122\n",
      "Progress: 215000 / 307122\n",
      "Progress: 220000 / 307122\n",
      "Progress: 225000 / 307122\n",
      "Progress: 230000 / 307122\n",
      "Progress: 235000 / 307122\n",
      "Progress: 240000 / 307122\n",
      "Progress: 245000 / 307122\n",
      "Progress: 250000 / 307122\n",
      "Progress: 255000 / 307122\n",
      "Progress: 260000 / 307122\n",
      "Progress: 265000 / 307122\n",
      "Progress: 270000 / 307122\n",
      "Progress: 275000 / 307122\n",
      "Progress: 280000 / 307122\n",
      "Progress: 285000 / 307122\n",
      "Progress: 290000 / 307122\n",
      "Progress: 295000 / 307122\n",
      "Progress: 300000 / 307122\n",
      "Progress: 305000 / 307122\n"
     ]
    }
   ],
   "source": [
    "out_corpus = []\n",
    "\n",
    "for i, row in df_merged_dataset.iterrows():\n",
    "    if i > 0 and i % 5000 == 0:\n",
    "        print(f'Progress: {i} / {df_merged_dataset.shape[0]}')\n",
    "    \n",
    "    company = row[\"companyName\"]\n",
    "    ans = row[\"answerContent\"]\n",
    "    ans_nlp = nlp(ans)\n",
    "    for sent in ans_nlp.sents:\n",
    "        sent_tok_list = [str(t) for t in sent]\n",
    "        _s = f' {company} : {\" \".join(sent_tok_list)} '.lower()\n",
    "        _ents = []\n",
    "        for _e in entities:\n",
    "            if f' {_e} ' in _s:\n",
    "                _ents.append(_e)\n",
    "        out_corpus.append({\n",
    "            \"tokens\": sent_tok_list,\n",
    "            \"company\": company,\n",
    "            \"entities\": _ents,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413232,\n",
       " {'tokens': ['I',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'open',\n",
       "   'interview',\n",
       "   'sessions',\n",
       "   'they',\n",
       "   'had',\n",
       "   'an',\n",
       "   'applied',\n",
       "   '.'],\n",
       "  'company': 'Marshalls',\n",
       "  'entities': ['marshalls']})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_corpus), out_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_corpus_path, 'w') as f:\n",
    "    for d in out_corpus:\n",
    "        f.write(json.dumps(d) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "#change to concept learning directory\n",
    "%cd $base_dir/src/concept_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|█████████████████████| 694/694 [00:00<00:00, 194471.34it/s]\n",
      "computing entity-wise embedding: 100%|████████| 177/177 [00:03<00:00, 50.59it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!python compute_keyphrase_embeddings.py -m bert-base-uncased -et ac -d ../../data/$data_ac/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenated Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|█████████████████████| 694/694 [00:00<00:00, 191566.11it/s]\n",
      "computing entity-wise embedding: 100%|████████| 177/177 [00:03<00:00, 53.88it/s]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "!python compute_keyphrase_embeddings.py -m bert-base-uncased -et pt -d ../../data/$data_pt/intermediate -c 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/tools/AutoPhrase\n"
     ]
    }
   ],
   "source": [
    "# change directory to autophrase\n",
    "%cd $base_dir/src/tools/AutoPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corel = 'sample-indeeda-corel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2021-06-18 00:36:18,384 : INFO : loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ubuntu/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2021-06-18 00:36:18,776 : INFO : loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ubuntu/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2021-06-18 00:36:18,777 : INFO : Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2021-06-18 00:36:19,108 : INFO : loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/ubuntu/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "Traceback (most recent call last):\n",
      "  File \"extractBertEmbedding.py\", line 86, in <module>\n",
      "    with open(inputFilePath, \"r\") as fin:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../../../data/sample-indeeda-corel/intermediate//sent_segmentation.txt'\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python extractBertEmbedding.py ../../../data/$data_corel/intermediate/ $thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add embeddings for seed instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_seed_concepts(path):\n",
    "    df = pd.read_csv(path)    \n",
    "    df[\"seedInstances\"] = df[\"seedInstances\"].map(lambda s : eval(str(s)))\n",
    "    return df\n",
    "\n",
    "def load_seed_aligned_concepts(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df[\"generalizations\"] != \"x\"]\n",
    "    df[\"seedInstances\"] = df[\"seedInstances\"].map(lambda s : eval(str(s)))\n",
    "    return df\n",
    "\n",
    "def load_seed_aligned_relations(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df[\"range\"] != \"x\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_masked_contexts_for_entities(entities, input_file):\n",
    "    \"\"\"Return a (list of) sentence(s) with entity replaced with MASK.\"\"\"\n",
    "    \"\"\"YS: input should be sentences.json\"\"\"\n",
    "    \n",
    "    ent_freq = {ent : 0 for ent in entities}\n",
    "    ent_context = {ent : [] for ent in entities}\n",
    "    \n",
    "    with open(input_file, \"r\") as fin:\n",
    "        lines = fin.readlines()\n",
    "        for line in tqdm(lines, total=len(lines), desc=\"loading corpus\"):\n",
    "            json_dict = json.loads(line)\n",
    "            sent = ' ' + ' '.join(json_dict['tokens']).lower() + ' '\n",
    "            #entities = [match.group(1) for match in re.finditer(pat, line)]\n",
    "            \n",
    "            for entity in entities:\n",
    "                pat = f' {entity} '\n",
    "                if pat not in sent:\n",
    "                    continue\n",
    "\n",
    "                context = sent.replace(pat, ' [MASK] ').strip()\n",
    "                c = context.split('[MASK]')\n",
    "                if len(c) != 2:  # sanity to not have too many repeating phrases in the context\n",
    "                    continue\n",
    "\n",
    "                # ignore too short contexts\n",
    "                if len(context) < 15:\n",
    "                    continue\n",
    "\n",
    "                # print(entity)\n",
    "                # print(context)\n",
    "                \n",
    "                _freq = ent_freq.get(entity, 0)\n",
    "                ent_freq[entity] = _freq + 1\n",
    "\n",
    "                context_lst = ent_context.get(entity, [])\n",
    "                context_lst.append(context)\n",
    "                ent_context[entity] = context_lst\n",
    "\n",
    "    dedup_context = {}\n",
    "    for e, v in ent_context.items():\n",
    "        dedup_context[e] = list(set(v))\n",
    "    return ent_freq, dedup_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_avg_context_embedding_for_entities(entities, model_path, input_file, max_context_ct):\n",
    "    '''\n",
    "    mean pooling from sentence-transformers\n",
    "    :param entity: List[str], the entities to compute embeddings for\n",
    "    :param model_path:\n",
    "    :param input_file:\n",
    "    :return:\n",
    "    '''\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "    ent_freq, ent_context = get_masked_contexts_for_entities(entities, input_file)\n",
    "    \n",
    "    entity_embeddings = {}\n",
    "    for entity, en_context_lst in tqdm(ent_context.items(), total=len(ent_context), desc=\"computing entity-wise embedding\"):\n",
    "#     for entity, en_context_lst in ent_context.items():\n",
    "        print(entity)\n",
    "        en_context_lst = random.sample(en_context_lst, min(len(en_context_lst), max_context_ct))\n",
    "        chunks = [en_context_lst[i:i + 100] for i in range(0, len(en_context_lst), 100)]\n",
    "        # print(entity)\n",
    "        # print(len(en_context_lst))\n",
    "        all_context_embeddings = []\n",
    "        for chunk in chunks:\n",
    "            encoded_input = tokenizer.batch_encode_plus(chunk, return_token_type_ids=True, add_special_tokens=True, max_length=128, return_tensors='pt', padding=True, pad_to_max_length=True, truncation=True)\n",
    "            mask = encoded_input['input_ids'] != mask_token_id\n",
    "            with torch.no_grad():\n",
    "                encoded_input = ensure_tensor_on_device(device, **encoded_input)\n",
    "                model_output = model(**encoded_input)  # Compute token embeddings\n",
    "            context_embeddings = mean_pooling(model_output, mask)  # mean pooling\n",
    "            all_context_embeddings.append(context_embeddings)\n",
    "            \n",
    "        assert len(all_context_embeddings) > 0\n",
    "            \n",
    "        entity_embedding = torch.mean(torch.cat(all_context_embeddings, dim=0), dim=0).cpu().detach().numpy().tolist()\n",
    "        entity_embeddings[entity] = entity_embedding\n",
    "    \n",
    "    return entity_embeddings, ent_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences.json')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "\n",
    "orig_bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed.txt')\n",
    "orig_bert_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum.txt')\n",
    "\n",
    "new_bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "new_bert_emb_num_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembednum+seeds.txt')\n",
    "\n",
    "orig_emb_df = load_embeddings(bert_emb_path, 768)\n",
    "emb_dict = dict(zip(orig_emb_df['entity'].to_list(), orig_emb_df['embedding'].to_list()))\n",
    "\n",
    "with open(orig_bert_emb_num_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    emb_freq_dict = dict([l.strip().rsplit(' ', 1) for l in lines])\n",
    "\n",
    "concepts_df = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "seed_instances_list = [inst for _, (_a_con, _u_con, _gnrl, _seed_instances) in concepts_df.iterrows()\n",
    "                           for inst in _seed_instances]\n",
    "\n",
    "## debug\n",
    "seed_instances_list = seed_instances_list[::10]\n",
    "\n",
    "print(seed_instances_list)\n",
    "\n",
    "entity_embeddings, ent_freq = \\\n",
    "    get_avg_context_embedding_for_entities(entities=seed_instances_list, \n",
    "                                           model_path='bert-base-uncased',\n",
    "                                           input_file=corpus_path,\n",
    "                                           max_context_ct=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "for inst in seed_instances_list:\n",
    "    emb = entity_embeddings[inst]\n",
    "    freq = ent_freq[inst]\n",
    "    if inst in emb_dict:\n",
    "        print(f'Already exists: {inst}')\n",
    "#         assert np.allclose(emb_dict[inst], emb)\n",
    "#         assert emb_freq_dict[inst] == freq, f'{inst}: orig {emb_freq_dict[inst]} != new {freq}'\n",
    "#         print(f'Check passed: {inst}')\n",
    "    else:\n",
    "        emb_dict[inst] = emb\n",
    "        emb_freq_dict[inst] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "entity_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "with open(new_bert_emb_path, 'w') as f, open(new_bert_emb_num_path, 'w') as f2:\n",
    "    for inst in seed_instances_list:\n",
    "        emb = emb_dict[inst]\n",
    "        freq = ent_freq[inst]\n",
    "        f.write(\"{} {}\\n\".format(inst, ' '.join([str(x) for x in emb])))\n",
    "        f2.write(\"{} {}\\n\".format(inst, freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed instances: ['walmart', 'amazon', 'subway', 'microsoft', 'target', 'business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings', 'delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher', 'weekly', 'biweekly', 'friday', 'saturday', 'health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance', 'base pay', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'direct deposit', 'prepaid card', 'drug test', 'criminal background check', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors', 'hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting', 'night shift', 'dinner shift', 'early morning shift', '8 hour shift', 'christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "New instances: ['uniform', 'hair color', 'tattoos', 'shoes', 'cashier', 'weekly', 'biweekly', 'friday', 'saturday', '401k', 'stock options', 'benefits', 'overtime pay', 'bonus', 'checks', 'employment verification', 'felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'pregnant', 'students', 'seniors', '8 hour shift', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend', 'full time', 'part time', 'seasonal', 'orientation', 'introduction', 'training', 'team lunch']\n",
      "loading corpus: 100%|████████████████| 465226/465226 [00:09<00:00, 47556.15it/s]\n",
      "computing entity-wise embedding: 100%|██████████| 36/36 [00:41<00:00,  1.14s/it]\n",
      "Saving embedding\n"
     ]
    }
   ],
   "source": [
    "# Using script\n",
    "\n",
    "!python add_seed_instances_embeddings.py -m bert-base-uncased -et ac -d $base_dir/data/$data_ac/intermediate -b $base_dir/data/indeed-benchmark -c 750\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub_dir = data_ac\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/BERTembed+seeds.txt')\n",
    "\n",
    "embeddings = load_embeddings(bert_emb_path, 768)\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>biweekly</td>\n",
       "      <td>[0.06975648552179337, -0.06970633566379547, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity                                          embedding\n",
       "8023  biweekly  [0.06975648552179337, -0.06970633566379547, 0...."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[embeddings['entity'] == 'biweekly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (X) Other ways of embeddings / clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|██████████| 458/458 [00:00<00:00, 73813.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(175, 175)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/sent_segmentation.txt')\n",
    "ent_freq, dedup_context = get_masked_contexts(input_file_path)\n",
    "len(ent_freq), len(dedup_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [\"we dropped by in hopes of finding atkinson 's peanut_butter bars ( we first tried them from honey salt 's [MASK] bowl ) and after searching a few minutes , we found it .\",\n",
       "  \"if you 're searching for a [MASK] or soda_pop you grew up with and can no longer find , there 's a good chance you 'll find it here .\"])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_freq['candy'], dedup_context['candy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_all_context_embeddings(model_path, input_file, max_context_ct):\n",
    "    '''\n",
    "    Adapted from get_avg_context_embeddings()\n",
    "    keep all context embeddings, using max similarity for knn\n",
    "    :param model_path:\n",
    "    :param input_file:\n",
    "    :return:\n",
    "    '''\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "    ent_freq, ent_context = get_masked_contexts(input_file)\n",
    "    entity_embeddings = {}\n",
    "    for entity, en_context_lst in tqdm(ent_context.items(), total=len(ent_context), desc=\"computing entity-wise embedding\"):\n",
    "        en_context_lst = random.sample(en_context_lst, min(len(en_context_lst), max_context_ct))\n",
    "        chunks = [en_context_lst[i:i + 100] for i in range(0, len(en_context_lst), 100)]\n",
    "        # print(entity)\n",
    "        # print(len(en_context_lst))\n",
    "        all_context_embeddings = []\n",
    "        for chunk in chunks:\n",
    "            encoded_input = tokenizer.batch_encode_plus(chunk, return_token_type_ids=True, add_special_tokens=True, max_length=128, return_tensors='pt', padding=True, pad_to_max_length=True, truncation=True)\n",
    "            mask = encoded_input['input_ids'] != mask_token_id\n",
    "            with torch.no_grad():\n",
    "                encoded_input = ensure_tensor_on_device(device, **encoded_input)\n",
    "                model_output = model(**encoded_input)  # Compute token embeddings\n",
    "            context_embeddings = mean_pooling(model_output, mask)  # mean pooling\n",
    "            # print(context_embeddings.size())\n",
    "            all_context_embeddings.append(context_embeddings)\n",
    "            \n",
    "        # entity_embedding = torch.mean(torch.cat(all_context_embeddings, dim=0), dim=0).cpu().detach().numpy().tolist()\n",
    "        # entity_embeddings[entity] = entity_embedding\n",
    "        entity_embeddings[entity] = torch.cat(all_context_embeddings, dim=0).cpu().detach().numpy().tolist()\n",
    "        \n",
    "    return entity_embeddings, ent_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|██████████| 458/458 [00:00<00:00, 150194.78it/s]\n",
      "computing entity-wise embedding: 100%|██████████| 175/175 [00:04<00:00, 41.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(175, 175)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'bert-base-uncased'\n",
    "input_file_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/sent_segmentation.txt')\n",
    "max_context_ct = 10\n",
    "\n",
    "entity_embeddings, ent_freq = get_all_context_embeddings(model_path, input_file_path, max_context_ct)\n",
    "len(entity_embeddings), len(ent_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_embeddings['candy'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _knn(entity_embeddings, embedding_dim, cluster_size, thread_ct=None, cluster_dest=None, **kwargs):\n",
    "    # entity_embeddings = load_embeddings(embed_src, embedding_dim)\n",
    "    \n",
    "    t = AnnoyIndex(embedding_dim, 'angular')\n",
    "    # entities = entity_embeddings['entity'].tolist()\n",
    "    entities = [f'{entity}-{_i}' for entity, embs in entity_embeddings.items() for _i in range(len(embs))]\n",
    "    # print(entities)\n",
    "    # for i, row in tqdm(entity_embeddings.iterrows(), total=entity_embeddings.shape[0], desc=\"building entity index\"):\n",
    "    #     t.add_item(i, row['embedding'])\n",
    "    i = 0\n",
    "    for entity, embs in tqdm(entity_embeddings.items(), total=len(entity_embeddings)):\n",
    "        for emb in embs:\n",
    "            t.add_item(i, emb)\n",
    "            i += 1\n",
    "    assert i == len(entities)\n",
    "    \n",
    "    t.build(100)\n",
    "    \n",
    "    neighbors = []\n",
    "    for i, entity in enumerate(tqdm(entities, desc=\"finding nearest neighbors by entity\")):\n",
    "        # print(i, entity)\n",
    "        nns, dists = t.get_nns_by_item(i, cluster_size + 1, include_distances=True)\n",
    "        cos_sim_scores = [(2 - d ** 2) / 2 for d in dists]  # convert angular distance to cosine similarity\n",
    "        zipped = list(zip(nns, cos_sim_scores))\n",
    "        sorted_nns = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "        if len(sorted_nns) > 0:\n",
    "            for nn_idx, d in sorted_nns:\n",
    "                neighbor_entity = entities[nn_idx]\n",
    "                if neighbor_entity == entity:\n",
    "                    continue\n",
    "                neighbors.append({\"entity\": entity, \"neighbor\": neighbor_entity, \"sim\": d})\n",
    "    c_df = pd.DataFrame(neighbors)\n",
    "    return c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 24854.50it/s]\n",
      "finding nearest neighbors by entity: 100%|██████████| 269/269 [00:00<00:00, 6006.44it/s]\n"
     ]
    }
   ],
   "source": [
    "knn_results = _knn(entity_embeddings, 768, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = 'meat'\n",
    "\n",
    "df = knn_results\n",
    "\n",
    "n_embs = len(entity_embeddings[query])\n",
    "sub_frames = []\n",
    "for _i in range(n_embs):\n",
    "    ent_name = f'{query}-{_i}'\n",
    "    sub_frames.append(df[df['entity'] == ent_name])\n",
    "\n",
    "pd.concat(sub_frames).sort_values('sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original avg context knn \n",
    "knn_path = os.path.join(base_dir, f'data/{data_sub_dir}/intermediate/knn_100.csv')\n",
    "\n",
    "knn_results = pd.read_csv(knn_path)\n",
    "df = knn_results\n",
    "\n",
    "query = 'walmart'\n",
    "sub_frame = df[df['entity'] == query]\n",
    "sub_frame.sort_values('sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Seed Entities (clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details here: https://github.com/rit-git/meg-kb/tree/main/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "#change to concept learning directory\n",
    "%cd ../../concept_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn sentence-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 100\n",
    "output = '../../data/'+data_ac+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|████████████████| 177/177 [00:00<00:00, 5435.26it/s]\n",
      "finding nearest neighbors by entity: 100%|██| 177/177 [00:00<00:00, 2001.57it/s]\n"
     ]
    }
   ],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_ac/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn token concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 20\n",
    "output = '../../data/'+data_pt+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|████████████████| 177/177 [00:00<00:00, 3661.18it/s]\n",
      "finding nearest neighbors by entity: 100%|██| 177/177 [00:00<00:00, 4052.00it/s]\n"
     ]
    }
   ],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_pt/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 20\n",
    "output = '../../data/'+data_pt+'/intermediate/knn_'+str(clusters)+'.csv'\n",
    "dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python compute_concept_clusters.py -d ../../data/$data_corel/intermediate/ -ca knn -s $clusters -dim $dim -o $output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit here: /meg_shared_scripts/meg-kb/src/analysis/concept_learning-test.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed instances clustering\n",
    "(using all seed instances of a concept to find neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_concept_knn(embed_src, embedding_dim, seed_aligned_concept_src, cluster_size, thread_ct, cluster_dest, **kwargs):\n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concept_src)\n",
    "    \n",
    "    entity_embeddings = load_embeddings(embed_src, embedding_dim)\n",
    "    t = AnnoyIndex(embedding_dim, 'angular')\n",
    "    entities = entity_embeddings['entity'].tolist()\n",
    "    for i, row in tqdm(entity_embeddings.iterrows(), total=entity_embeddings.shape[0], desc=\"building entity index\"):\n",
    "        t.add_item(i, row['embedding'])\n",
    "    t.build(100)\n",
    "    \n",
    "    entity_emb_dict = dict(zip(entities, entity_embeddings['embedding'].tolist()))\n",
    "\n",
    "    neighbors = []\n",
    "    for i, (a_concept, u_concept, gnrl, seed_instances) in tqdm(seed_concepts_df.iterrows(), desc=\"finding nearest neighbors by concept\"):\n",
    "        embs = []\n",
    "        for inst in seed_instances:\n",
    "            try:\n",
    "                embs.append(entity_emb_dict[inst])\n",
    "            except KeyError:\n",
    "                print(f\"{inst} not found in entity_emb_dict??\")\n",
    "                continue\n",
    "        if len(embs) == 0:\n",
    "            continue\n",
    "        concept_emb = np.mean(embs, axis=0)\n",
    "        \n",
    "        nns, dists = t.get_nns_by_vector(concept_emb, cluster_size + 1, include_distances=True)\n",
    "        cos_sim_scores = [(2 - d ** 2) / 2 for d in dists]  # convert angular distance to cosine similarity\n",
    "        zipped = list(zip(nns, cos_sim_scores))\n",
    "        sorted_nns = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
    "        if len(sorted_nns) > 0:\n",
    "            for nn_idx, d in sorted_nns:\n",
    "                neighbor_entity = entities[nn_idx]\n",
    "                if neighbor_entity in seed_instances:\n",
    "                    continue\n",
    "                neighbors.append({\"concept\": a_concept, \"neighbor\": neighbor_entity, \"sim\": d})\n",
    "    c_df = pd.DataFrame(neighbors)\n",
    "    c_df.to_csv(cluster_dest, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "cluster_size = 1000\n",
    "\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_{cluster_size}.csv')\n",
    "\n",
    "get_concept_knn(embed_src=bert_emb_path,\n",
    "            embedding_dim=768,\n",
    "            seed_aligned_concept_src=seed_aligned_concepts_path,\n",
    "            cluster_size=1000,\n",
    "            thread_ct=1,\n",
    "            cluster_dest=concept_knn_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/efs/shared/meg_shared_scripts/meg-kb/src/concept_learning\n"
     ]
    }
   ],
   "source": [
    "%cd $base_dir/src/concept_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building entity index: 100%|██████████████| 8053/8053 [00:01<00:00, 6459.29it/s]\n",
      "finding nearest neighbors by concept: 14it [00:00, 115.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use script\n",
    "# cluster_size = 1000\n",
    "!python compute_concept_seeds_knn.py -d $base_dir/data/$data_ac/intermediate -b $base_dir/data/indeed-benchmark -s 1000 -o $base_dir/data/$data_ac/intermediate/concept_knn_1000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company</td>\n",
       "      <td>wal mart</td>\n",
       "      <td>0.997038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company</td>\n",
       "      <td>costco</td>\n",
       "      <td>0.997013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>publix</td>\n",
       "      <td>0.996753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>company</td>\n",
       "      <td>walgreens</td>\n",
       "      <td>0.996623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "      <td>kroger</td>\n",
       "      <td>0.996477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>company</td>\n",
       "      <td>home depot</td>\n",
       "      <td>0.996124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>company</td>\n",
       "      <td>sam 's club</td>\n",
       "      <td>0.995978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>company</td>\n",
       "      <td>dollar general</td>\n",
       "      <td>0.995846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>company</td>\n",
       "      <td>family dollar</td>\n",
       "      <td>0.995645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>company</td>\n",
       "      <td>jcpenney</td>\n",
       "      <td>0.995513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   concept        neighbor       sim\n",
       "0  company        wal mart  0.997038\n",
       "1  company          costco  0.997013\n",
       "2  company          publix  0.996753\n",
       "3  company       walgreens  0.996623\n",
       "4  company          kroger  0.996477\n",
       "5  company      home depot  0.996124\n",
       "6  company     sam 's club  0.995978\n",
       "7  company  dollar general  0.995846\n",
       "8  company   family dollar  0.995645\n",
       "9  company        jcpenney  0.995513"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results \n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_{cluster_size}.csv')\n",
    "\n",
    "df = pd.read_csv(concept_knn_path)\n",
    "df[df['concept'] == 'company'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>sunday</td>\n",
       "      <td>0.989753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0.989047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>7 days</td>\n",
       "      <td>0.984987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>part time</td>\n",
       "      <td>0.984129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>8 hour shift</td>\n",
       "      <td>0.982685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>bonus</td>\n",
       "      <td>0.981976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>full time</td>\n",
       "      <td>0.981485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>0.979928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>training</td>\n",
       "      <td>0.978852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>pay_schedule</td>\n",
       "      <td>orientation</td>\n",
       "      <td>0.978359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           concept      neighbor       sim\n",
       "2985  pay_schedule        sunday  0.989753\n",
       "2986  pay_schedule       weekend  0.989047\n",
       "2987  pay_schedule        7 days  0.984987\n",
       "2988  pay_schedule     part time  0.984129\n",
       "2989  pay_schedule  8 hour shift  0.982685\n",
       "2990  pay_schedule         bonus  0.981976\n",
       "2991  pay_schedule     full time  0.981485\n",
       "2992  pay_schedule      seasonal  0.979928\n",
       "2993  pay_schedule      training  0.978852\n",
       "2994  pay_schedule   orientation  0.978359"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(concept_knn_path)\n",
    "df[df['concept'] == 'pay_schedule'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM probs correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')\n",
    "\n",
    "# with open(corpus_path, 'r') as f:\n",
    "#     sent_dicts = [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading corpus: 100%|██████████| 465226/465226 [00:01<00:00, 264452.90it/s]\n"
     ]
    }
   ],
   "source": [
    "input_file_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sent_segmentation.txt')\n",
    "ent_freq, dedup_context = get_masked_contexts(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dedup_context['health insurance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dedup_context['sick leave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7973"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = list(ent_freq.keys())\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2334, 4086, 1126, 319, 54]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ents_tokenized = [tuple(lm_probe.tokenizer.tokenize(e)) for e in entities]\n",
    "all_ents_tokenized = list(set(all_ents_tokenized))\n",
    "[sum([len(e_t) == _l for e_t in all_ents_tokenized]) for _l in (1,2,3,4,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: use geo-avg instead of prod for scoring \n",
    "## TODO: collect contexts from both sides (base / expansion) \n",
    "\n",
    "def entity_expansion_multiways(entity, \n",
    "                               contexts=None, \n",
    "                               all_ents_tokenized=all_ents_tokenized, \n",
    "                               lm_probe=lm_probe, \n",
    "                               top_k=300):\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    if contexts is None:\n",
    "        contexts = dedup_context[entity]\n",
    "    \n",
    "    entity2probs = defaultdict(list)\n",
    "\n",
    "    for _context in tqdm(contexts[:50]):\n",
    "        for n_grams in (1, 2, 3):\n",
    "            _ctxt = _context.replace('[MASK]', '[MASK]' + ' [MASK]' * (n_grams-1))\n",
    "            _ctxt = '[CLS] ' + _ctxt + ' [SEP]'\n",
    "            _cands = [e_t for e_t in all_ents_tokenized if len(e_t) == n_grams]\n",
    "            _cand_scores = lm_probe.score_candidates(_ctxt, _cands)\n",
    "\n",
    "            for _d in _cand_scores:\n",
    "                _c = ' '.join(_d['cand']).replace(' ##', '')\n",
    "                _s = _d['score']\n",
    "                entity2probs[_c].append(_s)\n",
    "    \n",
    "#     print('entity2probs:', len(entity2probs), len(entity2probs[entity]))\n",
    "    for _e, _ss in entity2probs.items():\n",
    "        assert len(_ss) == len(entity2probs[entity]), \\\n",
    "            f'entity: {_e} | {lm_probe.tokenizer.tokenize(_e)}; len(_ss): {len(_ss)}'\n",
    "    \n",
    "    _target_ss = entity2probs[entity]\n",
    "    _target_ss = _target_ss / np.sum(_target_ss)\n",
    "    \n",
    "    mean_l = [(_e, np.mean(_ss)) for _e, _ss in entity2probs.items()]\n",
    "    mean_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "    kl_l = [(_e, entropy(_target_ss, _ss)) for _e, _ss in entity2probs.items()]\n",
    "    kl_l.sort(key=lambda p : p[-1], reverse=False)\n",
    "    pearson_l = [(_e, pearsonr(_target_ss, _ss)[0]) for _e, _ss in entity2probs.items()]\n",
    "    pearson_l.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    mean_set = set([_e for _e, _s in mean_l[:top_k]])\n",
    "    kl_set = set([_e for _e, _s in kl_l[:top_k]])\n",
    "    pearson_set = set([_e for _e, _s in pearson_l[:top_k]])\n",
    "    \n",
    "    return mean_set, kl_set, pearson_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccda2abc479544b4b02d4312f9a73bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_entity = 'health insurance'\n",
    "mean_set, kl_set, pearson_set = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_set & kl_set & pearson_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bank',\n",
       " 'basic',\n",
       " 'cancer',\n",
       " 'community',\n",
       " 'disability',\n",
       " 'family',\n",
       " 'federal',\n",
       " 'general',\n",
       " 'government',\n",
       " 'health',\n",
       " 'health insurance',\n",
       " 'healthcare',\n",
       " 'insurance',\n",
       " 'life insurance',\n",
       " 'marriage',\n",
       " 'medical',\n",
       " 'medical insurance',\n",
       " 'mortgage',\n",
       " 'pregnancy',\n",
       " 'private',\n",
       " 'property',\n",
       " 'public',\n",
       " 'social life',\n",
       " 'state'}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_set & pearson_set & kl_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_grams: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56013b1717c04c8cbb544c779f665e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=95.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_entity = 'black jeans'\n",
    "mean_set, kl_set, pearson_set = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,\n",
       " {'beige pants',\n",
       "  'bermuda shorts',\n",
       "  'black church',\n",
       "  'black dress',\n",
       "  'black jeans',\n",
       "  'black pants',\n",
       "  'black polo',\n",
       "  'black slip',\n",
       "  'black tennis',\n",
       "  'black tie',\n",
       "  'blue collar',\n",
       "  'blue denim',\n",
       "  'blue hair',\n",
       "  'blue jacket',\n",
       "  'blue jean',\n",
       "  'blue jeans',\n",
       "  'blue polo',\n",
       "  'blue shield',\n",
       "  'brown apron',\n",
       "  'brown pants',\n",
       "  'brown shoes',\n",
       "  'casual clothes',\n",
       "  'colored hair',\n",
       "  'colored jeans',\n",
       "  'colored pants',\n",
       "  'colored shoes',\n",
       "  'dark jeans',\n",
       "  'dark pants',\n",
       "  'denim jeans',\n",
       "  'dress pants',\n",
       "  'dress slacks',\n",
       "  'green polo',\n",
       "  'hot pockets',\n",
       "  'jean pants',\n",
       "  'nice jeans',\n",
       "  'orange apron',\n",
       "  'orange shirt',\n",
       "  'pink hair',\n",
       "  'purple hair',\n",
       "  'purple heart',\n",
       "  'red button',\n",
       "  'red carpet',\n",
       "  'red cross',\n",
       "  'red hair',\n",
       "  'red jacket',\n",
       "  'red polo',\n",
       "  'red robin',\n",
       "  'red shirt',\n",
       "  'red square',\n",
       "  'red tape',\n",
       "  'redbook',\n",
       "  'ripped jeans',\n",
       "  'skinny jeans',\n",
       "  'sweat pants',\n",
       "  'tan pants',\n",
       "  'wear jeans',\n",
       "  'white bread',\n",
       "  'white button',\n",
       "  'white city',\n",
       "  'white collar',\n",
       "  'white paper',\n",
       "  'white polo',\n",
       "  'white trash',\n",
       "  'yellow pages'})"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_set & kl_set & pearson_set), mean_set & kl_set & pearson_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_grams: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dffec789212489c8db103ccdc08d1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_entity = 'walmart'\n",
    "mean_set, kl_set, pearson_set = entity_expansion_multiways(_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, {'apple store', 'general store'})"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_set & kl_set & pearson_set), mean_set & kl_set & pearson_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_set & kl_set), mean_set & kl_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_set & pearson_set), mean_set & pearson_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pearson_set & kl_set), pearson_set & kl_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity expansion evaluation\n",
    "Now using benchmark entities, mean reciprocal rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['company', 'dress_code', 'job_position', 'pay_schedule', 'benefits', 'compensation', 'payment_option', 'background_screening', 'person', 'hire_prerequisite', 'shifts', 'schedule', 'employee_type', 'onboarding_steps']\n",
      "['has_pay_schedule', 'has_pay_schedule', 'has_dress_code', 'has_dress_code', 'has_background_screening', 'has_benefits', 'has_benefits', 'hires_person', 'has_compensation', 'has_compensation', 'has_hire_prerequisite', 'operates_on', 'hires_employee_type', 'has_onboarding_steps', 'has_shifts', 'has_shifts', 'has_job_position', 'has_hiring_policy', 'has_payment_option']\n",
      "{'dress_code', 'shifts', 'job_position', 'background_screening', 'hire_prerequisite', 'onboarding_steps', 'payment_option', 'benefits', 'employee_type', 'schedule', 'compensation', 'company', 'pay_schedule', 'person'}\n",
      "(706, 16)\n"
     ]
    }
   ],
   "source": [
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')\n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "\n",
    "seed_aligned_concepts = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "seed_aligned_relations = load_seed_aligned_relations(seed_aligned_relations_path)\n",
    "benchmark = pd.read_csv(benchmark_path)\n",
    "concept_knn = pd.read_csv(concept_knn_path)\n",
    "\n",
    "print(seed_aligned_concepts['alignedCategoryName'].tolist())\n",
    "print(seed_aligned_relations['alignedRelationName'].tolist())\n",
    "print(set(concept_knn['concept'].tolist()))\n",
    "print(benchmark.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: company / company\n",
      "seeds: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "{\n",
      "    \"burger king\": 32,\n",
      "    \"subway\": -1,\n",
      "    \"tim hortons\": 97,\n",
      "    \"dunkin donuts\": 43,\n",
      "    \"home depot\": 6,\n",
      "    \"chipotle\": 44,\n",
      "    \"target\": -1,\n",
      "    \"family dollar\": 9,\n",
      "    \"training\": NaN,\n",
      "    \"planet fitness\": 52,\n",
      "    \"walgreens\": 4,\n",
      "    \"company\": 54,\n",
      "    \"pizza hut\": 11,\n",
      "    \"primark\": 121,\n",
      "    \"wendys\": NaN,\n",
      "    \"bonus\": NaN,\n",
      "    \"tj maxx\": 45,\n",
      "    \"hobby lobby\": 18,\n",
      "    \"kroger\": 5,\n",
      "    \"mcdonald\": 55,\n",
      "    \"panera\": NaN,\n",
      "    \"ups\": NaN,\n",
      "    \"fedex\": 40,\n",
      "    \"frito lay\": 42,\n",
      "    \"whataburger\": NaN,\n",
      "    \"amazon.com\": NaN,\n",
      "    \"dd\": 61,\n",
      "    \"costco\": 2,\n",
      "    \"pepsico\": 30,\n",
      "    \"extensive background checks\": 606,\n",
      "    \"dollar tree\": 15,\n",
      "    \"cvs\": 29,\n",
      "    \"lowes\": NaN,\n",
      "    \"marshalls\": 26,\n",
      "    \"safeway\": 17,\n",
      "    \"electric\": NaN,\n",
      "    \"amazon\": -1,\n",
      "    \"ihop\": 39,\n",
      "    \"heb\": NaN,\n",
      "    \"taco bell\": 25,\n",
      "    \"extensive background check\": NaN,\n",
      "    \"olive garden\": 28,\n",
      "    \"starbucks\": 12,\n",
      "    \"dollar general\": 8,\n",
      "    \"g4s\": 48,\n",
      "    \"walmart\": -1,\n",
      "    \"chilis\": 88,\n",
      "    \"mcdonalds\": 24,\n",
      "    \"subways\": NaN,\n",
      "    \"pepsi\": 35,\n",
      "    \"frito\": NaN,\n",
      "    \"petsmart\": 33,\n",
      "    \"instacart\": NaN\n",
      "}\n",
      "MRR: 0.04671939343074806\n",
      "\n",
      "Concept: dress_code / dress code\n",
      "seeds: ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\n",
      "{\n",
      "    \"center\": 719,\n",
      "    \"color hair\": 6,\n",
      "    \"shoes\": -1,\n",
      "    \"piercings\": -1,\n",
      "    \"business casual\": -1,\n",
      "    \"unnatural colored hair\": 182,\n",
      "    \"steel toe\": 152,\n",
      "    \"hat\": NaN,\n",
      "    \"non slip shoes\": NaN,\n",
      "    \"uniforms\": NaN,\n",
      "    \"polo shirts\": NaN,\n",
      "    \"resistant shoes\": NaN,\n",
      "    \"unnatural hair colors\": NaN,\n",
      "    \"black slacks\": NaN,\n",
      "    \"uniform policy\": 28,\n",
      "    \"brown pants\": NaN,\n",
      "    \"casual\": NaN,\n",
      "    \"red shirts\": NaN,\n",
      "    \"skirts\": NaN,\n",
      "    \"dress pants\": NaN,\n",
      "    \"scrubs\": 64,\n",
      "    \"uniform\": -1,\n",
      "    \"hats\": NaN,\n",
      "    \"blue collar\": NaN,\n",
      "    \"black jeans\": NaN,\n",
      "    \"hairnets\": NaN,\n",
      "    \"casual dress code\": NaN,\n",
      "    \"colorful hair\": 7,\n",
      "    \"dress shirts\": NaN,\n",
      "    \"fake nails\": 25,\n",
      "    \"shirt\": NaN,\n",
      "    \"lab coats\": 242,\n",
      "    \"unnatural hair color\": NaN,\n",
      "    \"shorts\": NaN,\n",
      "    \"tags\": NaN,\n",
      "    \"dress codes\": 47,\n",
      "    \"steel toed boots\": NaN,\n",
      "    \"tattoos\": -1,\n",
      "    \"ponytail\": NaN,\n",
      "    \"uniform shirts\": 129,\n",
      "    \"wear shorts\": NaN,\n",
      "    \"wear jeans\": NaN,\n",
      "    \"jewelry\": NaN,\n",
      "    \"shirts\": NaN,\n",
      "    \"acrylic nails\": 5,\n",
      "    \"attire\": NaN,\n",
      "    \"facial piercings\": 10,\n",
      "    \"facial hair\": -1,\n",
      "    \"hair net\": NaN,\n",
      "    \"pants\": NaN,\n",
      "    \"strict dress code\": 14,\n",
      "    \"nose rings\": 36,\n",
      "    \"hair color\": -1,\n",
      "    \"natural colored hair\": 57,\n",
      "    \"t shirt\": NaN,\n",
      "    \"dress code\": 1,\n",
      "    \"vest\": NaN,\n",
      "    \"mustaches\": NaN,\n",
      "    \"professional\": 18,\n",
      "    \"wear fake nails\": NaN,\n",
      "    \"dyed hair\": 45,\n",
      "    \"hair colors\": NaN,\n",
      "    \"natural colors\": 44,\n",
      "    \"jeans\": NaN,\n",
      "    \"face tattoos\": 40,\n",
      "    \"black pants\": NaN,\n",
      "    \"tag\": NaN\n",
      "}\n",
      "MRR: 0.033162389886330405\n",
      "\n",
      "Concept: job_position / job position\n",
      "seeds: ['delivery driver', 'store manager', 'cashier', 'package handler', 'sales associate', 'barista', 'dishwasher']\n",
      "{\n",
      "    \"position\": NaN,\n",
      "    \"entry level positions\": NaN,\n",
      "    \"job\": NaN,\n",
      "    \"company\": 89,\n",
      "    \"shift leader\": 11,\n",
      "    \"managers\": NaN,\n",
      "    \"management\": 31,\n",
      "    \"server\": NaN,\n",
      "    \"servers\": NaN,\n",
      "    \"district manager\": 85,\n",
      "    \"cashiers\": NaN,\n",
      "    \"delivery driver\": -1,\n",
      "    \"store manager\": -1,\n",
      "    \"manager\": 16,\n",
      "    \"walkers\": NaN,\n",
      "    \"crew members\": 29,\n",
      "    \"housekeeper\": NaN,\n",
      "    \"associates\": NaN,\n",
      "    \"package handler\": -1,\n",
      "    \"cashier\": -1,\n",
      "    \"contractor\": NaN,\n",
      "    \"truck drivers\": NaN,\n",
      "    \"assistant manager\": 4\n",
      "}\n",
      "MRR: 0.025955293420233807\n",
      "\n",
      "Concept: pay_schedule / pay period\n",
      "seeds: ['weekly', 'biweekly', 'friday', 'saturday']\n",
      "{\n",
      "    \"friday\": -1,\n",
      "    \"payday\": 62,\n",
      "    \"sundays\": NaN,\n",
      "    \"tuesday\": NaN,\n",
      "    \"payment\": NaN,\n",
      "    \"tuesdays\": NaN,\n",
      "    \"payed biweekly\": NaN,\n",
      "    \"pay period\": 47,\n",
      "    \"bi weekly\": 33,\n",
      "    \"paydays\": NaN,\n",
      "    \"weeks\": NaN,\n",
      "    \"paid bi weekly\": NaN,\n",
      "    \"paychecks\": NaN,\n",
      "    \"paid biweekly\": NaN,\n",
      "    \"pay periods\": 57,\n",
      "    \"pay\": NaN,\n",
      "    \"paid weekly\": 752,\n",
      "    \"week\": NaN,\n",
      "    \"weekly\": -1,\n",
      "    \"fridays\": NaN,\n",
      "    \"period\": 88,\n",
      "    \"biweekly\": -1\n",
      "}\n",
      "MRR: 0.00515504955539881\n",
      "\n",
      "Concept: benefits / benefits\n",
      "seeds: ['health insurance', 'flexible schedule', '401k', 'paid vacation', 'sick leave', 'vision insurance']\n",
      "{\n",
      "    \"discounts\": NaN,\n",
      "    \"health coverage\": NaN,\n",
      "    \"monthly bonus\": 456,\n",
      "    \"schooling\": NaN,\n",
      "    \"sick days\": 8,\n",
      "    \"vacations\": NaN,\n",
      "    \"tuition\": NaN,\n",
      "    \"health insurance\": -1,\n",
      "    \"pto\": NaN,\n",
      "    \"sick leave\": -1,\n",
      "    \"health\": 5,\n",
      "    \"healthcare\": 2,\n",
      "    \"bonus\": NaN,\n",
      "    \"vacation\": NaN,\n",
      "    \"life insurance\": 9,\n",
      "    \"tuition assistance\": 26,\n",
      "    \"relocate\": NaN,\n",
      "    \"pension\": 11,\n",
      "    \"401k plan\": 12,\n",
      "    \"paid vacations\": 7,\n",
      "    \"bonuses\": NaN,\n",
      "    \"breakfast\": NaN,\n",
      "    \"health benefits\": NaN,\n",
      "    \"discount\": NaN,\n",
      "    \"tuition reimbursement\": 15,\n",
      "    \"retirement\": NaN,\n",
      "    \"tips\": NaN,\n",
      "    \"health plans\": NaN,\n",
      "    \"stock options\": NaN,\n",
      "    \"free lunch\": NaN,\n",
      "    \"401k\": -1,\n",
      "    \"great benefits\": 22,\n",
      "    \"relocation\": NaN,\n",
      "    \"benefits\": NaN,\n",
      "    \"retirement plan\": 21,\n",
      "    \"stock option\": NaN,\n",
      "    \"prescription drugs\": 538,\n",
      "    \"health care\": 4,\n",
      "    \"401 k\": 59\n",
      "}\n",
      "MRR: 0.047844815207513026\n",
      "\n",
      "Concept: compensation / compensation\n",
      "seeds: ['base pay', 'stock options', 'benefits', 'overtime pay', 'bonus']\n",
      "{\n",
      "    \"compensation\": NaN,\n",
      "    \"benefits\": -1,\n",
      "    \"benfits\": NaN\n",
      "}\n",
      "MRR: 0.0\n",
      "\n",
      "Concept: payment_option / nan\n",
      "seeds: ['checks', 'direct deposit', 'prepaid card']\n",
      "{\n",
      "    \"check\": NaN,\n",
      "    \"prepaid card\": -1,\n",
      "    \"paycheck\": 8,\n",
      "    \"paper checks\": NaN,\n",
      "    \"direct deposit\": -1,\n",
      "    \"direct deposits\": 9,\n",
      "    \"checks\": -1\n",
      "}\n",
      "MRR: 0.059027777777777776\n",
      "\n",
      "Concept: background_screening / background screening\n",
      "seeds: ['drug test', 'criminal background check', 'employment verification']\n",
      "{\n",
      "    \"criminal background\": 6,\n",
      "    \"alcohol\": 411,\n",
      "    \"credit score\": 30,\n",
      "    \"previously worked\": NaN,\n",
      "    \"drug test\": -1,\n",
      "    \"urinalysis\": 10,\n",
      "    \"cannabis\": 326,\n",
      "    \"social media\": 85,\n",
      "    \"drug tested\": NaN,\n",
      "    \"credit check\": 4,\n",
      "    \"driving record\": 13,\n",
      "    \"credit report\": 35,\n",
      "    \"screening\": NaN,\n",
      "    \"swab\": NaN,\n",
      "    \"swab test\": 21,\n",
      "    \"cheek swab\": 91,\n",
      "    \"urine\": 138,\n",
      "    \"backround check\": 16,\n",
      "    \"previous employer\": 360,\n",
      "    \"drug screened\": NaN,\n",
      "    \"mouth\": NaN,\n",
      "    \"saliva drug test\": 208,\n",
      "    \"background report\": 481,\n",
      "    \"mouth swab\": 824,\n",
      "    \"drug screen\": NaN,\n",
      "    \"screening process\": 103,\n",
      "    \"previous jobs\": 114,\n",
      "    \"urine drug screen\": NaN,\n",
      "    \"urine test\": 5,\n",
      "    \"mouth swap\": NaN,\n",
      "    \"criminal records\": 33,\n",
      "    \"drug\": 45,\n",
      "    \"drug testing\": NaN,\n",
      "    \"backround\": NaN,\n",
      "    \"mouth swabs\": NaN,\n",
      "    \"previous employers\": 323,\n",
      "    \"criminal history\": 3,\n",
      "    \"testing\": NaN,\n",
      "    \"drug screening\": NaN,\n",
      "    \"saliva\": NaN,\n",
      "    \"urine testing\": NaN,\n",
      "    \"drugs\": 84,\n",
      "    \"criminal record\": 29,\n",
      "    \"drug screens\": NaN,\n",
      "    \"drugged tested\": NaN,\n",
      "    \"urine tests\": 48,\n",
      "    \"dui\": 88,\n",
      "    \"previous employment\": 36,\n",
      "    \"saliva test\": 47,\n",
      "    \"criminal background check\": -1,\n",
      "    \"backgrounds\": NaN,\n",
      "    \"drug tests\": 18,\n",
      "    \"urine drug test\": 11,\n",
      "    \"hair sample\": NaN,\n",
      "    \"random drug testing\": 15,\n",
      "    \"social security\": 185,\n",
      "    \"backround checks\": 322,\n",
      "    \"random drug test\": 25,\n",
      "    \"credit history\": 212,\n",
      "    \"drug text\": NaN,\n",
      "    \"random tests\": 56,\n",
      "    \"blood test\": 595,\n",
      "    \"background check\": 2,\n",
      "    \"random drug tests\": 28,\n",
      "    \"urine sample\": NaN,\n",
      "    \"hair follicle test\": 66,\n",
      "    \"criminal background checks\": NaN,\n",
      "    \"screen\": NaN,\n",
      "    \"social security number\": 72,\n",
      "    \"background checks\": 19,\n",
      "    \"test\": 9,\n",
      "    \"credit checks\": 79,\n",
      "    \"criminal backgrounds\": 328,\n",
      "    \"follicle test\": NaN,\n",
      "    \"pre employment drug screening\": NaN\n",
      "}\n",
      "MRR: 0.035303669471386794\n",
      "\n",
      "Concept: person / nan\n",
      "seeds: ['felons', 'criminals', 'disabled', 'drug addicts', 'high schoolers', 'misdemeanor', 'pregnant', 'students', 'seniors']\n",
      "{\n",
      "    \"senior citizens\": 25,\n",
      "    \"ex felons\": 191,\n",
      "    \"seniors\": -1,\n",
      "    \"drug addicts\": -1,\n",
      "    \"seniority\": NaN,\n",
      "    \"misdemeanor charges\": NaN,\n",
      "    \"high schoolers\": -1,\n",
      "    \"school students\": NaN,\n",
      "    \"high school students\": NaN,\n",
      "    \"convicted felons\": 168,\n",
      "    \"felons\": -1,\n",
      "    \"high school\": 309,\n",
      "    \"felonys\": NaN,\n",
      "    \"felony record\": NaN,\n",
      "    \"sex offenders\": 869,\n",
      "    \"disabilities\": NaN,\n",
      "    \"felonies\": 289,\n",
      "    \"high school graduate\": NaN,\n",
      "    \"disabled\": -1,\n",
      "    \"schoolers\": NaN,\n",
      "    \"misdemeanor theft\": NaN,\n",
      "    \"misdemeanor\": -1,\n",
      "    \"pregnant\": -1,\n",
      "    \"criminals\": -1,\n",
      "    \"felony\": 642,\n",
      "    \"pregnant women\": 75\n",
      "}\n",
      "MRR: 0.004107008351780519\n",
      "\n",
      "Concept: hire_prerequisite / qualification\n",
      "seeds: ['hiring age', 'bachelors degree', 'prior experience', 'working permit', 'heavy lifting']\n",
      "{\n",
      "    \"gpa\": NaN,\n",
      "    \"workers permit\": 775,\n",
      "    \"degrees\": NaN,\n",
      "    \"bachelor degree\": 106,\n",
      "    \"hs diploma\": NaN,\n",
      "    \"high school diploma\": 182,\n",
      "    \"college degree\": 3,\n",
      "    \"working permit\": -1,\n",
      "    \"high school education\": 6,\n",
      "    \"diploma\": 34,\n",
      "    \"ged\": 537,\n",
      "    \"birth certificate\": NaN\n",
      "}\n",
      "MRR: 0.049772068403464334\n",
      "\n",
      "Concept: shifts / work shift\n",
      "seeds: ['night shift', 'dinner shift', 'early morning shift', '8 hour shift']\n",
      "{\n",
      "    \"opening shifts\": 39,\n",
      "    \"weekend shift\": 37,\n",
      "    \"night shifts\": 9,\n",
      "    \"morning shift\": 1,\n",
      "    \"morning shifts\": 5,\n",
      "    \"3rd shift\": 3,\n",
      "    \"12 hour shifts\": 18,\n",
      "    \"open 24 hours\": NaN\n",
      "}\n",
      "MRR: 0.21908350658350662\n",
      "\n",
      "Concept: schedule / nan\n",
      "seeds: ['christmas eve', 'early morning', 'hoilday', '7 days', 'saturday', 'sunday', 'weekend']\n",
      "{\n",
      "    \"christmas eve\": -1,\n",
      "    \"early morning\": -1,\n",
      "    \"open 7 days\": NaN,\n",
      "    \"weekends\": NaN,\n",
      "    \"sunday\": -1,\n",
      "    \"federal holidays\": NaN,\n",
      "    \"fridays\": NaN,\n",
      "    \"saturdays\": NaN,\n",
      "    \"saturday\": -1,\n",
      "    \"weekend\": -1,\n",
      "    \"hoildays\": NaN\n",
      "}\n",
      "MRR: 0.0\n",
      "\n",
      "Concept: employee_type / nan\n",
      "seeds: ['full time', 'part time', 'seasonal']\n",
      "{\n",
      "    \"ft\": NaN,\n",
      "    \"seasonals\": NaN,\n",
      "    \"fulltime\": NaN,\n",
      "    \"seasonal employees\": 38,\n",
      "    \"season\": 175,\n",
      "    \"seasonal\": -1,\n",
      "    \"seasonal positions\": 156,\n",
      "    \"seasonal workers\": 53,\n",
      "    \"seasons\": NaN,\n",
      "    \"parttime\": NaN\n",
      "}\n",
      "MRR: 0.006367584014058691\n",
      "\n",
      "Concept: onboarding_steps / onboarding process steps\n",
      "seeds: ['orientation', 'introduction', 'workstation', 'training', 'team lunch']\n",
      "{\n",
      "    \"training program\": 46,\n",
      "    \"orientation\": -1,\n",
      "    \"training classes\": 63,\n",
      "    \"training\": -1\n",
      "}\n",
      "MRR: 0.01880607315389924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, d in seed_aligned_concepts.iterrows():\n",
    "    a_concept = d[\"alignedCategoryName\"]\n",
    "    u_concept = d[\"unalignedCategoryName\"]\n",
    "    seed_instances = d[\"seedInstances\"]\n",
    "\n",
    "    concept_knn_instances = concept_knn[concept_knn[\"concept\"] == a_concept][\"neighbor\"].to_list()\n",
    "    \n",
    "    _b_head_instances = benchmark[benchmark[\"n_head_category\"] == a_concept][\"n_head\"].to_list()\n",
    "    _b_tail_instances = benchmark[benchmark[\"n_tail_category\"] == a_concept][\"n_tail\"].to_list()\n",
    "    benchmark_instances = list(set(_b_head_instances + _b_tail_instances))\n",
    "    \n",
    "    print(f'Concept: {a_concept} / {u_concept}')\n",
    "    print(f'seeds: {seed_instances}')\n",
    "#     print(f'expanded (concept_knn_instances): {concept_knn_instances}')\n",
    "#     print(f'benchmark_instances: {benchmark_instances}')\n",
    "    b_inst_ranks = dict()\n",
    "    recip_ranks = []\n",
    "    for _inst in benchmark_instances:\n",
    "        if _inst in seed_instances:\n",
    "            b_inst_ranks[_inst] = -1\n",
    "        elif _inst in concept_knn_instances:\n",
    "            _rank = concept_knn_instances.index(_inst) + 1\n",
    "            b_inst_ranks[_inst] = _rank\n",
    "            recip_ranks.append(1.0 / _rank)\n",
    "        else:\n",
    "            b_inst_ranks[_inst] = float('nan')\n",
    "            recip_ranks.append(0.0)\n",
    "        \n",
    "    print(json.dumps(b_inst_ranks, indent=4))\n",
    "    print('MRR:', np.mean(recip_ranks))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Extraction Baselines\n",
    "Currently only for has_dress_code. TODO: include all other relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# Imported from lm_probing.ipynb \n",
    "# TODO: for scoring purpose, maybe better to use GPT-2\n",
    "\n",
    "class LMProbe(object):\n",
    "    def __init__(self, model_name='bert-base-uncased', use_gpu=False):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertForMaskedLM.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.mask_token = self.tokenizer.mask_token\n",
    "\n",
    "    def fill_multi_mask(self, input_txt, topk=3):\n",
    "        if not (input_txt.startswith('[CLS]') and input_txt.endswith('[SEP]')):\n",
    "            raise Exception('Input string must start with [CLS] and end with [SEP]')\n",
    "        if not '[MASK]' in input_txt:\n",
    "            raise Exception('Input string must have at least one mask token')\n",
    "        tokenized_txt = self.tokenizer.tokenize(input_txt)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        mask_indices = [i for i, x in enumerate(tokenized_txt) if x == \"[MASK]\"]\n",
    "        segment_idx = tokens_tensor * 0\n",
    "        tokens_tensor = tokens_tensor.to(self.device)\n",
    "        segments_tensors = segment_idx.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.softmax(predictions, dim=-1)[0]\n",
    "        sorted_probs, sorted_idx = probs.sort(dim=-1, descending=True)\n",
    "        sorted_probs = sorted_probs.detach().cpu().numpy()\n",
    "        sorted_idx = sorted_idx.detach().cpu().numpy()\n",
    "\n",
    "        masked_cands = []\n",
    "        for k in range(topk):\n",
    "            predicted_indices = [sorted_idx[i, k].item() for i in mask_indices]\n",
    "            predicted_tokens = self.tokenizer.convert_ids_to_tokens(predicted_indices)\n",
    "            predicted_probs = [sorted_probs[i, k].item() for i in mask_indices]\n",
    "            seq = []\n",
    "            for token_id, token, prob, masked_index in zip(predicted_indices, predicted_tokens, predicted_probs,\n",
    "                                                           mask_indices):\n",
    "                seq.append({\"token\": token_id, \"token_str\": token, \"prob\": prob, \"masked_pos\": masked_index})\n",
    "            masked_cands.append(seq)\n",
    "\n",
    "        return masked_cands\n",
    "    \n",
    "    def score_candidates(self, input_txt, cands):\n",
    "        # cands: List[List[str]], list of tokenized candidates \n",
    "        tokenized_txt = self.tokenizer.tokenize(input_txt)\n",
    "        \n",
    "        if tokenized_txt[0] != \"[CLS]\" or tokenized_txt[-1] != \"[SEP]\":\n",
    "            raise Exception(f'Input string must start with [CLS] and end with [SEP], got {input_txt}')\n",
    "        if \"[MASK]\" not in tokenized_txt:\n",
    "            raise Exception(f'Input string must have at least one mask token, got {input_txt}')\n",
    "        \n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        mask_indices = [i for i, x in enumerate(tokenized_txt) if x == \"[MASK]\"]\n",
    "        segment_idx = tokens_tensor * 0\n",
    "        tokens_tensor = tokens_tensor.to(self.device)\n",
    "        segments_tensors = segment_idx.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.softmax(predictions, dim=-1)[0]\n",
    "        # sorted_probs, sorted_idx = probs.sort(dim=-1, descending=True)\n",
    "        # sorted_probs = sorted_probs.detach().cpu().numpy()\n",
    "        # sorted_idx = sorted_idx.detach().cpu().numpy()\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "\n",
    "        cand_scores = []\n",
    "        for c in cands:\n",
    "            assert len(c) == len(mask_indices), f'cand {c}; len(mask_indices) = {len(mask_indices)}'\n",
    "            \n",
    "            # predicted_indices = [sorted_idx[i, k].item() for i in mask_indices]\n",
    "            # predicted_tokens = self.tokenizer.convert_ids_to_tokens(predicted_indices)\n",
    "            # predicted_probs = [sorted_probs[i, k].item() for i in mask_indices]\n",
    "            _scores = []\n",
    "            c_token_ids = self.tokenizer.convert_tokens_to_ids(c)\n",
    "            for i, token_id in zip(mask_indices, c_token_ids):\n",
    "                _scores.append(probs[i, token_id].item())\n",
    "            score = np.prod(_scores)\n",
    "            cand_scores.append({\"cand\": c, \"score\": score})\n",
    "\n",
    "        cand_scores.sort(key=lambda d : d[\"score\"], reverse=True)\n",
    "        return cand_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "lm_probe = LMProbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Hand-designed. \n",
    "# TODO: mining \n",
    "# TODO: put to a file\n",
    "\n",
    "offers_job_position_templates = [\n",
    "    '{0} hires {1} .',\n",
    "    '{0} is hiring {1} .',\n",
    "    '{0} can hire you as a {1} .',\n",
    "#     'You can get a {1} job at {0} .',\n",
    "#     'Double check with the {1} at {0} .'\n",
    "]\n",
    "\n",
    "has_benefits_templates = [\n",
    "    '{0} offer {1} for their employees.',\n",
    "    '{0} provide {1} for employees.',\n",
    "    '{0} have {1} for their employees.',\n",
    "]\n",
    "\n",
    "has_pay_schedule_templates = [\n",
    "    '{0} pay their employees every {1}',\n",
    "    '{0} has a pay schedule of {1}',\n",
    "    '{0} employees get paid {1}',\n",
    "]\n",
    "\n",
    "has_dress_code_templates = [\n",
    "    '{0} don\\'t allow workers to wear {1}',\n",
    "    '{0} allow workers to wear {1}',\n",
    "    '{0} has a dress code of {1}',\n",
    "    '{0} require employees to wear {1}',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_direct_probing_candidates(templates,\n",
    "                                  lm_probe=None,\n",
    "                                  head_entity=None,\n",
    "                                  tail_entity=None,\n",
    "                                  context=None,\n",
    "                                  topk=10):\n",
    "    '''\n",
    "    Direct probing: let BERT propose possible entities  \n",
    "    :param templates: List[str]: each have 2 slots, {0} for head, {1} for tail \n",
    "    :return: Dict[str, float]: proposed entities and scores \n",
    "    '''\n",
    "    \n",
    "    # ensure given one and propose one \n",
    "    assert (head_entity is None) != (tail_entity is None), f'{head_entity} {tail_entity}'\n",
    "\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    \n",
    "    names_scores = {}\n",
    "    for template in templates:\n",
    "        if head_entity is not None:\n",
    "            # head -> tail \n",
    "            _unigram_template = template.format(head_entity, '[MASK]')\n",
    "            _bigram_template = template.format(head_entity, '[MASK] [MASK]')\n",
    "        else:\n",
    "            # tail -> head \n",
    "            _unigram_template = template.format('[MASK]', tail_entity)\n",
    "            _bigram_template = template.format('[MASK] [MASK]', tail_entity)\n",
    "        \n",
    "        for _template in [_unigram_template, _bigram_template]:\n",
    "            if context:\n",
    "                query = '[CLS] ' + _template + '[SEP]' + context + '[SEP]'\n",
    "            else:\n",
    "                query = '[CLS] ' + _template + '[SEP]'\n",
    "            preds = lm_probe.fill_multi_mask(query, topk=topk)\n",
    "            for pred in preds:\n",
    "                name = ' '.join([p['token_str'] for p in pred])\n",
    "                name = name.replace(' ##', '')\n",
    "                score = np.prod([p['prob'] for p in pred])\n",
    "                scores = names_scores.get(name, [])\n",
    "                scores.append(score)\n",
    "                names_scores[name] = scores\n",
    "                \n",
    "    names_avg_scores = {k: float(sum(v))/ len(v) for k,v in names_scores.items()}\n",
    "    names_avg_scores = {k: v for k, v in sorted(names_avg_scores.items(), reverse=True, key=lambda item: item[1])[:topk]}\n",
    "    return names_avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def direct_probing_RE_v3(seed_aligned_concepts_path,\n",
    "                         seed_aligned_relations_path,\n",
    "                         emb_path,\n",
    "                         concept_knn_path,\n",
    "                         templates,\n",
    "                         lm_probe=None,\n",
    "                         emb_dim=768,\n",
    "                         scores_agg_func=None,\n",
    "                         topk=10,\n",
    "                         save_path=None):\n",
    "    '''\n",
    "    For each head / tail, rank candidate tails / heads by overall scores. \n",
    "    Current (default) overall score: 0.1 * ht_sim + 10 * concept_sim + log(lm_prob)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    seed_concepts_df = load_seed_aligned_concepts(seed_aligned_concepts_path)\n",
    "#     seed_relations_df = pd.read_csv(seed_relations_path)\n",
    "#     seed_relations_df = seed_relations_df.iloc[1]\n",
    "    entity_embeddings = load_embeddings(emb_path, emb_dim)\n",
    "    entity_emb_dict = dict(zip(entity_embeddings['entity'].tolist(),\n",
    "                               entity_embeddings['embedding'].tolist()))\n",
    "    concept_knn_results = pd.read_csv(concept_knn_path)\n",
    "\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    if scores_agg_func is None:\n",
    "        scores_agg_func = lambda ht_sim, concept_sim, lm_prob : 0.1 * ht_sim + 10 * concept_sim + np.log10(lm_prob)\n",
    "    \n",
    "#     head_type = seed_relations_df['domain']\n",
    "#     tail_type = seed_relations_df['range']\n",
    "    ## Just for testing\n",
    "    head_type = \"company\"\n",
    "    tail_type = \"dress_code\"\n",
    "    print(head_type, '\\t', tail_type)\n",
    "    seed_heads = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == head_type]['seedInstances'].item()\n",
    "#     seed_heads = eval(list(seed_heads)[0])\n",
    "    seed_tails = seed_concepts_df[seed_concepts_df['alignedCategoryName'] == tail_type]['seedInstances'].item()\n",
    "#     seed_tails = eval(list(seed_tails)[0])\n",
    "    print('seed_heads:', seed_heads)\n",
    "    print('seed_tails:', seed_tails)\n",
    "\n",
    "    # Candidate heads / tails from concept knn \n",
    "    cand_heads_df = concept_knn_results[concept_knn_results['concept'] == head_type]\n",
    "    cand_tails_df = concept_knn_results[concept_knn_results['concept'] == tail_type]\n",
    "    cand_heads_dict = dict(zip(cand_heads_df['neighbor'].tolist(), cand_heads_df['sim'].tolist()))\n",
    "    cand_tails_dict = dict(zip(cand_tails_df['neighbor'].tolist(), cand_tails_df['sim'].tolist()))\n",
    "    for h in seed_heads:\n",
    "        assert h not in cand_heads_dict\n",
    "        cand_heads_dict[h] = 1.0\n",
    "    for t in seed_tails:\n",
    "        assert t not in cand_tails_dict\n",
    "        cand_tails_dict[t] = 1.0\n",
    "    \n",
    "#     print(cand_heads_dict)\n",
    "#     print(cand_tails_dict)\n",
    "    \n",
    "    all_extraction_results = []\n",
    "    \n",
    "    # head -> tail \n",
    "    for seed_head in seed_heads:\n",
    "        print(f'seed_head: {seed_head}')\n",
    "        extraction_results = []\n",
    "\n",
    "        ## For each tail, extract concept sim, head sim, lm score, combine and report\n",
    "        \n",
    "        cand_bins = {1: [], 2: []} ## TODO: allow higher grams; switch to GPT-2 for fair probs \n",
    "        for c in cand_tails_dict.keys():\n",
    "            c_tokenized = lm_probe.tokenizer.tokenize(c)\n",
    "            if len(c_tokenized) in [1, 2]:\n",
    "                cand_bins[len(c_tokenized)].append(c_tokenized)\n",
    "        \n",
    "        cand_scores_per_template = []\n",
    "        for template in templates:\n",
    "            _unigram_template = '[CLS] ' + template.format(seed_head, '[MASK]') + '[SEP]'\n",
    "            _bigram_template = '[CLS] ' + template.format(seed_head, '[MASK] [MASK]') + '[SEP]'\n",
    "\n",
    "            _cand_scores_1 = lm_probe.score_candidates(_unigram_template, cand_bins[1])\n",
    "            _cand_scores_2 = lm_probe.score_candidates(_bigram_template, cand_bins[2])\n",
    "            _cand_scores = sorted(_cand_scores_1 + _cand_scores_2, key=lambda d : d[\"cand\"])\n",
    "            # List[Dict[\"cand\", \"score\"]]\n",
    "            cand_scores_per_template.append(_cand_scores)\n",
    "    \n",
    "        cand_scores = []  # List[Dict[\"cand\", \"score\"]], for each \"cand\" the average score \n",
    "        for _cand_score_lst in zip(*cand_scores_per_template):\n",
    "            # _cand_score_lst: List[Dict[\"cand\", \"score\"]], for the same \"cand\" and different template \n",
    "            _cand = _cand_score_lst[0][\"cand\"]\n",
    "            assert all(d[\"cand\"] == _cand for d in _cand_score_lst), _cand_score_lst\n",
    "            _score = np.mean([d[\"score\"] for d in _cand_score_lst])\n",
    "            cand_scores.append({\"cand\": _cand, \"score\": _score})\n",
    "#         cand_scores.sort(key = lambda d : d[\"score\"], reverse=True)\n",
    "\n",
    "        for d in cand_scores:\n",
    "            e_tail = ' '.join(d[\"cand\"]).replace(' ##', '')\n",
    "            if e_tail not in cand_tails_dict:\n",
    "                continue\n",
    "\n",
    "            lm_score = d[\"score\"]\n",
    "            try:\n",
    "                ht_sim_score = 1 - cosine(entity_emb_dict[seed_head], entity_emb_dict[e_tail])\n",
    "            except KeyError:\n",
    "                print(f'** embedding of {seed_head}: {(seed_head in entity_emb_dict)}')\n",
    "                print(f'** embedding of {e_tail}: {(e_tail in entity_emb_dict)}')\n",
    "                ht_sim_score = float(\"nan\")\n",
    "            concept_sim_score = cand_tails_dict[e_tail]\n",
    "            overall_score = scores_agg_func(ht_sim_score, concept_sim_score, lm_score)\n",
    "\n",
    "            extraction_results.append({'head': seed_head, 'tail': e_tail, 'base': 'HEAD',\n",
    "                                       'ht_sim_score': ht_sim_score,\n",
    "                                       'concept_sim_score': concept_sim_score,\n",
    "                                       'lm_score': lm_score,\n",
    "                                       'overall_score': overall_score})\n",
    "        \n",
    "        extraction_results.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "        all_extraction_results.extend(extraction_results[:topk])\n",
    "        \n",
    "    # tail -> head \n",
    "    for seed_tail in seed_tails:\n",
    "        print(f'seed_tail: {seed_tail}')\n",
    "        extraction_results = []\n",
    "        \n",
    "        ## For each tail, extract concept sim, head sim, lm score, combine and report\n",
    "        \n",
    "        cand_bins = {1: [], 2: []}\n",
    "        for c in cand_heads_dict.keys():\n",
    "            c_tokenized = lm_probe.tokenizer.tokenize(c)\n",
    "            if len(c_tokenized) in [1, 2]:\n",
    "                cand_bins[len(c_tokenized)].append(c_tokenized)\n",
    "        \n",
    "        cand_scores_per_template = []\n",
    "        for template in templates:\n",
    "            _unigram_template = '[CLS] ' + template.format('[MASK]', seed_tail) + '[SEP]'\n",
    "            _bigram_template = '[CLS] ' + template.format('[MASK] [MASK]', seed_tail) + '[SEP]'\n",
    "\n",
    "            _cand_scores_1 = lm_probe.score_candidates(_unigram_template, cand_bins[1])\n",
    "            _cand_scores_2 = lm_probe.score_candidates(_bigram_template, cand_bins[2])\n",
    "            _cand_scores = sorted(_cand_scores_1 + _cand_scores_2, key=lambda d : d[\"cand\"])\n",
    "            # List[Dict[\"cand\", \"score\"]]\n",
    "            cand_scores_per_template.append(_cand_scores)\n",
    "    \n",
    "        cand_scores = []  # List[Dict[\"cand\", \"score\"]], for each \"cand\" the average score \n",
    "        for _cand_score_lst in zip(*cand_scores_per_template):\n",
    "            # _cand_score_lst: List[Dict[\"cand\", \"score\"]], for the same \"cand\" and different template \n",
    "            _cand = _cand_score_lst[0][\"cand\"]\n",
    "            assert all(d[\"cand\"] == _cand for d in _cand_score_lst), _cand_score_lst\n",
    "            _score = np.mean([d[\"score\"] for d in _cand_score_lst])\n",
    "            cand_scores.append({\"cand\": _cand, \"score\": _score})\n",
    "#         cand_scores.sort(key = lambda d : d[\"score\"], reverse=True)\n",
    "\n",
    "        for d in cand_scores[:topk]:\n",
    "            e_head = ' '.join(d[\"cand\"]).replace(' ##', '')\n",
    "            if e_head not in cand_heads_dict:\n",
    "                continue\n",
    "                \n",
    "            lm_score = d[\"score\"]\n",
    "            try:\n",
    "                ht_sim_score = 1 - cosine(entity_emb_dict[e_head], entity_emb_dict[seed_tail])\n",
    "            except KeyError:\n",
    "                print(f'** embedding of {e_head}: {(e_head in entity_emb_dict)}')\n",
    "                print(f'** embedding of {seed_tail}: {(seed_tail in entity_emb_dict)}')\n",
    "                ht_sim_score = float(\"nan\")\n",
    "            concept_sim_score = cand_heads_dict[e_head]\n",
    "            overall_score = scores_agg_func(ht_sim_score, concept_sim_score, lm_score)\n",
    "        \n",
    "            extraction_results.append({'head': e_head, 'tail': seed_tail, 'base': 'TAIL',\n",
    "                                       'ht_sim_score': ht_sim_score,\n",
    "                                       'concept_sim_score': concept_sim_score,\n",
    "                                       'lm_score': lm_score,\n",
    "                                       'overall_score': overall_score})\n",
    "        \n",
    "        extraction_results.sort(key=lambda d : d['overall_score'], reverse=True)\n",
    "        all_extraction_results.extend(extraction_results[:topk])\n",
    "        \n",
    "    results_df = pd.DataFrame(all_extraction_results)\n",
    "    if save_path is not None:\n",
    "        results_df.to_csv(save_path, index=None)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_concepts.csv')\n",
    "seed_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_relations.csv')\n",
    "seed_aligned_concepts_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_concepts.csv')\n",
    "seed_aligned_relations_path = os.path.join(base_dir, f'data/indeed-benchmark/seed_aligned_relations.csv')\n",
    "# knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/knn_{cluster_size}.csv')\n",
    "concept_knn_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/concept_knn_1000.csv')\n",
    "bert_emb_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/BERTembed+seeds.txt')\n",
    "\n",
    "extraction_save_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "# extraction_save_path = None\n",
    "\n",
    "extraction_results = direct_probing_RE_v3(seed_aligned_concepts_path=seed_aligned_concepts_path,\n",
    "                                          seed_aligned_relations_path=seed_aligned_relations_path,\n",
    "                                          emb_path=bert_emb_path,\n",
    "                                          concept_knn_path=concept_knn_path,\n",
    "                                          templates=has_dress_code_templates,\n",
    "                                          lm_probe=lm_probe,\n",
    "                                          topk=300,\n",
    "                                          save_path=extraction_save_path)\n",
    "\n",
    "extraction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = extraction_results.copy()\n",
    "df[df['head'] == 'walmart'].head(50)\n",
    "# df['overall_score'] = df['ht_sim_score'] * 0.1 + df['concept_sim_score'] * 10 + np.log10(df['lm_score'])\n",
    "# df.sort_values(by='overall_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = extraction_results.copy()\n",
    "df[df['tail'] == 'hair color'].head(50)\n",
    "# df['overall_score'] = df['ht_sim_score'] * 0.1 + df['concept_sim_score'] * 10 + np.log10(df['lm_score'])\n",
    "# df.sort_values(by='overall_score', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "company \t dress_code\n",
      "seed_heads: ['walmart', 'amazon', 'subway', 'microsoft', 'target']\n",
      "seed_tails: ['business casual', 'uniform', 'hair color', 'tattoos', 'facial hair', 'shoes', 'piercings']\n",
      "seed_head: walmart\n",
      "seed_head: amazon\n",
      "seed_head: subway\n",
      "seed_head: microsoft\n",
      "seed_head: target\n",
      "seed_tail: business casual\n",
      "seed_tail: uniform\n",
      "seed_tail: hair color\n",
      "seed_tail: tattoos\n",
      "seed_tail: facial hair\n",
      "seed_tail: shoes\n",
      "seed_tail: piercings\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python relation_extraction_avg_scores.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/rel_extraction_2.csv \\\n",
    "-cknn $base_dir/data/$data_ac/intermediate/concept_knn_1000.csv \\\n",
    "-topk 300 \\\n",
    "-dim 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation \n",
    "\n",
    "def load_benchmark_relations(benchmark_path):\n",
    "    '''Currently only has_dress_code.'''\n",
    "    benchmark = pd.read_csv(benchmark_path)\n",
    "    \n",
    "    # List[Dict[head, tail]]\n",
    "    rel_pairs = []\n",
    "    \n",
    "    for i, row in benchmark.iterrows():\n",
    "        if row['relation_name'] != 'has_dress_code':\n",
    "            continue\n",
    "        if row['n_head_category'] != 'company' or row['n_tail_category'] != 'dress_code':\n",
    "            continue\n",
    "        if row['type'] != 'fact':\n",
    "            continue\n",
    "        \n",
    "        if row['n_head'] != 'company':\n",
    "            # already instance \n",
    "            rel_pairs.append({'head': str(row['n_head']).lower(),\n",
    "                              'tail': str(row['n_tail']).lower()})\n",
    "            continue\n",
    "        \n",
    "        evidence_sents = eval(str(row['sentences']))\n",
    "        head_instances = eval(str(row['Evidence']))\n",
    "        assert len(evidence_sents) == len(head_instances), f'Line {i} length mismatch'\n",
    "        \n",
    "        for inst in head_instances:\n",
    "            if len(inst) > 0:\n",
    "                rel_pairs.append({'head': inst.lower(),\n",
    "                                  'tail': str(row['n_tail']).lower()})\n",
    "        \n",
    "    return rel_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "\n",
    "benchmark_relations_list = load_benchmark_relations(benchmark_path)\n",
    "len(benchmark_relations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "\n",
    "rel_extraction = pd.read_csv(rel_extraction_path)\n",
    "rel_extraction_list = rel_extraction[['head', 'tail']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 3597, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_relations_set = set([tuple(d.values()) for d in benchmark_relations_list])\n",
    "rel_extraction_set = set([tuple(d.values()) for d in rel_extraction_list])\n",
    "\n",
    "intersection = benchmark_relations_set & rel_extraction_set\n",
    "\n",
    "len(benchmark_relations_set), len(rel_extraction_set), len(intersection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Verification baseline\n",
    "(finding co-occurrences of head / tail from corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "# # corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences.json')\n",
    "\n",
    "# indeed_dataset_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/question_answers.csv'\n",
    "# company_path = '/home/ubuntu/users/nikita/data/indeed/indeedQA/fccid-companyName.csv'\n",
    "\n",
    "# # with open(corpus_path, 'r') as f:\n",
    "# #     sent_dicts = [json.loads(l) for l in tqdm(f.readlines())]\n",
    "\n",
    "# indeed_dataset = pd.read_csv(indeed_dataset_path)\n",
    "# indeed_dataset = indeed_dataset[indeed_dataset['answerContent'].notna()]\n",
    "# company_df = pd.read_csv(company_path)\n",
    "# company_dict = dict(zip(company_df[\"fccompanyId\"].to_list(), company_df[\"companyName\"].to_list()))\n",
    "\n",
    "# indeed_dataset.shape, len(company_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extraction_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/rel_extraction.csv')\n",
    "corpus_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/sentences_with_company.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 7)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relations = pd.read_csv(rel_extraction_path)\n",
    "df_relations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0624bb851931491987a7a3d4dfc3d5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=413232.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "413232"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(corpus_path, 'r') as f:\n",
    "    sent_dicts = [json.loads(l) for l in tqdm(f.readlines())]\n",
    "\n",
    "len(sent_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['What', 'is', 'the', 'age', 'limit', '.'],\n",
       " 'company': 'Marshalls',\n",
       " 'entities': ['age limit', 'marshalls']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dicts[1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entailment model \n",
    "yutong_base_dir = \"/home/ubuntu/users/yutong\"\n",
    "roberta_ses_dir = os.path.join(yutong_base_dir, \"repos\", \"Roberta_SES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = contra, 1 = neutral, 2 = entail\n",
    "entailment_model = Roberta_SES_Entailment(roberta_path='/home/ubuntu/users/yutong/models/roberta-large',\n",
    "        ckpt_path=os.path.join(roberta_ses_dir, 'checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt'),\n",
    "        max_length=512,\n",
    "        device_name='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor([0.9972, 0.0014, 0.0014]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_model.predict(\n",
    "    \"walmart : no you can have tattoo\",\n",
    "    \"walmart allows tattoos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "# KV for (walmart, has_dress_code, uniform)\n",
    "\n",
    "_pos_templates = [\n",
    "    '{0} allows {1}',\n",
    "    '{0} requires {1}',\n",
    "]\n",
    "\n",
    "_neg_templates = [\n",
    "    '{0} doesn\\'t allow {1}',\n",
    "    '{0} doesn\\'t require {1}',\n",
    "]\n",
    "\n",
    "def find_evidences(head, tail, corpus=sent_dicts):\n",
    "    # (s1(evid), s2(tmpl), score)\n",
    "    _pos_evidences = []\n",
    "    _neg_evidences = []\n",
    "\n",
    "    for i, d in enumerate(sent_dicts):\n",
    "        if i > 0 and i % 50000 == 0:\n",
    "            print(f'Progress: {i} / {len(sent_dicts)}')\n",
    "            \n",
    "#         _company_id = row['fccompanyId']\n",
    "#         _company = company_dict[_company_id]\n",
    "\n",
    "#         _answer = row['answerContent']\n",
    "#         _tokens = [str(t) for t in spacy_tokenizer(_answer)]\n",
    "#         _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "        _company = d['company']\n",
    "        _tokens = d['tokens']\n",
    "        _s = f\"{_company.lower()} : {' '.join(_tokens).lower()}\"\n",
    "\n",
    "        if head in d['entities'] and tail in d['entities']:\n",
    "            # Try all pos/neg relation templates, save the best template  \n",
    "            _max_pos_ev = (None, None, 0)\n",
    "            for _tmpl in _pos_templates:\n",
    "                _tmpl_filled = _tmpl.format(head, tail)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_s, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_pos_ev[-1]:\n",
    "                    _max_pos_ev = (_s, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _max_neg_ev = (None, None, 0)\n",
    "            for _tmpl in _neg_templates:\n",
    "                _tmpl_filled = _tmpl.format(head, tail)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_s, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_neg_ev[-1]:\n",
    "                    _max_neg_ev = (_s, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _pos_evidences.append(_max_pos_ev)\n",
    "            _neg_evidences.append(_max_neg_ev)\n",
    "    \n",
    "    _pos_evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    _neg_evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    return _pos_evidences, _neg_evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_pos_evidences, _neg_evidences = find_evidences('walmart', 'long sleeve shirt')\n",
    "'POS:', _pos_evidences[:10], 'NEG:', _neg_evidences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def find_evidences_RE(df_relations, corpus=sent_dicts, p_thres=0.7):\n",
    "    ## TODO: to script \n",
    "    \n",
    "    \n",
    "    # Dict[Tuple(head, rel, tail): List[Tuple(s1(evid), s2(tmpl), score)]]\n",
    "    pos_evidences = defaultdict(list)\n",
    "    neg_evidences = defaultdict(list)\n",
    "    \n",
    "    # collect all relations \n",
    "    rels = []\n",
    "    head2rels = defaultdict(list)\n",
    "    tail2rels = defaultdict(list)\n",
    "    for i, row in df_relations.iterrows():\n",
    "        _h = row['head']\n",
    "        _t = row['tail']\n",
    "        _r = 'has_dress_code'\n",
    "        rels.append((_h, _r, _t))\n",
    "        if row['base'] == 'HEAD':\n",
    "            head2rels[_h].append((_h, _r, _t))\n",
    "        else:\n",
    "            tail2rels[_t].append((_h, _r, _t))\n",
    "\n",
    "    # collect sents for each entity \n",
    "    entity2sents = defaultdict(set)\n",
    "    for i, d in enumerate(sent_dicts):\n",
    "        _s = f\"{d['company']} : {' '.join(d['tokens'])}\".lower()\n",
    "        for _e in d['entities']:\n",
    "            entity2sents[_e].add(_s)\n",
    "    \n",
    "    for _h, _r, _t in tqdm(rels[200::200]):\n",
    "        # assure key existence\n",
    "        _ = pos_evidences[(_h, _r, _t)]\n",
    "        _ = neg_evidences[(_h, _r, _t)]\n",
    "        \n",
    "        h_sents = entity2sents[_h]\n",
    "        t_sents = entity2sents[_t]\n",
    "        intersect_sents = h_sents & t_sents\n",
    "        \n",
    "        for _s in intersect_sents:\n",
    "            _ss = _s.strip()\n",
    "\n",
    "            # Try all pos/neg relation templates, save the best template  \n",
    "            _max_pos_ev = (None, None, 0)\n",
    "            for _tmpl in _pos_templates:\n",
    "                _tmpl_filled = _tmpl.format(_h, _t)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_pos_ev[-1]:\n",
    "                    _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "            _max_neg_ev = (None, None, 0)\n",
    "            for _tmpl in _neg_templates:\n",
    "                _tmpl_filled = _tmpl.format(_h, _t)\n",
    "                _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "                _entail_score = _entail_probs[2].item()\n",
    "                if _entail_score > _max_neg_ev[-1]:\n",
    "                    _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "            if _max_pos_ev[-1] > p_thres:\n",
    "                pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "            if _max_neg_ev[-1] > p_thres:\n",
    "                neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "    \n",
    "    \n",
    "#     # Head-base\n",
    "#     for _h, _rels in rel_head_index.items():\n",
    "#         # First find sentences with _h\n",
    "#         _h_sents = [] \n",
    "#         for i, d in enumerate(sent_dicts):\n",
    "#             _company = d['company']\n",
    "#             _tokens = d['tokens']\n",
    "#             _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "#             if f' {_h} ' in _s:\n",
    "#                 _h_sents.append(_s)\n",
    "        \n",
    "#         # KV: check for _t only; entail\n",
    "#         for _h, _r, _t in tqdm(_rels):\n",
    "#             for _s in _h_sents:\n",
    "#                 if f' {_t} ' in _s:\n",
    "#                     _ss = _s.strip()\n",
    "                    \n",
    "#                     # Try all pos/neg relation templates, save the best template  \n",
    "#                     _max_pos_ev = (None, None, 0)\n",
    "#                     for _tmpl in _pos_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(_h, _t)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_pos_ev[-1]:\n",
    "#                             _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     _max_neg_ev = (None, None, 0)\n",
    "#                     for _tmpl in _neg_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(_h, _t)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_neg_ev[-1]:\n",
    "#                             _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     if _max_pos_ev[-1] > p_thres:\n",
    "#                         pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "#                     if _max_neg_ev[-1] > p_thres:\n",
    "#                         neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "\n",
    "#     # Tail-base\n",
    "#     for _t, _rels in tqdm(rel_tail_index.items(), total=len(rel_tail_index)):\n",
    "#         # First find sentences with _t\n",
    "#         _t_sents = [] \n",
    "#         for i, d in enumerate(sent_dicts):\n",
    "#             _company = d['company']\n",
    "#             _tokens = d['tokens']\n",
    "#             _s = f\" {_company.lower()} : {' '.join(_tokens).lower()} \"\n",
    "#             if f' {_t} ' in _s:\n",
    "#                 _t_sents.append(_s)\n",
    "        \n",
    "#         # KV: check for _h only; entail\n",
    "#         for _h, _r, _t in tqdm(_rels):\n",
    "#             if (_h, _r, _t) in pos_evidences or (_h, _r, _t) in neg_evidences:\n",
    "#                 # already computed \n",
    "#                 continue\n",
    "#             for _s in _t_sents:\n",
    "#                 if f' {_h} ' in _s:\n",
    "#                     _ss = _s.strip()\n",
    "                    \n",
    "#                     # Try all pos/neg relation templates, save the best template  \n",
    "#                     _max_pos_ev = (None, None, 0)\n",
    "#                     for _tmpl in _pos_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(head, tail)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_pos_ev[-1]:\n",
    "#                             _max_pos_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     _max_neg_ev = (None, None, 0)\n",
    "#                     for _tmpl in _neg_templates:\n",
    "#                         _tmpl_filled = _tmpl.format(head, tail)\n",
    "#                         _entail_pred, _entail_probs = entailment_model.predict(_ss, _tmpl_filled)\n",
    "#                         _entail_score = _entail_probs[2].item()\n",
    "#                         if _entail_score > _max_neg_ev[-1]:\n",
    "#                             _max_neg_ev = (_ss, _tmpl_filled, _entail_score)\n",
    "\n",
    "#                     if _max_pos_ev[-1] > p_thres:\n",
    "#                         pos_evidences[(_h, _r, _t)].append(_max_pos_ev)\n",
    "#                     if _max_neg_ev[-1] > p_thres:\n",
    "#                         neg_evidences[(_h, _r, _t)].append(_max_neg_ev)\n",
    "\n",
    "    for _rel, _evidences in pos_evidences.items():\n",
    "        _evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    for _rel, _evidences in neg_evidences.items():\n",
    "        _evidences.sort(key=lambda p : p[-1], reverse=True)\n",
    "    \n",
    "    return pos_evidences, neg_evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = find_evidences_RE(df_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Finding evidence for rels: 100%|██████████| 3600/3600 [4:46:02<00:00,  4.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use script \n",
    "!python knowledge_verification_entail.py \\\n",
    "-d $base_dir/data/$data_ac/intermediate \\\n",
    "-b $base_dir/data/indeed-benchmark \\\n",
    "-o $base_dir/data/$data_ac/intermediate/kv_evidences.json \\\n",
    "-r $yutong_base_dir/models/roberta-large \\\n",
    "-rs $yutong_base_dir/repos/Roberta_SES/checkpoints/epoch=2-valid_loss=-0.2620-valid_acc_end=0.9223.ckpt \\\n",
    "-p 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate \n",
    "benchmark_path = os.path.join(base_dir, f'data/indeed-benchmark/benchmark_evidence_clean.csv')\n",
    "\n",
    "benchmark_relations_list = load_benchmark_relations(benchmark_path)\n",
    "len(benchmark_relations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_evidences_path = os.path.join(base_dir, f'data/{data_ac}/intermediate/kv_evidences.json')\n",
    "\n",
    "with open(kv_evidences_path, 'r') as f:\n",
    "    kv_evidences = [json.loads(l) for l in f.readlines()]\n",
    "len(kv_evidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_thres = 0.9\n",
    "\n",
    "kv_filtered_rels = []\n",
    "for d in kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences']\n",
    "    _neg_evs = d['neg_evidences']\n",
    "    if (len(_pos_evs) > 0 and _pos_evs[0][-1] > p_thres):\n",
    "        kv_filtered_rels.append((_h, _t))\n",
    "    elif (len(_neg_evs) > 0 and _neg_evs[0][-1] > p_thres):\n",
    "        kv_filtered_rels.append((_h, _t))\n",
    "\n",
    "len(kv_filtered_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 665, 6)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_relations_set = set([tuple(d.values()) for d in benchmark_relations_list])\n",
    "kv_filtered_rels_set = set(kv_filtered_rels)\n",
    "\n",
    "intersection = benchmark_relations_set & kv_filtered_rels_set\n",
    "\n",
    "len(benchmark_relations_set), len(kv_filtered_rels_set), len(intersection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('best buy', 'uniform'),\n",
       " ('costco', 'hair color'),\n",
       " ('dd', 'facial hair'),\n",
       " ('dollar tree', 'uniform'),\n",
       " ('family dollar', 'facial hair'),\n",
       " ('walmart', 'uniform')}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walmart uniform\n",
      "['walmart : no a uniform shirt is required', \"walmart doesn't require uniform\", 0.9957914352416992]\n",
      "\n",
      "best buy uniform\n",
      "['best buy : the required uniform', 'best buy requires uniform', 0.989712119102478]\n",
      "\n",
      "dollar tree uniform\n",
      "['dollar tree : yes we have to where uniform that we supply ourselves .', 'dollar tree requires uniform', 0.9870349764823914]\n",
      "\n",
      "costco hair color\n",
      "[\"costco wholesale : costco does n't discriminate with any hair color\", 'costco allows hair color', 0.9456473588943481]\n",
      "\n",
      "dd facial hair\n",
      "[\"dunkin' donuts : yes , dd does allow facial hair .\", 'dd allows facial hair', 0.9918413162231445]\n",
      "\n",
      "family dollar facial hair\n",
      "['family dollar : yes , they allow facial hair .', 'family dollar allows facial hair', 0.9905114769935608]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences']\n",
    "    _neg_evs = d['neg_evidences']\n",
    "    \n",
    "    if (_h, _t) in intersection:\n",
    "        print(_h, _t)\n",
    "        _max = sorted(_pos_evs + _neg_evs, key=lambda p : p[-1], reverse=True)[0]\n",
    "        print(_max)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kv_evidences = list(kv_evidences)\n",
    "\n",
    "for d in test_kv_evidences:\n",
    "    _h, _r, _t = d['relation']\n",
    "    _pos_evs = d['pos_evidences'][:5]\n",
    "    _neg_evs = d['neg_evidences'][:5]\n",
    "    \n",
    "    _max = sorted(_pos_evs + _neg_evs, key=lambda p : p[-1], reverse=True)[0]\n",
    "    d['pos_evidences'] = _pos_evs\n",
    "    d['neg_evidences'] = _neg_evs\n",
    "    d['max_ev'] = _max\n",
    "\n",
    "sorted(test_kv_evidences, key=lambda d : d['max_ev'][-1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussions:\n",
    "# coherence clustering / ensemble models?\n",
    "# trying for other relations or entities\n",
    "# using entities in sub-categories\n",
    "# fine-tuning\n",
    "# ambiguous samples (high for pos and neg)\n",
    "# quantitative-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore various techniques\n",
    "# Get prompts \"between\" entities\n",
    "# Get prompts by syntactic parsing\n",
    "# Get prompts by paraphrasing\n",
    "# Get prompts uisng AutoPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit here: /meg-kb/src/analysis/pattern_mining.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Prompt Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit here: /meg-kb/src/analysis/lm_probing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggest Quality Prompts"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_transformers_nikita)",
   "language": "python",
   "name": "conda_transformers_nikita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
