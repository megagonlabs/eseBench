{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import torch\n",
    "import math\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LM probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMProbe(object):\n",
    "    def __init__(self, model_name='bert-base-uncased', use_gpu=False):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertForMaskedLM.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.mask_token = self.tokenizer.mask_token\n",
    "\n",
    "    def fill_multi_mask(self, input_txt, topk=3):\n",
    "        if not input_txt.startswith('[CLS]') and not input_txt.endswith('[SEP]'):\n",
    "            raise Exception('Input string must start with [CLS] and end with [SEP]')\n",
    "        if not '[MASK]' in input_txt:\n",
    "            raise Exception('Input string must have at least one mask token')\n",
    "        tokenized_txt = self.tokenizer.tokenize(input_txt)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_txt)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        mask_indices = [i for i, x in enumerate(tokenized_txt) if x == \"[MASK]\"]\n",
    "        segment_idx = tokens_tensor * 0\n",
    "        tokens_tensor = tokens_tensor.to(self.device)\n",
    "        segments_tensors = segment_idx.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        probs = torch.softmax(predictions, dim=-1)[0]\n",
    "        sorted_probs, sorted_idx = probs.sort(dim=-1, descending=True)\n",
    "        sorted_probs = sorted_probs.detach().cpu().numpy()\n",
    "        sorted_idx = sorted_idx.detach().cpu().numpy()\n",
    "\n",
    "        masked_cands = []\n",
    "        for k in range(topk):\n",
    "            predicted_indices = [sorted_idx[i, k].item() for i in mask_indices]\n",
    "            predicted_tokens = self.tokenizer.convert_ids_to_tokens(predicted_indices)\n",
    "            predicted_probs = [sorted_probs[i, k].item() for i in mask_indices]\n",
    "            seq = []\n",
    "            for token_id, token, prob, masked_index in zip(predicted_indices, predicted_tokens, predicted_probs,\n",
    "                                                           mask_indices):\n",
    "                seq.append({\"token\": token_id, \"token_str\": token, \"prob\": prob, \"masked_pos\": masked_index})\n",
    "            masked_cands.append(seq)\n",
    "\n",
    "        return masked_cands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class name from pair of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name_hearst(entities, lm_probe=None, context=None):\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    mask_token = lm_probe.mask_token\n",
    "    generation_templates = [\n",
    "        mask_token + ' such as {} , and {} .',\n",
    "        'such ' + mask_token + ' as {} , and {} .',\n",
    "        '{} , {} or other ' + mask_token + ' .',\n",
    "        '{} , {} and other ' + mask_token + ' .',\n",
    "        mask_token + ' including {} , and {} .',\n",
    "        mask_token + ' , especially {}, and {} .',\n",
    "        mask_token + ' ' + mask_token + ' such as {} , and {} .',\n",
    "        'such ' + mask_token + ' ' + mask_token  + ' as {} , and {} .',\n",
    "        '{} , {} or other ' + mask_token + ' ' + mask_token  + ' .',\n",
    "        '{} , {} and other ' + mask_token + ' ' + mask_token  + ' .',\n",
    "        mask_token + ' ' + mask_token  + ' including {} , and {} .',\n",
    "        mask_token + ' ' + mask_token  + ' , especially {}, and {} .',\n",
    "    ]\n",
    "\n",
    "    if len(entities) < 2:\n",
    "        raise Exception(\"not enough entity instances\")\n",
    "\n",
    "    names_scores = {}\n",
    "    for template in generation_templates:\n",
    "        e1 = entities[0]\n",
    "        e2 = entities[1]\n",
    "        if context:\n",
    "            query = '[CLS] ' + template.format(e1, e2) + '[SEP]' + context + '[SEP]'\n",
    "        else:\n",
    "            query = '[CLS] ' + template.format(e1, e2) + '[SEP]'\n",
    "        preds = lm_probe.fill_multi_mask(query)\n",
    "        for pred in preds:\n",
    "            name = ' '.join([p['token_str'] for p in pred])\n",
    "            score = numpy.prod([p['prob'] for p in pred])\n",
    "            scores = names_scores.get(name, [])\n",
    "            scores.append(score)\n",
    "            names_scores[name] = scores\n",
    "    names_avg_scores = {k: float(sum(v))/ len(v) for k,v in names_scores.items()}\n",
    "    names_avg_scores = {k: v for k, v in sorted(names_avg_scores.items(), reverse=True, key=lambda item: item[1])}\n",
    "    return names_avg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of name given an entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_name(entity, lm_probe=None, context=None, topk=10):\n",
    "    if lm_probe is None:\n",
    "        lm_probe = LMProbe()\n",
    "    mask_token = lm_probe.mask_token\n",
    "    generation_templates = [\n",
    "        mask_token + 'is part of {} .',\n",
    "        mask_token + ' ' +  mask_token + 'is part of {} .',\n",
    "        '{} has ' + mask_token + ' .',\n",
    "        '{} has ' + mask_token + ' ' + mask_token + ' .'\n",
    "    ]\n",
    "    names_scores = {}\n",
    "    for template in generation_templates:\n",
    "        if context:\n",
    "            query = '[CLS] ' + template.format(entity) + '[SEP]' + context + '[SEP]'\n",
    "        else:\n",
    "            query = '[CLS] ' + template.format(entity) + '[SEP]'\n",
    "        preds = lm_probe.fill_multi_mask(query, topk=topk)\n",
    "        for pred in preds:\n",
    "            name = ' '.join([p['token_str'] for p in pred])\n",
    "            score = numpy.prod([p['prob'] for p in pred])\n",
    "            scores = names_scores.get(name, [])\n",
    "            scores.append(score)\n",
    "            names_scores[name] = scores\n",
    "    names_avg_scores = {k: float(sum(v)) / len(v) for k, v in names_scores.items()}\n",
    "    names_avg_scores = {k: v for k, v in sorted(names_avg_scores.items(), reverse=True, key=lambda item: item[1])}\n",
    "    return names_avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/ubuntu/users/nikita/models/bert_finetuned_lm/indeed_reviews_ques_ans were not used when initializing BertForMaskedLM: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lm_probe = LMProbe('/home/ubuntu/users/nikita/models/bert_finetuned_lm/indeed_reviews_ques_ans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'token': 3105,\n",
       "   'token_str': 'job',\n",
       "   'prob': 0.2626919448375702,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 2832,\n",
       "   'token_str': 'process',\n",
       "   'prob': 0.13146057724952698,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 2731,\n",
       "   'token_str': 'training',\n",
       "   'prob': 0.10522313416004181,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 3343,\n",
       "   'token_str': 'policy',\n",
       "   'prob': 0.04612913727760315,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 2009,\n",
       "   'token_str': 'it',\n",
       "   'prob': 0.024157783016562462,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 7709,\n",
       "   'token_str': 'procedure',\n",
       "   'prob': 0.01594134047627449,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 2147,\n",
       "   'token_str': 'work',\n",
       "   'prob': 0.015837358310818672,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 2673,\n",
       "   'token_str': 'everything',\n",
       "   'prob': 0.01579480804502964,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 5918,\n",
       "   'token_str': 'requirements',\n",
       "   'prob': 0.015557022765278816,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 9095,\n",
       "   'token_str': 'requirement',\n",
       "   'prob': 0.015215539373457432,\n",
       "   'masked_pos': 6}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe.fill_multi_mask('[CLS] drug test is part of [MASK] . [SEP]', topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'token': 2832,\n",
       "   'token_str': 'process',\n",
       "   'prob': 0.202988401055336,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 3105,\n",
       "   'token_str': 'job',\n",
       "   'prob': 0.16196191310882568,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 2731,\n",
       "   'token_str': 'training',\n",
       "   'prob': 0.10627923160791397,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 14763,\n",
       "   'token_str': 'hiring',\n",
       "   'prob': 0.044770751148462296,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 2009,\n",
       "   'token_str': 'it',\n",
       "   'prob': 0.02841365523636341,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 6107,\n",
       "   'token_str': 'employment',\n",
       "   'prob': 0.026154039427638054,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 10296,\n",
       "   'token_str': 'orientation',\n",
       "   'prob': 0.020505793392658234,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 3343,\n",
       "   'token_str': 'policy',\n",
       "   'prob': 0.019412264227867126,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 11326,\n",
       "   'token_str': 'screening',\n",
       "   'prob': 0.014734169468283653,\n",
       "   'masked_pos': 6}],\n",
       " [{'token': 5918,\n",
       "   'token_str': 'requirements',\n",
       "   'prob': 0.014058711007237434,\n",
       "   'masked_pos': 6}]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe.fill_multi_mask('[CLS] drug test is part of [MASK] . [SEP] drug test email background hire [SEP]', topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'token': 12379,\n",
       "   'token_str': 'flexible',\n",
       "   'prob': 0.11059394478797913,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 2204,\n",
       "   'token_str': 'good',\n",
       "   'prob': 0.09503347426652908,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 2307,\n",
       "   'token_str': 'great',\n",
       "   'prob': 0.06696714460849762,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 1012,\n",
       "   'token_str': '.',\n",
       "   'prob': 0.06632491946220398,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 7929,\n",
       "   'token_str': 'ok',\n",
       "   'prob': 0.051000095903873444,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 4882,\n",
       "   'token_str': 'weekly',\n",
       "   'prob': 0.04453660175204277,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 4189,\n",
       "   'token_str': 'fair',\n",
       "   'prob': 0.029096927493810654,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 2275,\n",
       "   'token_str': 'set',\n",
       "   'prob': 0.025036100298166275,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 11519,\n",
       "   'token_str': 'decent',\n",
       "   'prob': 0.020469404757022858,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 3100,\n",
       "   'token_str': 'okay',\n",
       "   'prob': 0.017768269404768944,\n",
       "   'masked_pos': 4}]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe.fill_multi_mask('[CLS] pay schedule is [MASK] . [SEP]', topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'token': 4882,\n",
       "   'token_str': 'weekly',\n",
       "   'prob': 0.177995964884758,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 9857,\n",
       "   'token_str': 'tuesday',\n",
       "   'prob': 0.14633633196353912,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 9432,\n",
       "   'token_str': 'thursday',\n",
       "   'prob': 0.12900091707706451,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 6928,\n",
       "   'token_str': 'monday',\n",
       "   'prob': 0.08406960219144821,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 5958,\n",
       "   'token_str': 'friday',\n",
       "   'prob': 0.07963141053915024,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 9317,\n",
       "   'token_str': 'wednesday',\n",
       "   'prob': 0.054221030324697495,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 7058,\n",
       "   'token_str': 'monthly',\n",
       "   'prob': 0.045881446450948715,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 4465,\n",
       "   'token_str': 'sunday',\n",
       "   'prob': 0.010150549933314323,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 1012,\n",
       "   'token_str': '.',\n",
       "   'prob': 0.006899422034621239,\n",
       "   'masked_pos': 4}],\n",
       " [{'token': 2800,\n",
       "   'token_str': 'available',\n",
       "   'prob': 0.006658394355326891,\n",
       "   'masked_pos': 4}]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe.fill_multi_mask('[CLS] pay schedule is [MASK] . [SEP] pay schedule friday monthly paid  [SEP]', topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shifts': 0.40606245398521423,\n",
       " ',': 0.26602329313755035,\n",
       " 'shift': 0.2167864441871643,\n",
       " 'as such': 0.17379335917342864,\n",
       " 'departments': 0.12587101757526398,\n",
       " '.': 0.10468659549951553,\n",
       " 'such': 0.08616548031568527,\n",
       " 'shift .': 0.08373006346583474,\n",
       " 'shift ,': 0.06922138099221087,\n",
       " 'thing': 0.06822600960731506,\n",
       " 'different shifts': 0.05819503914694368,\n",
       " 'days': 0.030948365107178688,\n",
       " 'duties': 0.030666278675198555,\n",
       " 'people': 0.019882088527083397,\n",
       " 'all shift': 0.018312630556953785,\n",
       " 'shifts shifts': 0.015264405753421417,\n",
       " 'the shifts': 0.012394977859977452,\n",
       " 'shifts .': 0.0087607046969298,\n",
       " 'other shift': 0.005827367802047068,\n",
       " 'night shift': 0.005223425829630202,\n",
       " 'a ,': 0.00369603466209302,\n",
       " 'shifts far': 0.002672503210559174,\n",
       " 'departments shift': 0.0013202989668067572}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_name_hearst(['morning shift', 'night shift'], lm_probe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'token': 10103,\n",
       "   'token_str': 'nightmare',\n",
       "   'prob': 0.22245627641677856,\n",
       "   'masked_pos': 5}],\n",
       " [{'token': 9478,\n",
       "   'token_str': 'breeze',\n",
       "   'prob': 0.08262979239225388,\n",
       "   'masked_pos': 5}],\n",
       " [{'token': 6752,\n",
       "   'token_str': 'mess',\n",
       "   'prob': 0.049640536308288574,\n",
       "   'masked_pos': 5}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probe.fill_multi_mask('[CLS] morning shift is a [MASK] . [SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as such': 0.43733613785742875,\n",
       " ',': 0.42075057327747345,\n",
       " 'things': 0.2776534240692854,\n",
       " 'thing': 0.17522531747817993,\n",
       " 'such': 0.17029350996017456,\n",
       " '.': 0.14481838420033455,\n",
       " 'piercing .': 0.14278165690318012,\n",
       " 'colors': 0.11828122287988663,\n",
       " 'all ,': 0.08104194746758253,\n",
       " '##s': 0.07992054584125678,\n",
       " 'tattoos': 0.057640042155981064,\n",
       " 'certain ,': 0.041750938464703014,\n",
       " 'hair': 0.0404670424759388,\n",
       " 'hair .': 0.016858414259972143,\n",
       " ', far': 0.013993208231601051,\n",
       " 'offensive ##s': 0.012718825611116868,\n",
       " 'of .': 0.012042091326530668,\n",
       " 'all ##s': 0.00942369014160055,\n",
       " 'of hair': 0.008287945854710155,\n",
       " 'have ##s': 0.004615252299980166,\n",
       " 'your tattoos': 0.0025069542206117568,\n",
       " 'of ##s': 0.0016842648931715831,\n",
       " 'colored ##ities': 0.001684199194723776,\n",
       " 'things well': 0.0006482934268544037}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_name_hearst(['tattoos', 'piercings'], lm_probe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tests': 0.2956191450357437,\n",
       " 'test': 0.2912965764602025,\n",
       " ',': 0.22519341111183167,\n",
       " 'testing': 0.22195589169859886,\n",
       " 'as such': 0.18646264151812808,\n",
       " 'testing .': 0.1794008589777789,\n",
       " '.': 0.14398349821567535,\n",
       " 'drug test': 0.11761508577432522,\n",
       " 'things': 0.07416696846485138,\n",
       " 'drug ,': 0.06666907243964815,\n",
       " 'random test': 0.026148756885049806,\n",
       " 'test test': 0.019849586816945153,\n",
       " 'drug tests': 0.011564690442011555,\n",
       " 'of tests': 0.011472677921928742,\n",
       " 'test testing': 0.010680313054750099,\n",
       " 'test ,': 0.008002044270066788,\n",
       " 'tests test': 0.005254073502398537,\n",
       " 'drug testing': 0.00470752540166286,\n",
       " 'all .': 0.004546203769800888}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_name_hearst(['urine test', 'swab test'], lm_probe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0.4591578394174576,\n",
       " 'as far': 0.3131515095225179,\n",
       " 'thing': 0.2881258353590965,\n",
       " 'benefits': 0.2380053705225388,\n",
       " 'things': 0.2274885829538107,\n",
       " 'policies': 0.09467612951993942,\n",
       " '.': 0.0833433698862791,\n",
       " 'policy': 0.07025929540395737,\n",
       " 'all ,': 0.060510486888192716,\n",
       " 'rules': 0.05586520582437515,\n",
       " 'such': 0.05194425210356712,\n",
       " 'benefits benefits': 0.038104624996751824,\n",
       " 'stuff': 0.025048289448022842,\n",
       " 'the ,': 0.02315254734827299,\n",
       " 'things such': 0.013054041127456006,\n",
       " 'of .': 0.009818693481176366,\n",
       " 'per things': 0.009229950335676862,\n",
       " 'personal ##s': 0.009148165204145298,\n",
       " 'company ##s': 0.005164277678788576,\n",
       " 'important benefits': 0.005003145212758686,\n",
       " '. things': 0.004069842443769456,\n",
       " 'the policies': 0.003685950651606547,\n",
       " 'benefits .': 0.0036825491692631385,\n",
       " 'work policy': 0.0028935247978831014,\n",
       " 'per .': 0.0027636477912691693,\n",
       " 'of rules': 0.002558088221109589,\n",
       " 'thing well': 0.0014380955690048713}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_name_hearst(['dress code', 'vacation policy'], lm_probe, context='You get 20 vacation days and unlimited sick leaves .') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_transformers)",
   "language": "python",
   "name": "conda_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
